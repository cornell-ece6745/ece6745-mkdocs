{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ECE 6745 Complex Digital ASIC Design","text":"<p>Public Course Website: http://www.csl.cornell.edu/courses/ece6745</p> <p>This is the ECE 6745 Complex Digital ASIC Design documentation site. It includes topic notes, discussion section handouts, tutorials, and lab assignment handouts. If you find any bugs or errors with this documentation, please post on Ed or feel free to create a pull request in the corresponding documentation repo.</p>"},{"location":"ece6745-lab1/","title":"ECE 6745 Lab 1: Full-Custom Inverter","text":"<p>In this lab, we will first make sure we can access the Linux development environment on the <code>ecelinux</code> servers. We will be using the <code>ecelinux</code> servers for all of the labs and projects. The <code>ecelinux</code> servers all run the Red Hat Enterprise Linux 8 operating system, and they all use an identical setup. We will then design the basic CMOS inverter we saw in lecture using the following TinyFlow full-custom design flow.</p> <p></p> <p>We will write a transistor-level schematic, simulate the this schematic using Ngspice to verify its functionality, use the KLayout design editor to create the layout, perform a design-rules check (DRC), perform a layout vs. schematic check (LVS), and generate an extracted transistor-level schematic. Finally, we will re-simulate the extracted transistor-level schematic to characterize the timing. We will also be implementing a CMOS buffer to verify our intuition that NMOS transistors should only be used in the pull-down network and PMOS transistors should only be used in the pull-up network.</p> <p>To get started, find a free workstation and log into the workstation using your NetID and standard NetID password.</p>"},{"location":"ece6745-lab1/#1-linux-development-environment","title":"1. Linux Development Environment","text":"<p>It is important to keep in mind that we will use ecelinux as shorthand for the entire cluster of 20 servers. These servers are named as follows:</p> <ul> <li>ecelinux-01.ece.cornell.edu</li> <li>ecelinux-02.ece.cornell.edu</li> <li>ecelinux-03.ece.cornell.edu</li> <li>...</li> <li>ecelinux-18.ece.cornell.edu</li> <li>ecelinux-19.ece.cornell.edu</li> <li>ecelinux-20.ece.cornell.edu</li> </ul> <p>We need to try and balance the load across all the servers. So we have distributed handout which has specifies which server each student should use for today's lab. We will start by making sure we can access the <code>ecelinux</code> servers using PowerShell, then we will use VS Code, and finally we will setup MS Remote Desktop for running GUI Applications on <code>ecelinux</code>. We will also make sure our GitHub account is setup correctly.</p>"},{"location":"ece6745-lab1/#11-remote-access-via-powershell","title":"1.1. Remote Access via PowerShell","text":"<p>To start PowerShell click the Start menu then search for Windows PowerShell. After starting PowerShell, type in the following command at the prompt to log into an <code>ecelinux</code> server using SSH.</p> <pre><code>% ssh netid@ecelinux-XX.ece.cornell.edu\n</code></pre> <p>Replace netid with your Cornell NetID in the command above and replace XX with the assign ecelinux server. You should not enter the % character. We use the <code>%</code> character to indicate what commands we should enter on the command line. Executing the command will prompt you to enter your Cornell NetID password, and then you should be connected to your selected ecelinux server.</p> <p>The very first time you log into an <code>ecelinux</code> server you may see a warning like this:</p> <pre><code> The authenticity of host \u2019ecelinux-XX.ece.cornell.edu (128.253.51.206)\u2019\n can\u2019t be established. ECDSA key fingerprint is\n SHA256:smwMnf9dyhs5zW5I279C5oJBrTFc5FLghIJMfBR1cxI.\n Are you sure you want to continue connecting (yes/no)?\n</code></pre> <p>The very first time you log into an <code>ecelinux</code> server it is okay to enter yes, but from then on if you continue to receive this warning please contact the course staff.</p> <p>The very first thing you need to do after opening a terminal is source the course setup script. This will ensure your environment is setup with everything you need for working on the lab assignments. Enter the following command on the command line:</p> <pre><code>% source setup-ece6745.sh\n</code></pre> <p>Note that you do not need to enter <code>%</code> character. In a tutorial like this, the <code>%</code> simply indicates what you should type at the command line. You should now see a blue <code>ECE 6745</code> in your prompt which means your environment is setup for the course. If for any reason you do not see a blue <code>ECE 6745</code> in your prompt, stop and raise your hand for help from an instructor!</p> <p>It can be tedious to always remember to source the course setup script. You can also use auto setup which will automatically source the course setup for you when you log in. Note that if the environment for ECE 6745 conflicts with the environment required by a different course then you will need to manually source the setup script when you are working on this course. Enter the following command on the command line to use auto setup:</p> <pre><code>% source setup-ece6745.sh --enable-auto-setup\n</code></pre> <p>If at anytime you need to disable auto setup you can use the following command:</p> <pre><code>% source setup-ece6745.sh --disable-auto-setup\n</code></pre>"},{"location":"ece6745-lab1/#12-remote-access-via-vs-code","title":"1.2. Remote Access via VS Code","text":"<p>PowerShell is primarily just used as a backup if we have trouble accessing <code>ecelinux</code> using VS Code. Students primarily should use VS Code to log into the <code>ecelinux</code> servers.</p> <p>To start VS Code click the Start menu then search for Visual Studio Code. The key to VS Code is installing the correct extensions. We want to start by installing a special extension which will enable remotely accessing the <code>ecelinux</code> servers using SSH. Choose View &gt; Extensions from the menubar. Enter the name of the extension in the \"Search Extensions in Marketplace\" and then click the blue Install button. Here is the name of the extension to install:</p> <ul> <li>Remote - SSH (use the one from Microsoft)</li> </ul> <p></p> <p>Now we need to log into your assign <code>ecelinux</code> server. Choose View &gt; Command Palette from the menubar. This will cause a little \"command palette\" to drop down where you can enter commands to control VS Code. Enter the following command in the command palette:</p> <pre><code>Remote-SSH: Connect Current Window to Host...\n</code></pre> <p>As you start typing matching commands will be displayed and you can just click the command when you see it. VS Code will then ask you to Enter SSH Connection Command, and you should enter the following:</p> <pre><code>netid@ecelinux-XX.ece.cornell.edu\n</code></pre> <p>Replace <code>netid</code> with your Cornell NetID and XX with the number of your assign ecelinux server in the command above.</p> <p>You may see a pop-up which stays that the Windows Defender Firewall as blocked some features of this app. This is not a problem. Simply click Cancel. You might also see a drop down which asks you to choose the operating system of the remote server with options like Linux and Windows. Choose Linux. Finally, the very first time you log into an <code>ecelinux</code> server you may see a warning like this:</p> <pre><code>\"ecelinux-XX.ece.cornell.edu\" has fingerprint\n\"SHA256:YCh2FiadeTXEzuSkC0AOdglBgPciwc8WvcCPncvr2Fs\"\nAre you sure you want to continue?\nContinue\nCancel\n</code></pre> <p>Also the very first time you log into an <code>ecelinux</code> server you will see a pop up dialog box in the lower right-hand corner which says Setting up SSH host ecelinux-XX.ece.cornell.edu (details) Initializing.... It might take up to a minute for everything to be setup; please be patient! Once the pop up dialog box goes away and you see SSH: ecelinux-XX.ece.cornell.edu in the lower left-hand corner of VS Code then you know you are connected to your selected <code>ecelinux</code> server.</p> <p>VS Code includes an integrated file explorer which makes it very productive to browse and open files. Choose View &gt; Explorer from the menubar, and then click on Open Folder. VS Code will then ask you to Open File Or Folder with a default of <code>/home/netid</code>. Click OK.</p> <p>You might see a pop-up which asks you Do you trust the authors of the files in this folder? Since you will only be browsing your own files on the ecelinux servers, it is fine to choose Yes, I trust the authors.</p> <p>This will reload VS Code, and you should now you will see a file explore in the left sidebar. You can easily browse your directory hierarchy, open files by clicking on them, create new files, and delete files.</p> <p>VS Code includes an integrated terminal which will give you access to the Linux command line on the <code>ecelinux</code> servers. Choose Terminal &gt; New Terminal from the menubar. You should see the same kind of Linux command line prompt that you saw when using PowerShell.</p> <p>Remember, the very first thing you need to do after logging into the ecelinux servers is source the course setup script. If you used <code>--enable-auto-setup</code> in the last section, then the setup script is already sourced for you automatically when you log into the ecelinux servers. If not, you will need to enter the following command on the command line:</p> <pre><code>% source setup-ece6745.sh\n</code></pre> <p>You should now see a blue <code>ECE 6745</code> in your prompt which means your environment is setup for the course. If for any reason you do not see a blue <code>ECE 6745</code> in your prompt, stop and raise your hand for help from an instructor!</p> <p>We highly recommend turning on auto save so you don't forget to save your work. You can do this by choosing File &gt; Auto Save from the menubar.</p>"},{"location":"ece6745-lab1/#13-remote-access-via-ms-remote-desktop","title":"1.3. Remote Access via MS Remote Desktop","text":"<p>We cannot use VS Code to run Linux GUI applications on <code>ecelinux</code>. We will instead need to use MS Remote Desktop. Use the Start Menu to search for Microsoft Remote Desktop. For the Computer you must choose the same <code>ecelinux</code> server you selected earlier in this lab. Then click on Connect. You may see a message like this:</p> <pre><code>The remote computer could not be authenticated due to problems with its\nsecurity certificate. It may be unsafe to proceed.\n</code></pre> <p>If you see this message then take the following steps:</p> <ul> <li>Click Don't ask me again for connections to this computer</li> <li>Click Yes</li> </ul> <p>This should launch a \"virtual desktop\" on <code>ecelinux</code>. You will need to enter your NetID and password in the xrdp login.</p> <p>Now go back to your terminal in VS Code and use the following setup script.</p> <pre><code>% source setup-gui.sh\n% xclock &amp;\n</code></pre> <p>If everything works you should see an analog clock on the virtual desktop. Close the clock.</p> <p></p>"},{"location":"ece6745-lab1/#14-github-account-setup","title":"1.4. GitHub Account Setup","text":"<p>We will be using GitHub for centralized repository hosting. You can check to see if you have a GitHub account using this link: https://github.com/githubid where <code>githubid</code> is your GitHub username on GitHub. If the above link does not work, then you do not have an GitHub account. NOTE: We are using the commercial version of GitHub not the Cornell hosted GitHub! You will need to create one here:</p> <ul> <li>https://github.com/join</li> </ul> <p>Your NetID makes a great GitHub username. If you are creating a new GitHub account, then be sure to use your Cornell email address. If you have an existing account it is fine for it to use a non-Cornell email address.</p> <p>Once your account is setup, please make sure you set your full name so we can know who you are on GitHub. Go to the following page and enter your first and last name in the Name field.</p> <ul> <li>https://github.com/settings/profile</li> </ul> <p>Before you can begin using GitHub, you need to create an SSH key pair on an ecelinux server and upload the corresponding SSH public key to GitHub. GitHub uses these keys for authentication. The course setup script takes care of creating an SSH key pair which you can use. View the contents of your public key using the following command:</p> <pre><code>% cat ~/.ssh/ece6745-github.pub\n</code></pre> <p>Use the following page to upload the public key to GitHub:</p> <ul> <li>https://github.com/settings/ssh</li> </ul> <p>Click on New SSH Key, and then cut-and-paste the public key you displayed using cat into the key textbox. Give the key the title <code>ece6745-github</code>. Then click Add SSH key. To test things out try the following command on <code>ecelinux</code>.</p> <pre><code>% ssh -T git@github.com\n</code></pre> <p>You may see a warning about the authenticity of the host. Don\u2019t worry, this is supposed to happen the first time you access GitHub using your new key. Just enter <code>yes</code>. The GitHub server should output some text including your GitHub username. Verify that the GitHub username is correct, and then you should be all set.</p>"},{"location":"ece6745-lab1/#15-clone-lab-repo","title":"1.5. Clone Lab Repo","text":"<p>Now use the following commands to clone the repo we will be using for today's lab.</p> <pre><code>% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-lab1 lab1\n% cd lab1\n% tree\n</code></pre> <p>Your repo contains the following files for modeling and simulating both the inverter and buffer.</p> <pre><code>.\n\u251c\u2500\u2500 buf\n\u2502   \u251c\u2500\u2500 buf-rcx-sim.sp\n\u2502   \u251c\u2500\u2500 buf-sim.sp\n\u2502   \u251c\u2500\u2500 buf.gds\n\u2502   \u2514\u2500\u2500 buf.sp\n\u2514\u2500\u2500 inv\n    \u251c\u2500\u2500 inv-rcx-sim.sp\n    \u251c\u2500\u2500 inv-sim.sp\n    \u251c\u2500\u2500 inv.gds\n    \u2514\u2500\u2500 inv.sp\n</code></pre>"},{"location":"ece6745-lab1/#2-klayout-tutorial","title":"2. KLayout Tutorial","text":"<p>KLayout is a powerful, open-source layout tool that allows users to both view and edit layout files in GDS format. Additionally, it can perform design-rule checking, layout vs. schematic checking, and RC extraction among other features. In this lab, we will be using all of these features so that you can become familiar with making your own custom layout! We will start by designing a single NMOS transistor before working on the complete inverter in the next section.</p> <p>To open on the ECELinux server, first open KLayout in edit mode (<code>-e</code>).</p> <pre><code>% cd ${HOME}/ece6745/lab1\n% klayout -e &amp;\n</code></pre> <p>Do not worry about libGL errors when starting KLayout. There will be a pop-up the first time you open KLayout asking about whether to use full-hierarchy mode. Select Don't show this window again and then click Yes.</p> <p>Choose File &gt; New Layout from the menubar and click OK. The KLayout window should look as follows.</p> <p></p> <p>Take a minute to become familiar with the user interface (some items are omitted as they are not used for our class):</p> <ul> <li> <p>Toolbar: Includes back/forward (undo/redo) buttons, as well as    buttons for selecting a feature, moving a feature, drawing a feature,    measuring a feature (ruler), etc.</p> </li> <li> <p>Technology: Notice the technology is automatically selected to    tinyflow-180nm.</p> </li> <li> <p>Cells Panel: Displays names of all the cells in the current layout    file. In this case, we only have one cell in our layout file named    TOP, but we will have more cells in future labs/projects which    constitute an entire library of cells! You can right click on a cell    and choose Show As New Top to select which cell to view in the main    window.</p> </li> <li> <p>Layers Panel: Displays all available layers which elements can be    placed on, take a minute to correlate these names with what you have    seen in lecture. You can right click on a layer to set visibility    options for it and other layers.</p> </li> <li> <p>Main Drawing Area: The grid is also automatically set to 1x1    lambda. Recall that lambda is 90nm for the TinyFlow 180nm PDK. One    lambda is the minimum unit on which you can draw a feature.</p> </li> </ul> <p>Try zooming out by using the mouse scroll wheel. Eventually, the lines should disappear and a grid of interspersed dots only on the intersection of these boxes should be present instead. **When drawing a feature with a specific dimension of lambda, be sure that you are not zoomed out so far that you cannot see the lambda grid anymore. The intersection of the two solid lines represents the origin.</p> <p>Do not use Ctrl+S to save layouts!</p> <p>When saving your layout use File &gt; Save from the menubar. DO NOT DO CTRL+S AS IT BREAKS THE VIEW! If you do use Ctrl+S then try clicking the back arrow many times and you might be able to get your layout back.</p> <p>Let's now go ahead and draw an NMOS transistor step-by-step. First, draw two boxes on the active layer. Each box should be 8 lambda tall and 7 lambda wide. To draw a box:</p> <ul> <li>Choose the desired layer in the layer panel</li> <li>Choose the Box tool from the toolbar</li> <li>Click in the main drawing area where you want the upper-left corner</li> <li>Click in the main drawing area where you want the lower-right corner</li> </ul> <p></p> <p>Once you have drawn a box try deleting it.</p> <ul> <li>Choose the Select tool from the toolbar</li> <li>Hover over the box until it is highlighted</li> <li>Click on the box, it will stay highlighted</li> <li>Choose Edit &gt; Delete from the menubar</li> </ul> <p>Redraw the box. Now let's use move the two boxes so they are adjacent. To move a box:</p> <ul> <li>Click on the Move tool from the toolbar</li> <li>Hover over the box until it is highlighted</li> <li>Click on the box, it will stay highlighted</li> <li>Move the mouse to drag the box to the new location</li> <li>Click the box to place the box at the new location</li> </ul> <p></p> <p>We now two boxes that are adjacent to each other. Let's merge them into a single box. To merge boxes:</p> <ul> <li>Click on the Select tool from the toolbar</li> <li>Hover over the left box until it is highlighted</li> <li>Click on the box, it will stay highlighted</li> <li>Hover over the right box until it is highlighted</li> <li>Shift click on the box, both boxes will stay highlighted</li> <li>Choose Edit &gt; Selection &gt; Merge Shapes</li> </ul> <p></p> <p>Now use what you have learned to draw a complete NMOS with the active, nselect, poly, and contact layers. Note that in lecture we had separate layers for n-diffusion and p-diffusion. However, our TinyFlow 180nm PDK represents n-diffusion and p-diffusion differently. The active layer indicates where we want either n-diffusion or p-diffusion, and the pselect and nselect layers are used to select whether that diffusion is n-type or p-type. So to create n-diffusion we need a box of on the active layer overlapped with a box on the nselect layer. Since we are implementing a NMOS transistor, we draw an nselect layer around the active we have already drawn.</p> <p></p> <p>You can hide and show layers by double-clicking on the layer name in the Layer Panel. This can be useful to understand how different layers overlap.</p> <p>Once you have finish drawing your NMOS transistor let's make sure it follows all of the rules in the TinyFlow 180nm Design-Rule Manual (DRM):</p> <ul> <li>https://cornell-ece6745.github.io/ece6745-mkdocs/ece6745-design-rule-manual</li> </ul> <p>Go ahead and look through the DRM and find DRC Rule 3.3. This rule requires the poly box to extend at least 3 lambda beyond the active box. Verify that our NMOS transistor does indeed follow this rule. Obviously checking all of these rules would be tedious and error prone, so we will instead use KLayout to automatically check all DRC rules. Choose Tools &gt; DRC &gt; tinyflow-180nm.lydrc from the menubar.</p> <p>A new window should open with the DRC results, the left side shows all the performed DRC checks, with the numbers corresponding to the associated rules in the DRM. If your design is DRC-clean, then all the numbers should be green and the topcell name under By Cell should be green.</p> <p></p> <p>If the topcell name is black, scroll down to find the rule number(s) that is also black and cross-reference it with the DRM. If you click on the violated rule, details will also be populated in the Info window in the bottom right.</p> <p>Let's go ahead and create a violation by erasing some of the poly box. To erase part of a box:</p> <ul> <li>Choose the desired layer in the layer panel</li> <li>Click the down arrow next to the Add tool in toolbar</li> <li>Click Erase to change the tool to the Erase tool</li> <li>Draw a box in the main drawing area around what part of the poly    layer you want to erase</li> </ul> <p></p> <p>Once you have finish using the Erase tool don't forget to set it back to the Add tool otherwise you won't be able to draw new boxes in the future.</p> <p>Now rerun DRC. You should now have a DRC violation for DRC Rule 3.3. If you click on the violation in the DRC browser KLayout will highlight where the violation is on the layout. Edit your layout to fix the DRC violation and rerun DRC.</p> <p></p> <p>Once you are done go ahead and close KLayout. You can save your layout if you want but it is not required.</p>"},{"location":"ece6745-lab1/#3-full-custom-inverter","title":"3. Full-Custom Inverter","text":"<p>We are now ready to experiment with implementing a full-custom inverter. Revisit the TinyFlow full-custom design flow shows at the top of this lab handout.</p>"},{"location":"ece6745-lab1/#31-transistor-level-schematics","title":"3.1. Transistor-Level Schematics","text":"<p>The first step is to implement the transistor-level schematic for our inverter.</p> <p></p> <p>We will do this by writing a Spice file which is just a plain text file which specifies how to instantiate and connect transistors. Use VS Code to open the blank Spice file for our inverter:</p> <pre><code>% cd ${HOME}/lab1\n% code inv/inv.sp\n</code></pre> <p>Add a line for each device (transistor) in your inverter circuit inside the sub-circuit using the following format:</p> <ul> <li>For the PMOS: <code>M_P &lt;D&gt; &lt;G&gt; &lt;S&gt; &lt;B&gt; PMOS L=&lt;length&gt;U W=&lt;width&gt;U</code></li> <li>For the NMOS: <code>M_N &lt;D&gt; &lt;G&gt; &lt;S&gt; &lt;B&gt; NMOS L=&lt;length&gt;U W=&lt;width&gt;U</code></li> </ul> <p>where D, G, S, and B represent the drain, gate, source, and body connections for the transistor, respectively. You should replace these with the correct pin name (A, Y, VDD, VSS) for those connections as discussed in lecture. You should also fill in numerical values for the length and width of the transistor. For this inverter, we are defining the width to be 8-lambda wide. This is a design requirement we are providing to you, but custom-circuit designers will test their design for a wide variety of parameters, including modifying this width to achieve their design goals of power, performance, or area. Additionally, the definition of lambda states that the gate-width (transistor length) for a given process is equal to 2-lambda. Convert the lambda measurement of these values to micron using our conversion factor of 1 lambda = 0.09um (the U suffix on the end of the values denotes that the numerical value should be interpreted in micron).</p>"},{"location":"ece6745-lab1/#32-schematic-simulation-with-ngspice","title":"3.2. Schematic Simulation with Ngspice","text":"<p>Now that we have written our reference Spice schematic, we need to test it to make sure it is functionally correct. To check this functionality, we provide a Spice deck, or testbench, for our Spice circuit, which will simulate the circuit given specific input stimuli. Open this Spice deck using VS Code.</p> <pre><code>% cd ${HOME}/lab1\n% code inv/inv-sim.sp\n</code></pre> <p>Take a minute to browse the testbench as well and understand how it works at a high level. Copy-and-paste your Spice circuit from <code>inv/inv.sp</code> into the <code>inv/inv-sim.sp</code> file where it says to. You need to copy the entire subcircuit definition (i.e., you must include the <code>.SUBCKT</code> and <code>.ENDS</code> lines).</p> <p>Additionally, we need to make the following changes to the pasted Spice circuit to ensure it is compatible with the transistor models we will be using:</p> <ul> <li>Replace the <code>PMOS</code> identifier with <code>sky130_fd_pr__pfet_01v8</code></li> <li>Replace the <code>NMOS</code> identifier with <code>sky130_fd_pr__nfet_01v8</code></li> <li>Replace the <code>M_P</code> identifier with <code>XM_P</code>, and the <code>M_N</code> identifier with    <code>XM_N</code></li> </ul> <p>To allow the simulation to work, we need to provide pre-characterized device models for the transistors, and we use the open-source Sky130 models. The above changes modify the Spice to work with these models.</p> <p>We run the simulation using an open-source tool called Ngspice. Execute the following in your terminal to run the simulation:</p> <pre><code>% cd ${HOME}/lab1\n% ngspice inv/inv-sim.sp\n</code></pre> <p>Please be patient as it can take 30-45 seconds to finish the simulation. The simulation will open a new plot window in the virtual desktop, plotting both the input voltage (at A) vs. time as well as the output voltage (at Y) vs. time.</p> <p>Be sure to change both <code>inv.sp</code> and <code>inv-sim.sp</code>!</p> <p>If you make any fixes to your transistor-level schematic <code>inv-sim.sp</code>, be sure to make the same changes in <code>inv.sp</code> otherwise later steps will not work.</p> <p>Do not use Ctrl-C to exit Ngspice!</p> <p>To exit Ngspice type <code>exit</code> at the Ngspice prompt. If you try to use Ctr-C to exit Ngspice it will break your terminal. You might be able to fix your terminal by typing <code>clear</code> and then press enter, then typing <code>reset</code> and then press enter. You might not be able to see the letters when you type <code>clear</code> and <code>reset</code> but it still might work. You might need to use <code>source setup-gui.sh</code> again. Worst case you will need to close the terminal and open a new terminal.</p> <p>Critical Thinking Questions</p> <p>Does the behavior of the inverter look correct? Think about the desired high-level functionality.</p>"},{"location":"ece6745-lab1/#33-drawing-layout-with-klayout","title":"3.3. Drawing Layout with KLayout","text":"<p>We are now ready to draw the layout for the inverter. You can open the provided template in KLayout like this:</p> <pre><code>% cd ${HOME}/lab1\n% klayout -e inv/inv.gds &amp;\n</code></pre> <p>Here is the complete layout from lecture that you should use as a guide.</p> <p></p> <p>Be sure to follow the dimensions exactly! Otherwise you may fail DRC!</p> <p>Once your layout is finished, add the labels for these pins:</p> <ul> <li>A (input connecting to the gates of both transistors)</li> <li>Y (output from the drains of both transistors)</li> <li>VDD (positive voltage power rail)</li> <li>VSS (negative voltage power rail)</li> </ul> <p>Each pin should be positioned in the center of the corresponding metal1 box. To add a label:</p> <ul> <li>Choose the metal1 label layer in the layer panel</li> <li>Choose the Text tool from the toolbar</li> <li>Click in the main drawing area where you want the label</li> </ul> <p>Once the label is placed correctly, use the Select tool to select the label. Then choose Edit &gt; Properties from the menubar. Change the Text field to change the name of the pin. The pins need to be exactly labeled A, Y, VDD, and VSS.</p> <p>You can view your inverter in a semi-three-dimensional view called 2.5D. First, make sure your layout is fully-visible in the layout viewer. Then, choose Tools &gt; 2.5d View &gt; tinyflow-180nm.lyd25 from the menubar. A new window should pop up with a 2.5D viewer which you can use the mouse to scroll around and view the inverter from different angles!</p> <p></p>"},{"location":"ece6745-lab1/#34-drc-with-klayout","title":"3.4. DRC with KLayout","text":"<p>Once you have finished your layout, you should run DRC as before to ensure your design passes all design rule checks. Ensure your design is DRC-clean before moving onto the next step! Be sure to save the layout as well.</p>"},{"location":"ece6745-lab1/#35-lvs-with-klayout","title":"3.5. LVS with KLayout","text":"<p>Layout vs. schematic checks compare the layout you just created with the transistor-level schematic you wrote earlier to ensure that the layout drawing matches the intended high-level functionality. The LVS tool in KLayout will extract a Spice schematic from the drawn layout and compare this to the reference one.</p> <p>Make sure your desired cell to check via LVS is active in the viewer (important if multiple such cells are in the same layout file as will happen in later projects and labs). Choose Tools &gt; LVS &gt; tinyflow-180nm.lylvs from the menubar.</p> <p>After running the script, and if LVS passes, you should see all green in the window that pops up. You can click through the dropdowns under Cross Reference &gt; Objects to see the comparison between the layout and reference schematic for pins, nets, and devices (transistors).</p> <p></p> <p>If you see any red stop signs, this means LVS failed. You can view the violations by clicking the drop-down arrows under Cross Reference &gt; Objects to see what is failing the check. If you have mismatched or missing pins, these errors will show up in the Log tab. Edit your layout and/or reference Spice file to fix the violations. Here are some examples of what might cause LVS violations.</p> <ul> <li> <p>The width of the transistors in the reference schematic do not match     the layout.</p> </li> <li> <p>The pins are not on the metal1 label layer (pins must be on metal1     label not metal1).</p> </li> <li> <p>Make sure you are using <code>PMOS</code> and <code>NMOS</code> in your <code>inv.sp</code> file not     <code>sky130_fd_pr__pfet_01v8</code> and <code>sky130_fd_pr__nfet_01v8</code>. The     <code>sky130_fd_pr__pfet_01v8</code> and <code>sky130_fd_pr__nfet_01v8</code> versions are     only for simulation, so they should only be in the <code>inv-sim.sp</code>.</p> </li> <li> <p>Make sure your transistors in the layout are really transistors     (i.e., make sure you are really using the nselect and pselect     layers correctly).</p> </li> </ul> <p>Let's go ahead and force an LVS violation. Close the LVS dialog box and swap the names of the A and Y pins. Then rerun LVS and you should be able to see the LVS violations in the Log tab.</p> <p></p> <p>Now go back and fix the LVS violations and rerun LVS to verify your design is LVS clean.</p>"},{"location":"ece6745-lab1/#36-rcx-with-klayout","title":"3.6. RCX with KLayout","text":"<p>KLayout generates an extracted transistor-level schematic as a side-effect of running LVS. Go ahead and take a look at this extracted transistor-level schematic.</p> <pre><code>% cd ${HOME}/lab1\n% code inv/inv-rcx.sp\n</code></pre> <p>This file looks similar to the reference Spice file, except that it includes additional information for RC parasitics of the transistor using the parameters AS, AD, PS, and PD.</p>"},{"location":"ece6745-lab1/#37-extracted-simulation-with-ngspice","title":"3.7. Extracted Simulation with Ngspice","text":"<p>Our final step is to characterize the timing of our full-custom layout using the extracted transistor-level schematic. Open the following Spice deck using VS Code.</p> <pre><code>% cd ${HOME}/lab1\n% code inv/inv-rcx-sim.sp\n</code></pre> <p>Copy-and-paste the extracted Spice circuit from <code>inv/inv-rcx.sp</code> into the <code>inv/inv-rcx-sim.sp</code> file where it says to. Additionally, we need to make the following changes to the pasted Spice circuit to ensure it is compatible with the transistor models we will be using:</p> <ul> <li>Replace the <code>PMOS</code> identifier with <code>sky130_fd_pr__pfet_01v8</code></li> <li>Replace the <code>NMOS</code> identifier with <code>sky130_fd_pr__nfet_01v8</code></li> <li>Replace the <code>M$1</code> identifier with <code>XM$1</code>, and the <code>M$2</code> identifier with    <code>XM$2</code></li> </ul> <p>We are now ready to run our simulation. Execute the following in your terminal to run the simulation (it should take a few seconds to run):</p> <pre><code>% cd ${HOME}/lab1\n% ngspice inv/inv-rcx-sim.sp\n</code></pre> <p>The simulation will open a new plot window in the virtual desktop, plotting both the input voltage (at A) vs. time as well as the output voltage (at Y) vs. time.</p> <p>Critical Thinking Questions</p> <p>Qualitatively, how does the rise time of the output compare to the fall time (compare this to your lecture notes)? Can you explain why one is faster than the other?</p>"},{"location":"ece6745-lab1/#4-full-custom-buffer","title":"4. Full-Custom Buffer","text":"<p>Assume we want to implement a buffer in which the output is the same as the input. We might want this regenerate a signal for example. Many students wonder why we can't just make a buffer by \"flipping\" the NMOS and PMOS in the inverter.</p> <p></p> <p>If the input is one then the NMOS is on and the PMOS is off and the output would be one. If the input is zero then the NMOS is off and the PMOS is on and the output would be zero.</p> <p>Use everything you have learned to implement and test this kind of buffer. Go through all seven steps of the TinyFlow full-custom design flow:</p> <ul> <li>Step 1: Use VS Code to write a transistor-level schematic</li> <li>Step 2: Use Ngspice to functionally verify this schematic</li> <li>Step 3: Use KLayout to draw the layout for the buffer</li> <li>Step 4: Use KLayout to make sure the layout is DRC clean</li> <li>Step 5: Use KLayout to make sure the layout is LVS clean</li> <li>Step 6: Use KLayout to for RC extraction</li> <li>Step 7: Use Ngspice to characterize the timing of the buffer</li> </ul> <p>You should use these files which are provided for you.</p> <ul> <li><code>buf/buf.sp</code></li> <li><code>buf/buf-sim.sp</code></li> <li><code>buf/buf.gds</code></li> <li><code>buf/buf-rcx-sim.sp</code></li> </ul> <p>Here is a sketch of how to implement the layout for the buffer.</p> <p></p> <p>Start by copying your layout from your inverter as follows. First, use KLayout to open the layout for the buffer and inverter in two separate tabs.</p> <pre><code>% cd ${HOME}/lab1\n% klayout -e buf/buf.gds inv/inv.gds\n</code></pre> <p>Now use the following steps to copy the inverter cell from <code>inv.gds</code> into <code>buf.gds</code> and then rename this cell from INV to BUF.</p> <ul> <li>Click on the tab for the inverter layout</li> <li>Right click on INV in the Cells panel</li> <li>Choose Copy</li> <li>Click on the tab for the buffer layout</li> <li>Right click on the Cells pane</li> <li>Choose Paste</li> <li>Close the tab for the inverter layout</li> <li>Right click on INV in the Cells</li> <li>Choose Rename Cell</li> <li>Enter BUF</li> <li>Click OK</li> </ul> <p>Critical Thinking Questions</p> <p>Consider the plot showing both Vin and Vout over time from simulating the extracted transistor-level schematic (not from just simulating the reference transistor-level schematic). Will this approach work in practice? Why or why not?</p>"},{"location":"ece6745-lab2/","title":"ECE 6745 Lab 2: Standard-Cell Inverter","text":"<p>In this lab, we will implement a standard-cell inverter including the corresponding behavioral, schematic, layout, extracted schematic, front-end, and back-end views.</p> <ul> <li> <p>Behavioral View: Logical function of the standard cell, used for      gate-level simulation</p> </li> <li> <p>Schematic View: Transistor-level representation of standard cell,      used for functional verification and layout-vs-schematic</p> </li> <li> <p>Layout View: Layout of standard cell, used for design-rule      checking (DRC), layout-vs-schematic (LVS), resistance/capacitance      extraction (RCX), and fabrication</p> </li> <li> <p>Extracted Schematic View: Transistor-level representation with      extracted resistance and capacitances, used for layout-vs-schematic      (LVS) and timing characterization</p> </li> <li> <p>Front-End View: High-level information about standard cell      including area, input capacitance, logical function, and delay      model; used in synthesis</p> </li> <li> <p>Back-End View: Low-level information about standard cell including      height, width, and pin locations; used in placement and routing</p> </li> </ul> <p>We will be using the following TinyFlow standard-cell design flow.</p> <p></p> <p>We will by begin by writing the behavioral view in Verilog and verifying its functionality using a Verilog test bench and Icarus Verilog. We will then write the schematic view in SPICE and verify its functionality using a SPICE test bench and TinyFlow-Ngspice. Instead of using Ngspice directly as in Lab 1, we will now be using our TinyFlow-Ngspice wrapper script which makes it much easier to run SPICE simulatoins. We will then use the KLayout design editor to create the layout, perform a design-rules check (DRC), perform a layout vs. schematic check (LVS), and generate an extracted schematic. We will re-simulate the extracted transistor-level schematic using TinyFlow-Ngspice to characterize the propagation delay for different load capacitances in order to create a linear delay model. Finally, we will write the front-end and back-end views for our standard-cell inverter in two YAML files. We will also implement three auxillary standard cells (i.e., TIEHI, TIELO, FILL).</p>"},{"location":"ece6745-lab2/#1-logging-into-ecelinux","title":"1. Logging Into <code>ecelinux</code>","text":"<p>Follow the same process as previous labs Find a free workstation Find a free workstation and log into the workstation using your NetID and standard NetID password. Then complete the following steps. These are the same stes as in the first lab with one exception. We are now installing the VS Code Surfer extension to be able to view waveforms.</p> <ul> <li>Start VS Code</li> <li>Install the Remote-SSH extension and the Surfer extension</li> <li>Use View &gt; Command Palette to execute Remote-SSH: Connect Current Window to Host...</li> <li>Enter netid@ecelinux-XX.ece.cornell.edu where XX is an ecelinux server number</li> <li>Use View &gt; Explorer to open your home directory on ecelinux</li> <li>Use View &gt; Terminal to open a terminal on ecelinux</li> <li>Start MS Remote Desktop</li> </ul> <p></p> <p>Now use the following commands to clone the repo we will be using for today's lab.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% xclock &amp;\n% mkdir -p ${HOME}/ece6745\n% cd ${HOME}/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-lab2 lab2\n% cd lab2\n% tree\n</code></pre> <p>Your repo contains the following files for the views and simulation scripts for each standard cell.</p> <pre><code>.\n\u2514\u2500\u2500 stdcells\n    \u251c\u2500\u2500 verilog-test\n    \u2502   \u251c\u2500\u2500 AOI21X1-test.v\n    \u2502   \u251c\u2500\u2500 INVX1-test.v\n    \u2502   \u251c\u2500\u2500 NAND2X1-test.v\n    \u2502   \u251c\u2500\u2500 NOR2X1-test.v\n    \u2502   \u251c\u2500\u2500 TIEHI-test.v\n    \u2502   \u2514\u2500\u2500 TIELO-test.v\n    \u251c\u2500\u2500 stdcells-be.yml\n    \u251c\u2500\u2500 stdcells-fe.yml\n    \u251c\u2500\u2500 stdcells-rcx.yml\n    \u251c\u2500\u2500 stdcells.gds\n    \u251c\u2500\u2500 stdcells.sp\n    \u2514\u2500\u2500 stdcells.v\n</code></pre> <p>To make it easier to cut-and-paste commands from this handout onto the command line, you can tell Bash to ignore the <code>%</code> character using the following command:</p> <pre><code>% alias %=\"\"\n</code></pre> <p>Now you can cut-and-paste a sequence of commands from this tutorial document and Bash will not get confused by the <code>%</code> character which begins each line.</p>"},{"location":"ece6745-lab2/#2-standard-cell-inverter","title":"2. Standard-Cell Inverter","text":"<p>In this part, we will be implementing the six views for the standard-cell inverter. Remember that in addition to being DRC and LVS clean, your inverter must also follow all of the rules which make standard cells \"standard\":</p> <ul> <li>Standard transistor positions and orientation (PMOS at top, NMOS at      bottom, vertical gates)</li> <li>Standard n-well size and location (n-well at top)</li> <li>Standard VDD and ground metal layer and locations (on metal 1,      VDD rail 8 lambda tall at top, ground rail 8 lambda tall at      bottom)</li> <li>Standard n-well and substrate contacts</li> <li>Standard boundry and extension of n-well, VDD, and ground rails      beyond boundry (origin is in lower left)</li> <li>Standard metal 2+ routing grid (8 lambda track spacing)</li> <li>Standard cell height (64 lambda)</li> <li>Standard cell width (aligned to routing grid, i.e., 8 lambda,      16 lambda, 24 lambda, etc)</li> <li>Standard routing (all routing must be on polysilicon or metal 1)</li> <li>Standard pin layer and locations (on \"metal1 label\" layer and on     routing grid)</li> <li>Standard set of available drive strengths with equal rise and      fall times</li> </ul> <p>To get started, create a build directory which will use for all of our simulations.</p> <pre><code>% mkdir -p ${HOME}/ece6745/lab2/stdcells/build\n% cd ${HOME}/ece6745/lab2/stdcells/build\n</code></pre>"},{"location":"ece6745-lab2/#21-behavioral-view","title":"2.1. Behavioral View","text":"<p>We will begin by defining our inverter standard cell in a behavioral way, in other words, what is its *logical functionality? To do this, we use Verilog by writing a module definition for our cell in <code>stdcells.v</code> and testing the standard cell module with a Verilog testbench (provided in <code>stdcells/verilog-test/INVX1-test.v</code>). Use VS Code to implement the behavioral view for our INVX1 standard cell.</p> <pre><code>% cd ${HOME}/ece6745/lab2/stdcells/build\n% code ../stdcells.v\n</code></pre> <p>Use standard Verilog bitwise operations to assign the output Y as a function of the inputs. Next, we will test the inverter using the provided test bench.</p> <pre><code>% cd ${HOME}/ece6745/lab2/stdcells/build\n% iverilog -Wall -g2012 -I .. -o INVX1-test ../verilog-test/INVX1-test.v\n% ./INVX1-test\n</code></pre> <p>The test bench will display a single check for A=0. Open the test bench and add additional checks like this:</p> <pre><code>    //     A     Y\n    check( 1'b0, 1'b1 );\n    check( 1'b1, 1'b0 );\n    check( 1'b0, 1'b1 );\n    check( 1'b1, 1'b0 );\n    check( 1'b0, 1'b1 );\n    check( 1'b1, 1'b0 );\n</code></pre> <p>Now rerun the Verilog test bench to verify the functionality of your standard cell behavioral view for all possible inputs.</p> <pre><code>% cd ${HOME}/ece6745/lab2/stdcells/build\n% iverilog -Wall -g2012 -I .. -o INVX1-test ../verilog-test/INVX1-test.v\n% ./INVX1-test\n</code></pre> <p>The output should look like this:</p> <pre><code>  1: 0 &gt; 1\n  2: 1 &gt; 0\n  3: 0 &gt; 1\n  4: 1 &gt; 0\n  5: 0 &gt; 1\n  6: 1 &gt; 0\n</code></pre> <p>You can also view the waveforms from this simulation by using Surfer.</p> <pre><code>% cd ${HOME}/ece6745/lab2/stdcells/build\n% code INVX1-test.vcd\n</code></pre> <p>You can then click the dropdown arrow next to TOP in the top-left Scopes panel. Then click on A and B in the Variables panel to display the corresponding waveforms. Verify the output for your inverter matches your expectations for its logical functionality before moving on.</p> <p></p>"},{"location":"ece6745-lab2/#22-schematic-view","title":"2.2. Schematic View","text":"<p>Now that your Verilog behavioral/logical view for your inverter is ready and fully tested, we also need to define its schematic view as a SPICE file in <code>stdcells.sp</code>. This is the schematic for an INVX1 standard cell with equal rise and fall times:</p> <p></p> <p>Use VS Code to implement the schematic view for our INVX1 standard cell.</p> <pre><code>% cd ${HOME}/ece6745/lab2/stdcells/build\n% code ../stdcells.sp\n</code></pre> <p>Recall from from lab 1 the SPICE syntax is as follows:</p> <ul> <li>PMOS: <code>M_P &lt;D&gt; &lt;G&gt; &lt;S&gt; &lt;B&gt; PMOS L=&lt;length&gt;U W=&lt;width&gt;U</code></li> <li>NMOS: <code>M_N &lt;D&gt; &lt;G&gt; &lt;S&gt; &lt;B&gt; NMOS L=&lt;length&gt;U W=&lt;width&gt;U</code></li> </ul> <p>Remember that you are now implementing a 2:1 inverter for equal rise and fall times instead of a 1:1 inverter. Make sure you size the width of the transistors correctly!</p> <p>Once you have a completed the schematic view, you will now simulate it with TinyFlow-Ngspice. The following shows the syntax of how to use the new <code>tinyflow-ngspice</code> wrapper script.</p> <pre><code>tinyflow-ngspice --spice=&lt;SPICE_FILE&gt; --cell=&lt;CELLNAME&gt; --cload=&lt;CLOAD&gt; \\\n  --inputs=&lt;INPUTS_SPEC&gt;\n</code></pre> <p>Let's break down each input (all four are required):</p> <ul> <li> <p><code>--spice=&lt;SPICE_FILE&gt;</code>: replace <code>&lt;SPICE_FILE&gt;</code> with the path to    <code>stdcells.sp</code> where you have defined your SPICE schematic (e.g.,    <code>../stdcells.sp</code>)</p> </li> <li> <p><code>--cell=&lt;CELLNAME&gt;</code>: replace <code>&lt;CELLNAME&gt;</code> with the name of your cell    to test (e.g., <code>INVX1</code>)</p> </li> <li> <p><code>--cload=&lt;CLOAD&gt;</code>: replace <code>&lt;CLOAD&gt;</code> with the capacitance to put on    the output pin of your cell, you can use regular integers followed by    a unit suffix (e.g., <code>10f</code> for 10 femtofarads)</p> </li> <li> <p><code>--inputs=&lt;INPUTS_SPEC&gt;</code>: replace <code>&lt;INPUTS_SPEC&gt;</code> with a string    surrounded by quotes of the following form:    <code>&lt;PIN1&gt;:&lt;VAL0&gt;-&lt;VAL1&gt;...&lt;VALN&gt;;&lt;PIN2&gt;:&lt;VAL0&gt;-&lt;VAL1&gt;...&lt;VALN&gt;</code> where    <code>&lt;PINN&gt;</code> specifies one of the input pins for your cell (e.g. A, B,    etc.), and <code>&lt;VALN&gt;</code> specifies a 0 or 1 to assert on that input pin.    Each of these values are separated by a dash (-), such that each input    value will be set for one timestep (2ns) before the next value is set.    All input pins and their corresponding values are separated by a    semicolon (;), and input pin names are separated from their values    list by a colon (:). All input pins as specified by your standard cell    must be present, and they must all have the same number of    transitions.</p> </li> </ul> <p>Use TinyFlow-Ngspice to simulate the INVX1 standard cell with a 50fF load and an input going from 0 to 1 to 0:</p> <pre><code>% cd ${HOME}/ece6745/lab2/stdcells/build\n% tinyflow-ngspice --spice=../stdcells.sp --cell=INVX1 --cload=50f \\\n    --inputs=\"A:0-1-0\"\n</code></pre> <p>The command will take care of all of the manual steps you had to do in lab 1 for you:</p> <ul> <li>converting your Spice schematic to a Sky130-compatible version,</li> <li>setting up the Spice testbench,</li> <li>running the testbench,</li> <li>generating a waveform plot, and</li> <li>analyzing the propagation delays.</li> </ul> <p>When the command has completed, you will see an output to the console specifying the transitions of both the input and output pins of your standard cell throughout the simulation. It will also print rising and falling delays if captured from each input pin to the output; this will be discussed later when characterizing the cell. Additionally, your build directory will contain a new subdirectory <code>ngspice-results/</code> with more subdirectories within it named with a concatenation of the inputs you specified. Each of these subdirectories will contain the following:</p> <ul> <li><code>-tb.sp</code>: the Spice testbench used to simulate your schematic</li> <li><code>.csv</code>: CSV data generated by Ngspice for each pin of your standard cell</li> <li><code>.png</code>: an image plotting the voltage of each pin of your standard cell over    time</li> <li><code>.txt</code>: a text file containing the same output as what was printed to the    console</li> </ul> <p>Look at the results and verify functionality of the schematic view for your INVX1 standard cell. Look at the text output and the waveform plot.</p> <pre><code>% cd ${HOME}/ece6745/lab2/stdcells/build\n% code ngspice-results/INVX1-50f-stdcells-A_0_1_0/INVX1-50f-stdcells-A_0_1_0.png\n</code></pre>"},{"location":"ece6745-lab2/#23-layout-view","title":"2.3. Layout View","text":"<p>We can now move on to drawing the layout view for our INVX1 standard  cell. Use Klayout to open the <code>stdcells.gds</code> file:</p> <pre><code>% cd ${HOME}/ece6745/lab2/stdcells/build\n% klayout -e ../stdcells.gds\n</code></pre> <p>Make sure the inverter is your top cell view by clicking on INVX1 in the Cells panel and selecting \"Show As New Top\":</p> <p></p> <p>You should see a template for a standard-cell layout as shown below:</p> <p></p> <p>Because we want all our standard cells to follow out standard parameters as discussed in lecture, we have provided you with this template for every standard cell to get started. Notice how the height of the cell (from center of contact on bottom VSS rail to center of contact on top VDD rail) is 64 lambda (8 vertical routing tracks, each track is 8 lambda tall). The width of this standard cell is also 64 lambda (8 horizontal tracks, each of 8 lambda wide). You will also see some familiar layers here, particularly the nwell under the top half of the standard cell. You will also notice that we have already inserted pselect and nselect regions accordingly.</p> <p>To implement the inverter, you will follow the reference layout below (notice how the pins must be on the intersecting black track lines in the layout):</p> <p></p> <p>Be sure to reference the TinyFlow 180nm Design-Rule Manual (DRM) when drawing your layout:</p> <ul> <li>https://cornell-ece6745.github.io/ece6745-mkdocs/ece6745-design-rule-manual</li> </ul> <p>Notice how this inverter only needs to be 24 lambda wide (3 horizontal tracks), but the standard cell we have given you is 64 lambda wide (8 horizontal tracks). When drawing your layout, implement the above inverter all the way on the left side of your provided template. You will then need to \"trim\" the template from the right side by performing the following actions to achieve a minimum-width.</p> <p>Use the Erase tool to erase extra htrack and vtrack shapes, then use the Erase or Partial tool to move the right-hand edge of the prboundary so that it is aligned with the new right most track.</p> <p></p> <p>Use the Erase or Partial tool to move the right-hand edge of the nwell so that it extends beyond the prboundary by 3 lambda (symmetrical with the left edge of the cell)</p> <p></p> <p>Use the Erase or Partial tool to move the nselect and pselect boxes so that they extend beyond the prboundary by 2 lambda (symmetrical with the left edge of the cell).</p> <p></p> <p>Finally, use the Erase or Partial tool to adjust the well-tap structures (active + metal1 + contacts) at the top and bottom of the cell so that it is aligned with the prboundary.</p> <p></p> <p>As in lab 1, be sure to run DRC and LVS to ensure your design adheres to all design rules and matches your SPICE schematic. Use the 2.5D tool to visualize your standard cell in 3D!</p>"},{"location":"ece6745-lab2/#24-extracted-schematic-view","title":"2.4. Extracted Schematic View","text":"<p>Now that we have a DRC and LVS-clean layout, we can perform functional verification as well as characterization on our extracted schematic view.</p> <p>LVS dumps out your extracted schematic view in SPICE format for you automatically. You should see the file in <code>stdcells/invx1-rcx.sp</code>. Copy the contents of this file and paste it into <code>stdcells/stdcells-rcx.sp</code>. Delete <code>stdcells/invx1-rcx.sp</code> since it is no longer needed.</p> <p>We will now run functional simulation on the extracted schematic view. Notice the only difference for this command from functionally verifying the schematic view is the different Spice file.</p> <pre><code>% cd ${HOME}/ece6745/lab2/stdcells/build\n% tinyflow-ngspice --spice=../stdcells-rcx.sp --cell=INVX1 \\\n    --inputs=\"A:0-1-0\"\n</code></pre> <p>Compare the output waveforms from the console/txt file and png file to your expectations for what the functionality of the inverter should be. Only move on once your expectations are met (go back to fix your layout if the waveforms do not look correct).</p> <p>We will now perform timing characterization on the inverter. This means we are going to run multiple SPICE simulations to create a linear-delay model which we can then use in the standard cell front-end view. Our linear-delay model should represent the worst case propagation delay through the inverter (either rising input to falling output or falling output to rising input) as a function of its load capacitance (cload). To do this, focus on a single transition at a time. Then choose three values of <code>cload</code> and observe the values in the <code>Measured delays:</code> section of the TinyFlow-Ngspice output. <code>t_pdf</code> represents the falling propagation delay, while <code>t_pdr</code> represents the rising propagation delay. So here is how we would gather propagation delays at three load capacitances for the output falling transition.</p> <pre><code>% cd ${HOME}/ece6745/lab2/stdcells/build\n% tinyflow-ngspice --spice=../stdcells-rcx.sp --cell=INVX1 --cload=10f \\\n    --inputs=\"A:0-1\"\n% tinyflow-ngspice --spice=../stdcells-rcx.sp --cell=INVX1 --cload=20f \\\n    --inputs=\"A:0-1\"\n% tinyflow-ngspice --spice=../stdcells-rcx.sp --cell=INVX1 --cload=30f \\\n    --inputs=\"A:0-1\"\n</code></pre> <p>Remember, only analyze a single transition at a time. Once you have obtained a propagatoin delays for at least three load capacitances, converted the delay to ps and the load value to fF. Then generate a linear regression of the data with delay on the y-axis and load value on the x-axis using your favorite data analyzer (Google Sheets, TI calculator, etc.). Note down the y-intercept and slope. As discussed in lecture, the y-intercept represents the parasitic delay, or the delay when the cell is unloaded, while the slope represents the load-delay factor, a measure of how much the delay increases for increasing load capacitance. These values are necessary for static-timing analysis which will be performed in later labs.</p> <p>Once you have determined a linear for both transitions look at these equations and choose the worst case linear delay equation to use as the delay model for your front-end view.</p> <p>Critical Thinking Questions</p> <p>Go back and compare the rising and falling propagation delays of your pre-extracted SPICE schematic to your extracted SPICE schematic. Are the delays larger or smaller for the extracted schematic compared to the pre-extracted schematic? Why is this the case?</p>"},{"location":"ece6745-lab2/#25-front-end-view","title":"2.5. Front-End View","text":"<p>We are now ready to create a YAML file for the front-end ASIC flow that we will be working on in later labs. This YAML file will use much of the information we have obtained in previous steps, and combine it together for the front-end tools to use. This view primarily contains timing, logical, and basic area information for each cell. Use VS Code to open the <code>stdcells-fe.yml</code> file.</p> <pre><code>% cd ${HOME}/ece6745/lab2/stdcells/build\n% code ../stdcells-fe.yml\n</code></pre> <p>We give you the following template for the front-end view for your INVX1 standard cell.</p> <pre><code> - name: INVX1\n   area_cost: 0 # lambda^2\n\n   pins:\n\n     - name: A\n       type: input\n       cgate: 0 # fF\n\n     - name: Y\n       type: output\n       function: # tree of generic gates\n\n   parasitic_delay:   0 # ps\n   load_delay_factor: 0 # ps/fF\n\n   patterns:\n     - # list of equivalent trees of generic NAND and INV gates\n</code></pre> <p>Fill in the <code>area_cost</code> value as the area of the standard cell in lambda-squared, starting from the bottom-left corner of the intersecting black lines indicating the horizontal and vertical tracks, and ending at the top-right corner at the intersection of the black lines for the horizontal and vertical tracks (see the red circles in the below image):</p> <p></p> <p>Each cell also has pin information under the \"pin\" key. The pin information itself will be a list of data for each input and output pin, where each pin has a name and type (input or output).</p> <p>For input pins, you will need to specify a value for the gate capacitance (<code>cgate</code>) in fF associated with that pin. The calculation for gate capacitance is as follows:</p> <pre><code>Cgate = 1.60 * (total gate width in lambda) * 0.09\n</code></pre> <p>The value of 1.60 fF/um is a reasonable value for a generic 180nm process. You need to convert it to just units of fF by multiplying by the total gate width in um associated with the given input pin. You will need to find this total gate width in units of lambda by looking at your layout and comparing against your SPICE schematic. The multiplication by 0.09 is to convert lambda to microns.</p> <p>For output pins, you will need to specify the function which determines the logical functionality of this pin as a function of the input pins. You can specify it using a tree of generic gates. Here is a list of the valid generic gates:</p> <ul> <li><code>BUF</code>, <code>NOT</code>, <code>INV</code></li> <li><code>AND2</code>, <code>OR2</code>, <code>XOR2</code></li> <li><code>NAND2</code>, <code>NOR2</code>, <code>XNOR2</code></li> </ul> <p>So for example, here is an example tree for a more complicated three-input standard cell: <code>NAND2( INV(A), OR2(INV(B),C) )</code>.</p> <p>You will need to fill in your values for <code>load_delay_factor</code> and <code>parasitic_delay</code> as calculated in the previous step. Note that <code>load_delay_factor</code> MUST be in units of ps/fF, and <code>parasitic_delay</code> MUST be in units of ps. Go back and double check you performed the conversions if necessary.</p> <p>Finally, you will need to specify a list of patterns using only INV() and NAND2() logical gates that matches the functionality of your gate for all of its inputs. The reason for doing this will become clear as we discuss synthesis algorithms in lecture, as is needed when mapping your high-level Verilog code to these standard-cells.</p>"},{"location":"ece6745-lab2/#26-back-end-view","title":"2.6. Back-End View","text":"<p>We are now ready to create a YAML file for the back-end ASIC flow that we will be working on in later labs. Again, this file contains much of the information that we have previously found, and bundles it for use by the ASIC flow. This file primarily contains physical data for each cell including width, height, and pin locations. Use VS Code to open the <code>stdcells-fe.yml</code> file.</p> <pre><code>% cd ${HOME}/ece6745/lab2/stdcells/build\n% code ../stdcells-be.yml\n</code></pre> <p>You will first see a dictionary whose toplevel key is \"layers\". DO NOT MODIFY ANYTHING IN THIS DICTIONARY! It contains all the relevant information needed by the flow tools to properly route your design. Feel free to look through it to understand what information it contains.</p> <p>After the layer information, you will see a dictionary whose toplevel key is \"sites\". DO NOT MODIFY ANYTHING IN THIS DICTIONARY! It contains information for the standard-cell placement on a grid of sites. One site is defined as a 1-track wide \"slice\" of a standard-cell row. For instance, the FILL standard cell you will create only occupies one site, while the INVX1 standard cell occupies three sites. This unit standardizes the available widths for standard cells so that placement algorithms have an easier time placing the cells.</p> <p>Finally, we have the \"cells\" dictionary, where you will add in the physical information for each standard cell. Each cell is a list item as in the front-end with its name.</p> <p>We give you the following template for the back-end view for your INVX1 standard cell.</p> <pre><code>  - name: INVX1\n    size:\n      width:  0 # lambda\n      height: 0 # lambda\n    pins:\n      - name: A\n        loc:  (0,0) # (x,y) lambda\n      - name: Y\n        loc:  (0,0) # (x,y) lambda\n</code></pre> <p>Each cell has a \"size\" sub-dictionary, with keys for width and height. Fill these values in using the same lower-left and upper-right track intersection points used for calculating area in the front-end YAML. These width and height values should therefore be in units of lambda. Next is the pin list, similar again to the front-end view. In this file, each pin once again has a name, but also an X and Y location. Look at your layout, and get the X and Y location of the pin marker for each pin relative to the lower-left track intersection. These values should once again be in units of lambda.</p>"},{"location":"ece6745-lab2/#3-standard-cell-tiehi","title":"3. Standard-Cell TIEHI","text":"<p>To implement the TIEHI cell, you will follow the schematic and layout reference below (notice how the pins must be on the intersecting black track lines in the layout):</p> <p></p> <p></p> <p>Create the required standard cell views:</p> <ul> <li>Behavioral View (this will be very simple, run Verilog simulation)</li> <li>Schematic View (run TinyFlow-Ngspice simulation)</li> <li>Layout View</li> <li>Extracted Schematic View (run TinyFlow-Ngspice simulation for      functional verification)</li> <li>Front-end view</li> <li>Back-end view</li> </ul> <p>Note that your schematic view might need a temporary internal wire/net. To create a temporary internal wire/net simply use a new name like <code>net1</code>; SPICE will assume this implicitly refers to a new temporary internal wire/net.</p>"},{"location":"ece6745-lab2/#4-standard-cell-tielo","title":"4. Standard-Cell TIELO","text":"<p>To implement the TIELO cell, you will follow the schematic and layout reference below (notice how the pins must be on the intersecting black track lines in the layout):</p> <p></p> <p></p> <p>Create the required standard cell views:</p> <ul> <li>Behavioral View (this will be very simple, run Verilog simulation)</li> <li>Schematic View (run TinyFlow-Ngspice simulation)</li> <li>Layout View</li> <li>Extracted Schematic View (run TinyFlow-Ngspice simulation for      functional verification)</li> <li>Front-end view</li> <li>Back-end view</li> </ul> <p>Note that your schematic view might need a temporary internal wire/net. To create a temporary internal wire/net simply use a new name like <code>net1</code>; SPICE will assume this implicitly refers to a new temporary internal wire/net.</p>"},{"location":"ece6745-lab2/#5-standard-cell-fill","title":"5. Standard-Cell FILL","text":"<p>To implement the FILL cell, you will follow the layout reference below (notice how there are no pins other than VDD and VSS which are on the template already):</p> <p></p> <p>Create the required standard cell views:</p> <ul> <li>Behavioral View (this will be very simple, no simulation)</li> <li>No Schematic View</li> <li>Layout View</li> <li>No Extracted Schematic View</li> <li>Front-end view (only need area cost)</li> <li>Back-end view (only need width and heigh)</li> </ul>"},{"location":"ece6745-lab2/#6-batch-drc-and-lvs","title":"6. Batch-DRC and LVS","text":"<p>Performing DRC and LVS manually on each and every cell is tedious. To help you ensure all your cells are passing DRC/LVS, we have created batch scripts that will perform DRC and LVS on every cell for you. To run them, run the following commands after completing your standard cells:</p> <pre><code>% cd ${HOME}/ece6745/lab2/stdcells/build\n% tinyflow-batch-drc\n% tinyflow-batch-lvs\n</code></pre> <p>These two scripts will alert you if there are any DRC/LVS errors in any of your cells, all without needing to open the KLayout GUI. Output files from these scripts will be generated to <code>drc_results</code>, <code>lvs_results</code>, and <code>rcx-results</code> subdirectories within the <code>build</code> directory.</p>"},{"location":"ece6745-lab3-old/","title":"ECE 6745 Lab 3: TinyFlow Front End","text":"<p>In this lab, we will explore both the data structures and algorithms used in TinyFlow front end. We will implement a basic synthesis tool that transforms Verilog RTL into a gate-level netlist and then use this synthesis tool to create a very simple end-to-end front end flow which includes two-state RTL simulation, four-state RTL s walk through the complete frontend verification flow for an RTL design.</p> <ul> <li> <p>Verilog Parser: Reads Verilog RTL and converts it into an internal      tree representation of generic gates</p> </li> <li> <p>Substitution: Pattern matching and replacement operation that      transforms trees by matching a find pattern and producing a new tree      from a replace template</p> </li> <li> <p>Naive Technology Mapping: Maps generic gates to standard cells from      your library using simple pattern substitution</p> </li> <li> <p>Gate-Level Netlist Writer: Outputs the mapped design as a Verilog      gate-level netlist using your standard cells</p> </li> </ul> <p>We will be using the following TinyFlow frontend synthesis flow.</p> <p></p> <p>We will begin by exploring the TinyFlow data structures using the REPL and GUI. We will then implement a Verilog parser, tree printing, substitution, and naive technology mapping. Finally, we will walk through the four-step frontend flow (2-state simulation, 4-state simulation, synthesis, fast-functional gate-level simulation) to verify a Full Adder design.</p>"},{"location":"ece6745-lab3-old/#1-logging-into-ecelinux","title":"1. Logging Into <code>ecelinux</code>","text":"<p>Follow the same process as previous labs. Find a free workstation and log into the workstation using your NetID and standard NetID password. Then complete the following steps. These are the same steps as in the first lab with one exception. We are now installing the VS Code Surfer extension to be able to view waveforms.</p> <ul> <li>Start VS Code</li> <li>Install the Remote-SSH extension and the Surfer extension</li> <li>Use View &gt; Command Palette to execute Remote-SSH: Connect Current Window to Host...</li> <li>Enter netid@ecelinux-XX.ece.cornell.edu where XX is an ecelinux server number</li> <li>Use View &gt; Explorer to open your home directory on ecelinux</li> <li>Use View &gt; Terminal to open a terminal on ecelinux</li> <li>Start MS Remote Desktop</li> </ul> <p></p> <p></p> <p>Now use the following commands to clone the repo we will be using for today's lab.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p ${HOME}/ece6745\n% cd ${HOME}/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-lab3 lab3\n% cd lab3\n% tree\n</code></pre> <p>Your repo contains the following directories:</p> <pre><code>.\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 asic\n\u2502   \u2514\u2500\u2500 build-fa\n\u2502       \u251c\u2500\u2500 01-verilator-rtlsim\n\u2502       \u251c\u2500\u2500 02-iverilog-rtlsim\n\u2502       \u251c\u2500\u2500 03-tinyflow-synth\n\u2502       \u2502   \u2514\u2500\u2500 run.py\n\u2502       \u2514\u2500\u2500 04-tinyflow-ffglsim\n\u251c\u2500\u2500 rtl\n\u2502   \u251c\u2500\u2500 FullAdder.v\n\u2502   \u2514\u2500\u2500 test\n\u2502       \u2514\u2500\u2500 FullAdder-test.v\n\u251c\u2500\u2500 stdcells\n\u2514\u2500\u2500 tinyflow\n    \u251c\u2500\u2500 synth\n    \u2502   \u251c\u2500\u2500 StdCellFrontEndView.py\n    \u2502   \u251c\u2500\u2500 TinyFrontEndDB.py\n    \u2502   \u251c\u2500\u2500 TinyFrontEndGUI.py\n    \u2502   \u251c\u2500\u2500 print_tree.py\n    \u2502   \u251c\u2500\u2500 substitute.py\n    \u2502   \u251c\u2500\u2500 techmap_unopt.py\n    \u2502   \u251c\u2500\u2500 tinyv.lark\n    \u2502   \u2514\u2500\u2500 verilog_parser.py\n    \u2514\u2500\u2500 tinyflow-synth\n</code></pre> <p>To make it easier to cut-and-paste commands from this handout onto the command line, you can tell Bash to ignore the <code>%</code> character using the following command:</p> <pre><code>% alias %=\"\"\n</code></pre> <p>Now you can cut-and-paste a sequence of commands from this tutorial document and Bash will not get confused by the <code>%</code> character which begins each line.</p> <p>Our frontend tools use the front-end view you developed in Project 1 Part A. Copy your front-end view file into the lab3 folder:</p> <pre><code>% cd ${HOME}/ece6745\n% cp project1-groupXX/stdcells/stdcells-fe.yml lab3/stdcells\n</code></pre>"},{"location":"ece6745-lab3-old/#2-data-structures","title":"2. Data Structures","text":"<p>As discussed in lecture, TinyFlow represents logic designs as trees of gates. Our synthesis tool will form these trees from Verilog and manipulate them through various transformations. The trees are stored in a data container called <code>TinyFrontEndDB</code>.</p> <p>To get started, create a build directory and start the TinyFlow REPL:</p> <pre><code>% mkdir -p ${HOME}/ece6745/lab3/tinyflow/build\n% cd ${HOME}/ece6745/lab3/tinyflow/build\n% ../tinyflow-synth\n\nTinyFlow Synth REPL v0.1\n\nType 'help()' for available commands.\nType 'clear()' to clear the screen.\nType 'exit()' or Ctrl-D to quit.\n\ntinyflow-synth&gt;\n</code></pre> <p>The <code>tinyflow-synth</code> tool is where we will implement our synthesis algorithms. It provides a REPL for interactive exploration.</p>"},{"location":"ece6745-lab3-old/#21-nodes-and-trees","title":"2.1. Nodes and Trees","text":"<p>The base class for all gates is <code>Node</code>. Generic gates (AND2, OR2, NAND2, NOR2, XOR2, NOT, INV, BUF) are Nodes that represent logic operations. Standard cell gates (INVX1, NAND2X1, NOR2X1, etc.) are Nodes read in from your front-end view. <code>Signal</code> nodes represent inputs and wires. There are also special <code>Wildcard</code> nodes that we will explain later. Let's create a simple tree and explore it:</p> <pre><code>tinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; tree = AND2(OR2(a, b), c)\ntinyflow-synth&gt; print(tree)\ntinyflow-synth&gt; print(tree.type)\ntinyflow-synth&gt; print(tree.generic)\ntinyflow-synth&gt; print(tree.children)\ntinyflow-synth&gt; print(tree.children[0].type)\ntinyflow-synth&gt; print(tree.children[1])\ntinyflow-synth&gt; print(tree.eval(a=1, b=0, c=1))\n</code></pre> <p>Each node has a <code>type</code> (the gate name), <code>children</code> (its inputs), and <code>generic</code> (True for generic gates, False for standard cell gates). Signal nodes are leaf nodes with no children. Nodes also provide helper methods: <code>is_signal()</code> returns <code>True</code> for Signal nodes, <code>is_wildcard()</code> returns <code>True</code> for Wildcard nodes, and <code>==</code>/<code>!=</code> compare nodes by type.</p> <pre><code>tinyflow-synth&gt; a.is_signal()\nTrue\ntinyflow-synth&gt; tree.is_signal()\nFalse\ntinyflow-synth&gt; _a.is_wildcard()\nTrue\ntinyflow-synth&gt; a == Signal(\"a\")\nTrue\ntinyflow-synth&gt; a == AND2(a, b)\nFalse\ntinyflow-synth&gt; AND2(a, b) == AND2(c, c)\nTrue\ntinyflow-synth&gt; AND2(a, b) == OR2(a, b)\nFalse\n</code></pre> <p>Go ahead and evaluate all input combinations using <code>tree.eval()</code> and derive the truth table for <code>AND2(OR2(a, b), c)</code>.</p>"},{"location":"ece6745-lab3-old/#23-frontend-database-and-gui","title":"2.3. Frontend Database and GUI","text":"<p>Now let's use the frontend database to manage a design. To create a database using <code>TinyFrontEndDB</code>, we first need to have our frontend view ready. <code>StdCellFrontEndView</code> loads the front-end view YAML file you created in Project 1 Part A. It provides access to cell information (area, timing parameters), patterns for technology mapping, and standard cell gate classes (INVX1, NAND2X1, etc.).</p> <p>Let's create the view and database:</p> <pre><code>tinyflow-synth&gt; view = StdCellFrontEndView.parse_lib(\"../../stdcells/stdcells-fe.yml\")\ntinyflow-synth&gt; db = TinyFrontEndDB(view)\n</code></pre> <p>The database supports visualizing its contents through a GUI. Enable the GUI with:</p> <p><pre><code>tinyflow-synth&gt; db.enable_gui()\n</code></pre> The GUI window will open. </p> <p></p> <p>Now add inputs, outputs, and set a tree:</p> <pre><code>tinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; db.add_inports([\"a\", \"b\", \"c\"])\ntinyflow-synth&gt; db.add_outports([\"out\"])\ntinyflow-synth&gt; db.set_tree(\"out\", AND2(OR2(a, b), c))\n</code></pre> <p>Watch the GUI update to show your tree when you call <code>db.set_tree(...)</code>.</p> <p></p> <p>In the visualization above, you will only see primary inputs, primary outputs, and generic gates. The GUI uses the following visual conventions:</p> <ul> <li>Green ovals: Primary inputs</li> <li>Orange ovals: Wire signals</li> <li>Blue ovals: Primary outputs</li> <li>Grey rectangles: Generic gates</li> <li>Red rectangles: Standard cell gates</li> </ul> <p></p> <p>Once you are done with the GUI, you can exit the REPL by calling <code>exit()</code> or pressing Ctrl-D.</p>"},{"location":"ece6745-lab3-old/#3-synthesis-algorithms","title":"3. Synthesis Algorithms","text":"<p>In this section we will implement a couple of algorithms that will warm you up for writing recursive functions and will be useful for Project 1 Part B. By the end of this lab, you will have a working naive technology mapping implementation that does the job but may not guarantee minimal area cost.</p>"},{"location":"ece6745-lab3-old/#31-verilog-parser","title":"3.1. Verilog Parser","text":"<p>The first step of our synthesis flow is parsing. The parser lexes the simple Verilog syntax, forms an Abstract Syntax Tree (AST), and performs \"forresting\" to translate the AST into the forests of logic trees used in TinyFlow.</p> <p>In this part, we will be discussing the limitations of verilog we can write for the TinyFlow. This limitation is mainly pedagogical to simplify the flow as well as limitations due to our parser (this does not mean our parser is not good).</p> <p>Rules:</p> <ol> <li>Only Combinational Verilog</li> <li>Only Use <code>wire</code> keyword instead of <code>logic</code></li> <li>Only Gate level modeling. However NOT using the gate primitives like <code>and(), or(), not()</code> instead we will be using <code>assign</code> statements with operators: <code>&amp;, |, ~, ^</code>.</li> <li>No hierarchy, every module is flat.</li> <li>No multibit wires. So you cannot declare something like <code>wire[7:0] foo</code> you need something like     <pre><code>wire foo0;\nwire foo1;\n...\nwire foo7;\n</code></pre></li> <li>Limitations on ports. Note this is a limitation for the physical tapeout and we will communicate with you the number of input and output pins your module will get.</li> </ol> <p>If you are ever confused take a look at the Lark grammar that we use to see what our parser should parse.</p> <p>The database includes a method to read in Verilog by passing the path to the Verilog file:</p> <pre><code>tinyflow-synth&gt; view = StdCellFrontEndView.parse_lib(\"../../stdcells/stdcells-fe.yml\")\ntinyflow-synth&gt; db = TinyFrontEndDB(view)\ntinyflow-synth&gt; db.enable_gui()\ntinyflow-synth&gt; db.read_verilog(\"../../rtl/FullAdder.v\")\n</code></pre> <p>Watch the GUI update to show the parsed trees.</p>"},{"location":"ece6745-lab3-old/#32-printing-trees","title":"3.2. Printing Trees","text":"<p>Before we implement more complex algorithms, let's warm up with a simple recursive function. Implement <code>print_tree(node, indent=0)</code> in <code>synth/print_tree.py</code> that prints a tree structure to the terminal. The function should recursively visit a node and its children, passing along the indentation level. At each node, print the indent amount of spaces first, then the node type (accessible via <code>node.type</code>). <code>Signal</code> nodes are leaf nodes and should print their name. For example, given <code>AND2(OR2(Signal(\"a\"), Signal(\"b\")), Signal(\"c\"))</code>, it should print:</p> <pre><code>AND2\n OR2\n  a\n  b\n c\n</code></pre> <p>Open the <code>synth/print_tree.py</code> file:</p> <pre><code>% cd ${HOME}/ece6745/lab3/tinyflow\n% code synth/print_tree.py\n</code></pre> <p>Here are some hints: The function takes a <code>node</code> and an <code>indent</code> level. First, print the indentation (one space per indent level). Then check if the node is a Signal (with <code>.is_signal()</code>): if so, print its name; otherwise, print the node's type and recursively call <code>print_tree</code> on each child with <code>indent + 1</code>.</p> <p>Once you are done with your implementation, test your function in the REPL:</p> <pre><code>tinyflow-synth&gt; a, b, c, d = Signal(\"a\"), Signal(\"b\"), Signal(\"c\"), Signal(\"d\")\ntinyflow-synth&gt; tree = AND2(OR2(a, b), c)\ntinyflow-synth&gt; print_tree(tree)\ntinyflow-synth&gt; tree = XOR2(AND2(a, b), OR2(c, d))\ntinyflow-synth&gt; print_tree(tree)\n</code></pre>"},{"location":"ece6745-lab3-old/#33-matching-trees","title":"3.3. Matching Trees","text":"<p>Building on the spirt of recursively travering trees, we now implement <code>match(n_node, p_node)</code> which compares two trees and returns <code>True</code> if they match, <code>False</code> otherwise. This function takes a node tree <code>n_node</code> and a pattern tree <code>p_node</code>.</p> <p>Here we introduce a new type of node called <code>Wildcard</code>. A wildcard matches any subtree. For example, the pattern <code>AND2(_a, _b)</code> matches <code>AND2(x, y)</code>, <code>AND2(OR2(a, b), c)</code>, or any other AND2 tree regardless of its children. The REPL provides predefined wildcards <code>_a</code>, <code>_b</code>, <code>_c</code>, <code>_d</code> for convenience. In this <code>match</code> function, you can assume only the pattern tree <code>p_node</code> can contain wildcards.</p> <p>Open <code>synth/substitute.py</code>:</p> <pre><code>% cd ${HOME}/ece6745/lab3/tinyflow\n% code synth/substitute.py\n</code></pre> <p>Here are some hints: The function traverses both trees together. First, check if <code>p_node</code> is a wildcard (using <code>.is_wildcard()</code>): if so, return <code>True</code> because wildcards match anything. Then compare <code>p_node</code> and <code>n_node</code>: if they are different (using <code>!=</code>), return <code>False</code>. These are the base cases. For the recursive case, maintain a match state (to track whether all children match) and iterate through both nodes' children together (using <code>zip</code>). Recursively compare each pair of children and accumulate the results for whether children match. Return the final match result.</p> <p>Test your implementation in the REPL:</p> <pre><code>tinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; match(AND2(a, b), AND2(_a, _b))\nTrue\ntinyflow-synth&gt; match(AND2(a, b), OR2(_a, _b))\nFalse\ntinyflow-synth&gt; match(AND2(OR2(a, b), c), AND2(_a, _b))\nTrue\n</code></pre>"},{"location":"ece6745-lab3-old/#34-capturing-subtrees","title":"3.4. Capturing Subtrees","text":"<p>Now that we can recursively compare two trees, we want to also capture whatever the wildcards in the pattern tree match to. The captures should be a dictionary mapping the wildcard name to the subtree it matched. For example, matching <code>AND2(OR2(a, b), c)</code> against pattern <code>AND2(_a, _b)</code> produces <code>{\"a\": OR2(a, b), \"b\": c}</code>.</p> <p>Implement <code>capture(n_node, p_node)</code> which is similar to <code>match</code> but returns a dictionary instead of <code>True</code>/<code>False</code>. Here we can assume that <code>n_node</code> and <code>p_node</code> already match (you should call <code>match</code> first before calling <code>capture</code>).</p> <p>Open <code>synth/substitute.py</code>:</p> <pre><code>% cd ${HOME}/ece6745/lab3/tinyflow\n% code synth/substitute.py\n</code></pre> <p>Here are some hints: Similar to <code>match</code>, first check if <code>p_node</code> is a wildcard. If so, return a dictionary with just the wildcard's name mapped to <code>n_node</code>. Otherwise, recursively call <code>capture</code> on both nodes' children (using <code>zip</code>) and merge the results. You can use <code>|=</code> to merge dictionaries.</p> <p>Test your implementation in the REPL:</p> <pre><code>tinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; n = AND2(OR2(a, b), c)\ntinyflow-synth&gt; p = AND2(_a, _b)\ntinyflow-synth&gt; if match(n, p):\n              &gt;     captures = capture(n, p)\n              &gt;     print(captures)\n{'a': OR2(a, b), 'b': c}\n</code></pre>"},{"location":"ece6745-lab3-old/#35-replacing-trees","title":"3.5. Replacing Trees","text":"<p>Now that we can match and capture subtrees, we want to build a new tree using the captured values. Implement <code>replace(t_node, captures)</code> which takes a template tree <code>t_node</code> (containing wildcards) and the captures dictionary, and returns a new tree with wildcards replaced by their corresponding captured subtrees.</p> <p>Open <code>synth/substitute.py</code>:</p> <pre><code>% cd ${HOME}/ece6745/lab3/tinyflow\n% code synth/substitute.py\n</code></pre> <p>Here are some hints: The goal is to return a node, and the parent call updates its children with what each recursive call returns. In each call we check if <code>t_node</code> is a wildcard: if so, return the corresponding captured subtree instead of the wildcard. Otherwise, recursively call <code>replace</code> on each child, collect the results into a new children list, update <code>t_node.children</code>, and return <code>t_node</code>.</p> <p>Test your implementation in the REPL:</p> <pre><code>tinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; n = AND2(OR2(a, b), c)\ntinyflow-synth&gt; p = AND2(_a, _b)\ntinyflow-synth&gt; t = INV(NAND2(_a, _b))\ntinyflow-synth&gt; if match(n, p):\n              &gt;     captures = capture(n, p)\n              &gt;     result = replace(t, captures)\n              &gt;     print(result)\nINV(NAND2(OR2(a, b), c))\n</code></pre>"},{"location":"ece6745-lab3-old/#36-substitution","title":"3.6. Substitution","text":"<p>Now that we have implemented <code>match</code> (to check if a tree matches a pattern), <code>capture</code> (to extract the subtrees that wildcards match), and <code>replace</code> (to build a new tree using captured subtrees), we have the core implementation for substitution in TinyFlow's frontend.</p> <p>Substitution is one of the core functionalities that enables the synthesis flow. In the standard cell frontend view, each standard cell defines patterns that describe how generic gates map to that cell. The view captures these patterns as <code>Substitute</code> objects that can be applied to trees in the database.</p> <p>The <code>Substitute</code> class is a container that holds a find pattern and a replace template. Go ahead and implement the <code>apply</code> method which combines <code>match</code>, <code>capture</code>, and <code>replace</code>:</p> <pre><code>def apply(self, node):\n  # if match, capture and replace; otherwise return None\n</code></pre> <p>Test your implementation in the REPL:</p> <pre><code>tinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; sub = Substitute(find=AND2(_a, _b), replace=INV(NAND2(_a, _b)))\ntinyflow-synth&gt; result = sub.apply(AND2(OR2(a, b), c))\ntinyflow-synth&gt; print(result)\nINV(NAND2(OR2(a, b), c))\n</code></pre>"},{"location":"ece6745-lab3-old/#37-naive-technology-mapping","title":"3.7. Naive Technology Mapping","text":"<p>In Project 1 Part B you will implement an optimized version of technology mapping. For this lab, we will implement a naive version that simply replaces each generic gate with a corresponding standard cell.</p> <p>The idea is to use your substitution implementation to define a pattern for each generic gate. For example, to map AND2 to NAND2X1 + INVX1:</p> <pre><code>Substitute(find=AND2(_a, _b), replace=view.INVX1(view.NAND2X1(_a, _b)))\n</code></pre> <p>Note that you can access standard cell classes directly from the view using <code>view.INVX1</code>, <code>view.NAND2X1</code>, etc.</p> <p>Implement <code>techmap_unopt</code> in <code>synth/techmap_unopt.py</code>. The function takes the database and view as arguments:</p> <pre><code>def techmap_unopt(db, view):\n</code></pre> <p>First, we will need to define substitution rules for each generic gate type (AND2, OR2, NOT, INV, BUF):</p> <pre><code>rules = [\n  Substitute(find=AND2(_a, _b), replace=view.INVX1(view.NAND2X1(_a, _b))),\n  Substitute(find=..., replace=...)\n  # ... add rules for XOR2, NOT, INV, BUF\n]\n</code></pre> <p>Next, implement an <code>apply_rules</code> helper function that recursively applies rules bottom-up. The key insight is that we must transform children first before transforming the current node. This ensures that when we match a pattern at a node, its children have already been mapped to standard cells. The function should: (1) return immediately for Signal nodes (base case), (2) recursively apply rules to all children first, (3) iterate through all rules and try each one on the current node - return the result as soon as a rule matches (first match wins), (4) return the node unchanged if no rules match.</p> <p>Finally, iterate through all trees in the database and apply the rules:</p> <pre><code>for name in list(db.trees.keys()):\n  tree = db.get_tree(name)\n  if tree is not None:\n    new_tree = apply_rules(tree)\n    db.set_tree(name, new_tree)\n</code></pre> <p>Test your implementation with the REPL and GUI. After running techmap, the grey generic gates should become red standard cell gates:</p> <pre><code>tinyflow-synth&gt; view = StdCellFrontEndView.parse_lib(\"../../stdcells/stdcells-fe.yml\")\ntinyflow-synth&gt; db = TinyFrontEndDB(view)\ntinyflow-synth&gt; db.enable_gui()\ntinyflow-synth&gt; db.read_verilog(\"../../rtl/FullAdder.v\")\ntinyflow-synth&gt; techmap_unopt(db, view)\n</code></pre>"},{"location":"ece6745-lab3-old/#4-the-frontend-flow","title":"4. The Frontend Flow","text":"<p>As discussed in lecture, the frontend is more than just synthesis. The frontend flow consists of four stages: two-state simulation, four-state simulation, synthesis, and fast-functional gate-level simulation. As paranoid ASIC engineers, we verify our design at each step. We simulate the RTL before synthesis to catch design bugs early, then simulate the gate-level netlist after synthesis to ensure the transformation preserved functionality.</p>"},{"location":"ece6745-lab3-old/#41-two-state-rtl-simulation","title":"4.1 Two-State RTL Simulation","text":"<p>To ensure functionality, the first step is to verify our design quickly using two-state simulation. Two-state simulation tests only logic values 1 and 0 to ensure basic logic correctness. In this part we will use Verilator to perform two-state simulation.</p> <p>In this lab we will verify a Full Adder design. We provide the Verilog RTL in <code>rtl/FullAdder.v</code> and a basic testbench in <code>rtl/test/FullAdder-test.v</code>. Take a look at both files to understand the design and test structure.</p> <p>Now run the two-state simulation with Verilator:</p> <pre><code>% cd $HOME/ece6745/lab3/asic/build-fa/01-verilator-rtlsim\n% verilator --top Top --timing --binary -o FullAdder-test \\\n    ../../../rtl/FullAdder.v \\\n    ../../../rtl/test/FullAdder-test.v\n% ./obj_dir/FullAdder_test\n</code></pre> <p>As discussed in lecture, two-state simulation has a limitation: unassigned signals default to 0. This can hide bugs in your design. For example, if you forget to assign an output, two-state simulation will silently use 0 instead of flagging an error.</p> <p>Try this experiment: comment out the <code>assign g = a &amp; b;</code> line in your Full Adder and re-run the simulation. Notice that <code>g</code> silently takes the value 0 instead of producing an error. This is why we need four-state simulation in the next step. Change the code back before continuing.</p>"},{"location":"ece6745-lab3-old/#42-four-state-rtl-simulation","title":"4.2 Four-State RTL Simulation","text":"<p>Four-state simulation uses four logic values: 0, 1, X (unknown), and Z (high impedance). You get X when a signal is uninitialized, when multiple drivers are fighting (contention), or through propagation of uncertainty (X propagates through logic). You get Z when a wire is floating (nothing is driving it) or from a tri-stated output.</p> <p>We use four-state simulation to capture these bugs. It is slower than two-state simulation, but it narrows down our issue search space. If your design passes two-state but fails four-state, the problem is usually related to X propagation or uninitialized signals.</p> <p>Go ahead and run the four-state simulation with Icarus Verilog:</p> <pre><code>% cd $HOME/ece6745/lab3/asic/build-fa/02-iverilog-rtlsim\n% iverilog -g2012 -I ../../../rtl -o FullAdder-test \\\n    ../../../rtl/test/FullAdder-test.v\n% ./FullAdder-test\n</code></pre> <p>Now try the same experiment: comment out the <code>assign g = a &amp; b;</code> line and re-run the simulation. This time you should see the simulation catch the error because <code>g</code> becomes X instead of silently defaulting to 0. Change the code back before continuing.</p>"},{"location":"ece6745-lab3-old/#43-synthesis","title":"4.3 Synthesis","text":"<p>Now that we have rigorously tested our Verilog design, we are ready to synthesize it into a gate-level netlist. For this step, we will use the batch processing mode of <code>tinyflow-synth</code> instead of the REPL mode we have previous used. The batch mode takes a run script that describes the synthesis steps.</p> <p>Go ahead and edit the run script:</p> <pre><code>% cd $HOME/ece6745/lab3/asic/build-fa/03-tinyflow-synth\n% code run.py\n</code></pre> <p>Populate the script with the commands to perform technology mapping:</p> <pre><code>view = StdCellFrontEndView.parse_lib(\"../../../stdcells/stdcells-fe.yml\")\ndb = TinyFrontEndDB(view)\ndb.read_verilog(\"../../../rtl/FullAdder.v\")\ntechmap_unopt(db, view)\ndb.write_verilog(\"post-synth.v\")\n</code></pre> <p>Now run the synthesis:</p> <pre><code>% ../../../tinyflow/tinyflow-synth -f run.py\n</code></pre> <p>This outputs the <code>post-synth.v</code> file. Open it and have a look. You should see that all gates are now standard cells from your library, and the module still has the same inputs and outputs as the original RTL.</p>"},{"location":"ece6745-lab3-old/#44-fast-functional-gate-level-simulation","title":"4.4 Fast-Functional Gate-Level Simulation","text":"<p>Now that we have our synthesized design, as paranoid ASIC engineers we want to double check that the synthesized design still does what we intended. Synthesis tools may not always be correct! To verify this, we perform fast-functional gate-level simulation (FFGL), which is four-state simulation using the same testbench but with the synthesized design and the behavioral view of the standard cells.</p> <p>First, copy over your <code>stdcells.v</code> from your project directory to the lab3 stdcells directory:</p> <pre><code>% cp $HOME/ece6745/project1-groupXX/stdcells/stdcells.v $HOME/ece6745/lab3/stdcells/\n</code></pre> <p>Now run the fast-functional gate-level simulation:</p> <pre><code>% cd $HOME/ece6745/lab3/asic/build-fa/04-iverilog-ffglsim\n% iverilog -g2012 -o FullAdder-test \\\n    ../../../stdcells/stdcells.v ../03-tinyflow-synth/post-synth.v \\\n    ../../../rtl/test/FullAdder-test.v\n% ./FullAdder-test\n</code></pre> <p>If the simulation passes, your synthesized design is functionally correct.</p>"},{"location":"ece6745-lab3-old/#45-exercise-design-a-decoder","title":"4.5 Exercise: Design a Decoder","text":"<p>You have now walked through the frontend flow with the Full Adder. For the final part of this lab, design your own module from scratch. Implement a simple 2-to-4 decoder and push it through the complete four-step flow. </p> <p>First, create the build directory structure:</p> <pre><code>% mkdir -p $HOME/ece6745/lab3/asic/build-decoder\n% cd $HOME/ece6745/lab3/asic/build-decoder\n% mkdir 01-verilator-rtlsim 02-iverilog-rtlsim 03-tinyflow-synth 04-iverilog-ffglsim\n</code></pre> <p>Next, write the Verilog RTL for your decoder:</p> <pre><code>% cd $HOME/ece6745/lab3/rtl\n% code Decoder.v\n</code></pre> <p>Then write a testbench for your decoder:</p> <pre><code>% cd $HOME/ece6745/lab3/rtl/test\n% code Decoder-test.v\n</code></pre> <p>Now run through the four-step frontend flow, referring back to sections 4.1-4.4 for the commands. Remember to update the file paths to use your decoder files instead of the Full Adder files.</p>"},{"location":"ece6745-lab3/","title":"ECE 6745 Lab 3: TinyFlow Front End","text":"<p>In this lab, we will explore the TinyFlow front-end which takes as input a Verilog RTL design and produces a gate-level netlist of standard cells. The complete TinyFlow standard-cell and ASIC design flow is shown below with the front end highlighted in red.</p> <p></p> <p>The front end includes two-state RTL simulation, four-state RTL simulation, synthesis, and fast-functional gate-level simulation. In lecture, we discussed an approach to synthesis based on technology mapping with dynamic programming to optimize the area of the final gate-level netlist. In this lab, we will be instead implementing a very simple unoptimized synthesis tool. The three key algorithms in the unoptimized synthesis tool are shown below.</p> <p></p> <p>We will be begin by exploring the key data structure used in the synthesis tool: a forest of trees where the nodes are generic gates, standard cells, or signals. We will then explore the verilog reader, implement an unoptimized technology mapping algorithm, use the provided gate-level netlist writer to generate the final Verilog gate-level netlist, and then put these algorithms together into a synthesis tool. Finally, we will go through the entire end-to-end front end flow for a full adder.</p>"},{"location":"ece6745-lab3/#1-logging-into-ecelinux","title":"1. Logging Into <code>ecelinux</code>","text":"<p>Follow the same process as previous labs. Find a free workstation and log into the workstation using your NetID and standard NetID password. Then complete the following steps. These are the same steps as in the previous lab with one exception. We are now installing the Verilog extension both on the workstation and on the remote server.</p> <ul> <li>Start VS Code</li> <li>Install the Remote-SSH extension, Surfer, and Verilog extensions</li> <li>Use View &gt; Command Palette to execute Remote-SSH: Connect Current Window to Host...</li> <li>Enter netid@ecelinux-XX.ece.cornell.edu where XX is an ecelinux server number</li> <li>Find the Verilog extension again and install on the remote server</li> <li>Use View &gt; Explorer to open your home directory on ecelinux</li> <li>Use View &gt; Terminal to open a terminal on ecelinux</li> <li>Start MS Remote Desktop</li> </ul> <p></p> <p>Now use the following commands to clone the repo we will be using for today's lab.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p ${HOME}/ece6745\n% cd ${HOME}/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-lab3 lab3\n% cd lab3\n% tree\n</code></pre> <p>Your repo contains the following files.</p> <pre><code>.\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 asic\n\u2502   \u2514\u2500\u2500 build-fa\n\u2502       \u251c\u2500\u2500 01-verilator-rtlsim\n\u2502       \u251c\u2500\u2500 02-iverilog-rtlsim\n\u2502       \u251c\u2500\u2500 03-tinyflow-synth\n\u2502       \u2502   \u2514\u2500\u2500 run.py\n\u2502       \u2514\u2500\u2500 04-tinyflow-ffglsim\n\u251c\u2500\u2500 rtl\n\u2502   \u251c\u2500\u2500 FullAdder.v\n\u2502   \u2514\u2500\u2500 test\n\u2502       \u2514\u2500\u2500 FullAdder-test.v\n\u251c\u2500\u2500 stdcells\n\u2514\u2500\u2500 tinyflow\n    \u251c\u2500\u2500 synth\n    \u2502   \u251c\u2500\u2500 StdCellFrontEndView.py\n    \u2502   \u251c\u2500\u2500 TinyFrontEndDB.py\n    \u2502   \u251c\u2500\u2500 TinyFrontEndGUI.py\n    \u2502   \u251c\u2500\u2500 print.py\n    \u2502   \u251c\u2500\u2500 substitute.py\n    \u2502   \u251c\u2500\u2500 techmap_unopt.py\n    \u2502   \u251c\u2500\u2500 tinyv.lark\n    \u2502   \u2514\u2500\u2500 verilog_parser.py\n    \u2514\u2500\u2500 tinyflow-synth\n</code></pre> <p>Our front-end flow use the behavioral and front-end views you developed in Project 1, Part A. Copy these views into the lab3 directory.</p> <pre><code>% cd ${HOME}/ece6745/lab3/stdcells\n% cp project1-groupXX/stdcells/stdcells.v .\n% cp project1-groupXX/stdcells/stdcells-fe.yml .\n</code></pre> <p>where <code>XX</code> is your group number.</p> <p>To make it easier to cut-and-paste commands from this handout onto the command line, you can tell Bash to ignore the <code>%</code> character using the following command:</p> <pre><code>% alias %=\"\"\n</code></pre> <p>Now you can cut-and-paste a sequence of commands from this tutorial document and Bash will not get confused by the <code>%</code> character which begins each line.</p>"},{"location":"ece6745-lab3/#2-data-structure-forest-of-trees","title":"2. Data Structure: Forest of Trees","text":"<p>As discussed in lecture, the synthesis data structure used in our basic front-end is a forest of trees where nodes can be generic gates, standard cells, or signals. The synthesis algorithms create, transform, and analyze this forest of trees. The forest of trees is stored in a front-end database which includes methods for reading files into the databse and writing files from the database. We provide students the database, and students are responsible for writing the algorithms.</p> <p>To get started, create a build directory and start the TinyFlow synthesis REPL.</p> <pre><code>% mkdir -p ${HOME}/ece6745/lab3/tinyflow/build\n% cd ${HOME}/ece6745/lab3/tinyflow/build\n% ../tinyflow-synth\n</code></pre> <p>You should see the following:</p> <pre><code>TinyFlow Synth REPL v0.1\n\nType 'help()' for available commands.\nType 'clear()' to clear the screen.\nType 'exit()' or Ctrl-D to quit.\n\ntinyflow-synth&gt;\n</code></pre> <p><code>tinyflow-synth&gt;</code> is the TinyFlow synthesis REPL prompt which will enable you to intereactively experiment with different synthesis data structures and algorithms. The TinyFlow synthesis REPL is basically the Python REPL with a few extra features so most standard Python command should work as well. You can use <code>help()</code> to see the available commands.</p>"},{"location":"ece6745-lab3/#21-trees","title":"2.1. Trees","text":"<p>The nodes in a tree can either be generic gates, standard cells, or signals. The base class for all nodes is <code>Node</code>.</p> <ul> <li> <p>Generic-gate nodes represent generic logic operations. There is no area    nor delay associated with a generic logic operation. Generic-gate    nodes are named without an X1 suffix (e.g., BUF, NOT, INV, AND2, OR2,    XOR, NAND2, NOR2, XNOR2).</p> </li> <li> <p>Standard-cell nodes represent standard cells from our library. The    front-end view provides the list of valid standard-cell nodes and the    associated area and delay. Standard-cell nodes are named with an X1    suffix (e.g., INVX1, NAND2X1, NOR2X1, AOI21X1).</p> </li> <li> <p>Signal nodes represent input ports and wires. Every leaf of all every    tree must be a signal node.</p> </li> </ul> <p>There are also special <code>Wildcard</code> nodes that we will explain later. Let's start by creating three signals and a simple tree with a total of five nodes: two generic-gate nodes and three signal nodes.</p> <pre><code>tinyflow-synth&gt; a = Signal(\"a\")\ntinyflow-synth&gt; b = Signal(\"b\")\ntinyflow-synth&gt; c = Signal(\"c\")\ntinyflow-synth&gt; tree1 = AND2( OR2(a, b), c )\ntinyflow-synth&gt; print(tree1)\n</code></pre> <p>Note that the TinyFlow REPL will automatically ignore the leading <code>tinyflow-synth&gt;</code> so you should be able to copy-and-paste the above commands directly into the REPL.</p> <p>Every node has a <code>type</code> field and a list of its children. Let's print the type of every node in the tree.</p> <pre><code>tinyflow-synth&gt; print(tree1.type)\ntinyflow-synth&gt; print(tree1.children[0].type)\ntinyflow-synth&gt; print(tree1.children[0].children[0].type)\ntinyflow-synth&gt; print(tree1.children[0].children[1].type)\ntinyflow-synth&gt; print(tree1.children[1].type)\n</code></pre> <p>Each node also has the following helper methods</p> <ul> <li><code>is_generic_gate()</code></li> <li><code>is_standard_cell()</code></li> <li><code>is_signal()</code></li> <li><code>is_wildcard()</code></li> </ul> <p>Go ahead and check to see which of the five nodes are generic-gate nodes.</p> <pre><code>tinyflow-synth&gt; tree1.is_generic_gate()\ntinyflow-synth&gt; tree1.children[0].is_generic_gate()\ntinyflow-synth&gt; tree1.children[0].children[0].is_generic_gate()\ntinyflow-synth&gt; tree1.children[0].children[1].is_generic_gate()\ntinyflow-synth&gt; tree1.children[1].is_generic_gate()\n</code></pre> <p>The <code>==</code>/<code>!=</code> operators compare nodes by type. You can also evaluate a tree using the <code>eval</code> method. So the following will evaluate our tree when the input ports are set to the given values.</p> <pre><code>tinyflow-synth&gt; print(tree1.eval(a=0, b=0, c=0))\n</code></pre> <p>Go ahead and evaluate all input combinations using <code>tree.eval()</code> and derive the truth table for <code>AND2(OR2(a, b), c)</code>. Does it match your expectations?</p> <p>Use the TinyFlow REPL to create the following tree.</p> <p></p> <p>Evaluate all possible inputs to confirm that it implements the following truth table.</p> a b c y 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 0"},{"location":"ece6745-lab3/#22-front-end-database","title":"2.2. Front-End Database","text":"<p>The front-end database stores a forest of trees. To create a database using <code>TinyFrontEndDB</code>, we first need to have our front-end view ready. <code>StdCellFrontEndView</code> loads the front-end view YAML file. It provides access to cell information (area, timing parameters), patterns for technology mapping, and standard cell gate classes (INVX1, NAND2X1, etc.).</p> <p>Let's create the view and database:</p> <pre><code>tinyflow-synth&gt; view = StdCellFrontEndView.parse_lib(\"../../stdcells/stdcells-fe.yml\")\ntinyflow-synth&gt; db = TinyFrontEndDB(view)\n</code></pre> <p>The database supports visualizing its contents through a GUI. Enable the GUI with:</p> <p><pre><code>tinyflow-synth&gt; db.enable_gui()\n</code></pre> The GUI window will open.</p> <p></p> <p>Now add inputs, outputs, and set a tree:</p> <pre><code>tinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; db.add_inports([\"a\", \"b\", \"c\"])\ntinyflow-synth&gt; db.add_outports([\"out\"])\ntinyflow-synth&gt; db.set_tree(\"out\", AND2(OR2(a, b), c))\ntinyflow-synth&gt; db.get_tree(\"out\")\n</code></pre> <p>Watch the GUI update to show your tree when you call <code>db.set_tree(...)</code>.</p> <p></p> <p>In the visualization above, you will only see primary inputs, primary outputs, and generic gates. The GUI uses the following visual conventions:</p> <ul> <li>Green ovals: Primary inputs</li> <li>Orange ovals: Wire signals</li> <li>Blue ovals: Primary outputs</li> <li>Grey rectangles: Generic gates</li> <li>Red rectangles: Standard cell gates</li> </ul> <p></p> <p>Add the following tree to the front-end database and verify you can see both the old and new tree in the GUI.</p> <p></p> <p>Once you are done with the GUI, you can exit the REPL by calling <code>exit()</code> or pressing Ctrl-D.</p>"},{"location":"ece6745-lab3/#22-printing-trees-and-forests","title":"2.2. Printing Trees and Forests","text":"<p>Let's write some functions to print trees and forests. Open the <code>print.py</code> file in VS Code.</p> <pre><code>% cd ${HOME}/ece6745/lab3/tinyflow/build\n% code ../synth/print.py\n</code></pre> <p>Find the <code>print_tree</code> and <code>print_tree_h</code> functions.</p> <pre><code>def print_tree_h( node, indent ):\n  ...\n\ndef print_tree( db, name ):\n  ...\n</code></pre> <p>The <code>print_tree</code> function takes as input the front-end database and the name of the tree to print (i.e., the name of the output port at the root of the tree) and should print each node in the tree using indentation to indicate the depth of the node. So printing the <code>AND2(OR2(a, b), c))</code> tree should output</p> <pre><code>AND2\n  OR2\n    a\n    b\n  c\n</code></pre> <p>The <code>print_tree</code> function should get the correct tree from the database and then call the recursive <code>print_tree_h</code> helper function. The recursive helper function should use a preorder tree traversal to print the tree:</p> <ul> <li>Step 1: Print leading spaces based on <code>indent</code></li> <li>Step 2: Print the type for a generic-gate node or the name for a signal node</li> <li>Step 3: Recusively call helper function for all children with <code>indent+1</code></li> </ul> <p>Once you have finished writing your <code>print_tree</code> function try it out using the TinyFlow REPL.</p> <pre><code>tinyflow-synth&gt; view = StdCellFrontEndView.parse_lib(\"../../stdcells/stdcells-fe.yml\")\ntinyflow-synth&gt; db = TinyFrontEndDB(view)\ntinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; db.add_inports([\"a\", \"b\", \"c\"])\ntinyflow-synth&gt; db.add_outports([\"out\"])\ntinyflow-synth&gt; db.set_tree(\"out\", AND2(OR2(a, b), c))\ntinyflow-synth&gt; print_tree( db, \"out\" )\n</code></pre> <p>Now find the <code>print_forest</code> function.</p> <pre><code>def print_forest( db ):\n  ...\n</code></pre> <p>This function should iterate across all trees in the forest and print each one using <code>print_tree</code>. Trees are stored as a dictionary in the database. The dictionary maps the name of the tree (i.e, the name of the output port or wire) to the actual tree. So you can iterate over the trees in a front-end database like this.</p> <pre><code>  for name,tree in db.trees.items():\n    ... do something with the name and/or tree ...\n</code></pre> <p>Once you have finished writing your <code>print_forest</code> function try it out using the TinyFlow REPL.</p> <pre><code>tinyflow-synth&gt; view = StdCellFrontEndView.parse_lib(\"../../stdcells/stdcells-fe.yml\")\ntinyflow-synth&gt; db = TinyFrontEndDB(view)\n\ntinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; db.add_inports([\"a\", \"b\", \"c\"])\ntinyflow-synth&gt; db.add_outports([\"out1\"])\ntinyflow-synth&gt; db.set_tree(\"out1\", AND2(OR2(a, b), c))\n\ntinyflow-synth&gt; d, e, f = Signal(\"d\"), Signal(\"e\"), Signal(\"f\")\ntinyflow-synth&gt; db.add_inports([\"d\", \"e\", \"f\"])\ntinyflow-synth&gt; db.add_outports([\"out2\"])\ntinyflow-synth&gt; db.set_tree(\"out2\", INV(OR2(AND2(a, b), c)))\n\ntinyflow-synth&gt; print_forest(db)\n</code></pre>"},{"location":"ece6745-lab3/#3-algorithm-verilog-reader","title":"3. Algorithm: Verilog Reader","text":"<p>The first step of our synthesis flow is reading the Verilog RTL design to create the forest of trees data structure. This has three steps: lexing, parsing, and foresting.</p> <p>In this part, we will be discussing the limitations of verilog we can write for the TinyFlow. This limitation is mainly pedagogical to simplify the flow as well as limitations due to our parser. First let's look at the full adder we will be using as the motivation example in his lab.</p> <pre><code>% cd ${HOME}/ece6745/lab3/tinyflow/build\n% code ../../rtl/FullAdder.v\n</code></pre> <p>The full adder adheres to the following rules.</p> <ol> <li>Only combinational Verilog</li> <li>Only single-bit signals of type <code>wire</code></li> <li>Only single-bit bitwise operators (<code>&amp;</code>, <code>|</code>, <code>^</code>, <code>~</code>)</li> <li>No hierarchy</li> </ol> <p>Take a look at the Lark grammar which captures these rules.</p> <pre><code>% cd ${HOME}/ece6745/lab3/tinyflow/build\n% code ../synth/tinyv-lab3.lark\n</code></pre> <p>The grammer is shown below.</p> <pre><code>start: module\n\n//------------------------------------------------------------------------\n// Module\n//------------------------------------------------------------------------\n\nmodule: \"module\" MNAME port_decl_list? \";\" stmt* \"endmodule\"\n\nport_decl_list: \"(\" port_decl (\",\" port_decl)* \")\"\nport_decl: DIR (\"wire\" | \"logic\")? SIGNAL\nDIR: \"input\" | \"output\"\n\nstmt: decl_wire | assignment\n\n//------------------------------------------------------------------------\n// Statements\n//------------------------------------------------------------------------\n\ndecl_wire:  \"wire\" SIGNAL (\",\" SIGNAL)* \";\"\nassignment: \"assign\" SIGNAL \"=\" expr \";\"\n\n//------------------------------------------------------------------------\n// Expressions\n//------------------------------------------------------------------------\n\n?expr:\n  | expr \"|\" expr -&gt; or\n  | expr \"^\" expr -&gt; xor\n  | expr \"&amp;\" expr -&gt; and\n  | expr \"+\" expr -&gt; sum\n  | \"~\" expr      -&gt; not\n  | \"(\" expr \")\"\n  | SIGNAL\n\n//------------------------------------------------------------------------\n// Terminals\n//------------------------------------------------------------------------\n\nSIGNAL:  /[a-zA-Z_][a-zA-Z0-9_]*/\nMNAME:   /[a-zA-Z_][a-zA-Z0-9_]*/\n</code></pre> <p>The front-end database includes a <code>parse_verilog</code> method which will perform lexing and parsing for a Verilog RTL design before displaying the AST.</p> <pre><code>tinyflow-synth&gt; view = StdCellFrontEndView.parse_lib(\"../../stdcells/stdcells-fe.yml\")\ntinyflow-synth&gt; db = TinyFrontEndDB(view)\ntinyflow-synth&gt; db.parse_verilog(\"../../rtl/FullAdder.v\")\n</code></pre> <p>Try to see how the AST corresponds to the Verilog RTL design. Now let's use the <code>read_verilog</code> method to do all three steps: lexing, parsing, and foresting. Watch the GUI update to show the parsed trees.</p> <pre><code>tinyflow-synth&gt; db.enable_gui()\ntinyflow-synth&gt; db.read_verilog(\"../../rtl/FullAdder.v\")\n</code></pre>"},{"location":"ece6745-lab3/#4-algorithm-unoptimized-technology-mapping","title":"4. Algorithm: Unoptimized Technology Mapping","text":"<p>Our unoptimized technology mapping algorithm will be very simple. It will replace every generic gate with a logically equivalent subtree of standard cells. We will not be trying to optimize area. We are simply trying to develop the most basic possible technology mapping algorithm.</p> <p>We will develop a subtree substitution framework which we can then use to implement the unoptimized technology mapping algorithm. You can also use this subtree substitution framework to implement canoncalization and optimized technology mapping in the project. The subtree substitution framework will enable us to create a substitute like this:</p> <pre><code>Substitute( find=AND2(_0, _1), replace=INV(NAND2(_0, _1) ))\n</code></pre> <p>Once we have created a substitute we can apply to a tree. So applying the above subsittute would find every AND2 generig cate and replace it with a new INV/NAND2 subtree. Substitutes make use of wildcard nodes which are denoted using <code>_0</code>, <code>_1</code>, <code>_2</code>, and <code>_3</code>. A wildcard node will matches any subtree.</p> <p>So let's say we start with the tree on the left and we want to apply the above substitute to create the tree on the right.</p> <p></p> <p>Our goal is to be able to do this as follows.</p> <pre><code>tinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; sub = Substitute(find=AND2(_0, _1), replace=INV(NAND2(_0, _1)))\ntinyflow-synth&gt; result = sub.apply(AND2(OR2(a, b), c))\ntinyflow-synth&gt; print(result)\n</code></pre> <p>This is pretty complicated to implement, so we will take an incremental approach. We will start by implementing an exact match algorithm before implementing a partial match algorithm. Then we will work on capturing the wildcard subtrees from a partial match. We will implement the actual replacement before finalyl creating a substitution. Then we can use this to implement the unoptimized technology mapping.</p>"},{"location":"ece6745-lab3/#41-exactly-matching-trees","title":"4.1. Exactly Matching Trees","text":"<p>Our first step is to implement an exact match algorithm. Our earlier work on printing trees only traversed a single tree. Here we will need to recurse two trees in parallel to see if they match exactly.</p> <p>Open the <code>substitute.py</code> file in VS Code.</p> <pre><code>% cd ${HOME}/ece6745/lab3/tinyflow/build\n% code ../synth/substitute.py\n</code></pre> <p>Find the <code>match_exact</code> function in <code>substitute.py</code>.</p> <pre><code>def match_exact( node, p_node ):\n  ...\n</code></pre> <p>This recursive function takes as input two nodes in two trees and compares the corresponding subtrees starting from these two nodes using the following steps.</p> <ul> <li> <p>Base Case: If the nodes are not equal return false</p> </li> <li> <p>Recursive Case: Recursively call function for all children, keep track    if any children return false and if so then this function should    return false, otherwise return true</p> </li> </ul> <p>You can use the Python <code>zip</code> function to easily iterate over the children of both nodes together like this:</p> <pre><code>  for p_child, n_child in zip( p_node.children, node.children ):\n    ... do something with p_child and n_child ...\n</code></pre> <p>Once you have implemented your exact match algorithm, try it out using the TinyFlow REPL.</p> <pre><code>tinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; match_exact( AND2(OR2(a,b), c), AND2(OR2(a,b), c) )\ntinyflow-synth&gt; match_exact( AND2(OR2(a,b), c), OR2(AND2(a,b), c) )\ntinyflow-synth&gt; match_exact( AND2(OR2(a,b), c), AND2(a,b) )\n</code></pre>"},{"location":"ece6745-lab3/#42-partially-matching-trees","title":"4.2. Partially Matching Trees","text":"<p>Now that we know how to recursively traverse two trees in parallel, let's implement a partial match algorithm. Here is where we will start to take advantage of wildcards. A wildcard matches any subtree. The REPL provides predefined wildcards <code>_0</code>, <code>_1</code>, <code>_2</code>, <code>_3</code> for convenience. For example, if we have the tree below on the left, we want to be able to determine that the pattern on the right matches since there is an AND2 gate at the root of the tree on the left.</p> <p></p> <p></p> <p></p> <p>Find the <code>match</code> function in <code>substitute.py</code>.</p> <pre><code>def match( node, p_node ):\n  ...\n</code></pre> <p>This recursive function takes as input two nodes in two trees. The <code>p_node</code> tree is the pattern tree (i.e., the tree with wildcards) while the <code>node</code> tree is the tree want want to search over. The function compares the corresponding subtrees starting from these two nodes using the following steps.</p> <ul> <li> <p>Base Case 1: If the current <code>p_node</code> is a wildcard (i.e.,    <code>is_wildcard()</code> returns true) then it always matches the corresponding    <code>node</code> so return true.</p> </li> <li> <p>Base Case 2: If the current <code>p_node</code> does not equal the current    <code>node</code> (i.e., use <code>!=</code> which compares the types of the two nodes) then    there is no match so return false.</p> </li> <li> <p>Recursive Case: Recursively call function for all children, keep    track if any children return false and if so then this function should    return false, otherwise return true</p> </li> </ul> <p>Test your implementation in the REPL:</p> <pre><code>tinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; match( AND2(OR2(a,b), c), AND2(OR2(_0,_1), _2) )\ntinyflow-synth&gt; match( AND2(OR2(a,b), c), OR2(AND2(_0,_1), _2) )\ntinyflow-synth&gt; match( AND2(OR2(a,b), c), AND2(_0,_1) )\ntinyflow-synth&gt; match( INV(OR2(AND2(a,b), c)), INV(OR2(_0,_1)) )\ntinyflow-synth&gt; match( INV(OR2(AND2(a,b), c)), INV(_0) )\n</code></pre> <p>Notice how the final three matches should return true since the pattern partially matches the given tree.</p>"},{"location":"ece6745-lab3/#43-capturing-wildcard-subtrees","title":"4.3. Capturing Wildcard Subtrees","text":"<p>Now that we can recursively compare two trees, we want to also capture whatever the wildcards in the pattern tree match to. So in the following example, wildcard <code>_0</code> captures the <code>OR(a,b)</code> subtree and wildcard <code>_1</code> captures the <code>c</code> signal node.</p> <p></p> <p>The captures should be a dictionary mapping the wildcard name to the subtree it matched. For example, matching <code>AND2(OR2(a, b), c)</code> against pattern <code>AND2(_0, _1)</code> produces <code>{\"_0\": OR2(a, b), \"_1\": c}</code>.</p> <p>Find the <code>capture</code> function in <code>substitute.py</code>.</p> <pre><code>def capture( node, p_node ):\n  ...\n</code></pre> <p>This recursive function takes as input two nodes in two trees. The <code>p_node</code> tree is the pattern tree (i.e., the tree with wildcards) while the <code>node</code> tree is the tree want want to search over. The <code>capture</code> algorithm can assume we have already used the <code>match</code> algorithm to confirm there is indeed a partial match. The function compares the corresponding subtrees starting from these two nodes using the following steps.</p> <ul> <li> <p>Base Case: If the current <code>p_node</code> is a wildcard (i.e.,    <code>is_wildcard()</code> returns true) then we want to capture the    corresponding subtree starting at <code>node</code>. Return a new dictionary that    maps the wild card name (i.e., <code>p_node.name</code>) to <code>node</code>.</p> </li> <li> <p>Recursive Case: Recursively call function for all children, keep a    running dictionary and merge in the dictionary returned from each    recursive function call. You can use the <code>|=</code> operator to merge a new    dictionary into an existing dictionary.</p> </li> </ul> <p>Test your implementation in the REPL:</p> <pre><code>tinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; capture( AND2(OR2(a,b), c), AND2(_0,_1) )\ntinyflow-synth&gt; capture( INV(OR2(AND2(a,b), c)), INV(OR2(_0,_1)) )\ntinyflow-synth&gt; capture( INV(OR2(AND2(a,b), c)), INV(_0) )\n</code></pre>"},{"location":"ece6745-lab3/#44-replacing-trees","title":"4.4. Replacing Trees","text":"<p>Now that we can match and capture subtrees, we want to build a new tree using the captured subtrees. Find the <code>replace</code> function in <code>substitute.py</code>.</p> <pre><code>def replace( t_node, captures ):\n  ...\n</code></pre> <p>This recursive function takes as input a node in the template tree and the captures. The tempalte tree is the tree that we want to insert the captured subtrees. The function should use the following steps.</p> <ul> <li> <p>Base Case: If the current <code>t_node</code> is a wildcard (i.e.,    <code>is_wildcard()</code> returns true) then we want to insert the corresponding    captured subtree at this point. So all we need to do is look up the    wildcard in the captures dictionary (i.e., <code>captures[t_node.name]</code>)    and return the result.</p> </li> <li> <p>Recursive Case: Recursively call function for all children and append    the subtree returned from each recursive function call to running list    of new children. Once you have finished iterating over all of the    children create a copy of the current <code>t_node</code> using the list of    children (e.g., <code>type(t_node)(*children)</code>). Return this new node.</p> </li> </ul> <p>Test your implementation in the REPL:</p> <pre><code>tinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; n = AND2(OR2(a, b), c)\ntinyflow-synth&gt; p = AND2(_a, _b)\ntinyflow-synth&gt; t = INV(NAND2(_a, _b))\ntinyflow-synth&gt; captures = capture(n, p)\ntinyflow-synth&gt; replace(t, captures)\n</code></pre>"},{"location":"ece6745-lab3/#45-substitutions","title":"4.5. Substitutions","text":"<p>Now that we have implemented <code>match</code> (to check if a tree matches a pattern), <code>capture</code> (to extract the subtrees that wildcards match), and <code>replace</code> (to build a new tree using captured subtrees), we have the core implementation for the substitution framework.</p> <p>The <code>Substitute</code> class is a container that holds a find pattern and a replace template. Find the <code>Substitute</code> class in <code>substitute.py</code>. Go ahead and implement the <code>apply</code> method which combines <code>match</code>, <code>capture</code>, and <code>replace</code>:</p> <pre><code>def apply(self, node):\n  ...\n</code></pre> <p>The basic approach is:</p> <ul> <li>use the match function to see if there is match between the given node    and the stored find pattern</li> <li>if there is a match, then use the capture function to capture the    wildcard subtrees, and the replace these captures</li> </ul> <p>Test your implementation in the REPL:</p> <pre><code>tinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; sub = Substitute(find=AND2(_a, _b), replace=INV(NAND2(_a, _b)))\ntinyflow-synth&gt; result = sub.apply(AND2(OR2(a, b), c))\ntinyflow-synth&gt; print(result)\n</code></pre>"},{"location":"ece6745-lab3/#46-unoptimized-technology-mapping","title":"4.6. Unoptimized Technology Mapping","text":"<p>Now we can use our substitution framework to implement unoptimized technology mapping where we replace each generic gate with a corresponding standard cell. For example, to map AND2 to NAND2X1 + INVX1:</p> <pre><code>Substitute(find=AND2(_a, _b), replace=view.INVX1(view.NAND2X1(_a, _b)))\n</code></pre> <p>Note that you can access standard cell classes directly from the view using <code>view.INVX1</code>, <code>view.NAND2X1</code>, etc.</p> <p>Implement <code>techmap_unopt</code> in <code>synth/techmap_unopt.py</code>. The function takes the database and view as arguments:</p> <pre><code>def techmap_unopt(db, view):\n  ...\n</code></pre> <p>First, we will need to define substitution rules for each generic gate type. Just focus on the gates we need for the full adder: AND2, OR2, NOT.</p> <pre><code>rules = [\n  Substitute(find=AND2(_0, _1), replace=view.INVX1(view.NAND2X1(_0, _1))),\n  Substitute(find=OR2(_0, _1),  replace=...),\n  Substitute(find=NOT(_0),      replace=...),\n]\n</code></pre> <p>Next, implement an <code>apply_rules</code> helper function that recursively applies rules bottom-up. The key insight is that we must transform children first before transforming the current node. This ensures that when we match a pattern at a node, its children have already been mapped to standard cells. The function should: (1) return immediately for Signal nodes (base case), (2) recursively apply rules to all children first, (3) iterate through all rules and try each one on the current node -- return the result as soon as a rule matches (first match wins), (4) return the node unchanged if no rules match.</p> <p>Finally, iterate through all trees in the database and apply the rules:</p> <pre><code>for name in list(db.trees.keys()):\n  tree = db.get_tree(name)\n  new_tree = apply_rules(tree)\n  db.set_tree(name, new_tree)\n</code></pre> <p>Test your implementation with the REPL and GUI. After running techmap, the grey generic gates should become red standard cell gates:</p> <pre><code>tinyflow-synth&gt; view = StdCellFrontEndView.parse_lib(\"../../stdcells/stdcells-fe.yml\")\ntinyflow-synth&gt; db = TinyFrontEndDB(view)\ntinyflow-synth&gt; db.enable_gui()\ntinyflow-synth&gt; db.read_verilog(\"../../rtl/FullAdder.v\")\ntinyflow-synth&gt; techmap_unopt(db, view)\n</code></pre>"},{"location":"ece6745-lab3/#5-algorithm-gate-level-netlist-writer","title":"5. Algorithm: Gate-Level Netlist Writer","text":"<p>We provide you a gate-level netlist writer which will write a forest of trees of standard-cell nodes to a Verilog file. You can try it out like this.</p> <pre><code>tinyflow-synth&gt; view = StdCellFrontEndView.parse_lib(\"../../stdcells/stdcells-fe.yml\")\ntinyflow-synth&gt; db = TinyFrontEndDB(view)\ntinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; db.add_inports([\"a\", \"b\", \"c\"])\ntinyflow-synth&gt; db.add_outports([\"out1\"])\ntinyflow-synth&gt; db.set_tree(\"out1\", view.NAND2X1(view.NOR2X1(a, b), c))\ntinyflow-synth&gt; db.write_verilog(\"test.v\")\ntinyflow-synth&gt; exit()\n</code></pre> <p>Now take a look at the generated Verilog gate-level netlist.</p> <pre><code>% cd ${HOME}/ece6745/lab3/tinyflow/build\n% cat test.v\n</code></pre>"},{"location":"ece6745-lab3/#6-tinyflow-front-end","title":"6. TinyFlow Front End","text":"<p>As discussed in lecture, the front end is more than just synthesis. The front-end flow consists of four stages: two-state simulation, four-state simulation, synthesis, and fast-functional gate-level simulation. As paranoid ASIC engineers, we verify our design at each step. We simulate the RTL before synthesis to catch design bugs early, then simulate the gate-level netlist after synthesis to ensure the transformation preserved functionality.</p>"},{"location":"ece6745-lab3/#41-two-state-rtl-simulation","title":"4.1 Two-State RTL Simulation","text":"<p>To ensure functionality, the first step is to verify our design quickly using two-state simulation. Two-state simulation tests only logic values 1 and 0 to ensure basic logic correctness. In this part we will use Verilator to perform two-state simulation.</p> <p>In this lab we will verify a Full Adder design. We provide the Verilog RTL in <code>rtl/FullAdder.v</code> and a basic testbench in <code>rtl/test/FullAdder-test.v</code>. Take a look at both files to understand the design and test structure.</p> <p>Now run the two-state simulation with Verilator:</p> <pre><code>% cd $HOME/ece6745/lab3/asic/build-fa/01-verilator-rtlsim\n% verilator --top Top --timing --binary -o FullAdder-test \\\n    ../../../rtl/FullAdder.v \\\n    ../../../rtl/test/FullAdder-test.v\n% ./obj_dir/FullAdder-test\n</code></pre> <p>As discussed in lecture, two-state simulation has a limitation: unassigned signals default to 0. This can hide bugs in your design. For example, if you forget to assign an output, two-state simulation will silently use 0 instead of flagging an error.</p> <p>Try this experiment: comment out the <code>assign g = a &amp; b;</code> line in your Full Adder and re-run the simulation. Notice that <code>g</code> silently takes the value 0 instead of producing an error. This is why we need four-state simulation in the next step. Change the code back before continuing.</p>"},{"location":"ece6745-lab3/#42-four-state-rtl-simulation","title":"4.2 Four-State RTL Simulation","text":"<p>Four-state simulation uses four logic values: 0, 1, X (unknown), and Z (high impedance). You get X when a signal is uninitialized, when multiple drivers are fighting (contention), or through propagation of uncertainty (X propagates through logic). You get Z when a wire is floating (nothing is driving it) or from a tri-stated output.</p> <p>We use four-state simulation to capture these bugs. It is slower than two-state simulation, but it narrows down our issue search space. If your design passes two-state but fails four-state, the problem is usually related to X propagation or uninitialized signals.</p> <p>Go ahead and run the four-state simulation with Icarus Verilog:</p> <pre><code>% cd $HOME/ece6745/lab3/asic/build-fa/02-iverilog-rtlsim\n% iverilog -g2012 -o FullAdder-test \\\n    ../../../rtl/FullAdder.v \\\n    ../../../rtl/test/FullAdder-test.v\n% ./FullAdder-test\n</code></pre> <p>Now try the same experiment: comment out the <code>assign g = a &amp; b;</code> line and re-run the simulation. This time you should see the simulation catch the error because <code>g</code> becomes X instead of silently defaulting to 0. Change the code back before continuing.</p>"},{"location":"ece6745-lab3/#43-synthesis","title":"4.3 Synthesis","text":"<p>Now that we have rigorously tested our Verilog design, we are ready to synthesize it into a gate-level netlist. For this step, we will use the batch processing mode of <code>tinyflow-synth</code> instead of the REPL mode we have previous used. The batch mode takes a run script that describes the synthesis steps.</p> <p>Go ahead and edit the run script:</p> <pre><code>% cd $HOME/ece6745/lab3/asic/build-fa/03-tinyflow-synth\n% code run.py\n</code></pre> <p>Populate the script with the commands to perform technology mapping:</p> <pre><code>view = StdCellFrontEndView.parse_lib(\"../../../stdcells/stdcells-fe.yml\")\ndb = TinyFrontEndDB(view)\ndb.read_verilog(\"../../../rtl/FullAdder.v\")\ntechmap_unopt(db, view)\ndb.write_verilog(\"post-synth.v\")\n</code></pre> <p>Now run the synthesis:</p> <pre><code>% cd $HOME/ece6745/lab3/asic/build-fa/03-tinyflow-synth\n% ../../../tinyflow/tinyflow-synth -f run.py\n</code></pre> <p>This outputs the <code>post-synth.v</code> file. Open it and have a look. You should see that all gates are now standard cells from your library, and the module still has the same inputs and outputs as the original RTL.</p>"},{"location":"ece6745-lab3/#44-fast-functional-gate-level-simulation","title":"4.4 Fast-Functional Gate-Level Simulation","text":"<p>Now that we have our synthesized design, as paranoid ASIC engineers we want to double check that the synthesized design still does what we intended. Synthesis tools may not always be correct! To verify this, we perform fast-functional gate-level simulation (FFGL), which is four-state simulation using the same testbench but with the synthesized design and the behavioral view of the standard cells.</p> <pre><code>% cd $HOME/ece6745/lab3/asic/build-fa/04-iverilog-ffglsim\n% iverilog -g2012 -o FullAdder-test \\\n    ../../../stdcells/stdcells.v ../03-tinyflow-synth/post-synth.v \\\n    ../../../rtl/test/FullAdder-test.v\n% ./FullAdder-test\n</code></pre> <p>If the simulation passes, your synthesized design is functionally correct.</p>"},{"location":"ece6745-lab4/","title":"ECE 6745 Lab 4: TinyFlow Back End","text":"<p>In this lab, we will explore the TinyFlow back end which takes as input a gate-level netlist of standard cells and produces a placed and routed layout. The complete TinyFlow standard-cell and ASIC design flow is shown below with the back end highlighted in red.</p> <p></p> <p>The back end includes floorplanning, placement, routing, and filler cell insertion. In this lab, we will be implementing unoptimized versions of placement and routing. The key algorithms in the unoptimized back end flow are shown below.</p> <p></p>"},{"location":"ece6745-lab4/#1-logging-into-ecelinux","title":"1. Logging Into <code>ecelinux</code>","text":"<p>Follow the same process as previous labs. Find a free workstation and log into the workstation using your NetID and standard NetID password. Then complete the following steps.</p> <ul> <li>Start VS Code</li> <li>Install the Remote-SSH extension, Surfer, and Verilog extensions</li> <li>Use View &gt; Command Palette to execute Remote-SSH: Connect Current Window to Host...</li> <li>Enter netid@ecelinux-XX.ece.cornell.edu where XX is an ecelinux server number</li> <li>Use View &gt; Explorer to open your home directory on ecelinux</li> <li>Use View &gt; Terminal to open a terminal on ecelinux</li> <li>Start MS Remote Desktop</li> </ul> <p>Now use the following commands to clone the repo we will be using for today's lab.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p ${HOME}/ece6745\n% cd ${HOME}/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-lab4 lab4\n% cd lab4\n% tree\n</code></pre> <p>Your repo contains the following files.</p> <pre><code>.\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 asic\n\u2502   \u2514\u2500\u2500 build-fa\n\u2502       \u251c\u2500\u2500 00-verilator-rtlsim\n\u2502       \u251c\u2500\u2500 01-iverilog-rtlsim\n\u2502       \u251c\u2500\u2500 02-tinyflow-synth\n\u2502       \u251c\u2500\u2500 03-iverilog-ffglsim\n\u2502       \u2514\u2500\u2500 04-tinyflow-pnr\n\u251c\u2500\u2500 rtl\n\u2502   \u251c\u2500\u2500 FullAdder_cout.v\n\u2502   \u2514\u2500\u2500 FullAdder_cout-post-synth.v\n\u251c\u2500\u2500 stdcells\n\u2514\u2500\u2500 tinyflow\n    \u251c\u2500\u2500 pnr\n    \u2502   \u251c\u2500\u2500 StdCellBackEndView.py\n    \u2502   \u251c\u2500\u2500 TinyBackEndDB.py\n    \u2502   \u251c\u2500\u2500 TinyBackEndGUI.py\n    \u2502   \u251c\u2500\u2500 add_filler.py\n    \u2502   \u251c\u2500\u2500 floorplan.py\n    \u2502   \u251c\u2500\u2500 multi_route_unopt.py\n    \u2502   \u251c\u2500\u2500 place_unopt.py\n    \u2502   \u2514\u2500\u2500 single_route_unopt.py\n    \u251c\u2500\u2500 tinyflow-synth\n    \u2514\u2500\u2500 tinyflow-pnr\n</code></pre> <p>Our back end flow uses the back end and layout views from the sandard standard-cell library you developed in Project 1, Part A. You will also need your synthesis tool for the end-to-end flow. Copy these files into the lab4 directory.</p> <pre><code>% cd ${HOME}/ece6745/lab4\n% cp -r ${HOME}/ece6745/project1-groupXX/stdcells/stdcells .\n% cp -r ${HOME}/ece6745/project1-groupXX/tinyflow/synth tinyflow\n</code></pre> <p>where <code>XX</code> is your group number. We provide <code>FullAdder_cout.v</code> (the RTL) and <code>FullAdder_cout-post-synth.v</code> (a pre-synthesized gate-level netlist) in the <code>rtl</code> directory so you can test the back end flow directly.</p> <p>To make it easier to cut-and-paste commands from this handout onto the command line, you can tell Bash to ignore the <code>%</code> character using the following command:</p> <pre><code>% alias %=\"\"\n</code></pre> <p>Now you can cut-and-paste a sequence of commands from this tutorial document and Bash will not get confused by the <code>%</code> character which begins each line.</p>"},{"location":"ece6745-lab4/#2-data-structure-back-end-database","title":"2. Data Structure: Back End Database","text":"<p>As discussed in lecture, the back end takes a gate-level netlist and produces a physical layout. The key data structure is the back end database which manages cells (standard cell instances), IO ports (block boundary pins), nets (connections between pins), a 2D site grid of sites, and a 3D routing grid of nodes. The PnR algorithms -- floorplanning, placement, and routing -- read and modify this database. We provide students the database, and students are responsible for writing the algorithms. Similar to the front end, we have a REPL for interactive exploration of the back end database and algorithms.</p> <p>In this section, we will manually build a small design from scratch in the REPL to understand how these data structures work together. We will add cells, create nets, set up a floorplan, place cells, and route nets by hand before moving on to automated algorithms.</p> <p>To get started, create a build directory and start the TinyFlow PnR REPL.</p> <pre><code>% mkdir -p ${HOME}/ece6745/lab4/tinyflow/build\n% cd ${HOME}/ece6745/lab4/tinyflow/build\n% ../tinyflow-pnr\n</code></pre>"},{"location":"ece6745-lab4/#21-database-floorplan-and-the-grid","title":"2.1. Database, Floorplan, and the Grid","text":"<p>Before we can place cells or route wires, we need to set up the block's physical foundation: the site grid and the routing grid. The site grid is a 2D array of sites where cells can be placed. The routing grid is a 3D array of nodes where wires can be routed across multiple metal layers. Both are created when we call <code>floorplan</code> on the database.</p> <p>The figure below shows a top-down view of these two grids. Given the block's overall dimensions (left), the floorplan divides the area into a 2D grid of sites (center). Each site is one standard-cell slot. On top of that, a finer routing grid (right) provides nodes at every track pitch where wires and vias can be placed. The routing grid has many more rows than the site grid because sites are much taller than the track pitch.</p> <p></p> <p>The routing grid is actually 3D. Each node has coordinates <code>(i, j, k)</code> where <code>i</code> and <code>j</code> identify a position on the block and <code>k</code> selects the metal layer. The 3D view below shows how the routing grid stacks on top of the site grid, extending across multiple metal layers (M1 to M6) with vertical connections (vias) between layers.</p> <p></p> <p>Let's try this in TinyFlow. We first create a back end library view and an empty database, then call <code>floorplan</code> to set up a small block with 3 rows and 24 sites per row.</p> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; db.floorplan(3, 24)\n</code></pre> <p><code>StdCellBackEndView</code> is the back end counterpart to the front end view from Lab 3. It provides the physical information needed for place and route: site dimensions, cell layouts (pin locations, cell widths), and metal layer definitions.</p> <p><code>TinyBackEndDB</code> is the central database for the back end. It stores all cells, nets, pins, IO ports, and manages both the site grid and routing grid. All PnR algorithms read and modify this database.</p> <p><code>db.floorplan(num_rows, num_sites_per_row)</code> initializes the block's physical grid. It creates a 2D array of sites (rows x columns) where standard cells will be placed, and a 3D routing grid of nodes across all metal layers where wires will be routed. Nothing can be placed or routed until this is called. You should see the GUI show two panels: the top panel is the site pane showing the grid in sites, and the bottom panel is the routing pane showing a top-down view of the 3D routing grid.</p> <p></p> <p>Let's explore what <code>db.floorplan</code> created. First, check the dimensions of the site grid and the routing grid.</p> <pre><code>tinyflow-pnr&gt; db.get_num_rows()\ntinyflow-pnr&gt; db.get_num_cols()\ntinyflow-pnr&gt; db.get_grid_size_i()\ntinyflow-pnr&gt; db.get_grid_size_j()\n</code></pre> Expected output <pre><code>tinyflow-pnr&gt; db.get_num_rows()\n3\ntinyflow-pnr&gt; db.get_num_cols()\n24\ntinyflow-pnr&gt; db.get_grid_size_i()\n25\ntinyflow-pnr&gt; db.get_grid_size_j()\n25\n</code></pre> <p>The site grid has <code>num_rows</code> rows and <code>num_cols</code> sites per row -- these are the coordinates you use when placing cells. The routing grid is finer-grained: <code>grid_size_i</code> tracks in the vertical direction and <code>grid_size_j</code> tracks in the horizontal direction, across multiple metal layers.</p> <p>Each placement site is represented by a Site object. A site is the smallest unit of space where a cell can be placed, the same size as a filler cell. Each rectangular box in the placement panel GUI corresponds to one site. Let's inspect a site to see what information it tracks:</p> <pre><code>tinyflow-pnr&gt; db.get_site_at(0, 0)\ntinyflow-pnr&gt; db.get_site_at(0, 0).occupied_by == None\n</code></pre> Expected output <pre><code>tinyflow-pnr&gt; db.get_site_at(0, 0)\n&lt;Site(x=0, y=0, occupied=False)&gt;\ntinyflow-pnr&gt; db.get_site_at(0, 0).occupied_by == None\nTrue\n</code></pre> <p>The site at (0, 0) shows its coordinates and whether it is occupied. Since we haven't placed any cells yet, <code>occupied_by</code> is <code>None</code>. Once we place cells in Section 2.3, we will see this change.</p> <p>Each routing grid point is represented by a Node object, addressed by <code>(i, j, k)</code> where <code>i</code> is the row track, <code>j</code> is the column track, and <code>k</code> is the metal layer (1=M1, 2=M2, etc.). In the routing panel of the GUI, nodes are the intersections of the grid lines. Each node tracks what occupies it: a net's wire, a cell pin, or an IO port. Let's inspect a node to see what information it tracks:</p> <pre><code>tinyflow-pnr&gt; db.get_node_at(0, 0, 1)\ntinyflow-pnr&gt; db.get_occupancy(0, 0, 1) == None\n</code></pre> Expected output <pre><code>tinyflow-pnr&gt; db.get_node_at(0, 0, 1)\n&lt;Node(x=0, y=0, layer=1, occupied=None)&gt;\ntinyflow-pnr&gt; db.get_occupancy(0, 0, 1) == None\nTrue\n</code></pre> <p>The node at (0, 0, 1) is on M1 at row track 0, column track 0. Since we haven't routed any wires yet, the occupancy is <code>None</code>. Once we route nets in Section 2.3, we will see this change. <code>get_occupancy</code> will be very useful later when implementing the routing algorithms to check whether a node is available before routing through it.</p>"},{"location":"ece6745-lab4/#22-cells-io-ports-and-nets","title":"2.2. Cells, IO Ports, and Nets","text":"<p>Now that we have a floorplan, let's add cells, register IO ports, and create nets to connect them. We will build a simple two-inverter chain: input <code>a</code> drives <code>inv1</code>, whose output connects to <code>inv2</code>, whose output drives output <code>y</code>.</p> <p>A Cell represents an instance of a standard cell from the library (e.g., INVX1, NAND2X1). When we add a cell to the database, it automatically creates Pin objects based on the cell's layout definition. Let's add two inverters:</p> <pre><code>tinyflow-pnr&gt; db.add_cell('inv1', 'INVX1')\ntinyflow-pnr&gt; db.add_cell('inv2', 'INVX1')\ntinyflow-pnr&gt; db.get_cells()\n</code></pre> Expected output <pre><code>tinyflow-pnr&gt; db.add_cell('inv1', 'INVX1')\ntinyflow-pnr&gt; db.add_cell('inv2', 'INVX1')\ntinyflow-pnr&gt; db.get_cells()\n(&lt;Cell inv1, INVX1, placed=False&gt;, &lt;Cell inv2, INVX1, placed=False&gt;)\n</code></pre> <p>Each cell has pins that we can inspect. Pins are not yet placed on the grid since we haven't placed the cells yet. Note that the GUI only shows placed cells, so you won't see them in the GUI here:</p> <pre><code>tinyflow-pnr&gt; inv1 = db.get_cell('inv1')\ntinyflow-pnr&gt; inv1.get_pins()\ntinyflow-pnr&gt; inv1.get_pin('A')\ntinyflow-pnr&gt; inv1.get_pin('A').get_node()\n</code></pre> Expected output <pre><code>tinyflow-pnr&gt; inv1 = db.get_cell('inv1')\ntinyflow-pnr&gt; inv1.get_pins()\n[&lt;Pin A (unplaced)&gt;, &lt;Pin Y (unplaced)&gt;]\ntinyflow-pnr&gt; inv1.get_pin('A')\n&lt;Pin A (unplaced)&gt;\ntinyflow-pnr&gt; inv1.get_pin('A').get_node()\n(None, None, None)\n</code></pre> <p>An IO Port represents an external signal at the block boundary. IO ports are registered with <code>add_ioport</code> -- at this point, they are unplaced, we just declare that they exist. They will be placed on the block boundary later. Let's register that our design has an input <code>a</code> and an output <code>y</code>:</p> <pre><code>tinyflow-pnr&gt; db.add_ioport('a', 'input')\ntinyflow-pnr&gt; db.add_ioport('y', 'output')\ntinyflow-pnr&gt; db.get_ioports()\n</code></pre> Expected output <pre><code>tinyflow-pnr&gt; db.add_ioport('a', 'input')\ntinyflow-pnr&gt; db.add_ioport('y', 'output')\ntinyflow-pnr&gt; db.get_ioports()\n(&lt;Pin a (unplaced)&gt;, &lt;Pin y (unplaced)&gt;)\n</code></pre> <p><code>add_ioport</code> creates an IO port. It takes a direction to indicate whether it is an input or output.</p> <p>Now let's connect everything with Nets. A net represents a logical connection between pins. For our inverter chain, we need three nets: <code>a</code> connects the input IO port to <code>inv1</code>, <code>w</code> connects <code>inv1</code>'s output to <code>inv2</code>'s input, and <code>y</code> connects <code>inv2</code>'s output to the output IO port. Since IO ports are pins, we include them directly in the pin list.</p> <pre><code>tinyflow-pnr&gt; inv2 = db.get_cell('inv2')\ntinyflow-pnr&gt; db.add_net('a', [db.get_ioport('a'), inv1.get_pin('A')])\ntinyflow-pnr&gt; db.add_net('w', [inv1.get_pin('Y'), inv2.get_pin('A')])\ntinyflow-pnr&gt; db.add_net('y', [inv2.get_pin('Y'), db.get_ioport('y')])\ntinyflow-pnr&gt; db.get_nets()\n</code></pre> Expected output <pre><code>tinyflow-pnr&gt; inv2 = db.get_cell('inv2')\ntinyflow-pnr&gt; db.add_net('a', [db.get_ioport('a'), inv1.get_pin('A')])\ntinyflow-pnr&gt; db.add_net('w', [inv1.get_pin('Y'), inv2.get_pin('A')])\ntinyflow-pnr&gt; db.add_net('y', [inv2.get_pin('Y'), db.get_ioport('y')])\ntinyflow-pnr&gt; db.get_nets()\n(&lt;Net a, 2 pins&gt;, &lt;Net w, 2 pins&gt;, &lt;Net y, 2 pins&gt;)\n</code></pre> <p>Nets <code>a</code> and <code>y</code> each have two pins: a cell pin and an IO port. Net <code>w</code> is an internal wire between the two inverters with no IO port. Let's verify:</p> <pre><code>tinyflow-pnr&gt; db.get_net('a').pins\ntinyflow-pnr&gt; db.get_net('w').pins\ntinyflow-pnr&gt; db.get_net('y').pins\n</code></pre> Expected output <pre><code>tinyflow-pnr&gt; db.get_net('a').pins\n[&lt;Pin a (unplaced)&gt;, &lt;Pin A (unplaced)&gt;]\ntinyflow-pnr&gt; db.get_net('w').pins\n[&lt;Pin Y (unplaced)&gt;, &lt;Pin A (unplaced)&gt;]\ntinyflow-pnr&gt; db.get_net('y').pins\n[&lt;Pin Y (unplaced)&gt;, &lt;Pin y (unplaced)&gt;]\n</code></pre> <p>Note that the IO ports are registered but not yet placed. We will place them on the block boundary later in Section 2.3.</p> <p>With cells, IO ports, and nets defined, we have fully described the gate-level netlist -- what components exist and how they should be connected. The next step is to physically place and route them on the block.</p>"},{"location":"ece6745-lab4/#23-manually-placing-and-routing","title":"2.3. Manually Placing and Routing","text":"<p>With cells, IO ports, and nets created, let's physically place the cells and IO ports on the grid and manually route a net.</p> <p>Let's start with placing a cell. <code>cell.set_place(row, col)</code> places a cell with its origin at site <code>(row, col)</code>. The cell occupies one or more sites to the right depending on its width. If any of those sites are already occupied by another cell, the database raises an error. Cells in even rows are oriented normally; cells in odd rows are flipped vertically so that adjacent rows share VDD and VSS power rails. Go ahead and place <code>inv1</code> at (0, 2) and <code>inv2</code> at (2, 5):</p> <pre><code>tinyflow-pnr&gt; inv1.set_place(0, 2)\ntinyflow-pnr&gt; inv2.set_place(2, 5)\n</code></pre> <p>You should see something like this:</p> <p></p> <p>The cells should now appear in the placement panel as green boxes labeled with the cell name. In the routing panel, each placed cell shows as a teal dotted shadow box with its pin locations marked as yellow squares. When a cell is placed, its pins get assigned grid coordinates on metal layer 1 (M1):</p> <pre><code>tinyflow-pnr&gt; inv1.is_placed()\ntinyflow-pnr&gt; inv1.get_pin('Y').get_node()\ntinyflow-pnr&gt; inv2.get_pin('A').get_node()\n</code></pre> Expected output <pre><code>tinyflow-pnr&gt; inv1.is_placed()\nTrue\ntinyflow-pnr&gt; inv1.get_pin('Y').get_node()\n(4, 4, 1)\ntinyflow-pnr&gt; inv2.get_pin('A').get_node()\n(20, 6, 1)\n</code></pre> <p>Let's then place the IO ports on the block boundary. Recall that we registered them earlier but they were unplaced. We use <code>ioport.place(i, j)</code> to assign them to a grid location on the boundary. IO ports are placed on M2:</p> <pre><code>tinyflow-pnr&gt; db.get_ioport('a').place(3, 0)\ntinyflow-pnr&gt; db.get_ioport('y').place(24, 20)\n</code></pre> <p>You should see the Routing panel include the IO ports as light blue square boxes.</p> <p></p> <p>Let's run <code>db.check_design()</code> to verify our placement:</p> <pre><code>tinyflow-pnr&gt; db.check_design()\n</code></pre> Expected output <pre><code>tinyflow-pnr&gt; db.check_design()\nINFO: Placement check passed\nWARNING: UNROUTED: Net 'a' pins not fully connected\nWARNING: UNROUTED: Net 'w' pins not fully connected\nWARNING: UNROUTED: Net 'y' pins not fully connected\n</code></pre> <p>Placement passes, but all three nets are unrouted. Now that our cells and IO ports are placed, we want to connect their pins with wires. A wire is represented as a Line, a straight segment between two 3D grid points <code>(i, j, k)</code>. Exactly one coordinate changes: <code>i</code> or <code>j</code> for a wire on the same metal layer, or <code>k</code> for a via between layers.</p> <p>Cell pins live on M1 (k=1), but routing happens on M2 and above. In this example we will route on M2. To connect two cell pins, we need to:</p> <ol> <li>Go up from M1 to M2 at the source pin (via)</li> <li>Route on M2 to reach the destination (wire segments)</li> <li>Come back down from M2 to M1 at the destination pin (via)</li> </ol> <p>Since our two inverters are at different rows, the M2 route requires two segments forming an L-shape. Let's route net <code>w</code> which connects <code>inv1.Y</code> to <code>inv2.A</code>. We will add each line segment one at a time so you can see the route build up in the GUI:</p> <pre><code>tinyflow-pnr&gt; src_x, src_y, _ = inv1.get_pin('Y').get_node()\ntinyflow-pnr&gt; dst_x, dst_y, _ = inv2.get_pin('A').get_node()\ntinyflow-pnr&gt; net_w = db.get_net('w')\ntinyflow-pnr&gt; net_w.add_route_segments([Line((src_x, src_y, 1), (src_x, src_y, 2))])\ntinyflow-pnr&gt; net_w.add_route_segments([Line((src_x, src_y, 2), (src_x, dst_y, 2))])\ntinyflow-pnr&gt; net_w.add_route_segments([Line((src_x, dst_y, 2), (dst_x, dst_y, 2))])\ntinyflow-pnr&gt; net_w.add_route_segments([Line((dst_x, dst_y, 2), (dst_x, dst_y, 1))])\n</code></pre> <p></p> <p>The route should now appear in the routing panel of the GUI. You can verify the node occupancy along the route:</p> <pre><code>tinyflow-pnr&gt; db.get_occupancy(src_x, src_y, 2)\ntinyflow-pnr&gt; net_w.get_route()\n</code></pre> Expected output <pre><code>tinyflow-pnr&gt; db.get_occupancy(src_x, src_y, 2)\n&lt;Net w, 2 pins&gt;\ntinyflow-pnr&gt; net_w.get_route()\n[Line((4, 4, 1) -&gt; (4, 4, 2)), Line((4, 4, 2) -&gt; (4, 6, 2)), Line((4, 6, 2) -&gt; (20, 6, 2)), Line((20, 6, 2) -&gt; (20, 6, 1))]\n</code></pre> <p>At this point, we have only routed net <code>w</code>. Let's run <code>db.check_design()</code> to see if there are any issues:</p> <pre><code>tinyflow-pnr&gt; db.check_design()\n</code></pre> Expected output <pre><code>tinyflow-pnr&gt; db.check_design()\nINFO: Placement check passed\nWARNING: UNROUTED: Net 'a' pins not fully connected\nWARNING: UNROUTED: Net 'y' pins not fully connected\n</code></pre> <p>The checker reports that nets <code>a</code> and <code>y</code> are not yet routed. Now let's route the IO ports to their cells. Recall that IO ports are on M2 while cell pins are on M1. For net <code>a</code>, the IO port is already on M2, so we route on M2 to reach <code>inv1.A</code> and via down. For net <code>y</code>, we via up from <code>inv2.Y</code> to M2, route on M2 to reach the IO port:</p> <pre><code>tinyflow-pnr&gt; io_a = db.get_ioport('a').get_node()\ntinyflow-pnr&gt; pin_a = inv1.get_pin('A').get_node()\ntinyflow-pnr&gt; net_a = db.get_net('a')\ntinyflow-pnr&gt; net_a.add_route_segments([Line((io_a[0], io_a[1], 2), (io_a[0], pin_a[1], 2))])\ntinyflow-pnr&gt; net_a.add_route_segments([Line((io_a[0], pin_a[1], 2), (pin_a[0], pin_a[1], 2))])\ntinyflow-pnr&gt; net_a.add_route_segments([Line((pin_a[0], pin_a[1], 2), (pin_a[0], pin_a[1], 1))])\n\ntinyflow-pnr&gt; io_y = db.get_ioport('y').get_node()\ntinyflow-pnr&gt; pin_y = inv2.get_pin('Y').get_node()\ntinyflow-pnr&gt; net_y = db.get_net('y')\ntinyflow-pnr&gt; net_y.add_route_segments([Line((pin_y[0], pin_y[1], 1), (pin_y[0], pin_y[1], 2))])\ntinyflow-pnr&gt; net_y.add_route_segments([Line((pin_y[0], pin_y[1], 2), (pin_y[0], io_y[1], 2))])\ntinyflow-pnr&gt; net_y.add_route_segments([Line((pin_y[0], io_y[1], 2), (io_y[0], io_y[1], 2))])\n</code></pre> <p></p> <p>Now run <code>db.check_design()</code> again, your design should pass both placement and routing check now.</p>"},{"location":"ece6745-lab4/#24-reading-verilog","title":"2.4. Reading Verilog","text":"<p>In practice, we don't manually add cells, IO ports, and nets. The front end generates a gate-level Verilog netlist, and <code>db.read_verilog</code> reads it to create all cells, IO ports, and nets automatically. We have provided a synthesized <code>FullAdder_cout</code> design from lecture. Let's load it and verify what was created:</p> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.read_verilog('../../rtl/FullAdder_cout-post-synth.v')\ntinyflow-pnr&gt; db.get_cells()\ntinyflow-pnr&gt; db.get_ioports()\ntinyflow-pnr&gt; db.get_nets()\n</code></pre>"},{"location":"ece6745-lab4/#3-algorithm-floorplan","title":"3. Algorithm: Floorplan","text":"<p>In Section 2, we called <code>db.floorplan</code> directly with the number of rows and sites per row. In practice, the floorplan algorithm computes the grid dimensions and places IO ports on the block boundary.</p> <p>There are two approaches. <code>floorplan_fixed</code> takes explicit block width and height in micrometers along with IO port locations, and converts those physical dimensions into grid coordinates. <code>floorplan_auto</code> computes the block dimensions automatically from the total cell area and a target utilization. In this lab, we will implement <code>floorplan_fixed</code>.</p>"},{"location":"ece6745-lab4/#31-fixed-floorplan","title":"3.1. Fixed Floorplan","text":"<p><code>floorplan_fixed</code> takes the block width and height in micrometers, along with a dictionary of IO port locations also in micrometers. It converts all physical dimensions into grid coordinates using the back end library view.</p> <p>The algorithm works as follows:</p> <ol> <li>Get the technology's lambda value in micrometers from    <code>view.get_lambda_um()</code> and the site dimensions in lambda from    <code>view.get_site()</code></li> <li>Convert the block width and height from micrometers to lambda by    dividing by lambda_um</li> <li>Compute the number of rows and columns by dividing the lambda    dimensions by the site height and site width</li> <li>Call <code>db.floorplan(num_rows, num_cols)</code> to initialize the placement    and routing grids</li> <li>For each IO port, convert its (x_um, y_um) location from micrometers    to routing grid coordinates (i, j). You will need the metal1 track    pitch, which you can get with    <code>view.get_layer('metal1').get_track_pitch()</code>. Divide the lambda    coordinate by the track pitch to get the grid index. Then call    <code>ioport.place(i, j)</code> to place each port on the grid</li> </ol> <p>Function: <code>floorplan_fixed(db, view, width_um, height_um, io_locs)</code></p> <p>Args:</p> <ul> <li><code>db</code> -- TinyBackEndDB with cells and nets loaded</li> <li><code>view</code> -- StdCellBackEndView with site dimensions and lambda</li> <li><code>width_um</code> -- Block width in micrometers</li> <li><code>height_um</code> -- Block height in micrometers</li> <li><code>io_locs</code> -- Dict mapping port names to (x_um, y_um) locations</li> </ul> <p>Returns: None (modifies db in place)</p> <p>Go ahead and implement <code>floorplan_fixed</code> in <code>floorplan.py</code>. Use <code>logging.info</code> to print useful information such as the computed number of rows and columns. Once you are done, you can test your implementation using the <code>FullAdder_cout</code> design from lecture:</p> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; db.read_verilog('../../rtl/FullAdder_cout-post-synth.v')\ntinyflow-pnr&gt; io_locs = { 'a': (0.0, 7.2), 'b': (0.0, 14.4), 'cin': (0.0, 21.6), 'cout': (28.8, 14.4) }\ntinyflow-pnr&gt; floorplan_fixed(db, view, 28.8, 28.8, io_locs)\ntinyflow-pnr&gt; db.get_num_rows()\ntinyflow-pnr&gt; db.get_num_cols()\ntinyflow-pnr&gt; db.get_ioports()\n</code></pre> Expected output <pre><code>tinyflow-pnr&gt; db.get_num_rows()\n5\ntinyflow-pnr&gt; db.get_num_cols()\n40\ntinyflow-pnr&gt; db.get_ioports()\n(&lt;Pin a @(10,0,2)&gt;, &lt;Pin b @(20,0,2)&gt;, &lt;Pin cin @(30,0,2)&gt;, &lt;Pin cout @(20,40,2)&gt;)\n</code></pre>"},{"location":"ece6745-lab4/#4-algorithm-unoptimized-placement","title":"4. Algorithm: Unoptimized Placement","text":"<p>Placement assigns each cell to a location on the site grid. The goal is to find positions for all cells such that no two cells overlap. In an optimized flow, placement also minimizes wire length and improves timing. In this lab, we will implement <code>place_unopt</code>, which randomly assigns cells to grid positions without any optimization. In the project, we will build on this random placement using simulated annealing to iteratively improve cell positions for wire length.</p>"},{"location":"ece6745-lab4/#41-random-placement","title":"4.1. Random placement","text":"<p>The random placement we implement in this lab is a naive version that simply places cells at random positions without any optimization. If we recall the standard cells we drew in Part A, cells can have different widths. A site is the minimum cell width, and the site grid is the fine-grained grid of all site positions. To ensure no overlap, we use a coarser grid which we will refer to as the placement grid. We divide the columns into slots that are each as wide as the widest cell. Since every slot is at least as wide as any cell, placing one cell per slot in the placement grid guarantees no overlap.</p> <p>The algorithm works as follows:</p> <ol> <li>Find the maximum cell width across all cells</li> <li>Compute the number of placement columns by dividing the total columns    by the max cell width</li> <li>Randomly assign each cell to a unique placement grid position, placing    it at (row, placement_col * max_width)</li> </ol> <p>Function: <code>place_unopt(db, view, seed=0)</code></p> <p>Args:</p> <ul> <li><code>db</code> -- TinyBackEndDB with floorplan initialized</li> <li><code>view</code> -- StdCellBackEndView (unused, for consistency)</li> <li><code>seed</code> -- Random seed</li> </ul> <p>Returns: None (modifies db in place)</p> <p>Go ahead and implement <code>place_unopt</code> in <code>place_unopt.py</code>. You can use <code>logging.info</code> to print useful information such as the number of cells placed or cell's placed location. You can pass in a different seed to try a different random placement.</p> <p>Once you are done, test your implementation in the REPL:</p> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; db.read_verilog('../../rtl/FullAdder_cout-post-synth.v')\ntinyflow-pnr&gt; io_locs = { 'a': (0.0, 7.2), 'b': (0.0, 14.4), 'cin': (0.0, 21.6), 'cout': (28.8, 14.4) }\ntinyflow-pnr&gt; floorplan_fixed(db, view, 28.8, 28.8, io_locs)\ntinyflow-pnr&gt; place_unopt(db, view, seed=42)\ntinyflow-pnr&gt; db.get_cells()[0].is_placed()\ntinyflow-pnr&gt; db.get_cells()[0].get_place()\n</code></pre> <p>You should see all cells placed on the grid in the GUI. Each cell appears as a labeled box in the placement panel, with pin locations shown as yellow squares in the routing panel.</p>"},{"location":"ece6745-lab4/#5-algorithm-unoptimized-routing","title":"5. Algorithm: Unoptimized Routing","text":"<p>Routing draws the metal wiring and vias that connect the pins of each net. In Section 2, we manually routed a net by creating Line segments for vias and wires. In this section, we will automate that process. In this lab, we will implement a naive router that connects pins using manhattan L-shaped routes. Similar to Lab 3, we will start by implementing small modular functions and build up towards a working multi-net router. In the project, we will replace this with an optimized router.</p>"},{"location":"ece6745-lab4/#51-check-lines","title":"5.1. Check Lines","text":"<p>Before we can route a net, we need a way to check whether a proposed route is valid. When routing a net, we construct a route for that net. A route is a list of Lines, where each Line is a straight segment between two grid points with exactly one coordinate changing (a wire in the x or y direction on one layer, or a via in the z direction between layers). Together, the Lines in a route form the complete wiring for one net.</p> <p>Each Line passes through a sequence of grid points. If any of those points is already occupied by another net's wire, we cannot use that route. For example, if two nets try to use the same node on M2, that would be a short circuit.</p> <p>A Line provides <code>get_points()</code> which returns all grid points along the segment. We can check each point using <code>db.get_occupancy(i, j, k)</code>, which returns the net occupying that node or <code>None</code> if it is available. A point is a collision only if it is occupied by a different net. Points occupied by the current net are allowed since a net can cross its own wires.</p> <p>The algorithm works as follows:</p> <ol> <li>For each Line in the list, get all grid points using    <code>line.get_points()</code></li> <li>For each point, check occupancy using <code>db.get_occupancy(i, j, k)</code></li> <li>If occupied by a different net, return <code>False</code></li> <li>If all points are clear (or occupied by the same net), return <code>True</code></li> </ol> <p>Function: <code>check_lines(db, net, lines)</code></p> <p>Args:</p> <ul> <li><code>db</code> -- TinyBackEndDB for occupancy checks</li> <li><code>net</code> -- Current net (allowed to use its own nodes)</li> <li><code>lines</code> -- List of Line segments to check</li> </ul> <p>Returns: True if all lines are clear, False if any collision</p> <p>Go ahead and implement <code>check_lines</code> in <code>single_route_unopt.py</code>.</p> <p>To test, set up the design, then manually add a route to one net and check if the same lines collide with a different net:</p> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; db.read_verilog('../../rtl/FullAdder_cout-post-synth.v')\ntinyflow-pnr&gt; io_locs = { 'a': (0.0, 7.2), 'b': (0.0, 14.4), 'cin': (0.0, 21.6), 'cout': (28.8, 14.4) }\ntinyflow-pnr&gt; floorplan_fixed(db, view, 28.8, 28.8, io_locs)\ntinyflow-pnr&gt; place_unopt(db, view, seed=42)\ntinyflow-pnr&gt; net_a = db.get_net('a')\ntinyflow-pnr&gt; net_b = db.get_net('b')\ntinyflow-pnr&gt; lines = [Line((10, 0, 2), (10, 5, 2))]\ntinyflow-pnr&gt; net_a.add_route_segments(lines)\ntinyflow-pnr&gt; check_lines(db, net_b, lines)\ntinyflow-pnr&gt; check_lines(db, net_a, lines)\n</code></pre> <p>The first check should return <code>False</code> since the nodes are occupied by <code>net_a</code>. The second check should return <code>True</code> since a net is allowed to cross its own wires.</p>"},{"location":"ece6745-lab4/#52-manhattan-route-on-m2","title":"5.2. Manhattan Route on M2","text":"<p>Now we implement a simple routing function that only routes on the M2 layer. Given two pin locations on M1, <code>manhattan_route_m2</code> connects them with an L-shaped route on M2. Recall from Section 2 that a route is made up of Line segments. To go from one pin to another, we need four Lines: a via up from M1 to M2 at the source, a horizontal wire on M2, a vertical wire on M2, and a via down from M2 to M1 at the destination. The two wire segments form an L-shape (manhattan route) that meets at a right angle.</p> <p>The algorithm first tries one L-shape ordering, then the other:</p> <ol> <li>Try x-then-y: construct Lines for via up (M1 to M2), x-direction    wire, y-direction wire, via down (M2 to M1). Use <code>check_lines</code> to    test for collisions. If clear, commit with    <code>net.add_route_segments(lines)</code> and return <code>True</code>.</li> <li>Try y-then-x: construct Lines for via up, y-direction wire,    x-direction wire, via down. Check and commit if clear.</li> <li>If both orderings collide, return <code>False</code>.</li> </ol> <p>Function: <code>manhattan_route_m2(db, net, start, end)</code></p> <p>Args:</p> <ul> <li><code>db</code> -- TinyBackEndDB for occupancy checks</li> <li><code>net</code> -- Net to add route to</li> <li><code>start</code> -- Starting (i, j, k) tuple on M1</li> <li><code>end</code> -- Ending (i, j, k) tuple on M1</li> </ul> <p>Returns: True if route found and committed, False if both orderings blocked</p> <p>Go ahead and implement <code>manhattan_route_m2</code> in <code>single_route_unopt.py</code>. To test, pick a net and route between its first two pins:</p> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; db.read_verilog('../../rtl/FullAdder_cout-post-synth.v')\ntinyflow-pnr&gt; io_locs = { 'a': (0.0, 7.2), 'b': (0.0, 14.4), 'cin': (0.0, 21.6), 'cout': (28.8, 14.4) }\ntinyflow-pnr&gt; floorplan_fixed(db, view, 28.8, 28.8, io_locs)\ntinyflow-pnr&gt; place_unopt(db, view, seed=42)\n\n# Try routing g's first two pins\ntinyflow-pnr&gt; net_g = db.get_net('g')\ntinyflow-pnr&gt; start = net_g.pins[0].get_node()\ntinyflow-pnr&gt; end = net_g.pins[1].get_node()\ntinyflow-pnr&gt; manhattan_route_m2(db, net_g, start, end)\ntinyflow-pnr&gt; net_g.get_route()\n\n# Try routing _net_10's first two pins\ntinyflow-pnr&gt; net_n10 = db.get_net('_net_10')\ntinyflow-pnr&gt; start = net_n10.pins[0].get_node()\ntinyflow-pnr&gt; end = net_n10.pins[1].get_node()\ntinyflow-pnr&gt; manhattan_route_m2(db, net_n10, start, end)\n</code></pre> <p>The first route (<code>g</code>) should return <code>True</code>. In the GUI, the start and end pins should now show a filled circle (the via) where there was previously an empty square, and you should see the L-shaped wire segments connecting them. The second route (<code>_net_10</code>) should return <code>False</code> because its path crosses <code>g</code>'s route on M2.</p> <p></p>"},{"location":"ece6745-lab4/#53-manhattan-route-multi-layer","title":"5.3. Manhattan Route (Multi-Layer)","text":"<p>Now we generalize <code>manhattan_route_m2</code> to try multiple metal layers. Instead of only routing on M2, <code>manhattan_route</code> tries each routing layer from M6 down to M2. We try higher layers first with the hope that routing on upper layers leaves the lower layers free for later nets, reducing the chance of congestion.</p> <p>The algorithm works as follows:</p> <ol> <li>For each layer from M6 down to M2:</li> <li>Try x-then-y: construct 4 Lines (via up, x-wire, y-wire, via down).    Use <code>check_lines</code> to test. If clear, commit and return <code>True</code>.</li> <li>Try y-then-x: construct 4 Lines. Check and commit if clear.</li> <li>If all layers and orderings fail, return <code>False</code>.</li> </ol> <p>Function: <code>manhattan_route(db, net, start, end)</code></p> <p>Args:</p> <ul> <li><code>db</code> -- TinyBackEndDB for occupancy checks</li> <li><code>net</code> -- Net to add route to</li> <li><code>start</code> -- Starting (i, j, k) tuple</li> <li><code>end</code> -- Ending (i, j, k) tuple</li> </ul> <p>Returns: True if route found and committed, False if all options blocked</p> <p>Go ahead and implement <code>manhattan_route</code> in <code>single_route_unopt.py</code>. To test, try the same two nets from Section 5.2 but using <code>manhattan_route</code> instead. Both should succeed since the multi-layer version can route on different layers:</p> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; db.read_verilog('../../rtl/FullAdder_cout-post-synth.v')\ntinyflow-pnr&gt; io_locs = { 'a': (0.0, 7.2), 'b': (0.0, 14.4), 'cin': (0.0, 21.6), 'cout': (28.8, 14.4) }\ntinyflow-pnr&gt; floorplan_fixed(db, view, 28.8, 28.8, io_locs)\ntinyflow-pnr&gt; place_unopt(db, view, seed=42)\n\n# Try routing g's first two pins\ntinyflow-pnr&gt; net_g = db.get_net('g')\ntinyflow-pnr&gt; start = net_g.pins[0].get_node()\ntinyflow-pnr&gt; end = net_g.pins[1].get_node()\ntinyflow-pnr&gt; manhattan_route(db, net_g, start, end)\n\n# Try routing _net_10's first two pins\ntinyflow-pnr&gt; net_n10 = db.get_net('_net_10')\ntinyflow-pnr&gt; start = net_n10.pins[0].get_node()\ntinyflow-pnr&gt; end = net_n10.pins[1].get_node()\ntinyflow-pnr&gt; manhattan_route(db, net_n10, start, end)\n</code></pre> <p>Both should return <code>True</code>. The first net routes on the highest available layer (M6), and the second net finds a different free layer since they no longer compete for M2.</p>"},{"location":"ece6745-lab4/#54-single-net-routing-single_route_unopt","title":"5.4. Single-Net Routing (<code>single_route_unopt</code>)","text":"<p>Now we put the pieces together to route a single net. A net can have more than two pins (e.g., a fan-out net). <code>single_route_unopt</code> connects all pins sequentially using <code>manhattan_route</code>. Note that if a pair fails partway through, the previously routed segments are still committed -- the net's route will be incomplete but the partial segments remain on the grid.</p> <p>The algorithm works as follows:</p> <ol> <li>Get the net by name and collect all pin locations</li> <li>For each consecutive pair of pins (pin 0\u21921, pin 1\u21922, etc.), call    <code>manhattan_route</code> to connect them</li> <li>If any pair fails, return <code>False</code></li> <li>If all pairs succeed, mark the net as routed and return <code>True</code></li> </ol> <p>Function: <code>single_route_unopt(db, net_name)</code></p> <p>Args:</p> <ul> <li><code>db</code> -- TinyBackEndDB with placed design</li> <li><code>net_name</code> -- Name of the net to route</li> </ul> <p>Returns: True if routing succeeded, False otherwise</p> <p>Go ahead and implement <code>single_route_unopt</code> in <code>single_route_unopt.py</code>. To test, route a single net by name:</p> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; db.read_verilog('../../rtl/FullAdder_cout-post-synth.v')\ntinyflow-pnr&gt; io_locs = { 'a': (0.0, 7.2), 'b': (0.0, 14.4), 'cin': (0.0, 21.6), 'cout': (28.8, 14.4) }\ntinyflow-pnr&gt; floorplan_fixed(db, view, 28.8, 28.8, io_locs)\ntinyflow-pnr&gt; place_unopt(db, view, seed=42)\ntinyflow-pnr&gt; single_route_unopt(db, 'a')\ntinyflow-pnr&gt; db.get_net('a').get_route()\n</code></pre>"},{"location":"ece6745-lab4/#55-multi-net-routing-multi_route_unopt","title":"5.5. Multi-Net Routing (<code>multi_route_unopt</code>)","text":"<p>Finally, we route all nets in the design.</p> <p>The algorithm works as follows:</p> <ol> <li>Get all nets from the database</li> <li>For each net with two or more pins, call <code>single_route_unopt</code></li> <li>Track which nets failed to route</li> <li>Return <code>True</code> if all nets routed, <code>False</code> otherwise</li> </ol> <p>Function: <code>multi_route_unopt(db, view)</code></p> <p>Args:</p> <ul> <li><code>db</code> -- TinyBackEndDB with placed design</li> <li><code>view</code> -- StdCellBackEndView (unused, for consistency)</li> </ul> <p>Returns: True if all nets routed, False otherwise</p> <p>Go ahead and implement <code>multi_route_unopt</code> in <code>multi_route_unopt.py</code>. To test, route all nets in the design:</p> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; db.read_verilog('../../rtl/FullAdder_cout-post-synth.v')\ntinyflow-pnr&gt; io_locs = { 'a': (0.0, 7.2), 'b': (0.0, 14.4), 'cin': (0.0, 21.6), 'cout': (28.8, 14.4) }\ntinyflow-pnr&gt; floorplan_fixed(db, view, 28.8, 28.8, io_locs)\ntinyflow-pnr&gt; place_unopt(db, view, seed=42)\ntinyflow-pnr&gt; multi_route_unopt(db, view)\n</code></pre> <p>With your implementation, it is possible that not all nets route successfully. This is expected -- with a random unoptimized placement, some nets may fail to route due to congestion. Try a different seed to see how placement affects routability.</p>"},{"location":"ece6745-lab4/#6-algorithm-add-filler","title":"6. Algorithm: Add Filler","text":"<p>After placement and routing, some sites on the grid may still be empty. In a real chip, every site must be filled to satisfy manufacturing design rules and maintain continuous power rails. <code>add_filler</code> walks through every site in the site grid and marks any unoccupied site as a filler cell.</p> <p>The algorithm works as follows:</p> <ol> <li>Get the site grid using <code>db.get_core()</code>, which returns a 2D array    of sites</li> <li>Iterate through every site in the grid</li> <li>For each site, check if it is unoccupied using <code>site._get_occupancy()</code></li> <li>If unoccupied, mark it as filler using <code>site.add_filler()</code></li> </ol> <p>Function: <code>add_filler(db, view)</code></p> <p>Args:</p> <ul> <li><code>db</code> -- TinyBackEndDB with placed and routed design</li> <li><code>view</code> -- StdCellBackEndView (unused, for consistency)</li> </ul> <p>Returns: None (modifies db in place)</p> <p>Go ahead and implement <code>add_filler</code> in <code>add_filler.py</code>. To test:</p> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; db.read_verilog('../../rtl/FullAdder_cout-post-synth.v')\ntinyflow-pnr&gt; io_locs = { 'a': (0.0, 7.2), 'b': (0.0, 14.4), 'cin': (0.0, 21.6), 'cout': (28.8, 14.4) }\ntinyflow-pnr&gt; floorplan_fixed(db, view, 28.8, 28.8, io_locs)\ntinyflow-pnr&gt; place_unopt(db, view, seed=42)\ntinyflow-pnr&gt; multi_route_unopt(db, view)\ntinyflow-pnr&gt; add_filler(db, view)\n</code></pre> <p>You should see the empty sites in the GUI filled in after running <code>add_filler</code>.</p>"},{"location":"ece6745-lab4/#7-algorithm-layout-writer","title":"7. Algorithm: Layout Writer","text":"<p>The final step is to write out the layout as a GDS file. This is provided for you -- simply call <code>db.write_gds</code> with the desired output filename:</p> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.read_verilog('../../rtl/FullAdder_cout-post-synth.v')\ntinyflow-pnr&gt; io_locs = { 'a': (0.0, 7.2), 'b': (0.0, 14.4), 'cin': (0.0, 21.6), 'cout': (28.8, 14.4) }\ntinyflow-pnr&gt; floorplan_fixed(db, view, 28.8, 28.8, io_locs)\ntinyflow-pnr&gt; place_unopt(db, view, seed=42)\ntinyflow-pnr&gt; multi_route_unopt(db, view)\ntinyflow-pnr&gt; add_filler(db, view)\ntinyflow-pnr&gt; db.check_design()\ntinyflow-pnr&gt; db.report_summary()\ntinyflow-pnr&gt; db.write_gds('FA_cout.gds')\n</code></pre> <p>This merges your placed and routed design with the standard cell layouts and writes the combined result to a GDS file. Open <code>FA_cout.gds</code> in KLayout to inspect the final physical layout.</p>"},{"location":"ece6745-lab4/#8-tinyflow-front-and-back-end","title":"8. TinyFlow Front and Back End","text":"<p>The complete TinyFlow includes both the front-end and back-end. The front-end flow consists of four steps: two-state simulation, four-state simulation, synthesis, and fast-functional gate-level simulation. The back-end flow consists of three steps: place-and-route, design rule checking, and layout-vs-schematic. In this final part, we push the full adder design through all steps of the fron-end flow and the place-and-route step of the back-end flow to illustrate going from Verilog RTL to a gate-level netlist to layout. We first manually run each step before showing how we can automate running the flow.</p>"},{"location":"ece6745-lab4/#81-tiny-front-end-manual-flow","title":"8.1. Tiny Front-End Manual Flow","text":"<p>We need to first run the front-end flow as in the previous lab and project 1B to generate the gate-level netlist. We provide the Verilog RTL in <code>rtl/FullAdder.v</code> and a basic testbench in <code>rtl/test/FullAdder-test.v</code>. These are the same as in the previous lab. Trun the two-state simulation with Verilator.</p> <pre><code>% cd $HOME/ece6745/lab4/asic/playground/01-verilator-rtlsim\n% verilator --top Top --timing --binary -o FullAdder-test \\\n    ../../../rtl/FullAdder.v \\\n    ../../../rtl/test/FullAdder-test.v\n% ./obj_dir/FullAdder-test\n</code></pre> <p>Now run four-state simulation with Icarus Verilog.</p> <pre><code>% cd $HOME/ece6745/lab4/asic/playground/02-iverilog-rtlsim\n% iverilog -g2012 -o FullAdder-test \\\n    ../../../rtl/FullAdder.v \\\n    ../../../rtl/test/FullAdder-test.v\n% ./FullAdder-test\n</code></pre> <p>Create a <code>run.py</code> script for synthesis.</p> <pre><code>% cd $HOME/ece6745/lab4/asic/playground/03-tinyflow-synth\n% code run.py\n</code></pre> <p>Populate the script with the commands to perform optimized technology mapping and static timing analysis using your work Project 1B.</p> <pre><code># Load the standard-cell front-end view and create front-end database\n\nview = StdCellFrontEndView.parse_lib(\"../../../stdcells/stdcells-fe.yml\")\ndb = TinyFrontEndDB(view)\n\n# Read Verilog file into the database\n\ndb.read_verilog(\"../../../rtl/FullAdder.v\")\n\n# Optimized technology mapping\n\ntechmap(db, view)\n\n# Static timing analysis with output load of 10fF\n\noutput_load = 10\nsta(db, view, output_load)\n\n# Check design for issues\n\ndb.check_design()\n\n# Output reports\n\ndb.report_area()\ndb.report_timing()\ndb.report_summary()\n\n# Write front-end database to a Verilog gate-level netlist\n\ndb.write_verilog(\"post-synth.v\")\n</code></pre> <p>Now go ahead and run synthesis.</p> <pre><code>% cd $HOME/ece6745/lab4/asic/playground/03-tinyflow-synth\n% ../../../tinyflow/tinyflow-synth -f run.py\n</code></pre> <p>Finally run fast-functional gate-level simulation to ensure the gate-level netlist is correct.</p> <pre><code>% cd $HOME/ece6745/lab4/asic/playground/04-iverilog-ffglsim\n% iverilog -g2012 -o FullAdder-test \\\n    ../../../stdcells/stdcells.v ../03-tinyflow-synth/post-synth.v \\\n    ../../../rtl/test/FullAdder-test.v\n% ./FullAdder-test\n</code></pre>"},{"location":"ece6745-lab4/#82-tiny-back-end-manual-flow","title":"8.2. Tiny Back-End Manual Flow","text":"<p>Let's first run the back-end flow interactively, and then we will create a corresponding <code>run.py</code> script. Start the place-and-route REPL.</p> <pre><code>% cd $HOME/ece6745/lab4/asic/playground/05-tinyflow-pnr\n% ../../../tinyflow/tinyflow-pnr\n</code></pre> <p>Now load the standard view, create the tiny back-end database, and start the GUI.</p> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(\n                be  = '../../../stdcells/stdcells-be.yml',\n                gds = '../../../stdcells/stdcells.gds',\n              )\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.enable_gui()\n</code></pre> <p>Read the gate-level netlist Verilog file into the database.</p> <pre><code>tinyflow-pnr&gt; db.read_verilog('../03-tinyflow-synth/post-synth.v')\n</code></pre> <p>Create a fixed floorplan.</p> <pre><code>tinyflow-pnr&gt; io_locs = {\n                'a'    : (  0.0, 21.6),\n                'b'    : (  0.0, 14.4),\n                'cin'  : (  0.0,  7.2),\n                'cout' : (29.52, 21.6),\n                'sum'  : (29.52,  7.2),\n              }\ntinyflow-pnr&gt; floorplan_fixed(db, view, 30.0, 30.0, io_locs)\n</code></pre> <p>Place and route the design and insert filler cells.</p> <pre><code>tinyflow-pnr&gt; place_unopt(db, view)\ntinyflow-pnr&gt; multi_route_unopt(db, view)\ntinyflow-pnr&gt; add_filler(db, view)\n</code></pre> <p>Check the design for issues and output a summary report.</p> <pre><code>tinyflow-pnr&gt; db.check_design()\ntinyflow-pnr&gt; db.report_summary()\n</code></pre> <p>Note that the unoptimized routing algorithm is unlikely to be able to succesfully route all of the nets. This means we could not fabricate this design, but it is ok for illustrating the process during the lab. The optimized place and route algorithms you implement for Project 1C must be able to successfully route all nets in order to be able to contribute your block to the tinyflow tapeout.</p> <p>Write the tiny back-end database to a GDS layout file and exit the REPL.</p> <pre><code>tinyflow-pnr&gt; db.write_gds('post-pnr.gds')\ntinyflow-pnr&gt; exit()\n</code></pre> <p>You can now view the final layout using Klayout.</p> <pre><code>% cd $HOME/ece6745/lab4/asic/playground/05-tinyflow-pnr\n% klayout post-pnr.gds\n</code></pre> <p>Choose Display &gt; Top Level Only to hide the internals of each standard cell and show just the placement and routing of the standard cells. Try hiding and showing different metal layers to better visualize the routing. Spend some time appreciating all your hard work!</p> <p></p> <p>Create a <code>run.py</code> script to make it easier to run place-and-route.</p> <pre><code>% cd $HOME/ece6745/lab4/asic/playground/05-tinyflow-pnr\n% code run.py\n</code></pre> <p>Populate the script with the above commands. Note that we do not enable the GUI when using a <code>run.py</code> script.</p> <pre><code>view = StdCellBackEndView(\n         be  = '../../../stdcells/stdcells-be.yml',\n         gds = '../../../stdcells/stdcells.gds',\n       )\ndb = TinyBackEndDB(view)\n\ndb.read_verilog('../03-tinyflow-synth/post-synth.v')\n\nio_locs = {\n  'a'    : (  0.0, 21.6),\n  'b'    : (  0.0, 14.4),\n  'cin'  : (  0.0,  7.2),\n  'cout' : (29.52, 21.6),\n  'sum'  : (29.52,  7.2),\n}\nfloorplan_fixed(db, view, 30.0, 30.0, io_locs)\n\nplace_unopt(db, view)\nmulti_route_unopt(db, view)\nadd_filler(db, view)\n\ndb.check_design()\ndb.report_summary()\n\ndb.write_gds('post-pnr.gds')\n</code></pre> <p>Now rerun place-and-route using this <code>run.py</code> script.</p> <pre><code>% cd $HOME/ece6745/lab4/asic/playground/05-tinyflow-pnr\n% ../../../tinyflow/tinyflow-pnr -f run.py\n</code></pre>"},{"location":"ece6745-lab4/#83-tiny-automated-flow","title":"8.3. Tiny Automated Flow","text":"<p>In the previous sections, we manually commands entering commands for each tool to take a design from RTL to layout. Using <code>run.py</code> scripts can help, and we could even crate <code>run</code> Bash scripts to further automate the flow. However, truly agile hardware design demands more sophisticated automation to simplify rapidly exploring the design space of one or more designs. In this section, we will introduce a tool called pyhflow which takes as input step templates and a design YAML and generates appropriate flow scripts.</p> <p>pyflow is based on the idea of step templates which are located in the asic/steps directory.</p> <pre><code>% cd $HOME/ece6745/lab4/asic/steps\n% tree\n</code></pre> <p>The directory layout should look as follows.</p> <pre><code>.\n\u251c\u2500\u2500 01-verilator-rtlsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 02-iverilog-rtlsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 03-tinyflow-synth\n\u2502   \u251c\u2500\u2500 run\n\u2502   \u2514\u2500\u2500 run.py\n\u251c\u2500\u2500 04-iverilog-ffglsim\n\u2502   \u2514\u2500\u2500 run\n\u2514\u2500\u2500 05-tinyflow-pnr\n    \u251c\u2500\u2500 run\n    \u2514\u2500\u2500 run.py\n</code></pre> <p>Each step is a directory with a run script and possibly other scripts. The key difference from the <code>run.py</code> and <code>run</code> scripts we used previously, is that these scripts are templated using the Jinja2 templating system:</p> <ul> <li>https://jinja.palletsprojects.com</li> </ul> <p>Open the <code>run.py</code> script in the <code>03-tinyflow-synth</code> step template.</p> <pre><code>% cd $HOME/ece6745/lab4/asic/steps/03-tinyflow-synth\n% code run.py\n</code></pre> <p>Notice how the <code>run.py</code> script is templated based on the design name.</p> <pre><code>db.read_verilog(\"{{top_dir}}/rtl/{{design_name}}.v\")\n</code></pre> <p>The <code>{{ }}</code> directive is the standard syntax for template variable substitution using Jinja2. The pyhflow program takes as input a design YAML file which specifies how to fill in these template variables. Take a look at the provided design YAML for the full ader.</p> <pre><code>% cd $HOME/ece6745/lab4/asic/designs\n% code fa.py\n</code></pre> <p>The contents should look as follows.</p> <pre><code>steps:\n - 01-verilator-rtlsim\n - 02-iverilog-rtlsim\n - 03-tinyflow-synth\n - 04-iverilog-ffglsim\n - 05-tinyflow-pnr\n\ntop_dir      : ../../..\ndesign_name  : FullAdder\ntest         : FullAdder-test\n\nblock_width  : 30.0\nblock_height : 30.0\nio_locs: |\n  'a'    : (  0.0, 21.6),\n  'b'    : (  0.0, 14.4),\n  'cin'  : (  0.0,  7.2),\n  'cout' : (29.52, 21.6),\n  'sum'  : (29.52,  7.2),\n</code></pre> <p>This design YAML file specifies the generated flow should use five steps and also includes the design name, test name, and floorplan information. All pyhflow does is use the YAML file to figure out what to substitute into the templated steps and then copy the run scripts into the current working directory. You can also override parameters on pyhflow command line.</p> <p>Let's now use pyhflow to easily automate the entire process of pushing a full adder through the tiny flow.</p> <pre><code>% cd $HOME/ece6745/lab4/asic\n% mkdir -p build-fa\n% cd build-fa\n% pyhflow ../designs/fa.yml\n% ./01-verilator-rtlsim/run\n% ./02-iverilog-rtlsim/run\n% ./03-tinyflow-synth/run\n% ./04-iverilog-ffglsim/run\n% ./05-tinyflow-pnr/run\n</code></pre> <p>pyhflow also creates a <code>run-flow</code> script which will run all the steps further simplifying the process.</p> <pre><code>% cd $HOME/ece6745/lab4/asic\n% mkdir -p build-fa\n% cd build-fa\n% pyhflow ../designs/fa.yml\n% ./run-flow\n</code></pre>"},{"location":"ece6745-lab5/","title":"ECE 6745 Lab 5: TinyRV2 Accelerators","text":"<p>In this lab, we will be discussing how to implement a simple medium-grain accelerator. Fine-grain accelerators are tightly integrated within the processor pipeline (e.g., a specialized functional unit for bit-reversed addressing useful in implementing an FFT), while coarse-grain accelerators are loosely integrated with a processor through the memory hierarchy (e.g., a graphics rendering accelerator sharing the last-level cache with a general-purpose processor). Medium-grain accelerators are often integrated as co-processors: the processor can directly send/receive messages to/from the accelerator with special instructions, but the co-processor is relatively decoupled from the main processor pipeline and can also potentially independently interact with memory.</p> <p>This diagram illustrates a system architecture where the accelerator can independently interact with memory.</p> <p></p> <p>While this diagram illustrates a system architecture where the accelerator cannot independently interact with memory; the processor is responsible for moving data between memory and the accelerator.</p> <p></p> <p>While project 3 can explore accelerators with their own memory interface, project 2 will only explore accelerators without an independent memory interface.</p> <p>To illustrate how to implement a medium-grain accelerator, we will be working on a simple GCD accelerator that calculates the greatest common divisor of two 15-bit integers. Essentially, we will be exploring the stand-alone GCD unit you saw in Tutorial 4 and turn it into an accelerator which can be composed with a processor.</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/handouts/ece6745-tut3-verilog.pdf</li> </ul>"},{"location":"ece6745-lab5/#1-logging-into-ecelinux","title":"1. Logging Into <code>ecelinux</code>","text":"<p>Follow the same process as previous labs. Find a free workstation and log into the workstation using your NetID and standard NetID password. Then complete the following steps.</p> <ul> <li>Start VS Code</li> <li>Install the Remote-SSH extension, Surfer, Python, and Verilog extensions</li> <li>Use View &gt; Command Palette to execute Remote-SSH: Connect Current Window to Host...</li> <li>Enter netid@ecelinux-XX.ece.cornell.edu where XX is an ecelinux server number</li> <li>Use View &gt; Explorer to open your home directory on ecelinux</li> <li>Use View &gt; Terminal to open a terminal on ecelinux</li> <li>Start MS Remote Desktop</li> </ul> <p>Now use the following commands to clone the repo we will be using for today's lab.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p ${HOME}/ece6745\n% cd ${HOME}/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-lab5 lab5\n% cd lab5\n% tree\n</code></pre> <p>To make it easier to cut-and-paste commands from this handout onto the command line, you can tell Bash to ignore the <code>%</code> character using the following command:</p> <pre><code>% alias %=\"\"\n</code></pre> <p>Now you can cut-and-paste a sequence of commands from this tutorial document and Bash will not get confused by the <code>%</code> character which begins each line.</p>"},{"location":"ece6745-lab5/#3-software-baseline","title":"3. Software Baseline","text":"<p>Before implementing any kind of accelerator, we first need to implement a software version both to explore the algorithm and to create a baseline for comparative analysis. Our goal is to develop an accelerator which improves the performance compared to an equivalent software version; if our accelerator is slower then we are better off using a software implementation!</p> <p>Start the Python interpreter and experiment with Python's provided GCD function.</p> <pre><code>% cd ${HOME}/ece6745/lab5\n% python\n&gt;&gt;&gt; import math\n&gt;&gt;&gt; math.gcd( 15,  5 )\n&gt;&gt;&gt; math.gcd( 21, 49 )\n&gt;&gt;&gt; math.gcd( 13,  7 )\n</code></pre> <p>Now write your own GCD implementation using Euclid's algorithm.</p> <pre><code>&gt;&gt;&gt; def gcd( a, b ):\n...   while True:\n...     if a &lt; b:\n...       a,b = b,a\n...     elif b != 0:\n...       a = a - b\n...     else:\n...       return a\n...\n&gt;&gt;&gt; gcd(15, 5)\n&gt;&gt;&gt; gcd(21,39)\n&gt;&gt;&gt; gcd(13, 7)\n</code></pre> <p>Once you understand the algorithm, now we can impement the algorithm in C to serve as a baseline for comparative analysis. Use VS Code to open up the <code>ubmark-gcd.c</code> file.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/ubmark\n% code ubmark-gcd.c\n</code></pre> <p>Go ahead and write a C version of GCD using your Python algorithm for reference. Now we want to rigorously test our C baseline. Take a look at the provided C test program.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/ubmark\n% code ubmark-gcd-test.c\n</code></pre> <p>The C test program includes a number of test cases and then a main function with runs the test cases.</p> <pre><code>void test_case_1_basic()\n{\n  ECE6745_CHECK( L\"test_case_1_basic\" );\n\n  int result = ubmark_gcd( 15, 5 );\n\n  ECE6745_CHECK_INT_EQ( result, 5 );\n}\n\n...\n\nint main( int argc, char** argv )\n{\n  __n = ( argc == 1 ) ? 0 : ece6745_atoi( argv[1] );\n\n  if ( (__n &lt;= 0) || (__n ==  1) ) test_case_1_basic();\n  ...\n\n  ece6745_wprintf( L\"\\n\\n\" );\n  return ece6745_check_status;\n}\n</code></pre> <p>Note that our TinyRV2 processor does not support any kind of operating system or even any kind of C library. It is essentially a bare-metal micro-controller. You will need to implement or port all libraries yourself. We provide you a few very simple library functions in <code>app/ece6745</code>:</p> <ul> <li><code>ece6745_atoi</code>: converts strings to integers</li> <li><code>ece6745_wprintf</code>: very simple printf for 4B-character strings</li> <li><code>ece6745_malloc</code>: very simple bump-pointer malloc</li> <li><code>ece6745_free</code>: basically does nothing</li> <li><code>ece6745_srand</code>: set the random seed</li> <li><code>ece6745_rand</code>: return random integer</li> <li><code>ece6745_exit</code>: exit the program</li> </ul> <p>TinyRV2 does not support load byte or store byte so all characters must be four bytes. You can indicate a four-byte character string by using the L prefix.</p> <p>Let's go ahead and compile the C test program natively and ensure our implementation is functionally correct. Note that we will be using two different compilation flows:</p> <ul> <li> <p>Native compilation: Compile C programs for x86 and run them    directly on the server</p> </li> <li> <p>Cross compilation: Compile C programs for TinyRV2 and run them    on a functional-level or RTL simulator</p> </li> </ul> <p>Each compilation flow will have its own build directory.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app\n% mkdir build-native\n% cd build-native\n% ../configure\n% make ubmark-gcd-test\n% ./ubmark-gcd-test\n</code></pre> <p>You can run a specific test case as follows:</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build-native\n% ./ubmark-gcd-test 1\n</code></pre> <p>Test programs are used to ensure functional correctness. They are not used to evaluate performance. We will always use a seperate evaluation program to evaluate performance. Go ahead and take a look at the provided C evaluation program.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/ubmark\n% code ubmark-gcd-eval.c\n</code></pre> <p>The C evaluation program includes a region-of-interest (ROI) and verification code.</p> <pre><code>int main( void )\n{\n  // Allocate destination array for results\n\n  int* dest = ece6745_malloc( eval_size * (int)sizeof(int) );\n\n  // Run the evaluation\n\n  ece6745_stats_on();\n  for ( int i = 0; i &lt; eval_size; i++ ) {\n    dest[i] = ubmark_gcd( eval_a[i], eval_b[i] );\n  }\n  ece6745_stats_off();\n\n  // Verify the results\n\n  for ( int i = 0; i &lt; eval_size; i++ ) {\n    if ( dest[i] != eval_ref[i] ) {\n      ece6745_wprintf( L\"\\n FAILED: dest[%d] != eval_ref[%d] (%d != %d)\\n\\n\",\n                       i, i, dest[i], eval_ref[i] );\n      ece6745_exit(1);\n    }\n  }\n\n  // Free destination array\n\n  ece6745_free(dest);\n\n  // Check for no memory leaks\n\n  if ( ece6745_get_heap_usage() != 0 ) {\n    ece6745_wprintf( L\"\\n FAILED: memory leak of %d bytes!\\n\\n\",\n                     ece6745_get_heap_usage() );\n    ece6745_exit(1);\n  }\n\n  // Otherwise we passed\n\n  ece6745_wprintf( L\"\\n **PASSED** \\n\\n\" );\n\n  return 0;\n}\n</code></pre> <p>Take a look at the <code>ece6745_stats_on</code> and <code>ece6745_stats_off</code> function calls in <code>app/ece6745/ece6745-misc.h</code>.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/ece6745\n% code ece6745-misc.c\n</code></pre> <p>These functions simply use inline assembly to insert CSR write instructions to write a special CSR which tells the hardware when to start and stop collecting statistics. All of this is very similar to what you saw in ECE 4750.</p> <pre><code>#ifdef _RISCV\n\ninline\nvoid ece6745_stats_on()\n{\n  int status = 1;\n  __asm__ ( \"csrw 0x7c1, %0\" :: \"r\"(status) );\n}\n\n#else\n\ninline\nvoid ece6745_stats_on()\n{ }\n\n#endif\n</code></pre> <p>We use the <code>_RISCV</code> preprocessor define to make sure that when we compile this functional natively it is empty, but when we cross-compile it we insert the desired CSRW instruction.</p> <p>Lets compile and run the evaluation program natively.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build-native\n% make ubmark-gcd-eval\n% ./ubmark-gcd-eval\n</code></pre> <p>If everything is working we can now test out our GCD software baseline on the TinyRV1 processor. First we need to cross-compile the GCD function in a different build directory. Let's also go ahead and look at the corresponding TinyRV2 assembly.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app\n% mkdir build\n% cd build\n% ../configure --host=riscv64-unknown-elf\n% make ubmark-gcd.o\n% tinyrv2-objdump ubmark-gcd.o\n</code></pre> <p>Note that we have not linked the object file yet so addresses are relative to the start of this function. Spend some time seeing if you can connect the assembly to the C code you write. Now let's cross-compiler the entire test program and again look at the GCD function.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build\n% make ubmark-gcd-test\n% tinyrv2-objdump ubmark-gcd-test | less -p \"&lt;ubmark_gcd&gt;:\"\n</code></pre> <p>Notice that we have now linked the program so the addresses are global addresses in the context of the entire program.</p> <p>We can run this test program on a functional-level (FL) model of the TinyRV2 processor just like you did in ECE 4750. An FL model of a processor is sometimes called an \"ISA simulator\" since it just simulates the ISA and does not model any of the microarchitecture.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build\n% ../../sim/pmx/pmx-sim ./ubmark-gcd-test\n</code></pre> <p>The output should look exactly the same as the native execution, but of course now we are simulating thousands or TinyRV1 instructions. Use the <code>--trace</code> command line option to watch these instructions being executed.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build\n% ../../sim/pmx/pmx-sim --trace ./ubmark-gcd-test\n</code></pre> <p>Let's also verify that our evaluation program runs correctly on the ISA simulator.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build\n% make ubmark-gcd-eval\n% ../../sim/pmx/pmx-sim ./ubmark-gcd-eval\n</code></pre> <p>Let's save the disassembly of the evaluation program for future reference.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build\n% tinyrv2-objdump ubmark-gcd-eval &gt; ubmark-gcd-eval.dump\n</code></pre> <p>We are now finally ready to run test and evaluate the GCD software baseline on the RTL implementation. Recall that the five-stage TinyRV2 processor pipeline datapath looks like this:</p> <p></p> <p>Let's start by looking at a version of the system with no caches before seeing the impact of adding an instruction and data cache.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl ./ubmark-gcd-test\n% ../../sim/pmx/pmx-sim --proc-impl rtl ./ubmark-gcd-eval\n</code></pre> <p>Again, the output should look the exactly the same as the native execution and the cross-compiled execution running on the ISA simulator, but of course now we are simulating thousands of of TinyRV2 instructions executing on the five-stage TinyRV2 pipelined processor you implemented in ECE 4750. Let's dig into the trace output to understand how these instructions are executing on the pipeline.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --trace ./ubmark-gcd-eval &gt; ubmark-gcd-eval-nocache.trace\n% code ubmark-gcd-eval-nocache.trace\n</code></pre> <p>Search for the first execution of the CSRW instruction. This is where we turn on stats and thus this is where the ROI starts. You should be able to look down and see where the GCD function starts its work. Use the disassembly to connect the PCs in the trace with the addresses of the instructions in the actual program. Here is an example:</p> <pre><code>     fetch    decode                  mem  exe  wb   imem  dmem\n271: 00000760|lw     x11, 0x000(x19) |    |    |blt  rd&gt;rd|      &gt;\n272: 00000764|lw     x10, 0x000(x20) |lw  |    |     rd&gt;rd|rd&gt;   &gt;\n273: 00000768|addi   x08, x08, 0x001 |lw  |lw  |     rd&gt;rd|rd&gt;rd &gt;\n274: 0000076c|addi   x20, x20, 0x004 |addi|lw  |lw   rd&gt;rd|  &gt;rd &gt;\n275: /       |jal    x01, 0x1ffb90   |addi|addi|lw   rd&gt;rd|      &gt;\n276: 000002fc|                       |jal |addi|addi rd&gt;rd|      &gt;\n277: /       |jal    x00, 0x00000c   |    |jal |addi rd&gt;rd|      &gt;\n278: 00000308|                       |jal |    |jal  rd&gt;rd|      &gt;\n279: 0000030c|addi   x15, x10, 0x000 |    |jal |     rd&gt;rd|      &gt;\n280: 00000310|blt    x10, x11, 0x1ff4|addi|    |jal  rd&gt;rd|      &gt;\n281: 00000314|beq    x11, x00, 0x000c|blt |addi|     rd&gt;rd|      &gt;\n282: 00000318|sub    x10, x10, x11   |beq |blt |addi rd&gt;rd|      &gt;\n283: /       |jal    x00, 0x1ffff0   |sub |beq |blt  rd&gt;rd|      &gt;\n284: 00000308|                       |jal |sub |beq  rd&gt;rd|      &gt;\n285: 0000030c|addi   x15, x10, 0x000 |    |jal |sub  rd&gt;rd|      &gt;\n286: 00000310|blt    x10, x11, 0x1ff4|addi|    |jal  rd&gt;rd|      &gt;\n287: /       |/                      |blt |addi|     rd&gt;rd|      &gt;\n288: 00000300|                       |    |blt |addi rd&gt;rd|      &gt;\n289: 00000304|addi   x10, x11, 0x000 |    |    |blt  rd&gt;rd|      &gt;\n290: 00000308|addi   x11, x15, 0x000 |addi|    |     rd&gt;rd|      &gt;\n291: 0000030c|addi   x15, x10, 0x000 |addi|addi|     rd&gt;rd|      &gt;\n292: 00000310|blt    x10, x11, 0x1ff4|addi|addi|addi rd&gt;rd|      &gt;\n293: 00000314|beq    x11, x00, 0x000c|blt |addi|addi rd&gt;rd|      &gt;\n294: /       |/                      |beq |blt |addi rd&gt;rd|      &gt;\n295: 0000031c|                       |    |beq |blt  rd&gt;rd|      &gt;\n296: 00000320|jalr   x00, x01, 0x000 |    |    |beq  rd&gt;rd|      &gt;\n297: /       |/                      |jalr|    |     rd&gt;rd|      &gt;\n298: 00000770|                       |    |jalr|     rd&gt;rd|      &gt;\n299: 00000774|sw     x10, 0x000(x18) |    |    |jalr rd&gt;rd|      &gt;\n300: 00000778|lw     x15, 0xc70(x21) |sw  |    |     rd&gt;rd|wr&gt;   &gt;\n301: 0000077c|addi   x19, x19, 0x004 |lw  |sw  |     rd&gt;rd|rd&gt;wr &gt;\n302: 00000780|addi   x18, x18, 0x004 |addi|lw  |sw   rd&gt;rd|  &gt;rd &gt;\n</code></pre> <p>You can see the instructions flowing down the pipeline. It looks like there are maybe four iterations of the while loop. Notice how we are squashing one instruction for a JAL and two instructions for a BEQ and JALR. Let's go ahead and rerun the evaluation but this time with the <code>--stats</code> command line option so we can determine the number of cycles and instructions in the ROI.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --stats ./ubmark-gcd-eval\n</code></pre> <p>Real systems also include caches. We cannot directly use the non-blocking cache you developed in ECE 4750 for two reasons. First, the ECE 4750 design has a four-cycle hit latency which would drastically reduce performance. Second, the ECE 4750 design uses combinational-read SRAMs. Real ASICs use synchronous-read SRAMs which means you send in the read address on one cycle and the read data comes back the next cycle. We have improved the ECE 4750 cache design to address both of these weaknesses. Here is what the improved datapath looks like:</p> <p></p> <p>And here is what the improved control unit looks like:</p> <p></p> <p>Let's rerun our GCD tests and evaluation program on both the processor and cache RTL to ensure everything still works.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --cache-impl rtl ./ubmark-gcd-test\n% ../../sim/pmx/pmx-sim --proc-impl rtl --cache-impl rtl ./ubmark-gcd-eval\n</code></pre> <p>Let's dig into the trace output to understand how the processor and cache interact.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --cache-impl rtl \\\n    --trace ./ubmark-gcd-eval &gt; ubmark-gcd-eval-cache.trace\n% code ubmark-gcd-eval-cache.trace\n</code></pre> <p>The trace will look very different! There is a column that shows the FSM state for instruction cache and a separate column that shows the FSM state for the data cache. You can see the misses in the instruction cache the first time we call the GCD function ...</p> <pre><code>     fetch    decode                  mem  exe  wb   I$  D$   imem  dmem\n474: 000002fc|                       |    |    |    [MWT|I  ]      |      &gt;\n475: /       |jal    x00, 0x00000c   |    |    |    [I  |I  ]      |      &gt;\n476: #       |                       |jal |    |    [TC |I  ]      |      &gt;\n477: #       |                       |    |jal |    [RRQ|I  ] rd&gt;  |      &gt;\n478: #       |                       |    |    |jal [RWT|I  ]   &gt;rd|      &gt;\n479: #       |                       |    |    |    [RUP|I  ]      |      &gt;\n480: #       |                       |    |    |    [MR0|I  ]      |      &gt;\n481: #       |                       |    |    |    [MR1|I  ]      |      &gt;\n482: #       |                       |    |    |    [MWT|I  ]      |      &gt;\n483: #       |                       |    |    |    [I  |I  ]      |      &gt;\n484: 00000308|                       |    |    |    [TC |I  ]      |      &gt;\n485: 0000030c|addi   x15, x10, 0x000 |    |    |    [TC |I  ]      |      &gt;\n486: #       |blt    x10, x11, 0x1ff4|addi|    |    [TC |I  ]      |      &gt;\n487: #       |                       |blt |addi|    [RRQ|I  ] rd&gt;  |      &gt;\n488: #       |                       |    |blt |addi[RWT|I  ]   &gt;rd|      &gt;\n489: #       |                       |    |    |blt [RUP|I  ]      |      &gt;\n490: #       |                       |    |    |    [MR0|I  ]      |      &gt;\n491: #       |                       |    |    |    [MR1|I  ]      |      &gt;\n492: 00000310|                       |    |    |    [MWT|I  ]      |      &gt;\n493: #       |beq    x11, x00, 0x000c|    |    |    [I  |I  ]      |      &gt;\n494: /       |                       |beq |    |    [TC |I  ]      |      &gt;\n495: 0000031c|                       |    |beq |    [TC |I  ]      |      &gt;\n496: #       |jalr   x00, x01, 0x000 |    |    |beq [TC |I  ]      |      &gt;\n497: /       |                       |jalr|    |    [RRQ|I  ] rd&gt;  |      &gt;\n498: #       |                       |    |jalr|    [RWT|I  ]   &gt;rd|      &gt;\n499: #       |                       |    |    |jalr[RUP|I  ]      |      &gt;\n</code></pre> <p>... and then later you can see the instruction cache hits.</p> <pre><code>     fetch    decode                  mem  exe  wb   I$  D$   imem  dmem\n584: 000002fc|                       |jal |addi|addi[TC |I  ]      |      &gt;\n585: /       |jal    x00, 0x00000c   |    |jal |addi[TC |I  ]      |      &gt;\n586: 00000308|                       |jal |    |jal [TC |I  ]      |      &gt;\n587: 0000030c|addi   x15, x10, 0x000 |    |jal |    [TC |I  ]      |      &gt;\n588: 00000310|blt    x10, x11, 0x1ff4|addi|    |jal [TC |I  ]      |      &gt;\n589: 00000314|beq    x11, x00, 0x000c|blt |addi|    [TC |I  ]      |      &gt;\n590: 00000318|sub    x10, x10, x11   |beq |blt |addi[TC |I  ]      |      &gt;\n591: /       |jal    x00, 0x1ffff0   |sub |beq |blt [TC |I  ]      |      &gt;\n592: 00000308|                       |jal |sub |beq [TC |I  ]      |      &gt;\n593: 0000030c|addi   x15, x10, 0x000 |    |jal |sub [TC |I  ]      |      &gt;\n594: 00000310|blt    x10, x11, 0x1ff4|addi|    |jal [TC |I  ]      |      &gt;\n595: /       |/                      |blt |addi|    [TC |I  ]      |      &gt;\n596: 00000300|                       |    |blt |addi[TC |I  ]      |      &gt;\n597: 00000304|addi   x10, x11, 0x000 |    |    |blt [TC |I  ]      |      &gt;\n598: 00000308|addi   x11, x15, 0x000 |addi|    |    [TC |I  ]      |      &gt;\n599: 0000030c|addi   x15, x10, 0x000 |addi|addi|    [TC |I  ]      |      &gt;\n600: 00000310|blt    x10, x11, 0x1ff4|addi|addi|addi[TC |I  ]      |      &gt;\n601: 00000314|beq    x11, x00, 0x000c|blt |addi|addi[TC |I  ]      |      &gt;\n602: /       |/                      |beq |blt |addi[TC |I  ]      |      &gt;\n603: 0000031c|                       |    |beq |blt [TC |I  ]      |      &gt;\n604: 00000320|jalr   x00, x01, 0x000 |    |    |beq [TC |I  ]      |      &gt;\n605: /       |/                      |jalr|    |    [TC |I  ]      |      &gt;\n606: 00000770|                       |    |jalr|    [TC |I  ]      |      &gt;\n607: 00000774|sw     x10, 0x000(x18) |    |    |jalr[TC |I  ]      |      &gt;\n</code></pre> <p>Let's go ahead and rerun the evaluation with both the processor and caches.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --cache-impl rtl \\\n    --stats ./ubmark-gcd-eval\n</code></pre>"},{"location":"ece6745-lab5/#4-accelerator-fl-model","title":"4. Accelerator FL Model","text":"<p>Now that we have our software baseline we can start to explore an accelerator that will hopefully improve the performance compared to the software baseline. We should always build a functional-level (FL) model of our accelerator before actually implementing the accelerator in hardware. The FL model will enable us to develop a compelling testing strategy and to also develop the software which interacts with the accelerator. In this course we will write our FL models in Python using PyMTL3.</p> <p>Our accelerators include a set of accelerator registers that can be read and written from the processor using special instructions and the xcelreq/xcelresp interface. The GCD accelerator protocol defines the accelerator registers as follows:</p> <ul> <li><code>xr0</code>: a (only bottom 15 bits are used)</li> <li><code>xr1</code>: b (only bottom 15 bits are used)</li> <li><code>xr2</code>: result (only bottom 15 bits are used)</li> </ul> <p>The actual protocol involves the folloing steps:</p> <ul> <li>Write a to xr0</li> <li>Write b to xr1</li> <li>Read result from xr2 (which causes the xcel to do the calculation)</li> </ul> <p>Take a look at the incomplete FL model in <code>sim/lab5_xcel/GcdXcelFL.py</code>.</p> <pre><code>% cd ${HOME}/ece6745/lab5/sim/lab5_xcel\n% code GcdXcelFL.py\n</code></pre> <p>The FL model uses a PyMTL <code>@update_once</code> block to model some hardware which should execute once per cycle. You may need to work through Tutorial 4 to learn more about PyMTL multi-level modeling:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/handouts/ece6745-tut4-pymtl.pdf</li> </ul> <p>We have provided you code which handles the accelerator protocol. Spend a few minutes understanding how this works. Now go ahead and use the Python standard library <code>math.gcd</code> function to finish implementing the FL model.</p> <p>We provide you an incomplete test bench in <code>sim/lab5_xcel/test/GcdXcelFL_test.py</code>. Go head and take a look at this test bench.</p> <pre><code>% cd ${HOME}/ece6745/lab5/sim/lab5_xcel/test\n% code GcdXcelFL_test.py\n</code></pre> <p>This is very similar to how we did our testing in ECE 4750. You need to implement the <code>xgcd</code> function which takes as input a, b, result and returns a list of acceleratore request messages and the expected response messages.</p> <p>Once you have finished the FL model and the test bench, go ahead and use pytest to test your FL model.</p> <pre><code>% mkdir -p ${HOME}/ece6745/sim/build\n% pytest ../lab5_xcel/test/GcdXcelFL_test.py -v\n</code></pre> <p>Notice how the FL model enables us to rigorously get all of our tests ready before we have even started our RTL modeling. This is the key to test-driven design. Now if our RTL model fails a test we can be reasonable sure the test is correct and the RTL model is wrong.</p> <p>The other benefit of an FL model is it enable us to start developing the software that will control our accelerator right away. Software will send messages to the accelerator by reading and writing 32 special CSRs using the standard CSRW and CSRR instructions. These 32 special CSRs are as follows:</p> <pre><code>0x7e0 : accelerator register  0 (xr0)\n0x7e1 : accelerator register  1 (xr1)\n0x7e2 : accelerator register  2 (xr2)\n...\n0x7ff : accelerator register 31 (xr31)\n</code></pre> <p>Here is a simple assembly sequence which will write the value 1 to an accelerator register, read that value back from the accelerator register, and write the value to general-purpose register x2.</p> <pre><code>addi x1, x0, 1\ncsrw 0x7e0, x1\ncsrr x2, 0x7e0\n</code></pre> <p>To use an accelerator from a C microbenchmark, we need to embed assembly instructions directly into a C program. We can do this using the GCC inline assembly extensions. Take a closer look at the accelerated version of the GCD function in <code>app/ubmark/ubmark-gcd-xcel.c</code>.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/ubmark\n% code ubmark-gcd-xcel.c\n</code></pre> <p>The incomplete implementation looks as follows:</p> <pre><code>#ifdef _RISCV\n\nint ubmark_gcd_xcel( int a, int b )\n{\n  int result;\n  __asm__ (\n    \"csrw ???, %[a];\\n\"\n    \"csrw ???, %[b];\\n\"\n    \"csrr %[result], ???;\\n\"\n\n    // Outputs from the inline assembly block\n\n    : [result] \"=r\"(result)\n\n    // Inputs to the inline assembly block\n\n    : [a] \"r\"(a),\n      [b] \"r\"(b)\n  );\n  return result;\n}\n\n#else\n\nint ubmark_gcd_xcel( int a, int b )\n{\n  return ubmark_gcd( a, b );\n}\n\n#endif\n</code></pre> <p>The <code>asm</code> keyword enables embedding assembly into a C program. We have a sequence of strings, and each string is one assembly instruction. <code>%[a]</code> is special syntax that tells GCC to put the register that holds the src C variable into that location in the assembly. So if the compiler ends up allocating the <code>a</code> C variable to <code>x11</code> then it will put <code>x11</code> into the first assembly instruction. Notice how we use the non-accelerated version for native compilation just to make sure everything works.</p> <p>Go ahead and fill in the <code>???</code> with the correct CSRs based on the accelerator protocol described earlier.</p> <p>Let's cross-compile and run both our test program and evaluation program using the FL model of the GCD accelerator.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build\n% ../../sim/pmx/pmx-sim --xcel-impl gcd-fl ./ubmark-gcd-xcel-test\n% ../../sim/pmx/pmx-sim --xcel-impl gcd-fl ./ubmark-gcd-xcel-eval\n</code></pre>"},{"location":"ece6745-lab5/#5-gcd-accelerator","title":"5. GCD Accelerator","text":"<p>We always want to use an incremental design process when implementing our accelerator. We often create one or more stand-alone units, unit test them, and then compose them with a manager to create the final accelerator.</p>"},{"location":"ece6745-lab5/#51-stand-alone-gcd-unit","title":"5.1. Stand-Alone GCD Unit","text":"<p>In this case, we want to reuse the stand-alone GCD unit we developed in Tutorial 3. Go ahead and take look at the stand-alone GCD unit.</p> <pre><code>% cd ${HOME}/ece6745/lab5/sim/tut3_verilog/gcd\n% code GcdUnit.v\n</code></pre> <p>The stand-alone GCD unit uses latency insensitive interfaces and a clean datapath/control split.</p> <p></p> <p>Let's run all the tests to make sure the stand-alone GCD unit is working.</p> <pre><code>% cd ${HOME}/ece6745/lab5/sim/build\n% pytest ../tut3_verilog/gcd\n</code></pre> <p>We also have a simulator for evaluating the GCD unit in isolation. You can experiment with the simulator like this:</p> <pre><code>% cd ${HOME}/ece6745/lab5/sim/build\n% ../tut3_verilog/gcd/gcd-sim --impl rtl --trace\n</code></pre> <p>These kind of stand-alone simulators are critical for evaluating the performance of various hardware units before turning the unit into a medium-grain accelerator and integrating it with a processor.</p>"},{"location":"ece6745-lab5/#52-medium-grain-gcd-accelerator","title":"5.2. Medium-Grain GCD Accelerator","text":"<p>To turn the GCD unit into an accelerator, we need to compose it with a manager which will handle the accelerator protocol. We have provided you a GCD accelerator manager in <code>sim/lab5_xcel/GcdXcel.v</code>. Go ahead and take a look this manager and how we compose it with the stand-alone GCD unit to create the complete accelerator.</p> <pre><code>% cd ${HOME}/ece6745/lab5/sim/lab5_xcel\n% code GcdXcel.v\n</code></pre> <p>To test our GCD accelerator, we can simply reuse all of the tests we wrote to verify our GCD FL model. This is the whole point of developing an FL model in the first place!</p> <pre><code>% cd ${HOME}/ece6745/lab5/sim/build\n% pytest ../lab5_xcel/test/GcdXcel_test.py\n</code></pre>"},{"location":"ece6745-lab5/#6-tinyrv2-processor-accelerator","title":"6. TinyRV2 Processor + Accelerator","text":"<p>We are now ready to test and evaluate the complete system with the procesor, caches, and accelerator. We already developed the software to control the accelerator with the FL model. So all we need to do is run the test program and evaluation program on the accelerator RTL implementation.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --cache-impl rtl \\\n    --xcel-impl gcd-rtl ./ubmark-gcd-xcel-test\n% ../../sim/pmx/pmx-sim --proc-impl rtl --cache-impl rtl \\\n    --xcel-impl gcd-rtl ./ubmark-gcd-xcel-eval\n</code></pre> <p>As always, do not simply rely on aggregate performance metrics. Dig into the line trace to really understand what is going on.</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --cache-impl rtl \\\n    --xcel-impl gcd-rtl --trace ./ubmark-gcd-xcel-eval &gt; ubmark-gcd-xcel-eval.dump\n</code></pre> <p>You should be able to understand every line and every column. It is absolutely critical to use line traces productively to understand how the processor, cache, and accelerator are all executing together.</p> <pre><code>     fetch    decode                  mem  exe  wb   I$  D$  xcelreq     mngr gcdreq    a    b   ST  gcd xcelresp   imem  dmem\n641: 000002fc|                       |jal |addi|addi[TC |I  ]              [X]         (0000 0000 I )    .                |\n642: 00000300|csrw       0x7e0, x10  |    |jal |addi[TC |I  ]              [X]         (0000 0000 I )    .                |\n643: 00000304|csrw       0x7e1, x11  |csrw|    |jal [TC |I  ]wr:00:00000007[X]         (0000 0000 I )    .                |\n644: 00000308|csrr   x10,     0x7e2  |csrw|csrw|    [TC |I  ]wr:01:00000031[X]         (0000 0000 I )    wr:              |\n645: 0000030c|jalr   x00, x01, 0x000 |csrr|csrw|csrw[TC |I  ]rd:02:        [X]         (0000 0000 I )    wr:              |\n646: #       |#                      |#   |#   |csrw[TC |I  ]              [X]0007:0031(0000 0000 I )    .                |\n647: #       |#                      |#   |#   |    [HWT|I  ]              [C].        (0007 0031 Cs)    .                |\n648: #       |#                      |#   |#   |    [HWT|I  ]              [C].        (0031 0007 C-)    .                |\n649: #       |#                      |#   |#   |    [HWT|I  ]              [C].        (002a 0007 C-)    .                |\n650: #       |#                      |#   |#   |    [HWT|I  ]              [C].        (0023 0007 C-)    .                |\n651: #       |#                      |#   |#   |    [HWT|I  ]              [C].        (001c 0007 C-)    .                |\n652: #       |#                      |#   |#   |    [HWT|I  ]              [C].        (0015 0007 C-)    .                |\n653: #       |#                      |#   |#   |    [HWT|I  ]              [C].        (000e 0007 C-)    .                |\n654: #       |#                      |#   |#   |    [HWT|I  ]              [C].        (0007 0007 C-)    .                |\n655: #       |#                      |#   |#   |    [HWT|I  ]              [C].        (0000 0007 Cs)    .                |\n656: #       |#                      |#   |#   |    [HWT|I  ]              [C].        (0007 0000 C )    .                |\n657: #       |#                      |#   |#   |    [HWT|I  ]              [C].        (0007 0000 D )0007.                |\n658: /       |/                      |jalr|csrr|    [HWT|I  ]              [W]         (0007 0000 I )    rd:00000007      |\n659: #       |                       |    |jalr|csrr[I  |I  ]              [X]         (0000 0000 I )    .                |\n660: 0000075c|                       |    |    |jalr[TC |I  ]              [X]         (0000 0000 I )    .                |\n</code></pre> <p>Now we are ready to do the final experiment and see if our GCD accelerator improves the peroformance compared to the software baseline!</p> <pre><code>% cd ${HOME}/ece6745/lab5/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --cache-impl rtl \\\n    --xcel-impl gcd-rtl --stats ./ubmark-gcd-xcel-eval\n</code></pre>"},{"location":"ece6745-lab5/#7-project-2","title":"7. Project 2","text":"<p>Now that you better understand the kind of medium-grain accelerators we will be designing, implementing, testing, evaluating, and fabricating in project 2, start to brainstorm what you want to tapeout in project 2. We have some ideas here:</p> <ul> <li>https://cornell-ece6745.github.io/ece6745-mkdocs/ece6745-project2-ideas</li> </ul> <p>You must talk to Prof. Batten before you leave today about your ideas for project 2.</p>"},{"location":"ece6745-project1a/","title":"ECE 6745 Project 1: TinyFlow Tape-OutTinyFlow Standard Cells","text":"<p>In this project, students will build their own TinyFlow, a very simple standard-cell-based flow. They will develop seven standard cells in TSMC 180nm and the corresponding standard cell behavioral, schematic, layout, extracted schematic, front-end, and back-end views. They will then implement simple algorithms for synthesis (technology mapping via tree covering, static timing analysis) and place-and-route (simulated annealing, 3D maze routing). Finally they will combine this work with open-source Verilog RTL and gate-level simulators and an open-source LVS/DRC tool to create the complete TinyFlow. Even though their TinyFlow will only support a very small combinational subset of Verilog, this project still gives students a unique hands-on opportunity to appreciate every step required in more sophisticated commercial tools. Each group will create a tiny block using their TinyFlow and these blocks will be aggregated into a single unified tape-out on the TSMC 180nm technology node.</p> <p>The project includes three parts:</p> <ul> <li>Part A: TinyFlow Standard Cells</li> <li>Part B: TinyFlow Front End</li> <li>Part C: TinyFlow Back End</li> </ul> <p>All parts must be done in a group of 2-3 students. You can confirm your group on Canvas (Click on People, then Groups, then search for your name to find your project group).</p> <p>All students must contribute to all parts!</p> <p>It is not acceptable for one student to do all of Part A and a different student to do all of part B. It is not acceptable for one student to exclusively work on the layout while the other student exclusively works on SPICE characterization. All students must contribute to all parts. The instructors will also survey the Git commit log on GitHub to confirm that all students are contributing equally. If you are using a \"pair programming\" style, then both students must take turns using their own account so both students have representative Git commits. Students should create commits after finishing each step of the project, so their contribution is clear in the Git commit log. A student whose contribution is limited as represented by the Git commit log will receive a significant deduction to their project score.</p> <p>This handout assumes that you have read and understand the course tutorials and that you have attended the lab sections. To get started, use VS Code to log into a specific <code>ecelinux</code> server, use MS Remote Desktop to log into the same <code>ecelinux</code> server, source the setup scripts, and clone your remote repository from GitHub:</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% xclock &amp;\n% mkdir -p ${HOME}/ece6745\n% cd ${HOME}/ece6745\n% git clone git@github.com:cornell-ece6745/project1-groupXX\n% cd project1-groupXX\n% tree\n</code></pre> <p>where <code>XX</code> should be replaced with your group number. You can both pull and push to your remote repository. If you have already cloned your remote repository, then use git pull to ensure you have any recent updates before working on your lab assignment.</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX\n% git pull\n% tree\n</code></pre> <p>where <code>XX</code> should be replaced with your group number. Your repo contains the following files for the views and simulation scripts for each standard cell:</p> <pre><code>.\n\u2514\u2500\u2500 stdcells/\n    \u251c\u2500\u2500 verilog-test/\n    \u2502   \u251c\u2500\u2500 AOI21X1-test.v\n    \u2502   \u251c\u2500\u2500 INVX1-test.v\n    \u2502   \u251c\u2500\u2500 NAND2X1-test.v\n    \u2502   \u251c\u2500\u2500 NOR2X1-test.v\n    \u2502   \u251c\u2500\u2500 TIEHI-test.v\n    \u2502   \u2514\u2500\u2500 TIELO-test.v\n    \u251c\u2500\u2500 stdcells-be.yml\n    \u251c\u2500\u2500 stdcells-fe.yml\n    \u251c\u2500\u2500 stdcells-rcx.yml\n    \u251c\u2500\u2500 stdcells.gds\n    \u251c\u2500\u2500 stdcells.sp\n    \u2514\u2500\u2500 stdcells.v\n</code></pre> <p>Go ahead and create a build directory where you will run your simulations when verifying and characterizing your standard cells.</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX\n% mkdir -p stdcells/build\n% cd stdcells/build\n</code></pre>"},{"location":"ece6745-project1a/#1-standard-cell-library","title":"1. Standard-Cell Library","text":"<p>In this part, you will need to implement the following seven standard cells.</p> Name Logic Function Rise/Fall Time Drive Strength INVX1 \\(Y = \\overline{A}\\) Similar NAND2X1 \\(Y = \\overline{AB}\\) Similar Similar to INVX1 NOR2X1 \\(Y = \\overline{A+B}\\) (see below) (see below) AOI21X1 \\(Y = \\overline{AB+C}\\) (see below) (see below) TIEHI \\(Y = 1\\) n/a n/a TIELO \\(Y = 0\\) n/a n/a FILL n/a n/a n/a <p>The INVX1 and NAND2X1 standard cells should be sized to have roughly equal rise and fall times assuming the effective resistance of PNMOS transistor is twice the effective resistance of an NMOS transistor with the same width. The NAND2X1 standard cell should be sized to have roughly the same drive strength (i.e., effective resistance) as the INVX1 standard cell.</p> <p>For NOR2X1 and AOI21X1 standard cells, students can choose one of two options.</p> <ul> <li> <p>Option 1: Size these gates such that they have roughly equal rise and    fall times and roughly the same drive strength (i.e., effective    resistance) as the INVX1 standard cell; this will require using    fingers.</p> </li> <li> <p>Option 2: Do not use fingers meaning the gates will likely have    non-equal rise and fall times. You should size the pull-down network    to have similar effective resistance as compared to an INVX1 standard    cell. The pull-up network will likely have a different effective    resistance as compared to an INVX1 standard cell.</p> </li> </ul> <p>The TIEHI standard cell should use a weak PMOS to pull-up the output to VDD; gate of weak PMOS should be connected to a diode-connected NMOS. The TIELO standard cell should use a weak NMOS to pull-down the output to ground, gate of weak NMOS should be connected to a diode-connected PMOS.</p> <p>The FILL cell should be a one-track wide filler cell with a vertical strip of polysilicon to meet poly density design rules.</p> <p>Our standard cell library will include the following six views:</p> <ul> <li> <p>Behavioral View (BV): Logical function of the standard cell, used      for gate-level simulation</p> </li> <li> <p>Schematic View (SV): Transistor-level representation of standard      cell, used for functional verification and layout-vs-schematic</p> </li> <li> <p>Layout View (LV): Layout of standard cell, used for design-rule      checking (DRC), layout-vs-schematic (LVS), resistance/capacitance      extraction (RCX), and fabrication</p> </li> <li> <p>Extracted Schematic View (ESV): Transistor-level representation      with extracted resistance and capacitances, used for      layout-vs-schematic (LVS) and timing characterization</p> </li> <li> <p>Front-End View (FEV): High-level information about standard cell      including area, input capacitance, logical function, and delay      model; used in synthesis</p> </li> <li> <p>Back-End View (BEV): Low-level information about standard cell      including height, width, and pin locations; used in placement and      routing</p> </li> </ul> <p>The following table shows which views need to be implemented for which standard cells.</p> Name BV SV LV ESV FEV BEV INVX1 yes yes yes yes yes yes NAND2X1 yes yes yes yes yes yes NOR2X1 yes yes yes yes yes yes AOI21X1 yes yes yes yes yes yes TIEHI yes yes yes yes (b) yes (c) yes TIELO yes yes yes yes (b) yes (c) yes FILL yes (a) no yes no yes (c,d) yes (d) <ul> <li> <p>(a) The behavioral view for the FILL standard cell is an empty Verilog    module.</p> </li> <li> <p>(b) Extracted schematic simulation for the TIEHI and TIELO standard    cells is only for functional verification; these gates do not switch    so there is no timing characterization.</p> </li> <li> <p>(c) The front-end view for the TIEHI, TIELO, and FILL standard cells    does not include a linear delay model nor any patterns.</p> </li> <li> <p>(d) The front-end and back-end views for the FILL standard cell do not    include any pins.</p> </li> </ul> <p>We will be using the following TinyFlow standard-cell design flow.</p> <p></p> <p>We will begin by writing the behavioral view in Verilog and verifying its functionality using a Verilog test bench and Icarus Verilog. We will then write the schematic view in SPICE and verify its functionality using a SPICE test bench and TinyFlow-Ngspice. Instead of using Ngspice directly, we will use our TinyFlow-Ngspice wrapper script which makes it much easier to run SPICE simulations. We will then use the KLayout design editor to create the layout, perform a design-rules check (DRC), perform a layout vs. schematic check (LVS), and generate an extracted schematic. We will re-simulate the extracted transistor-level schematic using TinyFlow-Ngspice to characterize the propagation delay for different load capacitances in order to create a linear delay model. Finally, we will write the front-end and back-end views for our standard-cell inverter in two YAML files. We will also implement three auxiliary standard cells (i.e., TIEHI, TIELO, FILL).</p> <p>We recommend implementing all six views for one standard cell before moving on to the next standard cell. Consider having each student implement all six views for different standard cells.</p>"},{"location":"ece6745-project1a/#11-behavioral-view","title":"1.1. Behavioral View","text":"<p>Start by working out the truth table for a standard cell. Once you have your truth table, then implement the logic equation which corresponds to this truth table in a Verilog module in <code>stdcells.v</code>. The Verilog module must have the exact module name and port names as what is used in the other views. For example, the interface for the INVX1 standard cell is as follows.</p> <pre><code>module INVX1\n(\n  input  A,\n  output Y\n);\n\n...\n\nendmodule\n</code></pre> <p>The Verilog implementation should use a single assign statement with simple bitwise operators.</p> <p>We have provided test benches to test each Verilog module. The test benches are structured as shown below.</p> <pre><code>module Top;\n\n  //----------------------------------------------------------------------\n  // Instantiate design under test\n  //----------------------------------------------------------------------\n\n  logic A;\n  logic Y;\n\n  INVX1 dut\n  (\n    .A (A),\n    .Y (Y)\n  );\n\n  //----------------------------------------------------------------------\n  // check\n  //----------------------------------------------------------------------\n\n  task check\n  (\n    input logic A_,\n    input logic Y_\n  );\n\n    A = A_;\n\n    #1;\n\n    $display( \"%d: %b &gt; %b\", 8'($time), A, Y );\n\n    if ( Y !== Y_ ) begin\n      ... print error message ...\n      $finish();\n    end\n\n  endtask\n\n  //----------------------------------------------------------------------\n  // main\n  //----------------------------------------------------------------------\n\n  initial begin\n\n    $dumpfile(\"INVX1-test.vcd\");\n    $dumpvars();\n    $display(\"\");\n\n    //     A     Y\n    check( 1'b0, 1'b1 );\n\n    $display(\"\");\n  end\n\nendmodule\n</code></pre> <p>The <code>check</code> task is used to set the inputs and check that the output is as expected. We provide you a single check for each standard cell. You are responsible for adding additional checks to ensure you have exhaustively tested all inputs, i.e., you need one check for every row in your truth table. You can run a test bench as follows.</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/stdcells/build\n% iverilog -Wall -g2012 -I .. -o INVX1-test ../verilog-test/INVX1-test.v\n% ./INVX1-test\n</code></pre>"},{"location":"ece6745-project1a/#12-schematic-view","title":"1.2. Schematic View","text":"<p>Start by drawing the schematic view and then sizing the transistors appropriately based on whether you are targetting equal rise and fall times and your target drive strength. Once you have your drawing, then implement this schematic view in a SPICE subcircuit in <code>stdcells.sp</code>. The SPICE subcircuit must have the exact subcircuit name and port names as what is used in the other views. For example, the interface for the INVX1 standard cell is as follows.</p> <pre><code>.SUBCKT INVX1 A Y VDD VSS\n\n...\n\n.ENDS INVX1\n</code></pre> <p>Recall from from lecture that the SPICE syntax is as follows:</p> <ul> <li>PMOS: <code>M_P &lt;D&gt; &lt;G&gt; &lt;S&gt; &lt;B&gt; PMOS L=&lt;length&gt;U W=&lt;width&gt;U</code></li> <li>NMOS: <code>M_N &lt;D&gt; &lt;G&gt; &lt;S&gt; &lt;B&gt; NMOS L=&lt;length&gt;U W=&lt;width&gt;U</code></li> </ul> <p>For standard cells with more than one NMOS and PMOS. You will need to make sure each transistor has a unique name (e.g., <code>M_N1</code>, <code>M_N2</code>, etc). If your schematic view needs a temporary internal wire/net, simply use a new name like <code>net1</code>; SPICE will assume this implicitly refers to a new temporary internal wire/net.</p> <p>Once you have a completed the schematic view, you will now simulate it with TinyFlow-Ngspice. The following shows the syntax of how to use the new <code>tinyflow-ngspice</code> wrapper script.</p> <pre><code>tinyflow-ngspice --spice=&lt;SPICE_FILE&gt; --cell=&lt;CELLNAME&gt; --cload=&lt;CLOAD&gt; \\\n  --inputs=&lt;INPUTS_SPEC&gt;\n</code></pre> <p>Let's break down each input (all four are required):</p> <ul> <li> <p><code>--spice=&lt;SPICE_FILE&gt;</code>: replace <code>&lt;SPICE_FILE&gt;</code> with the path to    <code>stdcells.sp</code> where you have defined your SPICE schematic (e.g.,    <code>../stdcells.sp</code>)</p> </li> <li> <p><code>--cell=&lt;CELLNAME&gt;</code>: replace <code>&lt;CELLNAME&gt;</code> with the name of your cell    to test (e.g., <code>INVX1</code>)</p> </li> <li> <p><code>--cload=&lt;CLOAD&gt;</code>: replace <code>&lt;CLOAD&gt;</code> with the capacitance to put on    the output pin of your cell, you can use regular integers followed by    a unit suffix (e.g., <code>10f</code> for 10 femtofarads)</p> </li> <li> <p><code>--inputs=&lt;INPUTS_SPEC&gt;</code>: replace <code>&lt;INPUTS_SPEC&gt;</code> with a string    surrounded by quotes of the following form:    <code>&lt;PIN1&gt;:&lt;VAL0&gt;-&lt;VAL1&gt;...&lt;VALN&gt;;&lt;PIN2&gt;:&lt;VAL0&gt;-&lt;VAL1&gt;...&lt;VALN&gt;</code> where    <code>&lt;PINN&gt;</code> specifies one of the input pins for your cell (e.g. A, B,    etc.), and <code>&lt;VALN&gt;</code> specifies a 0 or 1 to assert on that input pin.    Each of these values are separated by a dash (-), such that each input    value will be set for one timestep (2ns) before the next value is set.    All input pins and their corresponding values are separated by a    semicolon (;), and input pin names are separated from their values    list by a colon (:). All input pins as specified by your standard cell    must be present, and they must all have the same number of    transitions.</p> </li> </ul> <p>Use TinyFlow-Ngspice to simulate the INVX1 standard cell with a 0fF load and an input toggling between zero and one.</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/stdcells/build\n% tinyflow-ngspice --spice=../stdcells.sp --cell=INVX1 --cload=0f \\\n    --inputs=\"A:0-1-0-1-0\"\n</code></pre> <p>When the command has completed, you will see an output to the console specifying the transitions of both the input and output pins of your standard cell throughout the simulation. It will also print rising and falling delays if captured from each input pin to the output; this will be discussed later when characterizing the cell. Additionally, your build directory will contain a new subdirectory <code>ngspice-results/</code> with more subdirectories within it named with a concatenation of the inputs you specified. Each of these subdirectories will contain the following:</p> <ul> <li><code>-tb.sp</code>: the Spice testbench used to simulate your schematic</li> <li><code>.csv</code>: CSV data generated by Ngspice for each pin of your standard cell</li> <li><code>.png</code>: an image plotting the voltage of each pin of your standard cell over    time</li> <li><code>.txt</code>: a text file containing the same output as what was printed to the    console</li> </ul> <p>Use TinyFlow-Ngspice to verify functionality of the schematic view for each standard cell. Look at the text output and the waveform plot.</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/stdcells/build\n% code ngspice-results/INVX1-50f-stdcells-A_0_1_0_1_0/INVX1-50f-stdcells-A_0_1_0_1_0.png\n</code></pre>"},{"location":"ece6745-project1a/#13-layout-view","title":"1.3. Layout View","text":"<p>Start by drawing a stick diagram for your layout to make a plan for how you want to place your transitors and use polysilicon and metal 1 to connect these transistors together. Once you have a stick diagram you can check to make sure your transistors will fit in a fixed height standard cell. If the transistors will not fit then you need to either consider using fingers OR supporting non-equal rise and fall times and/or reducing the drive strength. If you do use fingers you do not need to go back and add fingers to the schematic view. KLayout LVS is smart enough to know that a wide transistor in the schematic can map to fingers in the layout.</p> <p>Once you are happy with your stick diagram, go ahead and use KLayout to draw the corresponding standard cell in <code>stdcells.gds</code>. When switching to a new cell in the KLayout GUI, make sure to right-click it from the Cells panel on the left and select Show As New Top. Try to minimize the width of your standard cell; when you are done you can shrink it to take the minimum number of sites (i.e., vertical routing tracks). Use DRC and LVS to complete physical verification of your layout.</p>"},{"location":"ece6745-project1a/#14-extracted-schematic-view","title":"1.4. Extracted Schematic View","text":"<p>The extracted schematic view is generated automatically when you run LVS. You will need to copy the contents of the generated SPICE file into <code>stdcells-rcx.sp</code>. Now you can use TinyFlow-Ngspice to do functional verification and timing characterization of your standard cell.</p> <p>Start by creating a spreadsheet with one row for every possible input transition. For example, a two-input standard cell (i.e., NAND2X1 and NOR2X1) would use the following table:</p> A B Y intercept slope 0 0-&gt;1 0 1-&gt;0 1 0-&gt;1 1 1-&gt;0 0-&gt;1 0 1-&gt;0 0 0-&gt;1 1 1-&gt;0 1 <p>A three-input standard cell (i.e., AOI21X1) needs a table with 24 rows. For each row, run a simulation using TinyFlow-Ngspice with a load capacitance of 10fF and record what happens to the output in the table (i.e, does it stay at 0, stay at 1, transition from 0 to 1, transition from 1 to 0).</p> <p>If the output transitions, first ensure the propagation delay measurements are reasonable. You should be anywhere from 10s of ps to 100s of ps. Then rerun the TinyFlow-Ngspice simulation with a load capacitance of 20fF and then 30fF. Record the propagation delay for each simulation. You now have three points for load capacitance and propagation delay. Then use a spreadsheet to determine a linear regression through these three points. Confirm that the linear regression is a good fit, and record the corresponding intercept (i.e., parasitic delay in ps) and slope (i.e., load delay factor in ps/fF) in the table.</p> <p>Here is an example for how to generate the data necessary to analyze the fall time of the INVX1 standard cell. Note that 10f, 20f, 30f for the <code>cload</code> argument corresponds to 10fF, 20fF, and 30fF.</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/stdcells/build\n\n% tinyflow-ngspice --spice=../stdcells-rcx.sp --cell=INVX1 --cload=10f \\\n    --inputs=\"A:0-1\"\n\n% tinyflow-ngspice --spice=../stdcells-rcx.sp --cell=INVX1 --cload=20f \\\n    --inputs=\"A:0-1\"\n\n% tinyflow-ngspice --spice=../stdcells-rcx.sp --cell=INVX1 --cload=30f \\\n    --inputs=\"A:0-1\"\n</code></pre> <p>Once you are done look at all of your data. Our goal is to create a single path- and value-independent linear model for the propagation delay (i.e., the worst case delay through the standard cell across all possible paths and values). Find the maximum parasitic delay and the max load delay factor across all propagation delay equations. It is ok if these come from different rows. We will use this parasitic delay and load delay factor for the linear delay model of the standard cell.</p>"},{"location":"ece6745-project1a/#15-front-end-view","title":"1.5. Front-End View","text":"<p>The front-end view is stored in the <code>stdcells-fe.yml</code> file. This YAML file will use much of the information we have obtained in previous steps, and combine it together for the front-end tools to use. This view primarily contains timing, logical, and basic area information for each cell.</p> <p>The following is a template for the front-end view for the INVX1 standard cell.</p> <pre><code> - name: INVX1\n   area_cost: 0 # lambda^2\n\n   pins:\n\n     - name: A\n       type: input\n       cgate: 0 # fF\n\n     - name: Y\n       type: output\n       function: # tree of generic gates\n\n   parasitic_delay:   0 # ps\n   load_delay_factor: 0 # ps/fF\n\n   patterns:\n     - # list of equivalent trees of generic NAND and INV gates\n</code></pre> <p>Fill in the <code>area_cost</code> value as the area of the standard cell in lambda-squared, starting from the bottom-left corner of the intersecting black lines indicating the horizontal and vertical tracks, and ending at the top-right corner at the intersection of the black lines for the horizontal and vertical tracks.</p> <p>Each cell also has pin information under the \"pin\" key. The pin information itself will be a list of data for each input and output pin, where each pin has a name and type (input or output).</p> <p>For input pins, you will need to specify a value for the gate capacitance (<code>cgate</code>) in fF associated with that pin. The calculation for gate capacitance is as follows:</p> <pre><code>Cgate = 1.60 * (total gate width in lambda) * 0.09\n</code></pre> <p>The value of 1.60 fF/um is a reasonable value for a generic 180nm process. You need to convert it to just units of fF by multiplying by the total gate width in um associated with the given input pin. You will need to find this total gate width in units of lambda by looking at your layout and comparing against your SPICE schematic. The multiplication by 0.09 is to convert lambda to microns.</p> <p>For output pins, you will need to specify the function which determines the logical functionality of this pin as a function of the input pins. You can specify it using a tree of generic gates. Here is a list of the valid generic gates:</p> <ul> <li><code>BUF</code>, <code>NOT</code>, <code>INV</code></li> <li><code>AND2</code>, <code>OR2</code>, <code>XOR2</code></li> <li><code>NAND2</code>, <code>NOR2</code>, <code>XNOR2</code></li> </ul> <p>So for example, here is an example tree for a more complicated three-input standard cell: <code>NAND2(INV(A),OR2(INV(B),C))</code>.</p> <p>You will need to fill in your values for <code>load_delay_factor</code> and <code>parasitic_delay</code> as calculated when simulating the extracted schematic view. Note that <code>load_delay_factor</code> MUST be in units of ps/fF, and <code>parasitic_delay</code> MUST be in units of ps. Go back and double check you performed the conversions if necessary.</p> <p>Finally, you will need to specify a list of patterns using only INV() and NAND2() logical gates that matches the functionality of your gate for all of its inputs.</p>"},{"location":"ece6745-project1a/#16-back-end-view","title":"1.6. Back-End View","text":"<p>The back-end view is stored in the <code>stdcells-be.yml</code> file. This YAML file will use much of the information we have obtained in previous steps, and combine it together for the back-end tools to use. This file primarily contains physical data for each cell including width, height, and pin locations.</p> <p>We give you the following template for the back-end view for the INVX1 standard cell.</p> <pre><code>  - name: INVX1\n    size:\n      width:  0 # lambda\n      height: 0 # lambda\n    pins:\n      - name: A\n        loc:  (0,0) # (x,y) lambda\n      - name: Y\n        loc:  (0,0) # (x,y) lambda\n</code></pre> <p>Each cell has a \"size\" sub-dictionary, with keys for width and height. Fill these values in using the same lower-left and upper-right track intersection points used for calculating area in the front-end YAML. These width and height values should therefore be in units of lambda. Next is the pin list, similar again to the front-end view. In this file, each pin once again has a name, but also an X and Y location. Look at your layout, and get the X and Y location of the pin marker for each pin relative to the lower-left track intersection. These values should once again be in units of lambda.</p>"},{"location":"ece6745-project1a/#2-optional-extensions","title":"2. Optional Extensions","text":"<p>Students are welcome to add another standard cell to their standard cell library. Students should focus on adding a combinational logic gate since TinyFlow does not support sequential logic gates (e.g., flip-flops). Students should not implement a gate with increased drive strength (e.g., INVX2, INVX4) since TinyFlow cannot take advantage of these larger cells. Some ideas include:</p> <ul> <li>NAND3X1, NOR3X1, NAND4X1, NOR4X1</li> <li>AND2X1, OR2X1</li> <li>OAI21X1, AOI22X1, OAI22X1</li> </ul> <p>Students will need to add this new gate to all six views. We do not recommend implementing XORX1 or XNORX1. These are very complicated gates and they are unlikely to actually be used by the TinyFlow front end.</p>"},{"location":"ece6745-project1a/#3-project-submission","title":"3. Project Submission","text":"<p>To submit your code you simply push your code to GitHub. You can push your code as many times as you like before the deadline. Students are responsible for going to the GitHub website for your repository, browsing the source code, and confirming that the code they want to submit is on GitHub. Be sure to verify your code is passing all of your simulations on <code>ecelinux</code>.</p> <p>Here is how we will be testing your final code submission for Part A. First, we will create a build directory.</p> <pre><code>% mkdir -p ${HOME}/ece6745\n% cd ${HOME}/ece6745\n% git clone git@github.com:cornell-ece6745/project1-groupXX\n% mkdir -p project1-groupXX/stdcells/build\n% cd project1-groupXX/stdcells/build\n</code></pre> <p>We will check the behavioral views are functionally correct.</p> <pre><code>% iverilog -Wall -g2012 -I .. -o INVX1-test ../verilog-test/INVX1-test.v\n% ./INVX1-test\n\n% iverilog -Wall -g2012 -I .. -o NAND2X1-test ../verilog-test/NAND2X1-test.v\n% ./NAND2X1-test\n\n% iverilog -Wall -g2012 -I .. -o NOR2X1-test ../verilog-test/NOR2X1-test.v\n% ./NOR2X1-test\n\n% iverilog -Wall -g2012 -I .. -o AOI21X1-test ../verilog-test/AOI21X1-test.v\n% ./AOI21X1-test\n\n% iverilog -Wall -g2012 -I .. -o TIEHI-test ../verilog-test/TIEHI-test.v\n% ./TIEHI-test\n\n% iverilog -Wall -g2012 -I .. -o TIELO-test ../verilog-test/TIELO-test.v\n% ./TIELO-test\n</code></pre> <p>We will check if the schematic views are functionally correct.</p> <pre><code>% tinyflow-ngspice --spice=../stdcells.sp --cell=INVX1   --cload=0f \\\n                   --inputs=\"A:0-1-0-1\"\n\n% tinyflow-ngspice --spice=../stdcells.sp --cell=NAND2X1 --cload=0f \\\n                   --inputs=\"A:0-1-0-1;B:0-0-1-1\"\n\n% tinyflow-ngspice --spice=../stdcells.sp --cell=NOR2X1  --cload=0f \\\n                  --inputs=\"A:0-1-0-1;B:0-0-1-1\"\n\n% tinyflow-ngspice --spice=../stdcells.sp --cell=AOI21X1 --cload=0f \\\n                  --inputs=\"A:0-1-0-1-0-1-0-1;B:0-0-1-1-0-0-1-1;C:0-0-0-0-1-1-1-1\"\n</code></pre> <p>We will check to make sure the layout view is DRC and LVS clean.</p> <pre><code>% tinyflow-batch-drc\n% tinyflow-batch-lvs\n</code></pre> <p>We will check if the extracted schematic views are functionally correct.</p> <pre><code>% tinyflow-ngspice --spice=../stdcells-rcx.sp --cell=INVX1   --cload=0f \\\n                   --inputs=\"A:0-1-0-1\"\n\n% tinyflow-ngspice --spice=../stdcells-rcx.sp --cell=NAND2X1 --cload=0f \\\n                   --inputs=\"A:0-1-0-1;B:0-0-1-1\"\n\n% tinyflow-ngspice --spice=../stdcells-rcx.sp --cell=NOR2X1  --cload=0f \\\n                  --inputs=\"A:0-1-0-1;B:0-0-1-1\"\n\n% tinyflow-ngspice --spice=../stdcells-rcx.sp --cell=AOI21X1 --cload=0f \\\n                  --inputs=\"A:0-1-0-1-0-1-0-1;B:0-0-1-1-0-0-1-1;C:0-0-0-0-1-1-1-1\"\n</code></pre> <p>We will also simulate all possible transistors for all standard cells. We will check your front-end and back-end view values to ensure they are reasonable and match your other views.</p>"},{"location":"ece6745-project1b/","title":"ECE 6745 Project 1: TinyFlow Tape-OutTinyFlow Front-End","text":"<p>In this project, students will build their own TinyFlow, a very simple standard-cell-based flow. They will develop seven standard cells in TSMC 180nm and the corresponding standard cell behavioral, schematic, layout, extracted schematic, front-end, and back-end views. They will then implement simple algorithms for synthesis (technology mapping via tree covering, static timing analysis) and place-and-route (simulated annealing, 3D maze routing). Finally they will combine this work with open-source Verilog RTL and gate-level simulators and an open-source LVS/DRC tool to create the complete TinyFlow. Even though their TinyFlow will only support a very small combinational subset of Verilog, this project still gives students a unique hands-on opportunity to appreciate every step required in more sophisticated commercial tools. Each group will create a tiny block using their TinyFlow and these blocks will be aggregated into a single unified tape-out on the TSMC 180nm technology node.</p> <p>The project includes three parts:</p> <ul> <li>Part A: TinyFlow Standard Cells</li> <li>Part B: TinyFlow Front End</li> <li>Part C: TinyFlow Back End</li> </ul> <p>Continue working with your group from Part A. You can confirm your group on Canvas (Click on People, then Groups, then search for your name to find your project group).</p> <p>All students must contribute to all parts!</p> <p>It is not acceptable for one student to do all of Part A and a different student to do all of part B. It is not acceptable for one student to exclusively work on one algorithm while the other student exclusively works on a different algorithm. All students must contribute to all parts. The instructors will also survey the Git commit log on GitHub to confirm that all students are contributing equally. If you are using a \"pair programming\" style, then both students must take turns using their own account so both students have representative Git commits. Students should create commits after finishing each step of the project, so their contribution is clear in the Git commit log. A student's whose contribution is limited as represented by the Git commit log will receive a significant deduction to their project score.</p> <p>This handout assumes that you have read and understand the course tutorials and that you have attended the lab sections. To get started, use VS Code to log into a specific <code>ecelinux</code> server, use MS Remote Desktop to log into the same <code>ecelinux</code> server, source the setup scripts, and clone your remote repository from GitHub:</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% xclock &amp;\n% mkdir -p ${HOME}/ece6745\n% cd ${HOME}/ece6745\n% git clone git@github.com:cornell-ece6745/project1-groupXX\n% cd project1-groupXX\n% tree\n</code></pre> <p>where <code>XX</code> should be replaced with your group number. You can both pull and push to your remote repository. If you have already cloned your remote repository, then use git pull to ensure you have any recent updates before working on your lab assignment.</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX\n% git pull\n% tree\n</code></pre> <p>where <code>XX</code> should be replaced with your group number. Your repo contains the following files.</p> <pre><code>.\n\u251c\u2500\u2500 asic\n\u2502   \u2514\u2500\u2500 build-fa\n\u2502       \u251c\u2500\u2500 01-verilator-rtlsim\n\u2502       \u251c\u2500\u2500 02-iverilog-rtlsim\n\u2502       \u251c\u2500\u2500 03-tinyflow-synth\n\u2502       \u2502   \u2514\u2500\u2500 run.py\n\u2502       \u2514\u2500\u2500 04-iverilog-ffglsim\n\u251c\u2500\u2500 rtl\n\u2502   \u251c\u2500\u2500 FullAdder.v\n\u2502   \u2514\u2500\u2500 test\n\u2502       \u2514\u2500\u2500 FullAdder-test.v\n\u251c\u2500\u2500 stdcells\n\u2502   \u251c\u2500\u2500 stdcells.v\n\u2502   \u251c\u2500\u2500 stdcells.sp\n\u2502   \u251c\u2500\u2500 stdcells.gds\n\u2502   \u251c\u2500\u2500 stdcells-rcx.sp\n\u2502   \u251c\u2500\u2500 stdcells-fe.yml\n\u2502   \u251c\u2500\u2500 stdcells-be.yml\n\u2502   \u2514\u2500\u2500 verilog-test\n\u2502       \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 tinyflow\n    \u251c\u2500\u2500 conftest.py\n    \u251c\u2500\u2500 pytest.ini\n    \u251c\u2500\u2500 synth\n    \u2502   \u251c\u2500\u2500 tinyv.lark\n    \u2502   \u251c\u2500\u2500 verilog_parser.py\n    \u2502   \u251c\u2500\u2500 StdCellFrontEndView.py\n    \u2502   \u251c\u2500\u2500 TinyFrontEndDB.py\n    \u2502   \u251c\u2500\u2500 TinyFrontEndGUI.py\n    \u2502   \u251c\u2500\u2500 substitute.py\n    \u2502   \u251c\u2500\u2500 techmap_unopt.py\n    \u2502   \u251c\u2500\u2500 techmap.py\n    \u2502   \u251c\u2500\u2500 sta.py\n    \u2502   \u2514\u2500\u2500 tests\n    \u2502       \u2514\u2500\u2500 ...\n    \u2514\u2500\u2500 tinyflow-synth\n</code></pre> <p>Go ahead and create a build directory where you will run the synthesis tools and tests:</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX\n% mkdir -p tinyflow/build\n% cd tinyflow/build\n</code></pre>"},{"location":"ece6745-project1b/#1-background-on-tinyflow","title":"1. Background on TinyFlow","text":"<p>The complete TinyFlow standard-cell and ASIC design flow is shown below with the front end highlighted in red.</p> <p></p> <p>The front end includes two-state RTL simulation, four-state RTL simulation, synthesis, and fast-functional gate-level simulation. In lecture, we discussed an approach to synthesis based on technology mapping with dynamic programming to optimize the area of the final gate-level netlist.</p> <p>Synthesis itself consists of four key algorithms.</p> <p></p> <ul> <li> <p>Verilog Reader: Parses Verilog RTL design into forest of trees of    generic logic gates</p> </li> <li> <p>Technology Mapping: Maps trees of generic gates to trees of    standard cells; we will be implementing both an unoptimized and    optimized version</p> </li> <li> <p>Static Timing Analysis: Statically analyze all paths to find    critical path</p> </li> <li> <p>Gate-Level Netlist Writer: Outputs a standard-cell gate-level    netlist in a Verilog file</p> </li> </ul> <p>We provide you the Verilog reader and gate-level netlist writer. In this project you are reponsible for implementing technology mapping and static timing analysis.</p> <p>TinyFlow represents logic using expression trees stored in a front end database. This section describes the key data structures you will work with when implementing the synthesis algorithms.</p> <p>A design is represented as a forest of expression trees. Each primary output has one tree that computes its logic function. Intermediate signals (wires) can also have trees. The <code>TinyFrontEndDB</code> class is the container that holds the forest:</p> <pre><code>TinyFrontEndDB\n\u251c\u2500\u2500 _inputs:  { \"a\", \"b\", \"c\" }           # primary input names\n\u251c\u2500\u2500 _outputs: { \"out1\": &lt;tree&gt;, ... }     # output name -&gt; tree\n\u2514\u2500\u2500 _wires:   { \"tmp\": &lt;tree&gt;, ... }      # wire name -&gt; tree\n</code></pre> <p>You can access trees using <code>db.get_tree(name)</code> and modify them using <code>db.set_tree(name, tree)</code>. The <code>db.trees</code> property returns a dict of all trees (both outputs and wires).</p>"},{"location":"ece6745-project1b/#22-nodes","title":"2.2. Nodes","text":"<p>Each node in a tree represents a logic gate. The <code>Node</code> base class has these key attributes:</p> <ul> <li><code>type</code>: Name of the gate (e.g., <code>\"AND2\"</code>, <code>\"INVX1\"</code>)</li> <li><code>children</code>: List of inputs, which can be other Nodes or strings    (primary inputs / wire references)</li> </ul> <p>And the following useful methods to determine the type of node.</p> <ul> <li><code>is_generic_gate()</code></li> <li><code>is_standard_cell()</code></li> <li><code>is_signal()</code></li> <li><code>is_wildcard()</code></li> </ul> <p>Trees are recursive structures.</p> <pre><code>        NAND2                Node: type=\"NAND2\", children=[INV, INV]\n        /   \\\n      INV   INV              Node: type=\"INV\", children=[Signal]\n       |     |\n       a     b               Node: type=\"Signal\"\n</code></pre> <p>The <code>repr()</code> of a tree shows its structure: <code>NAND2(INV(a), INV(b))</code>.</p>"},{"location":"ece6745-project1b/#23-generic-gates","title":"2.3. Generic Gates","text":"<p>Generic gates represent logic operations parsed from Verilog RTL. They have no physical implementation. TinyFlow supports these generic gates:</p> <ul> <li>Two-input gates: AND2, OR2, NAND2, NOR2, XOR2, XNOR2</li> <li>Single-input gates: NOT, INV, BUF</li> </ul> <p>The NOT and INV gates both compute logical inversion but serve different purposes: NOT comes from Verilog (<code>~</code> operator), while INV is the canonical inverter used after canonicalization.</p> <pre><code>Node (base class)\n \u251c\u2500\u2500 AND2      (a1 AND a2)\n \u251c\u2500\u2500 OR2       (a1 OR a2)\n \u251c\u2500\u2500 NAND2     (NOT (a1 AND a2))\n \u251c\u2500\u2500 NOR2      (NOT (a1 OR a2))\n \u251c\u2500\u2500 XOR2      (a1 XOR a2)\n \u251c\u2500\u2500 XNOR2     (a1 XNOR a2)\n \u251c\u2500\u2500 NOT       (NOT a)  &lt;- from Verilog\n \u251c\u2500\u2500 INV       (NOT a)  &lt;- canonical form\n \u2514\u2500\u2500 BUF       (a)      &lt;- buffer/passthrough\n</code></pre>"},{"location":"ece6745-project1b/#24-wildcards-and-constants","title":"2.4. Wildcards and Constants","text":"<p>Wildcards and constants are special nodes used to write substitution patterns. They are not part of actual designs but are used to match and transform trees.</p> <p>Wildcards match any subtree and capture it by name:</p> <pre><code>_0 = Wildcard('_0') # matches any subtree, captures as '_0'\n_1 = Wildcard('_1') # matches any subtree, captures as '_1'\n</code></pre> <p>These are used in substitution rules. For example, to replace AND with NAND-INV:</p> <pre><code>Substitute(find=AND2(_0, _1), replace=INV(NAND2(_0, _1)))\n</code></pre> <p>The wildcards <code>_0</code>, <code>_1</code>, <code>_2</code>, <code>_3</code> and constants <code>_0</code>, <code>_1</code> are predefined in <code>TinyFrontEndDB</code> for convenience.</p>"},{"location":"ece6745-project1b/#25-standard-cells","title":"2.5. Standard Cells","text":"<p>Standard cells represent physical standard cells from your cell library and include physical information:</p> <ul> <li>area_cost: Area of the cell (in lambda^2)</li> <li>patterns: List of generic gate patterns the cell can implement</li> </ul> <p>For example, <code>NOR2X1</code> can implement multiple patterns:</p> <pre><code>NOR2X1\n\u251c\u2500\u2500 area_cost: 2048\n\u2514\u2500\u2500 patterns:\n    \u251c\u2500\u2500 INV(NAND2(INV(_0), INV(_1)))         # NOR via De Morgan's\n    \u2514\u2500\u2500 INV(INV(INV(NAND2(INV(_0), INV(_1))) # double inverter at output\n</code></pre> <p>The patterns tell techmap which generic gate combinations can be \"covered\" by a single standard cell. Technology mapping uses these patterns to find the minimum-area implementation.</p> <p>Standard cell classes (INVX1, NAND2X1, NOR2X1, AOI21X1, etc.) are dynamically created when you load the standard cell view.</p>"},{"location":"ece6745-project1b/#26-standard-cell-view","title":"2.6. Standard Cell View","text":"<p>The <code>StdCellFrontEndView</code> provides information about your standard cell library. It is loaded from <code>stdcells-fe.yml</code> and passed to <code>TinyFrontEndDB</code>:</p> <pre><code>view = StdCellFrontEndView(\"../stdcells/stdcells-fe.yml\")\ndb = TinyFrontEndDB(view)\n</code></pre> <p>The view provides information needed by synthesis algorithms:</p> <ul> <li> <p>For techmap: Cell area and patterns (which generic gate    combinations each cell implements)</p> </li> <li> <p>For STA: Timing model parameters:</p> </li> <li><code>Cgate</code>: Input capacitance (in fF)</li> <li><code>tau_d</code>: Intrinsic delay (in ps)</li> <li><code>tau_t</code>: Load-dependent delay factor (in ps/fF)</li> </ul> <p>The delay through a gate is computed as: <code>delay = tau_d + tau_t * load</code> where <code>load</code> is the total capacitance driven by the gate's output</p>"},{"location":"ece6745-project1b/#27-verilog-reader","title":"2.7. Verilog Reader","text":"<p>We provide you the verilog reader. Feel free to take a look at the associated grammar located in <code>tinyflow/synth/tinyv.lark</code>. You can use the following command to read a Verilog file into the TinyFlow front-end database.</p> <pre><code>tinyflow-synth&gt; db.read_verilog(\"path/to/design.v\")\n</code></pre>"},{"location":"ece6745-project1b/#28-gate-level-netlist-writer","title":"2.8. Gate-Level Netlist Writer","text":"<p>We provide you the gate-level netlist writer. You can use the following command to write the TinyFlow front-end database to a Verilog file.</p> <pre><code>tinyflow-synth&gt; db.write_verilog(\"post-synth.v\")\n</code></pre>"},{"location":"ece6745-project1b/#3-algorithm-unoptimized-technology-mapping","title":"3. Algorithm: Unoptimized Technology Mapping","text":"<p>Students should implement a substitution rule framework before implementing technology mapping.</p>"},{"location":"ece6745-project1b/#31-substitution","title":"3.1. Substitution","text":"<p>Substitution is a core operation used throughout our synthesis framework in TinyFlow. It matches a find pattern against a node and, if successful, produces a new node based on a replace template. Wildcards in the pattern capture subtrees, which are then substituted into the template. For example, to transform an AND gate into NAND-INV form:</p> <pre><code>tinyflow-synth&gt; a, b, c = Signal(\"a\"), Signal(\"b\"), Signal(\"c\")\ntinyflow-synth&gt; sub = Substitute(find=AND2(_0, _1), replace=INV(NAND2(_0, _1)))\ntinyflow-synth&gt; result = sub.apply(AND2(OR2(a, b), c))\ntinyflow-synth&gt; print(result)\n</code></pre> <p>The wildcards <code>_0</code> and <code>_1</code> in the pattern capture the inputs <code>x</code> and <code>y</code>, then those captured values are substituted into the replace template to produce <code>INV(NAND2(x, y))</code>.</p> <p>We require students to implement the following functions in <code>tinyflow/synth/substitute.py</code> to complete the substitution framework:</p> <ul> <li> <p><code>match</code>: Recursively compare the find pattern tree against the input     node. Wildcards match any subtree and capture it by name. If types or     structure don't match, return <code>False</code>.</p> </li> <li> <p><code>capture</code>: Capture whatever the wildcards in the pattern tree match    to. Returns a dictionary mapping the wildcard name to the subtree it    matched.</p> </li> <li> <p><code>replace</code>: Build a new tree using the template and the captured    subtrees.</p> </li> </ul> <p>Handling Repeated Wildcards</p> <p>In the lab, <code>match</code> did not track captures, and <code>capture</code> used <code>|=</code> to merge dictionaries from child recursions. This works for simple patterns but fails for repeated wildcards like <code>NAND2(_a, _a)</code> (which matches <code>INV</code>). With <code>|=</code>, the second capture silently overwrites the first, so <code>NAND2(x, y)</code> would incorrectly match <code>NAND2(_a, _a)</code>.</p> <p>In the project, we pass <code>captures</code> as an argument through <code>match</code> and <code>capture</code>. When a wildcard is encountered again, <code>match</code> checks if the new value equals the previously captured value. If they differ, <code>match</code> returns <code>False</code>. This correctly rejects <code>NAND2(x, y)</code> against <code>NAND2(_a, _a)</code>.</p> <p>Function: <code>match(node, p_node, captures)</code></p> <p>Goal: Check if <code>node</code> matches pattern <code>p_node</code>, populating captures dict.</p> <p>Args:</p> <ul> <li><code>node</code>: Tree node to match against</li> <li><code>p_node</code>: Pattern tree (contains wildcards)</li> <li><code>captures</code>: Dict to populate with wildcard name \u2192 matched subtree</li> </ul> <p>Returns: <code>True</code> if node matches pattern, <code>False</code> otherwise</p> <p>Function: <code>capture(node, p_node, captures)</code></p> <p>Goal: Populate captures dict by traversing a matched pattern.</p> <p>Args:</p> <ul> <li><code>node</code>: Tree node (already verified to match)</li> <li><code>p_node</code>: Pattern tree (contains wildcards)</li> <li><code>captures</code>: Dict to populate with wildcard name \u2192 matched subtree</li> </ul> <p>Returns: The <code>captures</code> dict</p> <p>Function: <code>replace(t_node, captures)</code></p> <p>Goal: Build a new tree from template, substituting captured values for wildcards.</p> <p>Args:</p> <ul> <li><code>t_node</code>: Template tree (contains wildcards to substitute)</li> <li><code>captures</code>: Dict mapping wildcard name \u2192 subtree to substitute</li> </ul> <p>Returns: New <code>Node</code> tree with wildcards replaced by captured subtrees</p>"},{"location":"ece6745-project1b/#32-unoptimized-technology-mapping","title":"3.2. Unoptimized Technology Mapping","text":"<p>Once you have your substitution framework working, you can use the substitution framework to implement a naive unoptimized technology mapping algorithm in <code>tinyflow/synth/techmap_unopt.py</code>. Simply create one rule for every generic gate and include a corresponding replacement which implements this generic gate using standard cells. Then apply these rules to every node in every tree. This unoptimized technology mapping algorithm makes no attempt to minimize area and will serve as a nice baseline for your optimized technology mapping algorithm.</p> <p>Function: <code>apply_rules(node)</code></p> <p>Goal: Recursively apply substitution rules to a tree, bottom-up.</p> <p>Args:</p> <ul> <li><code>node</code>: Tree node to transform</li> </ul> <p>Returns: Transformed node with matching pattern applied</p>"},{"location":"ece6745-project1b/#4-algorithm-optimized-technology-mapping","title":"4. Algorithm: Optimized Technology Mapping","text":"<p>The optimized technology mapping algorithm has three steps:</p> <ul> <li> <p>Canonicalize: Replace every generic gate with equivalent tree of      just NAND2 and INV generic gates; determine equivalent trees of      NAND2 and INV generic gates for each standard cell</p> </li> <li> <p>Cover: Use dynamic programming to determine optimal way to      cover each node in a canonicalized tree of generic gates with      equivalent standard cells; goal is to minmize total area</p> </li> <li> <p>Traceback: Determine final optimal cover of all trees in the      forest</p> </li> </ul>"},{"location":"ece6745-project1b/#41-canonicalize","title":"4.1. Canonicalize","text":"<p>With the ability to substitute patterns with a template, we can now build the first step of the technology mapping phase: canonicalization. In order to map between generic gates and a given standard cell library, we need to lower both sides to a common representation and match against each other. Canonicalization is that step. The input is a tree with generic gates (AND2, OR2, NOR2, XOR2, XNOR2, NOT, BUF) and the output is a logically equivalent tree using only NAND2 and INV gates.</p> <p>Go ahead and implement the <code>canonicalize</code> function in <code>tinyflow/synth/techmap.py</code>. You will need to define a substitution rule for each generic gate type (one rule per gate), apply the rules to the nodes in a tree, and apply it to all trees in the database. The recommended approach is to write a recursive function to apply the rules to a tree, but you can implement this however you want.</p> <p>Function: <code>canonicalize_node(node, rules)</code></p> <p>Goal: Recursively convert a tree to NAND2/INV basis.</p> <p>Args:</p> <ul> <li><code>node</code>: Tree node to canonicalize</li> <li><code>rules</code>: List of substitution rules for generic gates</li> </ul> <p>Returns: Canonicalized node using only NAND2 and INV gates</p> <p>Function: <code>canonicalize(db, view)</code></p> <p>Goal: Canonicalize all trees in the database.</p> <p>Args:</p> <ul> <li><code>db</code>: TinyFrontEndDB containing trees to canonicalize</li> <li><code>view</code>: StdCellFrontEndView (unused, but passed for API consistency)</li> </ul> <p>Returns: None (modifies db in place)</p> <p>Hint: Use <code>db.get_tree(name)</code> and <code>db.set_tree(name, node)</code> to modify db in place</p>"},{"location":"ece6745-project1b/#42-cover","title":"4.2. Cover","text":"<p>Technology mapping replaces the canonical NAND2/INV tree with library cells from your standard cell library. The goal is to find the minimum-area implementation.</p> <p>This is where the patterns field from your standard-cell front-end view comes into play. Each library cell has patterns describing which NAND2/INV combinations it can implement. For example, NOR2X1 has a pattern that matches <code>INV(NAND2(INV(_0), INV(_1)))</code>. When techmap finds this pattern in the canonical tree, it can replace all four gates with a single NOR2X1 cell.</p> <p>Input: Canonicalized tree (NAND2/INV gates only)</p> <p>Output: Tree with library cells (INVX1, NAND2X1, NOR2X1, AOI21X1, etc.) with minimum area (optimal for trees)</p> <p>The DP recurrence is:</p> <pre><code>opt_cost(node) = min over patterns p { p.area_cost + sum(opt_cost(child)) }\n</code></pre> <p>Go ahead and implement the <code>cover</code> function in <code>tinyflow/synth/techmap.py</code>.</p> <p>Hints:</p> <ul> <li>Use <code>repr(node)</code> as the key into <code>opt_cost</code> and <code>opt_pattern</code> dicts</li> <li>Iterate over <code>view.patterns</code> to try all possible pattern matches</li> <li>Process children before the current node (bottom-up)</li> <li>Signals have zero cost and pass through unchanged</li> </ul> <p>Function: <code>cover(node, view, opt_cost, opt_pattern)</code></p> <p>Goal: Compute optimal cost and pattern for each node using bottom-up DP.</p> <p>Args:</p> <ul> <li><code>node</code>: Canonicalized tree node to cover</li> <li><code>view</code>: StdCellFrontEndView containing patterns</li> <li><code>opt_cost</code>: Dict to populate with node key \u2192 minimum cost</li> <li><code>opt_pattern</code>: Dict to populate with node key \u2192 best pattern</li> </ul> <p>Returns: None (populates opt_cost and opt_pattern dicts)</p>"},{"location":"ece6745-project1b/#43-traceback","title":"4.3. Traceback","text":"<p>Finally, use a top-down approach to reconstruct the optimal technology mapping. Start from the root and recursively apply the optimal patterns. When you are done return the final tree which should exclusively contain standard-cell nodes.</p> <p>Function: <code>traceback(node, opt_pattern)</code></p> <p>Goal: Reconstruct optimal tree by applying best patterns top-down.</p> <p>Args:</p> <ul> <li><code>node</code>: Canonicalized tree node</li> <li><code>opt_pattern</code>: Dict mapping node key \u2192 best pattern</li> </ul> <p>Returns: New tree with standard cells</p>"},{"location":"ece6745-project1b/#44-optimized-technology-mapping","title":"4.4. Optimized Technology Mapping","text":"<p>Now put all three steps together in the <code>techmap</code> function located in 'tinyflow/synth/techmap.py`. Call canonicalize first. Then call cover on every tree in the front-end database. Finally call traceback on every tree in the front-end database and set each tree to the newly technology mapped tree.</p> <p>Function: <code>techmap(db, view)</code></p> <p>Goal: Technology map all trees: canonicalize, cover, traceback.</p> <p>Args:</p> <ul> <li><code>db</code>: TinyFrontEndDB containing trees to map</li> <li><code>view</code>: StdCellFrontEndView containing patterns and cell info</li> </ul> <p>Returns: None (modifies db in place)</p>"},{"location":"ece6745-project1b/#5-algorithm-static-timing-analysis","title":"5. Algorithm: Static Timing Analysis","text":"<p>Static timing analysis (STA) computes the delay through the mapped netlist and finds the critical path. This is where the timing model from your Part A front-end view is used.</p> <p>Recall the first-order delay model from Part A:</p> <pre><code>gate_delay = tau_d + tau_t * load\n</code></pre> <p>where <code>tau_d</code> is the intrinsic (parasitic) delay, <code>tau_t</code> is the load-dependent delay factor, and <code>load</code> is the capacitance the gate drives. The load includes the input capacitance (<code>Cgate</code>) of all gates connected to the output.</p> <p>Input: Mapped tree with library cells</p> <p>Output: Critical path delay and the path itself</p> <p>The algorithm has three phases:</p> <ul> <li> <p>Phase 1 (compute loads): Traverse the trees and accumulate the    load capacitance on each gate. A gate's load is the sum of <code>Cgate</code>    for all gates it drives. Primary outputs have a fixed output load.</p> </li> <li> <p>Phase 2 (compute arrivals): Propagate arrival times from inputs    to outputs. Primary inputs have arrival time 0. For each gate:    <code>arrival = max(children arrivals) + gate_delay</code>.</p> </li> <li> <p>Phase 3 (find critical path): Find the output with maximum    arrival time, then backtrace through the tree following the critical    pin at each node.</p> </li> </ul> <p>Your task: Implement <code>compute_loads</code>, <code>compute_arrivals</code>, and <code>find_critical_path</code> in <code>tinyflow/synth/sta.py</code>.</p> <p>Hints:</p> <ul> <li>Use <code>view.get_cgate(gate_type, pin_idx)</code> to get input capacitance</li> <li>Use <code>view.get_parasitic_delay()</code> and <code>view.get_load_delay_factor()</code>    for timing parameters</li> <li>Store results on nodes: <code>node.load_cap</code> for load, <code>node.timing</code> for    arrival time and critical pin (use <code>Timing</code> namedtuple)</li> <li>Primary inputs have arrival time 0</li> <li>For arrivals, use memoization via <code>node.timing</code> to avoid recomputation</li> </ul> <p>Function: <code>compute_loads(db, view, output_load)</code></p> <p>Goal: Compute load capacitance for all nodes.</p> <p>Args:</p> <ul> <li><code>db</code>: TinyFrontEndDB containing mapped trees</li> <li><code>view</code>: StdCellFrontEndView for Cgate lookup</li> <li><code>output_load</code>: Fixed load on primary outputs (default 10.0 fF)</li> </ul> <p>Returns: None (sets <code>node.load_cap</code> on each gate)</p> <p>Function: <code>compute_arrivals(db, view)</code></p> <p>Goal: Compute arrival times for all nodes using forward DP.</p> <p>Args:</p> <ul> <li><code>db</code>: TinyFrontEndDB containing mapped trees with <code>load_cap</code> set</li> <li><code>view</code>: StdCellFrontEndView for timing parameters</li> </ul> <p>Returns: None (sets <code>node.timing</code> on each gate)</p> <p>Function: <code>find_critical_path(db)</code></p> <p>Goal: Find critical path by backtracing from max delay output.</p> <p>Args:</p> <ul> <li><code>db</code>: TinyFrontEndDB with timing computed</li> </ul> <p>Returns: Tuple of <code>(max_delay, critical_path, critical_output)</code></p> <p>Function: <code>sta(db, view, output_load)</code></p> <p>Goal: Run full STA: compute_loads, compute_arrivals, find_critical_path.</p> <p>Args:</p> <ul> <li><code>db</code>: TinyFrontEndDB containing mapped trees</li> <li><code>view</code>: StdCellFrontEndView for timing parameters</li> <li><code>output_load</code>: Fixed load on primary outputs (default 10.0 fF)</li> </ul> <p>Returns: None (stores results in db via db.set_sta_results)</p> <p>Hint: You can set the STA results into DB using the following: <pre><code>path_stages = sum(1 for node in critical_path if node.is_gate())\ndb.set_sta_results(max_delay, critical_path, path_stages, critical_output)\n</code></pre></p> <p>After techmap, you can run STA and view timing results:</p> <pre><code>tinyflow-synth&gt; sta(db, view)\ntinyflow-synth&gt; db.report_timing()\ntinyflow-synth&gt; db.report_summary()\n</code></pre> <p>The timing report shows the critical path delay and the gates on the critical path.</p>"},{"location":"ece6745-project1b/#6-testing","title":"6. Testing","text":"<p>You can run the tests from your build directory like this.</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/tinyflow/build\n% pytest ../synth/tests/substitute_test.py -v\n% pytest ../synth/tests/techmap_test.py -v\n% pytest ../synth/tests/sta_test.py -v\n% pytest ../synth/tests/synth_test.py -v\n</code></pre> <p>You can also run all the tests at once.</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/tinyflow/build\n% pytest ../synth/tests\n</code></pre> <p>Just because all of the test passes does not mean your implementation is correct. You are encoraged to add more tests.</p>"},{"location":"ece6745-project1b/#7-tinyflow-front-end","title":"7. TinyFlow Front-End","text":"<p>As discussed in lecture, the front end is more than just synthesis. The front-end flow consists of four stages: two-state simulation, four-state simulation, synthesis, and fast-functional gate-level simulation. As paranoid ASIC engineers, we verify our design at each step. We simulate the RTL before synthesis to catch design bugs early, then simulate the gate-level netlist after synthesis to ensure the transformation preserved functionality.</p>"},{"location":"ece6745-project1b/#71-two-state-rtl-simulation","title":"7.1 Two-State RTL Simulation","text":"<p>To ensure functionality, the first step is to verify our design quickly using two-state simulation. Two-state simulation tests only logic values 1 and 0 to ensure basic logic correctness. In this part we will use Verilator to perform two-state simulation.</p> <p>In this project, we will verify a Full Adder design. We provide the Verilog RTL in <code>rtl/FullAdder.v</code> and a basic testbench in <code>rtl/test/FullAdder-test.v</code>. You can run the two-state simulation with Verilator as follows.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/build-fa/01-verilator-rtlsim\n% verilator --top Top --timing --binary -o FullAdder-test \\\n    ../../../rtl/FullAdder.v \\\n    ../../../rtl/test/FullAdder-test.v\n% ./obj_dir/FullAdder-test\n</code></pre> <p>We have put the above command in a shell script to simplify running two-state RTL simulation.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/build-fa\n% ./01-verilator-rtlsim/run\n</code></pre>"},{"location":"ece6745-project1b/#72-four-state-rtl-simulation","title":"7.2 Four-State RTL Simulation","text":"<p>Four-state simulation uses four logic values: 0, 1, X (unknown), and Z (high impedance). You get X when a signal is uninitialized, when multiple drivers are fighting (contention), or through propagation of uncertainty (X propagates through logic). You get Z when a wire is floating (nothing is driving it) or from a tri-stated output.</p> <p>We use four-state simulation to capture these bugs. It is slower than two-state simulation, but it narrows down our issue search space. If your design passes two-state but fails four-state, the problem is usually related to X propagation or uninitialized signals.</p> <p>Go ahead and run the four-state simulation with Icarus Verilog:</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/build-fa/02-iverilog-rtlsim\n% iverilog -g2012 -o FullAdder-test \\\n    ../../../rtl/FullAdder.v \\\n    ../../../rtl/test/FullAdder-test.v\n% ./FullAdder-test\n</code></pre> <p>We have put the above command in a shell script to simplify running two-state RTL simulation.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/build-fa\n% ./02-iverilog-rtlsim/run\n</code></pre>"},{"location":"ece6745-project1b/#73-synthesis","title":"7.3 Synthesis","text":"<p>Now that we have rigorously tested our Verilog design, we are ready to synthesize it into a gate-level netlist. For this step, we will use the batch processing mode of <code>tinyflow-synth</code> instead of the REPL mode we have previous used. The batch mode takes a run script that describes the synthesis steps. Populate the 'asic/build-fa/03-tinyflow-synth/run.py' script with the commands to perform synthesis and STA.</p> <pre><code># Load the standard-cell front-end view and create front-end database\n\nview = StdCellFrontEndView.parse_lib(\"../../../stdcells/stdcells-fe.yml\")\ndb = TinyFrontEndDB(view)\n\n# Read Verilog file into the database\n\ndb.read_verilog(\"../../../rtl/FullAdder.v\")\n\n# Optimized technology mapping\n\ntechmap(db, view)\n\n# Static timing analysis with output load of 10fF\n\noutput_load = 10\nsta(db, view, output_load)\n\n# Check design for issues\n\ndb.check_design()\n\n# Output reports\n\ndb.report_area()\ndb.report_timing()\ndb.report_summary()\n\n# Write front-end database to a Verilog gate-level netlist\n\ndb.write_verilog(\"post-synth.v\")\n</code></pre> <p>Now run the synthesis:</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/build-fa/03-tinyflow-synth\n% ../../../tinyflow/tinyflow-synth -f run.py\n</code></pre> <p>This outputs the <code>post-synth.v</code> file. We have put the above command in a shell script to simplify running synthesis.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/build-fa\n% ./03-tinyflow-synth/run\n</code></pre>"},{"location":"ece6745-project1b/#74-fast-functional-gate-level-simulation","title":"7.4 Fast-Functional Gate-Level Simulation","text":"<p>Now that we have our synthesized design, as paranoid ASIC engineers we want to double check that the synthesized design still does what we intended. Synthesis tools may not always be correct! To verify this, we perform fast-functional gate-level simulation (FFGL), which is four-state simulation using the same testbench but with the synthesized design and the behavioral view of the standard cells.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/build-fa/04-iverilog-ffglsim\n% iverilog -g2012 -o FullAdder-test \\\n    ../../../stdcells/stdcells.v ../03-tinyflow-synth/post-synth.v \\\n    ../../../rtl/test/FullAdder-test.v\n% ./FullAdder-test\n</code></pre> <p>If the simulation passes, your synthesized design is functionally correct. We have put the above command in a shell script to simplify running synthesis.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/build-fa\n% ./04-iverilog-ffglsim/run\n</code></pre>"},{"location":"ece6745-project1b/#9-project-submission","title":"9. Project Submission","text":"<p>To submit your code you simply push your code to GitHub. You can push your code as many times as you like before the deadline. Students are responsible for going to the GitHub website for your repository, browsing the source code, and confirming that the code they want to submit is on GitHub. Be sure to verify your code is passing all of your simulations on <code>ecelinux</code>.</p> <p>Here is how we will be testing your final code submission for Part B. First, we will create a build directory.</p> <pre><code>% mkdir -p ${HOME}/ece6745\n% cd ${HOME}/ece6745\n% git clone git@github.com:cornell-ece6745/project1-groupXX\n</code></pre> <p>Then we will run all of the tests for the synthesis flow.</p> <pre><code>% mkdir -p ${HOME}/ece6745/project1-groupXX/tinyflow/build\n% cd ${HOME}/ece6745/project1-groupXX/tinyflow/build\n% pytest ../synth\n</code></pre> <p>Then we will verify that we can succesfully push the full adder through your TinyFlow.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/build-fa\n% ./01-verilator-rtlsim/run\n% ./02-iverilog-rtlsim/run\n% ./03-tinyflow-synth/run\n% ./04-iverilog-ffglsim/run\n</code></pre>"},{"location":"ece6745-project1c/","title":"ECE 6745 Project 1: TinyFlow Tape-OutTinyFlow Back-End","text":"<p>In this project, students will build their own TinyFlow, a very simple standard-cell-based flow. They will develop seven standard cells in TSMC 180nm and the corresponding standard cell behavioral, schematic, layout, extracted schematic, front-end, and back-end views. They will then implement simple algorithms for synthesis (technology mapping via tree covering, static timing analysis) and place-and-route (simulated annealing, 3D maze routing). Finally they will combine this work with open-source Verilog RTL and gate-level simulators and an open-source LVS/DRC tool to create the complete TinyFlow. Even though their TinyFlow will only support a very small combinational subset of Verilog, this project still gives students a unique hands-on opportunity to appreciate every step required in more sophisticated commercial tools. Each group will create a tiny block using their TinyFlow and these blocks will be aggregated into a single unified tape-out on the TSMC 180nm technology node.</p> <p>The project includes three parts:</p> <ul> <li>Part A: TinyFlow Standard Cells</li> <li>Part B: TinyFlow Front End</li> <li>Part C: TinyFlow Back End</li> </ul> <p>Continue working with your group from Part A and B. You can confirm your group on Canvas (Click on People, then Groups, then search for your name to find your project group).</p> <p>All students must contribute to all parts!</p> <p>It is not acceptable for one student to do all of Part A+B and a different student to do all of part C. It is not acceptable for one student to exclusively work on one algorithm while the other student exclusively works on a different algorithm. All students must contribute to all parts. The instructors will also survey the Git commit log on GitHub to confirm that all students are contributing equally. If you are using a \"pair programming\" style, then both students must take turns using their own account so both students have representative Git commits. Students should create commits after finishing each step of the project, so their contribution is clear in the Git commit log. A student's whose contribution is limited as represented by the Git commit log will receive a significant deduction to their project score.</p> <p>This handout assumes that you have read and understand the course tutorials and that you have attended the lab sections. To get started, use VS Code to log into a specific <code>ecelinux</code> server, use MS Remote Desktop to log into the same <code>ecelinux</code> server, source the setup scripts, and clone your remote repository from GitHub:</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% xclock &amp;\n% mkdir -p ${HOME}/ece6745\n% cd ${HOME}/ece6745\n% git clone git@github.com:cornell-ece6745/project1-groupXX\n% cd project1-groupXX\n% tree\n</code></pre> <p>where <code>XX</code> should be replaced with your group number. You can both pull and push to your remote repository. If you have already cloned your remote repository, then use git pull to ensure you have any recent updates before working on your lab assignment.</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX\n% git pull\n% tree\n</code></pre> <p>where <code>XX</code> should be replaced with your group number. Your repo currently contains the following files (more files will be released soon!).</p> <pre><code>.\n\u251c\u2500\u2500 asic\n\u2502   \u2514\u2500\u2500 build-fa\n\u2502       \u251c\u2500\u2500 01-verilator-rtlsim\n\u2502       \u251c\u2500\u2500 02-iverilog-rtlsim\n\u2502       \u251c\u2500\u2500 03-tinyflow-synth\n\u2502       \u2502   \u2514\u2500\u2500 run.py\n\u2502       \u2514\u2500\u2500 04-iverilog-ffglsim\n\u251c\u2500\u2500 rtl\n\u2502   \u251c\u2500\u2500 FullAdder.v\n\u2502   \u2514\u2500\u2500 test\n\u2502       \u2514\u2500\u2500 FullAdder-test.v\n\u251c\u2500\u2500 stdcells\n\u2502   \u251c\u2500\u2500 stdcells.v\n\u2502   \u251c\u2500\u2500 stdcells.sp\n\u2502   \u251c\u2500\u2500 stdcells.gds\n\u2502   \u251c\u2500\u2500 stdcells-rcx.sp\n\u2502   \u251c\u2500\u2500 stdcells-fe.yml\n\u2502   \u251c\u2500\u2500 stdcells-be.yml\n\u2502   \u2514\u2500\u2500 verilog-test\n\u2502       \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 tinyflow\n    \u251c\u2500\u2500 conftest.py\n    \u251c\u2500\u2500 pytest.ini\n    \u251c\u2500\u2500 pnr\n    \u2502   \u251c\u2500\u2500 tinyv.lark\n    \u2502   \u251c\u2500\u2500 verilog_parser.py\n    \u2502   \u251c\u2500\u2500 StdCellBackEndView.py\n    \u2502   \u251c\u2500\u2500 TinyBackEndDB.py\n    \u2502   \u251c\u2500\u2500 TinyBackEndGUI.py\n    \u2502   \u251c\u2500\u2500 floorplan.py\n    \u2502   \u251c\u2500\u2500 place.py\n    \u2502   \u251c\u2500\u2500 place_unopt.py\n    \u2502   \u2514\u2500\u2500 tests\n    \u2502       \u2514\u2500\u2500 ...\n    \u251c\u2500\u2500 synth\n    \u2502   \u251c\u2500\u2500 tinyv.lark\n    \u2502   \u251c\u2500\u2500 verilog_parser.py\n    \u2502   \u251c\u2500\u2500 StdCellFrontEndView.py\n    \u2502   \u251c\u2500\u2500 TinyFrontEndDB.py\n    \u2502   \u251c\u2500\u2500 TinyFrontEndGUI.py\n    \u2502   \u251c\u2500\u2500 substitute.py\n    \u2502   \u251c\u2500\u2500 techmap_unopt.py\n    \u2502   \u251c\u2500\u2500 techmap.py\n    \u2502   \u251c\u2500\u2500 sta.py\n    \u2502   \u2514\u2500\u2500 tests\n    \u2502       \u2514\u2500\u2500 ...\n    \u251c\u2500\u2500 tinyflow-pnr\n    \u2514\u2500\u2500 tinyflow-synth\n</code></pre> <p>Go ahead and create a build directory where you will run the synthesis tools and tests:</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX\n% mkdir -p tinyflow/build\n% cd tinyflow/build\n</code></pre>"},{"location":"ece6745-project1c/#1-background-on-tinyflow","title":"1. Background on TinyFlow","text":"<p>The complete TinyFlow standard-cell and ASIC design flow is shown below with the back end highlighted in red.</p> <p></p> <p>The back end includes place-and-route, design rule checking (DRC), and layout-vs-schematic (LVS). Place-and-route itself consists of six key algorithms.</p> <p></p> <ul> <li> <p>Gate-Level Netlist Reader: Parses Verilog gate-level netlist into    directed acyclic graph of standard cells</p> </li> <li> <p>Floorplan: Creates grid of sites and positions input/output pins</p> </li> <li> <p>Place: Places each standard cell on the grid of sites</p> </li> <li> <p>Route: Routes each net on the routing grid</p> </li> <li> <p>Fill: Fills in empty space using FILL standard cells</p> </li> <li> <p>Layout &amp; Gate-Level Netlist Writer: Outputs the final layout along      with an updated standard-cell gate-level netlist</p> </li> </ul> <p>We provide you the readers and writers. In this project you are reponsible for implementing the floorplan, place, route, and fill algorithms.</p>"},{"location":"ece6745-project1c/#2-algorithm-floorplan","title":"2. Algorithm: Floorplan","text":"<p>Implement both fixed floorplan and automatic floorplan algorithms in the <code>tinyflow/pnr/floorplan.py</code> file.</p>"},{"location":"ece6745-project1c/#21-fixed-floorplan","title":"2.1. Fixed Floorplan","text":"<p>The fixed floorplan is useful if we know ahead of time the size of the final block and the position of the input and output pins. This kind of floorplanning will be used for the actual tapeout.</p> <p>Function: <code>floorplan_fixed(db, view, width_um, height_um, io_locs)</code></p> <p>Goal: Initialize floorplan with fixed dimensions and IO locations.</p> <p>Args:</p> <ul> <li><code>db</code>: TinyBackEndDB containing cells to place</li> <li><code>view</code>: StdCellBackEndView containing site dimensions</li> <li><code>width_um</code>: Chip width in micrometers</li> <li><code>height_um</code>: Chip height in micrometers</li> <li><code>io_locs</code>: Dict mapping port names to (x_um, y_um) locations</li> </ul> <p>Returns: None (modifies db in place)</p> <p>Hint: You will need to use <code>db.floorplan(width,height)</code> which takes as input a width and height in units of sites. You will need to use <code>db.get_ioport(name).place(i,j)</code> which takes as input the location of the ioport in units of the routing grid. Carefully consider how to convert the provided width, height, and locations in um to the appropriate units when calling <code>db.floorplan(width,height)</code> and <code>db.get_ioport(name).place(i,j)</code></p> <p>To test your floorplan interactively with the REPL and GUI, you will need a gate-level netlist as input. Run <code>FullAdder.v</code> through Part B's synthesis first to generate <code>asic/playground/03-tinyflow-synth/post-synth.v</code>. Then try your fixed floorplan:</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/tinyflow/build\n% ../tinyflow-pnr\n</code></pre> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.read_verilog('../../asic/playground/03-tinyflow-synth/post-synth.v')\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; io_locs = { '&lt;port_name&gt;': (&lt;x_um&gt;, &lt;y_um&gt;), ... }\ntinyflow-pnr&gt; floorplan_fixed(db, view, &lt;width_um&gt;, &lt;height_um&gt;, io_locs)\n</code></pre> <p>You should see the site grid and IO ports appear in the GUI.</p>"},{"location":"ece6745-project1c/#22-automatic-floorplan","title":"2.2. Automatic Floorplan","text":"<p>The automatic floorplan is useful for design-space exploration where we want to rapidly place-and-route a design without knowing ahead of time how large it might be. The actual width and height of the floorplan is calculated from the target utilization. If the target utilization is 0.5 then this means we want the sum of the area of all the standard cells divided by the area of the final floorplan to be about 0.5. The actual input pin locations are evenly distributed along the left edge of the block, and the actual output pin locations are evenly distributed along the right edge of the block.</p> <p>Function: <code>floorplan_auto(db, view, target_utilization, aspect_ratio)</code></p> <p>Goal: Determine chip dimensions based on cell area and utilization. Also places IO pins along the chip edges.</p> <p>Args:</p> <ul> <li><code>db</code>: TinyBackEndDB containing cells to place</li> <li><code>view</code>: StdCellBackEndView containing site dimensions</li> <li><code>target_utilization</code>: Fraction of area used (0.0 to 1.0)</li> <li><code>aspect_ratio</code>: Physical width / height (1.0 = square chip)</li> </ul> <p>Returns: None (modifies db in place)</p> <p>Hint: Sum the area of all of the standard cells. Keep in mind <code>get_width()</code> for a standard cell returns the width of the standard cell in sites. Divide this total area by the target utilization to get the actual block are. Use the aspect ratio to determine the height and width of the block, and then use these values with <code>db.floorplan(width,height)</code>. Use <code>db.get_ioport(name).place(i,j)</code> to place the input/output pins. Carefully consider the units when specifying all widths, heights, and locations.</p> <p>Try your automatic floorplan interactively using the REPL with the GUI:</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/tinyflow/build\n% ../tinyflow-pnr\n</code></pre> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.read_verilog('../../asic/playground/03-tinyflow-synth/post-synth.v')\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; floorplan_auto(db, view, 0.3, 1.0)\n</code></pre> <p>You should see the floorplan grid and IO ports appear in the GUI. Try different utilization and aspect ratio values to see how they affect the floorplan.</p> <p>Once you have implemented both floorplan algorithms, run all of the floorplan tests:</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/tinyflow/build\n% pytest ../pnr/tests/floorplan_test.py -v\n</code></pre>"},{"location":"ece6745-project1c/#3-algorithm-optimized-placement","title":"3. Algorithm: Optimized Placement","text":"<p>Implement a simulated annealing placement algorithm that attempts to optimize overall wirelength in the <code>tinyflow/pnr/place.py</code> file. Use the total half-perimeter wire length (HPWL) as the cost estimate for a placement.</p> <p>Instead of placing cells on the site grid, your algorithm should place cells on the coarser placement grid. To determine the placement grid, first find the max width across all standard cells in the design. Then use this max width to set the size of each location in the placement grid. Although this is less area efficient, it significantly simplifies placement since we are guaranteed placed cells will not overlap.</p>"},{"location":"ece6745-project1c/#31-half-perimeter-wire-length-hpwl","title":"3.1. Half-Perimeter Wire Length (HPWL)","text":"<p>We will be using the total half-perimeter wire length (HPWL) as our cost metric for any given placement. The HPWL is computed over all placed cells and IO ports. For each net:</p> <ul> <li>Collect all placed pins (skip pins whose cell is not yet placed)</li> <li>Find the minimal bounding box around these pins</li> <li>The HPWL for that net is the height plus width of the bounding box</li> </ul> <p>Nets with fewer than two placed pins contribute zero (no wires!). To find the total HPWL simply add together the HPWL for every net. Implement the <code>hpwl</code> function in <code>tinyflow/pnr/place.py</code>.</p> <p>Function: <code>hpwl(db)</code></p> <p>Goal: Compute total HPWL (half-perimeter wirelength) using bounding box per net. Use pin locations in routing grid units (from <code>pin.get_node()</code>).</p> <p>Args:</p> <ul> <li><code>db</code>: TinyBackEndDB with placement</li> </ul> <p>Returns: HPWL (<code>int</code>)</p> <p>Hint: <code>pin.get_node()</code> returns <code>(None, None, None)</code> if the pin's cell is not placed. Use this to skip unplaced pins.</p> <p>Try computing HPWL interactively using the REPL with the GUI:</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/tinyflow/build\n% ../tinyflow-pnr\n</code></pre> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.read_verilog('../../asic/playground/03-tinyflow-synth/post-synth.v')\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; floorplan_auto(db, view, 0.3, 1.0)\ntinyflow-pnr&gt; hpwl(db)\n</code></pre> <p>The IO ports are already placed by <code>floorplan_auto</code>. Try manually placing cells using <code>cell.set_place(row, col)</code> and calling <code>hpwl(db)</code> to see how your HPWL changes. You can also call <code>cell.set_unplace()</code> and <code>cell.set_place()</code> to move cells around and re-evaluate the HPWL. </p>"},{"location":"ece6745-project1c/#32-initial-placement","title":"3.2. Initial Placement","text":"<p>For simulated annealing we want to start with a random initial placement. Remember we are placing cells on the coarser placement grid. The seed can be used to create different random initial placements which might be useful if we are unable to route a specific placement. Ensure that two cells are never overlap. Implement the <code>place_initial</code> function in <code>tinyflow/pnr/place.py</code>.</p> <p>Function: <code>place_initial(db, seed)</code></p> <p>Goal: Random initial cell placement.</p> <p>Args:</p> <ul> <li><code>db</code>: TinyBackEndDB with floorplan initialized</li> <li><code>seed</code>: Random seed for reproducibility (None = don't reseed)</li> </ul> <p>Returns: None (modifies db in place)</p> <p>Try your initial placement in the REPL:</p> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.read_verilog('../../asic/playground/03-tinyflow-synth/post-synth.v')\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; floorplan_auto(db, view, 0.3, 1.0)\ntinyflow-pnr&gt; place_initial(db, seed=0)\n</code></pre> <p>You should see the cells randomly placed in the GUI.</p>"},{"location":"ece6745-project1c/#33-simulated-annealing-placement","title":"3.3. Simulated Annealing Placement","text":"<p>This function should assume we have already done the initial placement. The function should iterate for a given number of iterations. Each iteration should:</p> <ul> <li>Initialize the temperature with the given initial temperature</li> <li>Randomly select a cell</li> <li>Randomly select a location in the coarser placement grid</li> <li>If the selected location is empty, perform the move by calling    <code>cell.set_unplace()</code> then <code>cell.set_place()</code> at the new location</li> <li>If the selected location is not empty, perform the swap by first    calling <code>set_unplace()</code> on both cells to free their sites, then    calling <code>set_place()</code> on both cells at their new locations</li> <li>Compute the new total HPWL cost after the move or swap</li> <li>If the change in cost is negative, accept the move or swap</li> <li>If the change in cost is positive, only accept the move or swap with    probability \\(e^{-\\Delta c/T}\\)</li> <li>If the move or swap is not accepted, revert by calling    <code>set_unplace()</code> and <code>set_place()</code> to restore the original positions</li> <li>Decrease the temperature by the cooling rate</li> <li>If the temperature is less than the given final temperature stop</li> </ul> <p>Note that students can experiment with different cost functions. They may want to penalize a net with a very small HPWL to try and avoid cells from being bunched too close together causing significant routing congestion. Implement the <code>place_anneal</code> function in <code>tinyflow/pnr/place.py</code>.</p> <p>Function: <code>place_anneal(db, seed, initial_temp, cooling_rate, final_temp, max_iter)</code></p> <p>Goal: Simulated annealing optimization to minimize wirelength.</p> <p>Args:</p> <ul> <li><code>db</code>: TinyBackEndDB with initial placement</li> <li><code>seed</code>: Random seed for reproducibility (None = don't reseed)</li> <li><code>initial_temp</code>: Starting temperature</li> <li><code>cooling_rate</code>: T *= cooling_rate each iteration</li> <li><code>final_temp</code>: Stop when T &lt; final_temp</li> <li><code>max_iter</code>: Maximum iterations</li> </ul> <p>Returns: None (modifies db in place)</p> <p>Try simulated annealing in the REPL:</p> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.read_verilog('../../asic/playground/03-tinyflow-synth/post-synth.v')\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; floorplan_auto(db, view, 0.3, 1.0)\ntinyflow-pnr&gt; place_initial(db, seed=0)\ntinyflow-pnr&gt; place_anneal(db, seed=0)\n</code></pre> <p>You should see the cells move in the GUI as simulated annealing optimizes the placement. The HPWL should decrease compared to the initial placement.</p>"},{"location":"ece6745-project1c/#34-placement","title":"3.4. Placement","text":"<p>Now that we have an initial placement algorithm and the simulated annealing we can put them together in the placement function which should just call <code>place_init</code> and then <code>place_anneal</code>. Implement the <code>place</code> function in <code>tinyflow/pnr/place.py</code>.</p> <p>Function: <code>place(db, seed)</code></p> <p>Goal:   Run complete placement: initial placement, SA optimization.</p> <p>Args:</p> <ul> <li><code>db</code>: TinyBackEndDB with initial placement</li> <li><code>seed</code>: Random seed for reproducibility (None = don't reseed)</li> </ul> <p>Returns: None (modifies db in place)</p> <p>Once you have implemented all placement functions, try running the complete placement in a fresh REPL session:</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/tinyflow/build\n% ../tinyflow-pnr\n</code></pre> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.read_verilog('../../asic/playground/03-tinyflow-synth/post-synth.v')\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; floorplan_auto(db, view, 0.3, 1.0)\ntinyflow-pnr&gt; place(db)\n</code></pre> <p>You should see the cells being placed and then optimized in the GUI. Then run all of the placement tests to verify your implementation:</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/tinyflow/build\n% pytest ../pnr/tests/place_test.py -v\n</code></pre>"},{"location":"ece6745-project1c/#4-algorithm-routing","title":"4. Algorithm: Routing","text":"<p>After placement, we need to connect the pins of each net using metal wires. Routing operates on a 3D routing grid where <code>(i, j)</code> are the spatial coordinates and <code>k</code> is the metal layer. Each layer serves a different purpose:</p> <ul> <li>M1 (k=1): Intra-cell routing only (pins live here) \u2014 do not    route on M1</li> <li>M2\u2013M4 (k=2\u20134): Inter-cell routing layers \u2014 route here</li> <li>M5\u2013M6 (k=5-6): Power grid \u2014 do not use</li> </ul> <p>A wire segment on the same layer is a planar move. Changing layers at the same <code>(i, j)</code> location is a via. Each node <code>(i, j, k)</code> in the routing grid can only be occupied by one net at a time. Use <code>db.get_occupancy(i, j, k)</code> to check if a node is available; it returns <code>None</code> if free, or the occupying <code>Net</code> if taken.</p> <p>Routing is decomposed into three functions that build on each other:</p> <ul> <li> <p><code>bfs_to_tree</code> finds a path on M2\u2013M4 from a starting node to    an existing routing tree using BFS and commits the path to the    routing grid. This is the core pathfinding building block.</p> </li> <li> <p><code>single_route</code> routes all pins of a single net. It is    responsible for adding M1-to-M2 via segments at each cell pin    (since pins live on M1 but BFS operates on M2-M4). It connects    pins incrementally by growing a routing tree; each unconnected    pin is BFS-routed to the nearest tree node.</p> </li> <li> <p><code>multi_route</code> routes all nets in the design by calling    <code>single_route</code> for each net. If a net fails to route, it rips up    all routing and retries with a different net ordering.</p> </li> </ul> <p>Implement these functions in <code>tinyflow/pnr/single_route.py</code> and <code>tinyflow/pnr/multi_route.py</code> as described below.</p> <p>Pin Occupancy Reservation</p> <p>Cell pins live on M1 and IO port pins live on M2. When a cell is placed, the backend database automatically reserves M1 through M4 at each pin location in the occupancy grid. When an IO port is placed, it reserves M2 through M4. This creates a pillar of occupied nodes so that other nets will route around the pin rather than across it. Without this reservation, a net could route across a pin's M2 node without knowing a pin is directly below on M1, and when we later try to route that pin upward, there would be no escape path. Nodes belonging to the pin's own net can still pass through.</p> <p>You do not need to do anything to handle this reservation. It is already reflected in <code>db.get_occupancy(i, j, k)</code>, so your BFS will naturally route around these pillars. Your routing code only needs to add the M1-to-M2 via segments to connect each cell pin up to the routing layers.</p>"},{"location":"ece6745-project1c/#41-bfs-to-tree","title":"4.1. BFS to Tree","text":"<p>The core building block for routing is a BFS (breadth-first search) that finds a path from a starting node to any node in an existing routing tree. The BFS explores the 3D routing grid on layers M2\u2013M4, making planar moves (same layer, adjacent <code>i</code> or <code>j</code>) and via moves (same <code>i,j</code>, adjacent <code>k</code>). A node is blocked if it is occupied by a different net. Nodes occupied by the current net (i.e., already part of the routing tree) are valid targets; reaching any of them means we have connected to the tree.</p> <p>Implement the <code>bfs_to_tree</code> function in <code>tinyflow/pnr/single_route.py</code>.</p> <p>Function: <code>bfs_to_tree(db, net, start, tree)</code></p> <p>Goal: BFS from <code>start</code> to any node in <code>tree</code>, avoiding nodes occupied by other nets.</p> <p>Args:</p> <ul> <li><code>db</code>: TinyBackEndDB for occupancy checks</li> <li><code>net</code>: Current net (allowed to pass through own routes)</li> <li><code>start</code>: Starting <code>(i, j, k)</code> tuple</li> <li><code>tree</code>: Set of <code>(i, j, k)</code> tuples representing the current   routing tree</li> </ul> <p>Returns: Path as list of <code>(i, j, k)</code> tuples from <code>start</code> to tree, or <code>None</code> if no path exists. On success, the path is also committed as <code>Line</code> segments to the net.</p> <p>Hint: Use a standard BFS with a queue and parent dictionary. Each node has up to six neighbors and should stay within layers 2-4. Use <code>db.get_occupancy(i, j, k)</code> to check if a neighbor is blocked by another net. Backtrace through the parent dictionary to obtain the path. Convert the path to <code>Line</code> segments with <code>Line(path[n], path[n+1])</code> and commit with <code>net.add_route_segments(lines)</code>.</p> <p>Try your BFS interactively using the REPL with the GUI:</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/tinyflow/build\n% ../tinyflow-pnr\n</code></pre> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.read_verilog('../../asic/playground/03-tinyflow-synth/post-synth.v')\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; floorplan_auto(db, view, 0.3, 1.0)\ntinyflow-pnr&gt; place(db, seed=0)\ntinyflow-pnr&gt; net = db.get_net('&lt;net_name&gt;')\ntinyflow-pnr&gt; start = (&lt;i&gt;, &lt;j&gt;, 2)\ntinyflow-pnr&gt; tree = {(&lt;i_t&gt;, &lt;j_t&gt;, 2)}\ntinyflow-pnr&gt; path = bfs_to_tree(db, net, start, tree)\n</code></pre> <p>Pick a net and two of its pin locations (elevated to M2) as the start and tree. You should see the BFS path appear in the GUI. You can use <code>db.clear_all_routing()</code> to clear and try again easily.</p>"},{"location":"ece6745-project1c/#42-single-net-routing","title":"4.2. Single-Net Routing","text":"<p>Given a net, <code>single_route</code> connects all of its pins by growing a routing tree. Cell pins live on M1, but BFS operates on M2-M4, so you need to work with the M2 \"elevated\" pin locations for BFS and add the M1-to-M2 via segments separately.</p> <p>The algorithm works as follows:</p> <ul> <li>Collect the pin locations for the net. For cell pins on M1, add    the M1-to-M2 via <code>Line</code> segment and use the M2 location    <code>(i, j, 2)</code> as the BFS routing point</li> <li>Initialize the routing tree with the first pin</li> <li>For each remaining unconnected pin, use <code>bfs_to_tree</code> to find    a path from the pin to the tree (this also commits the path)</li> <li>Grow the tree with the returned path so subsequent pins can    connect to any node routed so far</li> </ul> <p>Implement the <code>single_route</code> function in <code>tinyflow/pnr/single_route.py</code>.</p> <p>Function: <code>single_route(db, net_name)</code></p> <p>Goal: Route a single net by connecting all pins using tree-growing BFS.</p> <p>Args:</p> <ul> <li><code>db</code>: TinyBackEndDB with placed design</li> <li><code>net_name</code>: Name of the net to route</li> </ul> <p>Returns: <code>True</code> if routing succeeded, <code>False</code> otherwise.</p> <p>Hint: Use a <code>set</code> for the tree and <code>tree.update(path)</code> to grow it after each successful BFS. <code>bfs_to_tree</code> handles committing the path to the routing grid. You still need to commit the M1-to-M2 via segments separately using <code>net.add_route_segments()</code>.</p> <p>Try routing a single net in the REPL:</p> <pre><code>tinyflow-pnr&gt; db.clear_all_routing()\ntinyflow-pnr&gt; single_route(db, '&lt;net_name&gt;')\n</code></pre> <p>You should see the full route for that net appear in the GUI, including the M1-to-M2 vias at each pin. Use <code>db.clear_all_routing()</code> to clear and try different nets.</p> <p>Heuristic: Connect Closest Pin First</p> <p>Instead of connecting pins in arbitrary order, you can improve route quality by always connecting the closest unconnected pin to the tree next (using Manhattan distance). This tends to produce shorter routes and reduce congestion.</p>"},{"location":"ece6745-project1c/#43-multi-net-routing","title":"4.3. Multi-Net Routing","text":"<p>The goal of <code>multi_route</code> is to route all nets in the design using <code>single_route</code>. The order in which nets are routed matters: nets routed first have more available routing resources, while nets routed later may be blocked by earlier routes.</p> <p>The algorithm works as follows:</p> <ul> <li>Sort nets by HPWL (shortest first) using <code>net_hpwl</code> as the sort    key, since shorter nets are easier to route and less likely to    block others</li> <li>Route each net using <code>single_route</code></li> <li>If a net fails to route, rip up all routing using    <code>db.clear_all_routing()</code>, move the failed net to the front of the    list, and retry</li> <li>If all retries are exhausted, return <code>False</code></li> </ul> <p>Implement the <code>multi_route</code> function and the <code>net_hpwl</code> helper function in <code>tinyflow/pnr/multi_route.py</code>.</p> <p>Function: <code>net_hpwl(net)</code></p> <p>Goal: Compute HPWL for a single net (used for sorting).</p> <p>Args:</p> <ul> <li><code>net</code>: A single <code>Net</code> object</li> </ul> <p>Returns: HPWL for this net (<code>int</code>)</p> <p>Function: <code>multi_route(db, max_retries)</code></p> <p>Goal: Route all nets in the design.</p> <p>Args:</p> <ul> <li><code>db</code>: TinyBackEndDB with placed design</li> <li><code>max_retries</code>: Maximum rip-up and retry attempts</li> </ul> <p>Returns: <code>True</code> if all nets routed, <code>False</code> otherwise.</p> <p>Hint: Use <code>db.clear_all_routing()</code> to rip up all routes before each retry attempt. Only route nets with two or more pins. Use <code>list.remove()</code> and <code>list.insert(0, ...)</code> to move the failed net to the front.</p> <p>Try routing all nets in the REPL:</p> <pre><code>tinyflow-pnr&gt; db.clear_all_routing()\ntinyflow-pnr&gt; multi_route(db)\n</code></pre> <p>You should see all nets get routed in the GUI.</p> <p>Once you have implemented the routing algorithms, run all of the routing tests:</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/tinyflow/build\n% pytest ../pnr/tests/single_route_test.py -v\n% pytest ../pnr/tests/multi_route_test.py -v\n</code></pre>"},{"location":"ece6745-project1c/#5-algorithm-fill","title":"5. Algorithm: Fill","text":"<p>After placement and routing, any sites in the core that are not occupied by a standard cell need to be filled with FILL cells. Filler cells ensure there are no gaps in the layout. They maintain continuous n-well and power rail connections across the chip.</p> <p>The algorithm is straightforward: iterate through every site in the core grid and mark any empty site as filler. Implement the <code>add_filler</code> function in <code>tinyflow/pnr/add_filler.py</code>.</p> <p>Function: <code>add_filler(db)</code></p> <p>Goal: Insert filler cells into all empty sites.</p> <p>Args:</p> <ul> <li><code>db</code>: TinyBackEndDB with placed and routed design</li> </ul> <p>Returns: None (modifies db in place)</p> <p>Hint: Use <code>db.get_core()</code> to get the 2D site grid. See the Site API reference (Section 7.8) for methods to check and mark sites. After filling, count the filler sites and call <code>db.set_filler_count(count)</code>.</p> <p>Try adding filler interactively using the REPL with the GUI:</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/tinyflow/build\n% ../tinyflow-pnr\n</code></pre> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(be='../../stdcells/stdcells-be.yml', gds='../../stdcells/stdcells.gds')\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.read_verilog('../../asic/playground/03-tinyflow-synth/post-synth.v')\ntinyflow-pnr&gt; db.enable_gui()\ntinyflow-pnr&gt; floorplan_auto(db, view, 0.3, 1.0)\ntinyflow-pnr&gt; place(db, seed=0)\ntinyflow-pnr&gt; multi_route(db)\ntinyflow-pnr&gt; add_filler(db)\n</code></pre> <p>You should see filler cells appear in all empty sites in the GUI. Every site should now be either occupied by a standard cell or marked as filler.</p> <p>Once you have implemented the fill algorithm, run the filler tests:</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/tinyflow/build\n% pytest ../pnr/tests/add_filler_test.py -v\n</code></pre>"},{"location":"ece6745-project1c/#6-testing","title":"6. Testing","text":"<p>Once you have implemented all algorithms, run all of the back-end tests at once to verify everything works together.</p> <pre><code>% cd ${HOME}/ece6745/project1-groupXX/tinyflow/build\n% pytest ../pnr/tests -v\n</code></pre> <p>Just because all of the tests pass does not mean your implementation is correct. You are encouraged to add more tests.</p>"},{"location":"ece6745-project1c/#7-tinyflow-front-and-back-end","title":"7. TinyFlow Front and Back End","text":"<p>The complete TinyFlow includes both the front-end and back-end. The front-end flow consists of four steps: two-state simulation, four-state simulation, synthesis, and fast-functional gate-level simulation. The back-end flow consists of three steps: place-and-route, design rule checking, and layout-vs-schematic. In this final part, we push the full adder design through all steps of the flow to illustrate going from Verilog RTL to a gate-level netlist to layout. We first manually run each step before showing how we can automate running the flow.</p>"},{"location":"ece6745-project1c/#71-front-end-manual-flow","title":"7.1. Front-End Manual Flow","text":"<p>We need to first run the front-end flow as in project 1B to generate the gate-level netlist. We provide the Verilog RTL in <code>rtl/FullAdder.v</code> and a basic testbench in <code>rtl/test/FullAdder-test.v</code>. These are the same as in the project 1B. Run the two-state simulation with Verilator.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/playground/01-verilator-rtlsim\n% verilator --top Top --timing --binary -o FullAdder-test \\\n    ../../../rtl/FullAdder.v \\\n    ../../../rtl/test/FullAdder-test.v\n% ./obj_dir/FullAdder-test\n</code></pre> <p>Now run four-state simulation with Icarus Verilog.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/playground/02-iverilog-rtlsim\n% iverilog -g2012 -o FullAdder-test \\\n    ../../../rtl/FullAdder.v \\\n    ../../../rtl/test/FullAdder-test.v\n% ./FullAdder-test\n</code></pre> <p>Create a <code>run.py</code> script for synthesis.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/playground/03-tinyflow-synth\n% code run.py\n</code></pre> <p>Populate the script with the commands to perform optimized technology mapping and static timing analysis using your work Project 1B.</p> <pre><code># Load the standard-cell front-end view and create front-end database\n\nview = StdCellFrontEndView.parse_lib(\"../../../stdcells/stdcells-fe.yml\")\ndb = TinyFrontEndDB(view)\n\n# Read Verilog file into the database\n\ndb.read_verilog(\"../../../rtl/FullAdder.v\")\n\n# Optimized technology mapping\n\ntechmap(db, view)\n\n# Static timing analysis with output load of 10fF\n\noutput_load = 10\nsta(db, view, output_load)\n\n# Check design for issues\n\ndb.check_design()\n\n# Output reports\n\ndb.report_area()\ndb.report_timing()\ndb.report_summary()\n\n# Write front-end database to a Verilog gate-level netlist\n\ndb.write_verilog(\"post-synth.v\")\n</code></pre> <p>Now go ahead and run synthesis.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/playground/03-tinyflow-synth\n% ../../../tinyflow/tinyflow-synth -f run.py\n</code></pre> <p>Finally run fast-functional gate-level simulation to ensure the gate-level netlist is correct.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/playground/04-iverilog-ffglsim\n% iverilog -g2012 -o FullAdder-test \\\n    ../../../stdcells/stdcells.v ../03-tinyflow-synth/post-synth.v \\\n    ../../../rtl/test/FullAdder-test.v\n% ./FullAdder-test\n</code></pre>"},{"location":"ece6745-project1c/#72-place-and-route","title":"7.2. Place and Route","text":"<p>Let's first run the back-end flow interactively, and then we will create a corresponding <code>run.py</code> script. Start the place-and-route REPL.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/playground/05-tinyflow-pnr\n% ../../../tinyflow/tinyflow-pnr\n</code></pre> <p>Now load the standard view, create the tiny back-end database, and start the GUI.</p> <pre><code>tinyflow-pnr&gt; view = StdCellBackEndView(\n                be     = '../../../stdcells/stdcells-be.yml',\n                gds    = '../../../stdcells/stdcells.gds',\n                rcx_sp = '../../../stdcells/stdcells-rcx.sp',\n              )\ntinyflow-pnr&gt; db = TinyBackEndDB(view)\ntinyflow-pnr&gt; db.enable_gui()\n</code></pre> <p>Read the gate-level netlist Verilog file into the database.</p> <pre><code>tinyflow-pnr&gt; db.read_verilog('../03-tinyflow-synth/post-synth.v')\n</code></pre> <p>Create an automated floorplan.</p> <pre><code>tinyflow-pnr&gt; floorplan_auto(db, view, 0.5, 1.0)\n</code></pre> <p>Place and route the design and insert filler cells.</p> <pre><code>tinyflow-pnr&gt; place(db)\ntinyflow-pnr&gt; multi_route(db)\ntinyflow-pnr&gt; add_filler(db)\n</code></pre> <p>Check the design for issues and output a summary report.</p> <pre><code>tinyflow-pnr&gt; db.check_design()\ntinyflow-pnr&gt; db.report_summary()\n</code></pre> <p>If the design is not able to route then you might need to try replacing the design with a different seed and/or decreasing the density during automated floorplanning. Write the tiny back-end database to a SPICE netlist and GDS layout file and exit the REPL.</p> <pre><code>tinyflow-pnr&gt; db.write_spice('post-pnr-rcx.sp')\ntinyflow-pnr&gt; db.write_gds('post-pnr.gds')\ntinyflow-pnr&gt; exit()\n</code></pre> <p>You can now view the final layout using Klayout.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/playground/05-tinyflow-pnr\n% klayout post-pnr.gds\n</code></pre> <p>Choose Display &gt; Top Level Only to hide the internals of each standard cell and show just the placement and routing of the standard cells. Try hiding and showing different metal layers to better visualize the routing. Spend some time appreciating all your hard work!</p> <p>Create a <code>run.py</code> script to make it easier to run place-and-route.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/playground/05-tinyflow-pnr\n% code run.py\n</code></pre> <p>Populate the script with the above commands. Note that we do not enable the GUI when using a <code>run.py</code> script. Now rerun place-and-route using this <code>run.py</code> script.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/playground/05-tinyflow-pnr\n% ../../../tinyflow/tinyflow-pnr -f run.py\n</code></pre>"},{"location":"ece6745-project1c/#73-design-rule-checking","title":"7.3. Design Rule Checking","text":"<p>Although we have already ensured our standard cells are DRC clean, we also need to check to ensure the final layout for entire full adder is DRC clean. We can do that interactively using Klayout or using the command line like this:</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/playground/06-tinyflow-drc\n% tinyflow-batch-drc ../05-tinyflow-pnr/post-pnr.gds\n</code></pre>"},{"location":"ece6745-project1c/#74-layout-vs-schematic","title":"7.4. Layout vs. Schematic","text":"<p>Similarly, although we have already ensured our standard cells are LVS clean, we also need to check to ensure the final layout for entire full adder is LVS clean. We can do that interactively using Klayout or using the command line like this:</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/playground/07-tinyflow-lvs\n% tinyflow-batch-lvs ../05-tinyflow-pnr/post-pnr.gds ../05-tinyflow-pnr/post-pnr-rcx.sp\n</code></pre>"},{"location":"ece6745-project1c/#75-tiny-automated-flow","title":"7.5. Tiny Automated Flow","text":"<p>In the previous sections, we manually commands entering commands for each tool to take a design from RTL to layout. Using <code>run.py</code> scripts can help, and we could even create <code>run</code> Bash scripts to further automate the flow. However, truly agile hardware design demands more sophisticated automation to simplify rapidly exploring the design space of one or more designs. In this section, we will introduce a tool called pyhflow which takes as input step templates and a design YAML and generates appropriate flow scripts.</p> <p>pyflow is based on the idea of step templates which are located in the asic/steps directory.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/steps\n% tree\n</code></pre> <p>The directory layout should look as follows.</p> <pre><code>.\n\u251c\u2500\u2500 01-verilator-rtlsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 02-iverilog-rtlsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 03-tinyflow-synth\n\u2502   \u251c\u2500\u2500 run\n\u2502   \u2514\u2500\u2500 run.py\n\u251c\u2500\u2500 04-iverilog-ffglsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 05-tinyflow-pnr\n\u2502   \u251c\u2500\u2500 run\n\u2502   \u2514\u2500\u2500 run.py\n\u251c\u2500\u2500 06-klayout-drc\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 07-klayout-lvs\n\u2502   \u2514\u2500\u2500 run\n\u2514\u2500\u2500 08-summarize-results\n    \u2514\u2500\u2500 run\n</code></pre> <p>Each step is a directory with a run script and possibly other scripts. The key difference from the <code>run.py</code> and <code>run</code> scripts we used previously, is that these scripts are templated using the Jinja2 templating system:</p> <ul> <li>https://jinja.palletsprojects.com</li> </ul> <p>Open the <code>run.py</code> script in the <code>03-tinyflow-synth</code> step template.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/steps/03-tinyflow-synth\n% code run.py\n</code></pre> <p>Notice how the <code>run.py</code> script is templated based on the design name.</p> <pre><code>db.read_verilog(\"{{top_dir}}/rtl/{{design_name}}.v\")\n</code></pre> <p>The <code>{{ }}</code> directive is the standard syntax for template variable substitution using Jinja2. The pyhflow program takes as input a design YAML file which specifies how to fill in these template variables. Take a look at the provided design YAML for the full ader.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic/designs\n% code fa.yml\n</code></pre> <p>The contents should look as follows.</p> <pre><code>steps:\n - 01-verilator-rtlsim\n - 02-iverilog-rtlsim\n - 03-tinyflow-synth\n - 04-iverilog-ffglsim\n - 05-tinyflow-pnr\n - 06-klayout-drc\n - 07-klayout-lvs\n - 08-summarize-results\n\ntop_dir     : ../../..\ndesign_name : FullAdder\ntest        : FullAdder-test\n\ntechmap     : optimized\nplace       : optimized\n\nfloorplan              : auto\nfloorplan_density      : 0.5\nfloorplan_aspect_ratio : 1.0\n</code></pre> <p>This design YAML file specifies the generated flow should use eight steps and also includes the design name, test name, and floorplan information. You can choose to use your unoptimized technology mapping algorithm and simply random placement as a baseline. All pyhflow does is use the YAML file to figure out what to substitute into the templated steps and then copy the run scripts into the current working directory. You can also override parameters on pyhflow command line.</p> <p>Let's now use pyhflow to easily automate the entire process of pushing a full adder through the tiny flow.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic\n% mkdir -p build-fa\n% cd build-fa\n% pyhflow ../designs/fa.yml\n% ./01-verilator-rtlsim/run\n% ./02-iverilog-rtlsim/run\n% ./03-tinyflow-synth/run\n% ./04-iverilog-ffglsim/run\n% ./05-tinyflow-pnr/run\n% ./06-klayout-drc/run\n% ./07-klayout-lvs/run\n% ./08-summarize-results/run\n</code></pre> <p>pyhflow also creates a <code>run-flow</code> script which will run all the steps further simplifying the process.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic\n% mkdir -p build-fa\n% cd build-fa\n% pyhflow ../designs/fa.yml\n% ./run-flow\n\n timestamp            = 2026-02-18 16:27:36\n design_name          = FullAdder\n techmap              = optimized\n place                = optimized\n rtlsim_2state        = passed\n rtlsim_4state        = passed\n synth_num_stdcells   = 20\n synth_area           = 38912 lambda^2\n synth_critical_path  = 319.604 ps\n ffglsim              = passed\n pnr_area             = 1069.978 um^2\n pnr_num_placed_cells = 20/20\n pnr_num_routed_nets  = 23/23\n pnr_check_design     = passed\n drc_check_design     = passed\n lvs_check_design     = passed\n</code></pre> <p>Now try taking the four-bit ripple-carry adder from RTL to a gate-level netlist to layout using the tiny automated flow.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic\n% mkdir -p build-addrc-4b\n% cd build-addrc-4b\n% pyhflow ../designs/addrc-4b.yml\n% ./run-flow\n\n timestamp            = 2026-02-18 16:28:09\n design_name          = AdderRippleCarry_4b\n techmap              = optimized\n place                = optimized\n rtlsim_2state        = passed\n rtlsim_4state        = passed\n synth_num_stdcells   = 77\n synth_area           = 158208 lambda^2\n synth_critical_path  = 814.604 ps\n ffglsim              = passed\n pnr_area             = 2575.411 um^2\n pnr_num_placed_cells = 77/77\n pnr_num_routed_nets  = 85/85\n pnr_check_design     = passed\n drc_check_design     = passed\n lvs_check_design     = passed\n</code></pre>"},{"location":"ece6745-project1c/#8-tinyflow-tapeout","title":"8. TinyFlow Tapeout","text":"<p>Once your entire Tiny Flow is working, you can now implement a project of your choice as a Tiny Flow block. Each Tiny Flow block is limited to 100x100um with exactly eight inputs pins and exactly eight output pins in a fixed floorplan. The course staff will the compose all of the Tiny Flow blocks into a single chip for a shared tapeout on TSMC 180nm. Each group will have a chance to test their Tiny Flow block on the shared tapeout in the fall. Here are some project ideas:</p> <ul> <li>3-bit ALU (add, sub, lt, gt)</li> <li>8-bit comparator (outputs indicate lt, gt, eq)</li> <li>8-bit popcount (output is number of ones in the input)</li> <li>3-bit multiplier (output is 6-bit product, 4-bit multiplier is probably too big)</li> <li>4-bit variable shifter (1-bit indicates left/right, 2-bits indicate amount to shift)</li> <li>4-bit variable rotator (1-bit indicates left/right, 2-bits indicate amount to shift)</li> <li>8-bit parity generator</li> <li>4-bit binary to seven-segment display</li> <li>8-bit absolute value</li> <li>4-bit min-max unit (top 4-bits of output is max, bottom 4-bits of output is min)</li> <li>3-bit median of three</li> <li>hamming(7,4) encoder</li> <li>8-bit S-box</li> </ul> <p>Students can implement any project they want as long as it meets the following requirements:</p> <ul> <li>no unused inputs, no undriven outputs</li> <li>exhaustive Verilog test bench</li> <li>passes all tests for 2-state RTL simulation</li> <li>passes all tests for 4-state RTL simulation</li> <li>passes generic gates are technology mapped</li> <li>passes synthesis check design</li> <li>passes all tests for fast-function gate-level simulation</li> <li>uses standard 100x100um fixed floorplan</li> <li>all cells are successfully placed</li> <li>all nets are successfully placed</li> <li>passes pnr check design</li> <li>passes DRC check design</li> <li>passes LVS check design</li> </ul> <p>We have included an example of what a Tiny Flow block might look like in your repo. Take a look at the code in <code>TapeoutExample.v</code>. Notice that all inputs must be used and all outputs must be driven! Let's say you do use in0 but you do not use in7. Then you could do something like this:</p> <pre><code>  assign in7_ = ~(in7 &amp; in7);\n  assign in0_ = in7_ | in0;\n</code></pre> <p>This way in7 will be used but will not impact the output. If you do not use an output then simply assign one of the outputs you do use to the unused output to ensure all outputs are always driven. If your Tiny Flow block has unused inputs and/or undriven outputs it will not be included on the shared tapeout.</p> <p>You can try pushing this example through your Tiny Flow as follows.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic\n% mkdir -p build-tapeout-example\n% cd build-tapeout-example\n% pyhflow ../designs/tapeout-example.yml\n% ./run-flow\n\n timestamp            = 2026-02-18 20:43:29\n design_name          = TapeoutExample\n techmap              = optimized\n place                = optimized\n rtlsim_2state        = passed\n rtlsim_4state        = passed\n synth_num_stdcells   = 109\n synth_area           = 207360 lambda^2\n synth_critical_path  = 971.452 ps\n ffglsim              = passed\n pnr_area             = 9729.331 um^2\n pnr_num_placed_cells = 109/109\n pnr_num_routed_nets  = 117/117\n pnr_check_design     = passed\n drc_check_design     = passed\n lvs_check_design     = passed\n</code></pre> <p></p> <p>Notice that the block is 100x100um. The eight input pins are in fixed locations along the left edge and the eight output pins are in fixed locations on the right edge.</p> <p>You must implement your Tiny Flow project in <code>TapeoutGroupXX</code> where <code>XX</code> is your group number. To include your Tiny Flow project on the TinyFlow tapeout you must copy the final post-pnr layout and extracted schematic into this subdirectory, add them to your repository, and push them to GitHub like this.</p> <pre><code>% cd $HOME/ece6745/project1-groupXX/asic\n% mkdir build-tapeout-groupXX\n% cd build-tapeout-groupXX\n% pyhflow ../designs/tapeout-groupXX.yml\n% cp 05-tinyflow-pnr/post-pnr.gds ../tapeout\n% cp 05-tinyflow-pnr/post-pnr-rcx.sp ../tapeout\n% git add ../tapeout\n% git commit -m \"tapeout ready\"\n% git push\n</code></pre> <p>Where <code>XX</code> is your group number.</p>"},{"location":"ece6745-project1c/#9-api-reference","title":"9. API Reference","text":"<p>This section provides a quick reference for the classes and methods you will use when implementing the back-end algorithms.</p> <p>Coordinate Systems</p> <p>There are two coordinate systems used in the back end:</p> <ul> <li> <p>Site grid uses <code>(row, col)</code> coordinates. Each cell occupies   one or more sites in a row. Cell placement uses site grid   coordinates (e.g., <code>cell.set_place(row, col)</code>).</p> </li> <li> <p>Routing grid uses <code>(i, j, k)</code> coordinates. <code>i</code> corresponds   to the row direction (vertical), <code>j</code> corresponds to the column   direction (horizontal), and <code>k</code> is the metal layer (1=M1, 2=M2,   etc.). The routing grid is finer than the site grid \u2014 there are   multiple routing tracks per site row in the <code>i</code> direction. Pin   locations and I/O port placement use routing grid coordinates   (e.g., <code>pin.get_node()</code> returns <code>(i, j, k)</code>).</p> </li> </ul>"},{"location":"ece6745-project1c/#71-stdcellbackendview-view","title":"7.1. StdCellBackEndView (<code>view</code>)","text":"<p>The library view provides technology information (site dimensions, layer info, cell definitions).</p> Method/Attribute Returns Description <code>view.get_site()</code> <code>Site</code> Get the site definition <code>view.get_site().get_width()</code> <code>int</code> Site width in lambda <code>view.get_site().get_height()</code> <code>int</code> Site height in lambda <code>view.get_cell(ref)</code> <code>Cell</code> Get library cell by reference name <code>view.get_cell(ref).get_width()</code> <code>int</code> Cell width in lambda <code>view.get_layer('metal1')</code> <code>Layer</code> Get a metal layer <code>view.get_layer(name).get_track_pitch()</code> <code>int</code> Track pitch in lambda <code>view.get_lambda_um()</code> <code>float</code> Lambda unit in micrometers (0.09)"},{"location":"ece6745-project1c/#72-tinybackenddb-db","title":"7.2. TinyBackEndDB (<code>db</code>)","text":"<p>The backend database manages cells, nets, I/O ports, and the site and routing grids.</p> <p>Floorplan and grid:</p> Method/Attribute Returns Description <code>db.floorplan(num_rows, num_cols)</code> None Initialize site grid (units: sites) <code>db.get_num_rows()</code> <code>int</code> Number of rows in site grid <code>db.get_num_cols()</code> <code>int</code> Number of sites per row <code>db.get_grid_size_i()</code> <code>int</code> Routing grid size in i (vertical tracks) <code>db.get_grid_size_j()</code> <code>int</code> Routing grid size in j (horizontal tracks) <code>db.get_core()</code> <code>list[list[Site]]</code> 2D site grid <p>Cells:</p> Method/Attribute Returns Description <code>db.get_cells()</code> <code>tuple[Cell]</code> Get all cell instances <code>db.get_cell(name)</code> <code>Cell</code> Get a cell by instance name <p>Nets:</p> Method/Attribute Returns Description <code>db.get_nets()</code> <code>tuple[Net]</code> Get all nets <code>db.get_net(name)</code> <code>Net</code> Get a net by name <p>I/O ports:</p> Method/Attribute Returns Description <code>db.get_ioport(name)</code> <code>IOPort</code> Get an I/O port by name <code>db.get_in_ports()</code> <code>tuple[IOPort]</code> Get all input ports <code>db.get_out_ports()</code> <code>tuple[IOPort]</code> Get all output ports <p>Placement helpers:</p> Method/Attribute Returns Description <code>db.get_placement()</code> <code>dict</code> Get current placement as <code>{name: (row, col)}</code> <code>db.apply_placement(dict)</code> None Apply a saved placement (unplaces all first) <p>Routing:</p> Method/Attribute Returns Description <code>db.get_occupancy(i, j, k)</code> <code>Net</code> or <code>None</code> Get the net occupying a routing node, or <code>None</code> if free <code>db.clear_all_routing()</code> None Clear all routing and restore pin/IO occupancy <code>db.set_filler_count(count)</code> None Set filler cell count"},{"location":"ece6745-project1c/#73-cell","title":"7.3. Cell","text":"Method/Attribute Returns Description <code>cell.get_name()</code> <code>str</code> Instance name <code>cell.get_width()</code> <code>int</code> Width in sites <code>cell.get_place()</code> <code>list</code> Current placement <code>[row, col]</code> (site coords) <code>cell.is_placed()</code> <code>bool</code> Whether the cell is placed <code>cell.set_place(row, col)</code> None Place cell at site coordinates <code>cell.set_unplace()</code> None Remove cell from placement <code>cell.pins</code> <code>list[Pin]</code> List of pins on this cell"},{"location":"ece6745-project1c/#74-pin","title":"7.4. Pin","text":"Method/Attribute Returns Description <code>pin.get_name()</code> <code>str</code> Pin name <code>pin.get_node()</code> <code>(i, j, k)</code> Routing grid coordinates (None if unplaced) <code>pin.net</code> <code>Net</code> The net this pin belongs to"},{"location":"ece6745-project1c/#75-ioport","title":"7.5. IOPort","text":"<p>IOPort is a subclass of Pin. It represents an I/O port at the chip boundary.</p> Method/Attribute Returns Description <code>ioport.place(i, j)</code> None Place at routing grid edge coordinates <code>ioport.get_node()</code> <code>(i, j, k)</code> Routing grid coordinates (k = 2, i.e., M2) <code>ioport.name</code> <code>str</code> Port name"},{"location":"ece6745-project1c/#76-net","title":"7.6. Net","text":"Method/Attribute Returns Description <code>net.net_name</code> <code>str</code> Net name <code>net.pins</code> <code>list[Pin]</code> List of connected pins (includes IOPorts) <code>net.add_route_segments(lines)</code> None Commit a list of <code>Line</code> segments to the routing grid"},{"location":"ece6745-project1c/#77-line","title":"7.7. Line","text":"<p>A <code>Line</code> represents a wire segment between two adjacent nodes in the routing grid.</p> Method/Attribute Returns Description <code>Line(start, end)</code> <code>Line</code> Create a segment from <code>(i,j,k)</code> to <code>(i,j,k)</code> <code>line.start</code> <code>(i,j,k)</code> Start node <code>line.end</code> <code>(i,j,k)</code> End node"},{"location":"ece6745-project1c/#78-site","title":"7.8. Site","text":"<p>Sites are accessed from <code>db.get_core()</code> which returns a 2D list indexed as <code>core[row][col]</code>.</p> Method/Attribute Returns Description <code>site._get_occupancy()</code> <code>Cell</code> or <code>None</code> Get the cell occupying this site, or <code>None</code> if empty <code>site.is_fill()</code> <code>bool</code> Whether this site is marked as filler <code>site.add_filler()</code> None Mark this site as filler"},{"location":"ece6745-project2-ideas/","title":"ECE 6745 Project 2 Ideas","text":"<p>For project 2, you will be designing, implementing, testing, evaluating, and fabricating an accelerator which connects to a TinyRV2 processor. The processor can read and write accelerator registers using CSR instructions to send data to and receive data from the accelerator. Here is the top-level system diagram.</p> <p></p> <p>Even though you will only be taping out the accelerator, we still want to do a rigorous comparative analysis of the system as a whole. Here are some project ideas.</p> <ul> <li> <p>Compression/Decompression Accelerator: Create an accelerator that    implements some kind of advanced compression algorithm. The processor    would send over 32-64B of data by writing 8-16 accelerator registers    and then read back the result by reading a different set of 8-16    accelerator registers. The accelerator could be for compression,    decompression, or both.</p> </li> <li> <p>Cryptographic Hashing Accelerator: Create an accelerator for for a    cryptographic hash function like SHA-1 or SHA-2. The processor would    send over the 32-64B of data by writing 8-16 accelerator registers and    then read back the hashed version by reading a different set of 8-16    accelerator registers.</p> </li> <li> <p>Encryption/Decryption Accelerator: Create an accelerator that    implements some kind of encryption or decryption algorithm such as    AES. The processor would send over 32-64B of data by writing 8-16    accelerator registers and then read back the result by reading a    different set of 8-16 accelerator registers. The accelerator could be    for encryption, decryption, or both.</p> </li> <li> <p>Floating-Point Adder or Multiplier: Create a hardware floating    point unit (FPU). The procecssor would write the operands to two    accelerator registers and read the result from a third accelerator    register. The FPU could potentially support both addition and    multiplication; the processor might write a fourth accelerator    register to indicate which operation to perform.</p> </li> <li> <p>DNA Sequence Alignment Accelerator: Create an accelerator for DNA    sequence alignment using a dynamic programming algorithm such as    Smith-Waterman. The processor would send over two DNA sequences packed    into 32-bit words (two bits per basepair, so 16 basepairs per 32-bit    word, so up a 256-basepair sequence can be written using 16    accelerator registers). The processor would read back the alignment    score and potentially also read back the actual alignment. Such an    accelerator could eventually be used to process a tile of a much    larger sequence alignment.</p> </li> <li> <p>Image Processing Accelerator: Create an accelerator for corner or    feature detection or even optical flow might be interesting. The    processor would send over a small image. For example, assuming 4-bit    gray-scale pixels, the processor could send over a 16x16 image block    by writing 32 accelerator registers (i.e., a 16x16 image block has 256    pixels, eight pixels packed into each 32-bit word). The processor can    read back the output image by reading these same 32 accelerator    registers. Such an accelerator could eventually be used to process a    tile of a much larger image.</p> </li> <li> <p>Dense Matrix Multiplication Accelerator: Create a systolic array    to accelerate integer matrix multiplication. The processor would send    over two small matrices. For example, assuming 8-bit elements pixels,    the processor could send over an 8x8 matrix by writing 16 accelerator    registers (i.e., a 8x8 matrix has 64 elements, four elements packed    into each 32-bit word). The processor would need to write two matrices    and then read the result by reading some of these same registers.</p> </li> <li> <p>Sparse Matrix Vector Accelerator: Create a accelerator for sparse    matrxi-vector multiplication. Assume the metrix is stored in CSR    format and the vector is dense. The accelerator would need to operate    on very small matrices; just what is feasible to write through    accelerator registers.</p> </li> <li> <p>FFT Butterfly Accelerator: Create an accelerator to accelerate the    butterfly operation in an FFT. The processor would need to send over    the data but also potentially the twiddle factors. Ideally the FFT    butterfly accelerator would be evaluated in the context of a    performing an FFT on a small input array.</p> </li> <li> <p>CORDIC Accelerator: Create an accelerator for trigonometric    functions by using the CORDIC algorithm. The processor might send over    a vector and an angle by writing several four accelerator registers    (i.e., three to specify the vector, one to specify the angle) and then    read the result (i.e., the rotated vector) by reading three additional    accelerator registers.</p> </li> <li> <p>Integer Square Root Accelerator: Create an accelerator that can    find the square root of an integer value using an iterative approach.</p> </li> <li> <p>Approximate Multiplier: Create an approximate integer multiplier using    a log-based approach. Instead of computing A\u00d7B directly, the accelerator    computes log2(A) + log2(B) and applies the antilog. This hopefully yields    area and power savings at the cost of a small, bounded error. Target a    4-bit \u00d7 4-bit multiplier producing an 8-bit approximate product.    Students can compare area, delay, power, and error metrics against    an exact multiplier to explore the accuracy-vs-efficiency trade-off.</p> </li> <li> <p>FIR Filter Accelerator: Create an accelerator for a finite    impulse response (FIR) filter. An N-tap FIR filter computes a    weighted sum of the N most recent input samples using fixed    coefficients. The processor writes the filter coefficients and    input samples packed into accelerator registers and reads back    the filtered output.</p> </li> <li> <p>Priority Queue Accelerator: Create an accelerator for a    hardware priority queue that supports insert and extract-min    (or extract-max) operations. The processor writes a key-value    pair to an accelerator register to insert an element and reads    from another register to extract the highest-priority element.    The accelerator maintains a sorted structure internally. Such    an accelerator is useful for task scheduling, network packet    prioritization, and graph algorithms like Dijkstra's shortest path.</p> </li> <li> <p>Prefix Sum Accelerator: Create an accelerator that computes    the prefix sum of a small vector of integers. The processor    writes a small input vector into several accelerator registers    (for example, eight 32-bit values written to eight registers).    The processor then writes a control register to start the    operation. After completion, the processor reads back the    prefix-sum results from the accelerator registers. The    accelerator computes the inclusive prefix sum of the input    vector. It can be evaluated by comparing area and latency    against a software implementation running on the TinyRV2    processor.</p> </li> </ul>"},{"location":"ece6745-sec01-asic-front-end/","title":"ECE 6745 Section 1: ASIC Front-End Flow","text":"<p>In this section, we will be discussing the front-end of the ASIC toolflow. More detailed tutorials will be posted on the public course website, but this section will at least give you a chance to edit some RTL, synthesize that to a gate-level netlist, and then simulate that gate-level netlist. The following diagram illustrates the tool flow we will be using in ECE 6745. Notice that the Synopsys and Cadence ASIC tools all require various views from the standard-cell library which part of the ASIC design kit (ADK).</p> <p></p> <p>The \"front-end\" of the flow is highlighted in red and refers to the PyMTL simulator, Synopsys DC, and Synopsys VCS:</p> <ul> <li>We write our RTL models in Verilog, and we use the PyMTL framework to    test, verify, and evaluate the execution time (in cycles) of our    design. This part of the flow is very similar to the flow used in ECE</li> <li> <p>Once we are sure our design is working correctly, we can then    start to push the design through the flow.</p> </li> <li> <p>We use Synopsys VCS for RTL and gate-level simulation. PyMTL uses    the Verilator two-state RTL simulator meaning every wire will be    either a 0 (logic low) or 1 (logic high). Synopsys VCS uses four-state    RTL simulation meaning every wire will be either a 0 (logic low), 1    (logic high), X (unknown), or Z (floating). Four-state RTL simulation    can identify different kinds of bugs than two-state simulation such as    bugs due to uninitialized state. Gate-level simulation involves    simulating every standard-cell gate and helps verify that the Verilog    gate-level netlist is functionally correct.</p> </li> <li> <p>We use Synopsys Design Compiler (DC) to synthesize our design,    which means to transform the Verilog RTL model into a Verilog    gate-level netlist where all of the gates are selected from the    standard-cell library. We need to provide Synopsys DC with abstract    logical and timing views of the standard-cell library in <code>.db</code> format.    In addition to the Verilog gate-level netlist, Synopsys DC can also    generate a <code>.ddc</code> file which contains information about the gate-level    netlist and timing, and this <code>.ddc</code> file can be inspected using    Synopsys Design Vision (DV).</p> </li> </ul> <p>Extensive documentation is provided by Synopsys and Cadence. We have organized this documentation and made it available to you on the Canvas course page:</p> <ul> <li>https://www.csl.cornell.edu/courses/ece6745/asicdocs</li> </ul> <p>The first step is to access <code>ecelinux</code>. Use Microsoft Remote Desktop to log into a specific <code>ecelinux</code> server. Then use VS Code to log into the same specific <code>ecelinux</code> server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone https://github.com/cornell-ece6745/ece6745-sec01-asic-front-end sec01\n% cd sec01\n% TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#1-nangate-45nm-standard-cell-libraries","title":"1. NanGate 45nm Standard-Cell Libraries","text":"<p>A standard-cell library is a collection of combinational and sequential logic gates that adhere to a standardized set of logical, electrical, and physical policies. For example, all standard cells are usually the same height, include pins that align to a predetermined vertical and horizontal grid, include power/ground rails and nwells in predetermined locations, and support a predetermined number of drive strengths. In this course, we will be using the a NanGate 45nm standard-cell library. It is based on a \"fake\" 45nm technology. This means you cannot actually tapeout a design using this standard cell library, but the technology is representative enough to provide reasonable area, energy, and timing estimates for teaching purposes. All of the files associated with this standard cell library are located in the <code>${ECE6745_STDCELLS}</code> directory.</p> <p>Let's first look at the data book which is on the Canvas course page:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/resources/nangate-freepdk45nm-stdcell-databook.pdf</li> </ul> <p>Scroll through the PDF and find the entry for the NAND3_X1 cell (it is on page 104). The data book provides information on the standard cell's logic function, delay, area, and power consumption. Let's take a look at the layout for the same cell. Note that since Klayout is a Linux GUI application you will need to use Microsoft Remote Desktop.</p> <pre><code>% klayout -l ${ECE6745_STDCELLS}/klayout.lyp ${ECE6745_STDCELLS}/stdcells.gds\n</code></pre> <p>Find the NAND3_X1 cell in the left-hand cell list, and then choose Display &gt; Show as New Top from the menu. We will learn more about layout and how this layout corresponds to a static CMOS circuit later in the course. The key point is that the layout for the standard cells are the basic building blocks that we will be using to create our ASIC chips.</p> <p>The Synopsys and Cadence tools do not actually use this layout directly; it is actually too detailed. Instead these tools use abstract views of the standard cells, which capture logical functionality, timing, geometry, and power usage at a much higher level. Let's look at the Verilog behavioral specification for the 3-input NAND cell.</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells.v\n</code></pre> <p>Note that the Verilog implementation of the 3-input NAND cell looks nothing like the Verilog we used in ECE 4750. This cell is implemented using three Verilog primitive gates (i.e., two <code>and</code> gates and one <code>not</code> gate), and it includes a <code>specify</code> block which is used for advanced gate-level simulation with back-annotated delays.</p> <p>Finally, let's look at an abstract view of the timing and power of the 3-input NAND cell suitable for use by the ASIC flow. This abstract view is in the <code>.lib</code> file for the standard cell library.</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells.lib\n</code></pre> <p>Now that we have looked at some of the views of the standard cell library, we can now try using these views and the ASIC flow front-end to synthesize RTL into a gate-level netlist.</p>"},{"location":"ece6745-sec01-asic-front-end/#2-pymtl-based-testing-simulation-translation","title":"2. PyMTL-Based Testing, Simulation, Translation","text":"<p>Our goal in this section is to generate a gate-level netlist for the following four-stage registered incrementer:</p> <p></p> <p>We will take an incremental design approach. We will start by implementing and testing a single registered incrementer, and then we will write a generic multi-stage registered incrementer. For this section (and indeed the entire course) you will use Verilog for RTL design and Python for test harnesses, simulation drivers, function-level models, and cycle-level models.</p>"},{"location":"ece6745-sec01-asic-front-end/#21-implement-and-test-a-registered-incrementer","title":"2.1. Implement and Test a Registered Incrementer","text":"<p>Now let's run all of the tests for the registered incrementer:</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr\n</code></pre> <p>The tests will fail because we need to finish the implementation. Let's start by focusing on the basic registered incrementer module.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr/test/RegIncr_test.py\n</code></pre> <p>Use VS Code to open the implementation and uncomment the actual combinational logic for the increment operation. The Verilog RTL implementation should look as follows:</p> <pre><code>`ifndef TUT3_VERILOG_REGINCR_REG_INCR_V\n`define TUT3_VERILOG_REGINCR_REG_INCR_V\n\nmodule tut3_verilog_regincr_RegIncr\n(\n  input  logic       clk,\n  input  logic       reset,\n  input  logic [7:0] in_,\n  output logic [7:0] out\n);\n\n  // Sequential logic\n\n  logic [7:0] reg_out;\n\n  always @( posedge clk ) begin\n    if ( reset )\n      reg_out &lt;= 0;\n    else\n      reg_out &lt;= in_;\n  end\n\n  // Combinational logic\n\n  logic [7:0] temp_wire;\n\n  always @(*) begin\n    temp_wire = reg_out + 1;\n  end\n\n  // Combinational logic\n\n  assign out = temp_wire;\n\n  // Line tracing\n\n  `ifndef SYNTHESIS\n\n  logic [`VC_TRACE_NBITS-1:0] str;\n  `VC_TRACE_BEGIN\n  begin\n    $sformat( str, \"%x (%x) %x\", in_, reg_out, out );\n    vc_trace.append_str( trace_str, str );\n  end\n  `VC_TRACE_END\n\n  `endif /* SYNTHESIS */\n\nendmodule\n\n`endif /* TUT3_VERILOG_REGINCR_REG_INCR_V */\n</code></pre> <p>If you have an error you can use a trace-back to get a more detailed error message:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr/test/RegIncr_test.py --tb=long\n</code></pre> <p>Once you have finished the implementation let's rerun the tests:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr/test/RegIncr_test.py -sv\n</code></pre> <p>The <code>-v</code> command line option tells <code>pytest</code> to be more verbose in its output and the <code>-s</code> command line option tells <code>pytest</code> to print out the line tracing. Make sure you understand the line tracing output. You can also dump VCD files using <code>--dump-vcd</code> for waveform debugging with Surfer.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr/test/RegIncr_test.py -sv --dump-vcd\n% code regincr.test.RegIncr_test__test_small_top.verilator1.vcd\n</code></pre> <p>You can also use GTKWave if you prefer to view waveforms, but since GTKWave is a Linux GUI application you will need to use Microsoft Remote Desktop. PyMTL takes care of including all Verilog dependencies into a single Verilog file (also called \"pickling\") suitable for use with the ASIC flow. Take a look at the generated pickled Verilog file.</p> <pre><code>% cd $TOPDIR/sim/build\n% less RegIncr_noparam__pickled.v\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#22-test-the-multi-stage-registered-incrementer","title":"2.2. Test the Multi-Stage Registered Incrementer","text":"<p>Now let's work on composing a single registered incrementer into a multi-stage registered incrementer. We will be using static elaboration to make the multi-stage registered incrementer generic. In other words, our design will be parameterized by the number of stages so we can easily generate a pipeline with one stage, two stages, four stages, etc.</p> <p>Use VS Code to open the implementation and look at the static elaboration logic to instantiate a pipeline of registered incrementers. The Verilog RTL implementation looks as follows:</p> <pre><code>`ifndef TUT3_VERILOG_REGINCR_REG_INCR_NSTAGE_V\n`define TUT3_VERILOG_REGINCR_REG_INCR_NSTAGE_V\n\n`include \"tut3_verilog/regincr/RegIncr.v\"\n\nmodule tut3_verilog_regincr_RegIncrNstage\n#(\n  parameter nstages = 2\n)(\n  input  logic       clk,\n  input  logic       reset,\n  input  logic [7:0] in_,\n  output logic [7:0] out\n);\n\n  // This defines an _array_ of signals. There are p_nstages+1 signals\n  // and each signal is 8 bits wide. We will use this array of\n  // signals to hold the output of each registered incrementer stage.\n\n  logic [7:0] reg_incr_out [nstages+1];\n\n  // Connect the input port of the module to the first signal in the\n  // reg_incr_out signal array.\n\n  assign reg_incr_out[0] = in_;\n\n  // Instantiate the registered incrementers and make the connections\n  // between them using a generate block.\n\n  genvar i;\n  generate\n  for ( i = 0; i &lt; nstages; i = i + 1 ) begin: gen\n\n    tut3_verilog_regincr_RegIncr reg_incr\n    (\n      .clk   (clk),\n      .reset (reset),\n      .in_   (reg_incr_out[i]),\n      .out   (reg_incr_out[i+1])\n    );\n\n  end\n  endgenerate\n\n  // Connect the last signal in the reg_incr_out signal array to the\n  // output port of the module.\n\n  assign out = reg_incr_out[nstages];\n\nendmodule\n\n`endif /* TUT3_VERILOG_REGINCR_REG_INCR_NSTAGE_V */\n</code></pre> <p>Before running the tests, let's take a look at how we are doing the testing in the corresponding test script. Use VS Code to open up <code>RegIncrNstage_test.py</code>. Notice how PyMTL enables sophisticated testing for highly parameterized components. The test script includes directed tests for two and three stage pipelines with various small, large, and random values, and also includes random testing with 1, 2, 3, 4, 5, 6 stages. Writing a similar test harness in Verilog would likely require 10x more code and be significantly more tedious!</p> <p>Let's run all of the tests for the multi-stage registered incrementer.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr/test/RegIncrNstage_test.py -sv\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#23-interactive-simulator-for-multi-stage-registered-incrementer","title":"2.3. Interactive Simulator for Multi-Stage Registered Incrementer","text":"<p>Test scripts are great for verification, but when we want to push a design through the flow we usually want to use an interactive simulator to drive that process. An interactive simulator is meant for evaluting the area, energy, and performance of a design as opposed to verification. We have included a simple interactive simulator called <code>regincr-sim</code> which takes a list of values on the command line and sends these values through the pipeline. Let's see the simulator in action:</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut3_verilog/regincr/regincr-sim -s 0xff 0x20 0x30 0x40 0x00\n</code></pre> <p>The simulator will generate the pickled Verilog file we want to push through the ASIC front-end flow.</p> <pre><code>% cd $TOPDIR/sim/build\n% less RegIncr4stage__pickled.v\n</code></pre> <p>Notice how PyMTL3 has generated a wrapper which picks a specific parameter value for this instance of the multi-stage registered incrementer. The interactive simulator will also generate pure-Verilog test bench with associated test cases which we can use to run four-state RTL and gate-level simulation.</p> <pre><code>% cd $TOPDIR/sim/build\n% less RegIncr4stage_basic_tb.v\n% less RegIncr4stage_basic_tb.v.cases\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#3-synopsys-vcs-for-4-state-rtl-simulation","title":"3. Synopsys VCS for 4-State RTL Simulation","text":"<p>Recall that PyMTL3 simulation of Verilog RTL uses Verilator which is a two-state simulator. To help catch bugs due to uninitialized state (and also just to help verify the design using another Verilog simulator), we can use Synopsys VCS for four-state RTL simulation. This simulator will make use of the Verilog test-bench generated by the <code>--test-verilog</code> and <code>--dump-vtb</code> options from earlier (although we could also write our own Verilog test-bench from scratch). Here is how to run VCS for RTL simulation:</p> <pre><code>% mkdir -p $TOPDIR/asic/build-regincr/01-synopsys-vcs-rtlsim\n% cd $TOPDIR/asic/build-regincr/01-synopsys-vcs-rtlsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${TOPDIR}/sim/build/RegIncr4stage__pickled.v \\\n    ${TOPDIR}/sim/build/RegIncr4stage_basic_tb.v\n</code></pre> <p>You should see a <code>simv</code> binary which is the compiled RTL simulator which you can run like this:</p> <pre><code>% cd $TOPDIR/asic/build-regincr/01-synopsys-vcs-rtlsim\n% ./simv\n</code></pre> <p>It should pass the test. Now let's look at the resulting waveforms with Surfer.</p> <pre><code>% code waves.vcd\n</code></pre> <p>You can also use GTKWave if you prefer to view waveforms, but since GTKWave is a Linux GUI application you will need to use Microsoft Remote Desktop. Browse the signal hierarchy and view the waveforms for one of the four registered incrementers. Note how the signals are initialized to X and only become 0 or 1 after a few cycles once we come out of reset. If we improperly used an initialized value then we would see X-propagation which would hopefully cause a failing test case.</p>"},{"location":"ece6745-sec01-asic-front-end/#4-synopsys-design-compiler-for-synthesis","title":"4. Synopsys Design Compiler for Synthesis","text":"<p>We use Synopsys Design Compiler (DC) to synthesize Verilog RTL models into a gate-level netlist where all of the gates are from the standard cell library. So Synopsys DC will synthesize the Verilog + operator into a specific arithmetic block at the gate-level. Based on various constraints it may synthesize a ripple-carry adder, a carry-look-ahead adder, or even more advanced parallel-prefix adders.</p> <p>We start by creating a subdirectory for our work, and then launching Synopsys DC.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-regincr/02-synopsys-dc-synth\n% cd $TOPDIR/asic/build-regincr/02-synopsys-dc-synth\n% dc_shell-xg-t\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#41-initial-setup","title":"4.1. Initial Setup","text":"<p>We need to set two variables before starting to work in Synopsys DC. These variables tell Synopsys DC the location of the standard cell library <code>.db</code> file which is just a binary version of the <code>.lib</code> file we saw earlier.</p> <pre><code>dc_shell&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db\"\ndc_shell&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db\"\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#42-analyze-and-elaborate-the-design","title":"4.2. Analyze and Elaborate the Design","text":"<p>We are now ready to read in the Verilog file which contains the top-level design and all referenced modules. We do this with two commands. The analyze command reads the Verilog RTL into an intermediate internal representation. The elaborate command recursively resolves all of the module references starting from the top-level module, and also infers various registers and/or advanced data-path components.</p> <pre><code>dc_shell&gt; analyze -format sverilog ../../../sim/build/RegIncr4stage__pickled.v\ndc_shell&gt; elaborate RegIncr4stage\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#43-create-timing-constraints","title":"4.3. Create Timing Constraints","text":"<p>We now need to create a clock constraint to tell Synopsys DC what our target cycle time is:</p> <pre><code>dc_shell&gt; create_clock clk -name ideal_clock1 -period 1\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#44-synthesize-the-design","title":"4.4. Synthesize the Design","text":"<p>Finaly, the <code>compile</code> comamnd will do the actual logic synthesis:</p> <pre><code>dc_shell&gt; compile\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#45-write-final-outputs-and-reports","title":"4.5. Write Final Outputs and Reports","text":"<p>We write the output to a <code>.ddc</code> file which we can use with Synopsys DV and a Verilog gate-level netlist.</p> <pre><code>dc_shell&gt; write -format ddc     -hierarchy -output post-synth.ddc\ndc_shell&gt; write -format verilog -hierarchy -output post-synth.v\n</code></pre> <p>We can also generate usful reports about area and timing. Prof. Batten will spend some time explaining these reports:</p> <pre><code>dc_shell&gt; report_area   -hierarchy\ndc_shell&gt; report_timing -nets\n</code></pre> <p>Make some notes about what you find. Note the total cell area used in this design. Finally, we go ahead and exit Synopsys DC.</p> <pre><code>dc_shell&gt; exit\n</code></pre> <p>Take a few minutes to examine the resulting Verilog gate-level netlist. Notice that the module hierarchy is preserved.</p> <pre><code>% less post-synth.v\n</code></pre> <p>Take a close look at the implementation of the incrementer. What kind of standard cells has the synthesis tool chosen? What kind of adder microarchitecture?</p>"},{"location":"ece6745-sec01-asic-front-end/#46-synopsys-design-vision","title":"4.6. Synopsys Design Vision","text":"<p>We can use the Synopsys Design Vision (DV) tool for browsing the resulting gate-level netlist, plotting critical path histograms, and generally analyzing our design. Start Synopsys DV and setup the <code>target_library</code> and <code>link_library</code> variables as before. Note that since Synsopsy DV is a Linux GUI application you will need to use Microsoft Remote Desktop.</p> <pre><code>% design_vision-xg\ndesign_vision&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db\"\ndesign_vision&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db\"\n</code></pre> <p>You can use the following steps to open the <code>.ddc</code> file generated during synthesis.</p> <ul> <li>Choose File &gt; Read from the menu</li> <li>Open the <code>post-synth.dcc</code> file</li> </ul> <p>You can use the following steps to view the gate-level schematic for the design.:</p> <ul> <li>Select the <code>RegIncr4stage</code> module in the Logical Hierarchy panel</li> <li>Choose Select &gt; Cells &gt; Leaf Cells of Selected Cells from the menu</li> <li>Choose Schematic &gt; New Schematic View from the menu</li> <li>Choose Select &gt; Clear from the menu</li> </ul> <p>You can use the Logical Hierarchy browser to highlight modules in the schematic view. If you click on the drop down you can choose Cells (All) instead of Cells (Hierarchical) to browse the standard cells as well. You can determine the type of module or gate by selecting the module or gate and choosing Edit &gt; Properties from the menu. Then look for <code>ref_name</code>. You should be able to see the schematic for eaech stage of the pipline including the flip-flops and and the add module. See if you can figure out why the synthesis tool has inserted AND gates in front of each flip-flop. If you look inside the <code>add</code> module you should be able to see the adder microarchitecture.</p> <p>You can use the following steps to view a histogram of path slack, and also to open a gave-level schematic of just the critical path.</p> <ul> <li>Choose Timing &gt; Path Slack from the menu</li> <li>Click OK in the pop-up window</li> <li>Select the left-most bar in the histogram to see list of most critical paths</li> <li>Select one of the paths in the path list to highlight the path in the schematic view</li> </ul>"},{"location":"ece6745-sec01-asic-front-end/#5-synopsys-vcs-for-fast-functional-gate-level-simulation","title":"5. Synopsys VCS for Fast-Functional Gate-Level Simulation","text":"<p>Good ASIC designers are always paranoid and never trust their tools. How do we know that the synthesized gate-level netlist is correct? One way we can check is to rerun our test suite on the gate-level model. We can do this using Synopsys VCS for fast-functional gatel-level simulation. Fast-functional refers to the fact that this simulation will not take account any of the gate delays. All gates will take zero time and all signals will still change on the rising clock edge just like in RTL simulation. Here is how to run VCS for RTL simulation.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-regincr/03-synopsys-vcs-ffglsim\n% cd $TOPDIR/asic/build-regincr/03-synopsys-vcs-ffglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top\\\n    +delay_mode_zero \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../02-synopsys-dc-synth/post-synth.v \\\n    ${TOPDIR}/sim/build/RegIncr4stage_basic_tb.v\n</code></pre> <p>The key difference from four-state RTL simulation is that this simulation takes as input the Verilog for the standard-cell library and the Verilog for the post-synthesis gate-level netlist. You should see a <code>simv</code> binary which is the compiled RTL simulator which you can run as follows.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/03-synopsys-vcs-ffglsim\n% ./simv\n</code></pre> <p>It should pass the test. Now let's look at the resulting waveforms using Surfer.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/03-synopsys-vcs-ffglsim\n% code waves.vcd\n</code></pre> <p>You can also use GTKWave if you prefer to view waveforms, but since GTKWave is a Linux GUI application you will need to use Microsoft Remote Desktop. Browse the signal hierarchy and display all the waveforms for a subset of the gate-level netlist using these steps:</p> <ul> <li>Expand out the Scopes panel until you find an add module</li> <li>Click on the _add_module</li> <li>Click the + button in the Variables panel</li> </ul> <p>Notice how we can see all of the single-bit signals corresponding to each gate in the gate-level netlist, and how these signals all change without any delays.</p>"},{"location":"ece6745-sec02-asic-back-end/","title":"ECE 6745 Section 2: ASIC Back-End Flow","text":"<p>In this section, we will be discussing the back-end of the ASIC toolflow. More detailed tutorials will be posted on the public course website, but this section will at least give you a chance to take a gate-level netlist through place-and-route, simulate the final gate-level netlist, and energy analysis. The following diagram illustrates the tool flow we will be using in ECE 6745. Notice that the Synopsys and Cadence ASIC tools all require various views from the standard-cell library which part of the ASIC design kit (ADK).</p> <p></p> <p>The \"back-end\" of the flow is highlighted in red and refers to the PyMTL simulator, Synopsys DC, and Synopsys VCS:</p> <ul> <li> <p>We use Cadence Innovus to place-and-route our design, which means    to place all of the gates in the gate-level netlist into rows on the    chip and then to generate the metal wires that connect all of the    gates together. We need to provide Cadence Innovus with similar    abstract logical and timing views used in Synopsys DC. Cadence Innovus    takes as input the <code>.lib</code> file which is the ASCII text version of a    <code>.db</code> file. In addition, we need to provide Cadence Innovus with    technology information in <code>.lef</code> and <code>.captable</code> format and abstract    physical views of the standard-cell library in <code>.lef</code> format. Cadence    Innovus will generate an updated Verilog gate-level netlist, a <code>.spef</code>    file which contains parasitic resistance/capacitance information about    all nets in the design, and a <code>.gds</code> file which contains the final    layout. The <code>.gds</code> file can be inspected using the open-source Klayout    GDS viewer. Cadence Innovus also generates reports which can be used    to accurately characterize area and timing.</p> </li> <li> <p>We use Synopsys VCS for back-annotated gate-level simulation.    Gate-level simulation involves simulating every standard-cell gate and    helps verify that the Verilog gate-level netlist is functionally    correct. Fast-functional gate-level simulation does not include any    timing information, while back-annotated gate-levle simulation does    include the estimated delay of every gate and every wire.</p> </li> <li> <p>We use Synopsys PrimeTime (PT) to perform power-analysis of our    design. This requires switching activity information for every net in    the design (which comes from the back-annotated gate-level simulation)    and parasitic capacitance information for every net in the design    (which comes from Cadence Innovus). Synopsys PT puts the switching    activity, capacitance, clock frequency, and voltage together to    estimate the power consumption of every net and thus every module in    the design.</p> </li> </ul> <p>Extensive documentation is provided by Synopsys and Cadence. We have organized this documentation and made it available to you on the Canvas course page:</p> <ul> <li>https://www.csl.cornell.edu/courses/ece6745/asicdocs</li> </ul> <p>The first step is to access <code>ecelinux</code>. Use Microsoft Remote Desktop to log into a specific <code>ecelinux</code> server. Then use VS Code to log into the same specific <code>ecelinux</code> server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone https://github.com/cornell-ece6745/ece6745-sec02-asic-back-end sec02\n% cd sec02\n% TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-sec02-asic-back-end/#1-nangate-45nm-standard-cell-libraries","title":"1. NanGate 45nm Standard-Cell Libraries","text":"<p>Recall that a standard-cell library is a collection of combinational and sequential logic gates that adhere to a standardized set of logical, electrical, and physical policies. For example, all standard cells are usually the same height, include pins that align to a predetermined vertical and horizontal grid, include power/ground rails and nwells in predetermined locations, and support a predetermined number of drive strengths. In this course, we will be using the a NanGate 45nm standard-cell library. It is based on a \"fake\" 45nm technology. This means you cannot actually tapeout a design using this standard cell library, but the technology is representative enough to provide reasonable area, energy, and timing estimates for teaching purposes. All of the files associated with this standard cell library are located in the <code>$ECE6745_STDCELLS</code> directory.</p> <p>Let's look at some layout for the standard cell library just like we did in the last section.</p> <pre><code>% klayout -l ${ECE6745_STDCELLS}/klayout.lyp ${ECE6745_STDCELLS}/stdcells.gds\n</code></pre> <p>Let's look at a 3-input NAND cell, find the NAND3_X1 cell in the left-hand cell list, and then choose Display &gt; Show as New Top from the menu. We will learn more about layout and how this layout corresponds to a static CMOS circuit later in the course. The key point is that the layout for the standard cells are the basic building blocks that we will be using to create our ASIC chips.</p> <p>The Synopsys and Cadence tools do not actually use this layout directly; it is actually too detailed. Instead these tools use abstract views of the standard cells, which capture logical functionality, timing, geometry, and power usage at a much higher level. In the last section, we looked at Verilog and <code>.lib</code> views. The back-end flow takes as input the <code>.lib</code> view for logical timing information, but it also takes as input a <code>.lef</code> view which contains physical information about the standard cell. Let's look at the LEF for the 3-input NAND cell.</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells.lef\n</code></pre> <p>The <code>.lef</code> view includes information about the size of the standard cell, but also includes information about where every pin is physically located. You can use Klayout to view <code>.lef</code> files as well. Start Klayout like this:</p> <pre><code>% klayout ${ECE6745_STDCELLS}/stdcells.lef\n</code></pre> <p>Let's look at a 3-input NAND cell, find the NAND3_X1 cell in the left-hand cell list, and then choose Display &gt; Show as New Top from the menu. The <code>.lef</code> file does not contain any transistor-level information. It only contains information relevant to placement and routing.</p> <p>In addition to physical information about each standard cell, the back-end flow also needs to take as input general information about the technology. This information is contained in two files:</p> <pre><code>% less ${ECE6745_STDCELLS}/rtk-tech.lef\n% less ${ECE6745_STDCELLS}/rtk-typical.captable\n</code></pre> <p>The first provides information about the geometry and orientation of wires for each metal layer. The second provides information about the resistance and capacitance of each metal layer.</p> <p>Now that we have looked at the physical views of the standard cell library, we can now try using these views and the ASIC flow back-end to place and route a gate-level netlist.</p>"},{"location":"ece6745-sec02-asic-back-end/#2-revisiting-the-asic-flow-front-end","title":"2. Revisiting the ASIC Flow Front-End","text":"<p>As in the last section, we will be using the following four-stage registered incrementer as our example design:</p> <p></p> <p>Before we can place and route a gate-level netlist, we need to synthesize that netlist. This is what we learned about in the last section. Here are the steps to test and then synthesize the design using Synopsys DC.</p>"},{"location":"ece6745-sec02-asic-back-end/#21-test-simulate-translate","title":"2.1. Test, Simulate, Translate","text":"<p>Always run the tests before pushing anything through the ASIC flow. There is no sense in running the flow if the design is incorrect!</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr\n</code></pre> <p>You can run the simulator for our four-stage registered incrementer like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut3_verilog/regincr/regincr-sim -s 0xff 0x20 0x30 0x04 0x00\n% less RegIncr4stage__pickled.v\n</code></pre> <p>You should now have the Verilog that we want to push through the ASIC flow.</p>"},{"location":"ece6745-sec02-asic-back-end/#22-simulate-synthesize-simulate","title":"2.2. Simulate, Synthesize, Simulate","text":"<p>We have provided you run scripts that will reproduce the three key steps we learned about in the previous discussion section:</p> <ul> <li>Use Synopsys VCS for four-state RTL simulation</li> <li>Use Synopsys DC to synthesize RTL to gate-level netlist</li> <li>Use Synopsys VCS for fast-functional gate-level simulation</li> </ul> <p>Let's take a look at each script to confirm it matches the manual commands we used in the previous discussion section. Here is the run script for four-start RTL simulation.</p> <pre><code>% cd $TOPDIR/asic/build-regincr\n% cat ./01-synopsys-vcs-rtlsim/run\n</code></pre> <p>Here is the run script for synthesis.</p> <pre><code>% cd $TOPDIR/asic/build-regincr\n% cat ./02-synopsys-dc-synth/run\n</code></pre> <p>Notice that this script simply executes <code>dc_shell-xg-t</code> with a TCL script which contains the commands to: configure the standard cell library, analyze and elaborate the design; setup timing constraints; synthesize the design; write outputs; and write final outputs (i.e., Verilog and DDC) and reports (i.e., timing report and area report).</p> <pre><code>% cd $TOPDIR/asic/build-regincr\n% cat ./02-synopsys-dc-synth/run.tcl\n</code></pre> <p>Finally, here is the run script for fast-functional gate-level simulation. The key difference from four-state RTL simulation is that this simulation takes as input the Verilog for the standard-cell library and the Verilog for the post-synthesis gate-level netlist.</p> <pre><code>% cd $TOPDIR/asic/build-regincr\n% cat ./03-synopsys-vcs-ffglsim/run\n</code></pre> <p>You can run these steps as follows:</p> <pre><code>% cd $TOPDIR/asic/build-regincr\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% ./03-synopsys-vcs-ffglsim/run\n</code></pre> <p>Verify that your design passes four-state RTL simulation and fast-functional gate-level simulation. Then take a look at the synthesis reports.</p> <pre><code>% cd $TOPDIR/asic/build-regincr\n% less ./02-synopsys-dc-synth/area.rpt\n% less ./02-synopsys-dc-synth/timing.rpt\n</code></pre> <p>Finally, take a few minutes to examine the resulting Verilog gate-level netlist. Notice that the module hierarchy is preserved.</p> <pre><code>% cd $TOPDIR/asic/build-regincr\n% less ./02-synopsys-dc-synth/post-synth.v\n</code></pre> <p>This is the gate-level netlist that we now want to push through the ASIC back-end flow.</p>"},{"location":"ece6745-sec02-asic-back-end/#3-cadence-innovus-for-place-and-route","title":"3. Cadence Innovus for Place-and-Route","text":"<p>We will be running Cadence Innovus in a separate directory to keep the input and output files separate.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-regincr/04-cadence-innovus-pnr\n% cd $TOPDIR/asic/build-regincr/04-cadence-innovus-pnr\n</code></pre>"},{"location":"ece6745-sec02-asic-back-end/#31-constraint-and-timing-input-files","title":"3.1. Constraint and Timing Input Files","text":"<p>Before starting Cadence Innovus, we need to create two files which will be loaded into the tool. The first file is a <code>.sdc</code> file which contains timing constraint information about our design. This file is where we specify our target clock period, but it is also where we could specify input or output delay constraints (e.g., the output signals must be stable 200ps before the rising edge). Use VS Code to create a file named <code>constraints.sdc</code>.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/04-cadence-innovus-pnr\n% code constraints.sdc\n</code></pre> <p>The file should have the following constraint:</p> <pre><code>create_clock clk -name ideal_clock -period 1\n</code></pre> <p>The <code>create_clock</code> command is similar to the command we used in synthesis, and usually, we use the same target clock period that we used for synthesis. In this case, we are targeting a 1GHz clock frequency (i.e., a 1ns clock period).</p> <p>The second file is a \"multi-mode multi-corner\" (MMMC) analysis file. This file specifies what \"corner\" to use for our timing analysis. A corner is a characterization of the standard cell library and technology with specific assumptions about the process temperature, and voltage (PVT). So we might have a \"fast\" corner which assumes best-case process variability, low temperature, and high voltage, or we might have a \"slow\" corner which assumes worst-case variability, high temperature, and low voltage. To ensure our design worked across a range of operating conditions, we need to evaluate our design across a range of corners. In this course, we will keep things simple by only considering a \"typical\" corner (i.e., average PVT). Use VS Code to create a file named <code>setup-timing.tcl</code>.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/04-cadence-innovus-pnr\n% code setup-timing.tcl\n</code></pre> <p>The file should have the following content:</p> <pre><code>create_rc_corner -name typical \\\n   -cap_table \"$env(ECE6745_STDCELLS)/rtk-typical.captable\" \\\n   -T 25\n\ncreate_library_set -name libs_typical \\\n   -timing [list \"$env(ECE6745_STDCELLS)/stdcells.lib\"]\n\ncreate_delay_corner -name delay_default \\\n   -library_set libs_typical \\\n   -rc_corner typical\n\ncreate_constraint_mode -name constraints_default \\\n   -sdc_files [list constraints.sdc]\n\ncreate_analysis_view -name analysis_default \\\n   -constraint_mode constraints_default \\\n   -delay_corner delay_default\n\nset_analysis_view -setup analysis_default -hold  analysis_default\n</code></pre> <p>The <code>create_rc_corner</code> command loads in the <code>.captable</code> file that we examined earlier. This file includes information about the resistance and capacitance of every metal layer. Notice that we are loading in the \"typical\" captable and we are specifying an \"average\" operating temperature of 25 degC. The <code>create_library_set</code> command loads in the <code>.lib</code> file that we examined in the last section. This file includes information about the input/output capacitance of each pin in each standard cell along with the delay from every input to every output in the standard cell. The <code>create_delay_corner</code> specifies a specific corner that we would like to use for our timing analysis by putting together a <code>.captable</code> and a <code>.lib</code> file. In this specific example, we are creating a typical corner by putting together the typical <code>.captable</code> and typical <code>.lib</code> we just loaded. The <code>create_constraint_mode</code> command loads in the <code>.sdc</code> file we mentioned earlier in this section. The <code>create_analysis_view</code> command puts together constraints with a specific corner, and the <code>set_analysis_view</code> command tells Cadence Innovus that we would like to use this specific analysis view for both setup and hold time analysis.</p>"},{"location":"ece6745-sec02-asic-back-end/#32-initial-setup-and-floorplanning","title":"3.2. Initial Setup and Floorplanning","text":"<p>Now that we have created our <code>constraints.sdc</code> and <code>setup-timing.tcl</code> files we can start Cadence Innovus. Note that we are using the Cadence Innovus GUI so you will need to use Microsoft Remote Desktop.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/04-cadence-innovus-pnr\n% innovus\n</code></pre> <p>We can enter commands in the terminal and watch the effect of these commands on our design in the GUI. We need to set various variables before starting to work in Cadence Innovus. These variables tell Cadence Innovus the location of the MMMC file, the location of the Verilog gate-level netlist, the name of the top-level module in our design, the location of the <code>.lef</code> files, and finally the names of the power and ground nets.</p> <pre><code>innovus&gt; set init_mmmc_file \"setup-timing.tcl\"\ninnovus&gt; set init_verilog   \"../02-synopsys-dc-synth/post-synth.v\"\ninnovus&gt; set init_top_cell  \"RegIncr4stage\"\ninnovus&gt; set init_lef_file  \"$env(ECE6745_STDCELLS)/rtk-tech.lef $env(ECE6745_STDCELLS)/stdcells.lef\"\ninnovus&gt; set init_gnd_net   \"VSS\"\ninnovus&gt; set init_pwr_net   \"VDD\"\n</code></pre> <p>We can now use the <code>init_design</code> command to read in the verilog, set the design name, setup the timing analysis views, read the technology <code>.lef</code> for layer information, and read the standard cell <code>.lef</code> for physical information about each cell used in the design.</p> <pre><code>innovus&gt; init_design\n</code></pre> <p>We start by working on power planning which is the process of routing the power and ground signals across the chip. First, we use the <code>floorPlan</code> command to set the dimensions for our chip.</p> <pre><code>innovus&gt; floorPlan -su 1.0 0.70 4.0 4.0 4.0 4.0\n</code></pre> <p>In this example, we have chosen the aspect ration to be 1.0, the target cell utilization to be 0.7, and we have added 4.0um of margin around the top, bottom, left, and right of the chip. This margin gives us room for the power ring which will go around the entire chip.</p>"},{"location":"ece6745-sec02-asic-back-end/#33-placement","title":"3.3. Placement","text":"<p>The first step is to place all of the standard cells and perform a very preliminary routing using the <code>place_design</code> command:</p> <pre><code>innovus&gt; place_design\n</code></pre> <p>You should be able to see the standard cells placed in the rows along with preliminary routing to connect all of the standard cells together. You can toggle the visibility of metal layers by pressing the number keys on the keyboard. So try toggling the visibility of M1, M2, M3, etc. You can visualize how the modules in the original Verilog mapped to the place-and-routed design by using the Design Browser. Choose the Windows &gt; Workspaces &gt; Design Browser + Physical menu option. Then use the Design Browser to click on specific modules or nets to highlight them in the physical view.</p>"},{"location":"ece6745-sec02-asic-back-end/#34-power-routing","title":"3.4. Power Routing","text":"<p>Now we need to tell Cadence Innovus that <code>VDD</code> and <code>VSS</code> in the gate-level netlist correspond to the physical pins labeled <code>VDD</code> and <code>VSS</code> in the <code>.lef</code> files.</p> <pre><code>innovus&gt; globalNetConnect VDD -type pgpin -pin VDD -inst * -verbose\ninnovus&gt; globalNetConnect VSS -type pgpin -pin VSS -inst * -verbose\n</code></pre> <p>For this discussion section we will just draw M1 wires for the power and ground rails that go along each row of standard cells.</p> <pre><code>innovus&gt; sroute -nets {VDD VSS}\n</code></pre> <p>In a more realistic flow we would also create a power ring and connect the rows of standard cells to this power ring.</p>"},{"location":"ece6745-sec02-asic-back-end/#35-signal-routing","title":"3.5. Signal Routing","text":"<p>The <code>place_design</code> command will perform a very preliminary route to help ensure a good placement, but we will now use the <code>routeDesign</code> command to do a more detailed routing pass.</p> <pre><code>innovus&gt; routeDesign\n</code></pre> <p>Watch the physical view to see the result before and after running this command. You should be able to appreciate that the final result requires fewer and shorter wires.</p> <p>Now that our design is fully placed and routed, we can extract the parasitic resistance and capacitances to enable more accurate timing and power analysis.</p> <pre><code>innovus&gt; extractRC\n</code></pre>"},{"location":"ece6745-sec02-asic-back-end/#36-final-output-and-reports","title":"3.6. Final Output and Reports","text":"<p>The final step is to insert \"filler\" cells. Filler cells are essentially empty standard cells whose sole purpose is to connect the wells across each standard cell row.</p> <pre><code>innovus&gt; setFillerMode -core {FILLCELL_X4 FILLCELL_X2 FILLCELL_X1}\ninnovus&gt; addFiller\n</code></pre> <p>Now we are basically done! Obviously there are many more steps required before you can really tape out a chip. We would need to add a real power grid and an I/O ring to connect the chip to the package. We would need to do further verification and additional optimization.</p> <p>We can generate various artifacts. We might want to save the final gate-level netlist for the chip since Cadence Innovus will often insert new cells or change cells during its optimization passes.</p> <pre><code>innovus&gt; saveNetlist post-pnr.v\n</code></pre> <p>We can write parasitic information to a special <code>.spef</code> file and all of the delay information (including interconnect delays) to a <code>.sdf</code> file. These files can be used for later back-annotated gate-level simulation and/or power analysis.</p> <pre><code>innovus&gt; rcOut -rc_corner typical -spef post-pnr.spef\ninnovus&gt; write_sdf post-pnr.sdf\n</code></pre> <p>And of course the step is to generate the real layout as a <code>.gds</code> file. This is what we will send to the foundry when we are ready to tapeout the chip.</p> <pre><code>innovus&gt; streamOut post-pnr.gds \\\n  -merge \"$env(ECE6745_STDCELLS)/stdcells.gds\" \\\n  -mapFile \"$env(ECE6745_STDCELLS)/rtk-stream-out.map\"\n</code></pre> <p>We can also use Cadence Innovus to do timing and area analysis similar to what we did with Synopsys DC. These post-place-and-route results will be much more accurate than the preliminary post-synthesis results.</p> <pre><code>innovus&gt; report_timing -late  -path_type full_clock -net\ninnovus&gt; report_timing -early -path_type full_clock -net\ninnovus&gt; report_area\n</code></pre> <p>Finally, we go ahead and exit Cadence Innovus.</p> <pre><code>innovus&gt; exit\n</code></pre> <p>Open the final layout using Klayout.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/04-cadence-innovus-pnr\n% klayout -l ${ECE6745_STDCELLS}/klayout.lyp post-pnr.gds\n</code></pre> <p>Choose Display &gt; Full Hierarchy from the menu to display the entire design. Zoom in and out to see the individual transistors as well as the entire block.</p>"},{"location":"ece6745-sec02-asic-back-end/#4-synopsys-vcs-for-back-annotated-gate-level-simulation","title":"4. Synopsys VCS for Back-Annotated Gate-Level Simulation","text":"<p>As we learned in the last discussion section, good ASIC designers are always paranoid and never trust their tools. How do we know that the final post-place-and-route gate-level netlist is correct? Once again, we can rerun our test suite on the gate-level model. We can do this using Synopsys VCS for back-annotated gatel-level simulation. Back-annotated refers to the fact that this simulation will take into account all of the gate and interconnect delays. So this also helps build our confidence not just that the final gate-level netlist is functionally correct, but also that it meets all setup and hold time constraints. Here is how to run VCS for RTL simulation:</p> <pre><code>% mkdir -p $TOPDIR/asic/build-regincr/05-synopsys-vcs-baglsim\n% cd $TOPDIR/asic/build-regincr/05-synopsys-vcs-baglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +neg_tchk +sdfverbose \\\n    -sdf max:Top.DUT:../04-cadence-innovus-pnr/post-pnr.sdf \\\n    +define+CYCLE_TIME=1.000 \\\n    +define+VTB_INPUT_DELAY=0.025 \\\n    +define+VTB_OUTPUT_DELAY=0.025 \\\n    +define+VTB_DUMP_SAIF=waves.saif \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+$TOPDIR/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../04-cadence-innovus-pnr/post-pnr.v \\\n    ${TOPDIR}/sim/build/RegIncr4stage_basic_tb.v\n</code></pre> <p>You should see a <code>simv</code> binary which is the compiled RTL simulator which you can run like this:</p> <pre><code>% cd $TOPDIR/asic/build-regincr/05-synopsys-vcs-baglsim\n% ./simv\n</code></pre> <p>It should pass the test and also dump out an SAIF file which has the activity factors for every net in the design. We will use the SAIF file in power analysis. Now let's look at the resulting waveforms using Surfer.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/05-synopsys-vcs-baglsim\n% code waves.vcd\n</code></pre> <p>Browse the signal hierarchy and display all the waveforms for the DUT using these steps:</p> <ul> <li>Expand out the Scopes until you find the DUT module</li> <li>Select the clk, in, out signals</li> <li>Expand out the Scopes until you find the <code>gen[0].reg_incr.add</code> module</li> <li>Select all of the signals in this adder</li> </ul> <p>Zoom in and notice how the signals now change throughout the cycle. This is because the delay of every gate and wire is now modeled. Let's rerun the simulation, but this time let's use a very fast clock frequency (much faster than the 1ns clock constraint we used during synthesis and place-and-route).</p> <pre><code>% cd $TOPDIR/asic/build-regincr/05-synopsys-vcs-baglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +neg_tchk +sdfverbose \\\n    -sdf max:Top.DUT:../04-cadence-innovus-pnr/post-pnr.sdf \\\n    +define+CYCLE_TIME=0.300 \\\n    +define+VTB_INPUT_DELAY=0.025 \\\n    +define+VTB_OUTPUT_DELAY=0.025 \\\n    +vcs+dumpvars+waves-300ps.vcd \\\n    +incdir+$TOPDIR/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../04-cadence-innovus-pnr/post-pnr.v \\\n    ${TOPDIR}/sim/build/RegIncr4stage_basic_tb.v\n% ./simv\n</code></pre> <p>You should see timing violations and the test will fail. If you look at the resulting waveforms you can see that the adder does not have time to finish its calculation and cannot meet the setup time contraint.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/05-synopsys-vcs-baglsim\n% code waves-300ps.vcd\n</code></pre>"},{"location":"ece6745-sec02-asic-back-end/#5-synopsys-primetime-for-power-analysis","title":"5. Synopsys PrimeTime for Power Analysis","text":"<p>Synopsys PrimeTime (PT) is primarily used for very accurate \"sign-off\" static timing analysis (more accurate than the analysis performed by Synopsys DC and Cadence Innovus), but in this course, we will only use Synopsys PT for power analysis. There are many ways to perform power analysis. Synthesis and place-and-route power reports use statistical power analysis where we simply assume some toggle probability on each net. For more accurate power analysis, we need to find out the actual activity for every net for a given experiment; this is exactly what we figured out during back-annotated gate-level simulation.</p> <p>We start by creating a subdirectory for our work and then launching Synopsys PT.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-regincr/06-synopsys-pt-pwr\n% cd $TOPDIR/asic/build-regincr/06-synopsys-pt-pwr\n% pt_shell\n</code></pre> <p>We begin by setting the <code>target_library</code> and <code>link_library</code> variables as before.</p> <pre><code>pt_shell&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db\"\npt_shell&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db\"\n</code></pre> <p>Since Synopsys PT is primarily used for static timing analysis, we need to explicitly tell Synopsys PT that we want to use it for power analysis.</p> <pre><code>pt_shell&gt; set_app_var power_enable_analysis true\n</code></pre> <p>We now read in the gate-level netlist, tell Synopsys PT we want to do power analysis for the top-level module, and link the design (i.e., recursively resolve all of the module references starting from the top-level module).</p> <pre><code>pt_shell&gt; read_verilog   \"../04-cadence-innovus-pnr/post-pnr.v\"\npt_shell&gt; current_design RegIncr4stage\npt_shell&gt; link_design\n</code></pre> <p>In order to do power analysis, Synopsys PT needs to know the clock period. Here we will set the clock frequency to be the same as the initial clock constraint.</p> <pre><code>pt_shell&gt; create_clock clk -name ideal_clock1 -period 1\n</code></pre> <p>We now read in the SAIF file with the activity factors and the SPEF file with the parasitic cpacitances for every net in our design.</p> <pre><code>pt_shell&gt; read_saif \"../05-synopsys-vcs-baglsim/waves.saif\" -strip_path \"Top/DUT\"\npt_shell&gt; read_parasitics -format spef \"../04-cadence-innovus-pnr/post-pnr.spef\"\n</code></pre> <p>We now have everything we need to perform the power analysis: (1) the activity factor of a subset set of the nets, (2) the capacitance of every net/port, (3) the supply voltage, and (4) the clock frequency. We use the <code>update_power</code> command to propagate activity factors to unannotated nest and to estimate the power of our design.</p> <pre><code>pt_shell&gt; update_power\n</code></pre> <p>We can use the <code>report_power</code> command to show a high-level overview of how much power the sort unit consumes as well as how much each module in our design consumes.</p> <pre><code>pt_shell&gt; report_power\npt_shell&gt; report_power -hierarchy\n</code></pre> <p>Finally, we go ahead and exit Synopsys PT.</p> <pre><code>pt_shell&gt; exit\n</code></pre>"},{"location":"ece6745-sec03-asic-auto/","title":"ECE 6745 Section 3: ASIC Automated Flow","text":"<p>In the previous sections, we manually commands entering commands for each tool to take a design from RTL to layout. Flow scripts can help automate the process but copying and modifying these flow scripts for every design is tedious and error prone. An agile hardware design flow demands automation to simplify rapidly exploring the area, energy, timing design space of one or more designs. In this section, we will introduce a simple tool called pyhflow which takes as input a step templates and a design YAML and generates appropriate flow scripts.</p> <p>The following diagram illustrates the five primary tools we have already seen in the previous discussion sections. Notice that the ASIC tools all require various views from the standard-cell library.</p> <p></p> <p>Extensive documentation is provided by Synopsys and Cadence for these ASIC tools. We have organized this documentation and made it available to you on the public course webpage:</p> <ul> <li>https://www.csl.cornell.edu/courses/ece6745/asicdocs</li> </ul> <p>The first step is to access <code>ecelinux</code>. Use Microsoft Remote Desktop to log into a specific <code>ecelinux</code> server. Then use VS Code to log into the same specific <code>ecelinux</code> server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-sec03-asic-auto sec03\n% cd sec03\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-sec03-asic-auto/#1-testing-simulation-and-translation","title":"1. Testing, Simulation, and Translation","text":"<p>As in the last section, we will be using the following four-stage registered incrementer as our example design:</p> <p></p> <p>Before we can use the ASIC flow, we need to verify the design and generate the corresponding Verilog files for each test which can be used for RTL simulation, fast-functional gate-level simulation, and back-annotated gate-level simulation. Always run the tests before pushing anything through the ASIC flow. There is no sense in running the flow if the design is incorrect!</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr  --test-verilog --dump-vtb\n</code></pre> <p>You can run the interactive simulator for our four-stage registered incrementer like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut3_verilog/regincr/regincr-sim 0xff 0x20 0x30 0x04 0x00\n% less RegIncrNstage__p_nstages_4__pickled.v\n</code></pre> <p>You should now have the Verilog that we want to push through the ASIC flow.</p>"},{"location":"ece6745-sec03-asic-auto/#2-pyhflow-for-generating-flows","title":"2. pyhflow For Generating Flows","text":"<p>pyflow is based on the idea of step templates which are located in the <code>asic/steps</code> directory.</p> <pre><code>% cd $TOPDIR/asic/steps\n% tree\n.\n\u251c\u2500\u2500 01-synopsys-vcs-rtlsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 02-synopsys-dc-synth\n\u2502   \u251c\u2500\u2500 run\n\u2502   \u2514\u2500\u2500 run.tcl\n\u251c\u2500\u2500 03-synopsys-vcs-ffglsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 04-cadence-innovus-pnr\n\u2502   \u251c\u2500\u2500 run\n\u2502   \u251c\u2500\u2500 run.tcl\n\u2502   \u2514\u2500\u2500 setup-timing.tcl\n\u251c\u2500\u2500 05-synopsys-vcs-baglsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 06-synopsys-pt-pwr\n\u2502   \u251c\u2500\u2500 run\n\u2502   \u2514\u2500\u2500 run.tcl\n\u2514\u2500\u2500 07-summarize-results\n    \u251c\u2500\u2500 run\n    \u2514\u2500\u2500 summarize-results\n</code></pre> <p>Each step is a directory with a run script and possibly other scripts. The key difference from the scripts we used in the previous tutorials, is that these scripts are templated using the Jinja2 templating system:</p> <ul> <li>https://jinja.palletsprojects.com</li> </ul> <p>Open the <code>run.tcl</code> script in the <code>02-synopsys-dc-synth</code> step template which uses Synopsys DC for synthesis.</p> <pre><code>% cd $TOPDIR/asic/steps/02-synopsys-dc-synth\n% code run.tcl\n</code></pre> <p>Notice how the <code>run.tcl</code> script is templated based on the design name and the target clock period.</p> <pre><code>analyze -format sverilog $env(TOPDIR)/sim/build/{{design_name}}__pickled.v\nelaborate {{design_name}}\n\ncreate_clock clk -name ideal_clock1 -period {{clock_period}}\n</code></pre> <p>The <code>{{ }}</code> directive is the standard syntax for template variable substitution using Jinja2.</p> <p>The pyhflow program takes as input a design YAML file which specifies:</p> <ul> <li>what steps make up the flow</li> <li>key/value pairs for variables to substitute into scripts</li> <li>list of tests</li> <li>list of evals</li> </ul> <p>Take a look at the provided design YAML file for the registered incrementer.</p> <pre><code>% cd $TOPDIR/asic/designs\n% cat sec03-regincr.yml\n\nsteps:\n - 01-synopsys-vcs-rtlsim\n - 02-synopsys-dc-synth\n - 03-synopsys-vcs-ffglsim\n - 04-cadence-innovus-pnr\n - 05-synopsys-vcs-baglsim\n - 06-synopsys-pt-pwr\n - 07-summarize-results\n\nsrc_dir      : ../../../sim/build\ndesign_name  : RegIncrNstage__p_nstages_4\nclock_period : 1.0\ndump_vcd     : true\n\ntests:\n - RegIncrNstage__p_nstages_4_test_4stage_large\n - RegIncrNstage__p_nstages_4_test_4stage_overflow\n - RegIncrNstage__p_nstages_4_test_4stage_random\n - RegIncrNstage__p_nstages_4_test_4stage_small\n\nevals:\n - RegIncrNstage__p_nstages_4_regincr-sim-basic\n</code></pre> <p>This design YAML file specifies the generated flow should use all seven steps. We run RTL sim, FFGL sim, and BAGL sim on all tests and evals, but we only do energy analysis on the evals. The evals usually come from running an interactive simulator like <code>regincr-sim</code>. All pyhflow does is use the YAML file to figure out what to substitute into the templated steps and then copy the run scripts into the current working directory. You can also override parameters on pyhflow command line.</p>"},{"location":"ece6745-sec03-asic-auto/#11-running-asic-flow-with-one-test","title":"1.1. Running ASIC Flow with One Test","text":"<p>Let's go ahead and use pyhflow to generate the flow scripts for the registered incrementer.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sec03-regincr\n% cd $TOPDIR/asic/build-sec03-regincr\n% pyhflow --one-test ../designs/sec03-regincr.yml\n</code></pre> <p>The <code>--one-test</code> command line option tells pyhflow to only include the first test and no evals in the flow scripts. This is a useful way to get started with a single test and reduces the overall runtime of the flow. Once we know that everything works with one test we can circle back and regenerate the flow scripts with all of the tests and evals.</p> <p>Let's see how the step template has been filled in for the Synopsys DC synthesis step.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% cat 02-synopsys-dc-synth/run.tcl\n...\nanalyze -format sverilog $env(TOPDIR)/sim/build/RegIncrNstage__p_nstages_4__pickled.v\nelaborate RegIncrNstage__p_nstages_4\ncreate_clock clk -name ideal_clock1 -period 1.0\n</code></pre> <p>Notice how the name of the source Verilog RTL File, the top-level modulename, and the clock period have all been filled in.</p> <p>After generating a flow, we always recommend explicitly running at least the first two steps to ensure there are no errors. You can run the four-state RTL simulation as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% ./01-synopsys-vcs-rtlsim/run\n</code></pre> <p>Make sure the step can find the source files and passes the test. Then run synthesis as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% ./02-synopsys-dc-synth/run\n</code></pre> <p>Carefully look at the output from the synthesis step (also stored in the <code>run.log</code> file). Look for the output after <code>Running PRESTO HDLC</code> for any warnings to ensure that all of your Verilog RTL is indeed synthesizable. Scan through the rest of the logs to ensure there are no worrying warnings or errors.</p> <p>Once you have explicitly run the first two steps to ensure there are no errors, you can run the remaning steps.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% 03-synopsys-vcs-ffglsim\n% 04-cadence-innovus-pnr\n% 05-synopsys-vcs-baglsim\n% 06-synopsys-pt-pwr\n% 07-summarize-results\n</code></pre> <p>If all looks good, then you would regenerate the with all of the tests and evals; however, we will stick to just running one test though to save time in this discussion section. pyhflow will also create a <code>run-flow</code> script which will run all of the steps in sequence for you, but only use this if you are confident there are no errors!</p> <p>For the results to be valid, the following must be true:</p> <ul> <li>all four-state RTL simulations pass</li> <li>all fast-functional gate-level simulations pass</li> <li>all back-annotated gate-level simulations pass</li> <li>place-and-route setup slack is positive</li> <li>place-and-route hold slack is positive</li> </ul> <p>If your design does not meet timing after synthesis but does meet timing after place-and-route then these are still valid results. It just means Synopsys DC was conservative and/or Cadence Innovus did a good job further optimizing the design.</p>"},{"location":"ece6745-sec03-asic-auto/#13-interactive-debugging","title":"1.3. Interactive Debugging","text":"<p>Let's start Cadence Innovus in interactive mode and then load the design.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% innovus\ninnovus&gt; source 04-cadence-innovus-pnr/post-pnr.enc\n</code></pre> <p>You can use Cadence Innovus to analyze the static timing of any path in the design. For example, let's look at the static timing for a path in the first stage:</p> <pre><code>innovus&gt; report_timing -path_type full_clock -net \\\n  -from v/gen[0].reg_incr/reg_out_reg[0] \\\n  -to v/gen[1].reg_incr/reg_out_reg[0]\n</code></pre> <p>You can use the Amobea workspace to help visualize how modules are mapped across the chip. Choose Windows &gt; Workspaces &gt; Amoeba from the menu. However, we recommend using the design browser to help visualize how modules are mapped across the chip. Here are the steps:</p> <ul> <li>Choose Windows &gt; Workspaces &gt; Design Browser + Physical from the menu</li> <li>Hide all of the metal layers by pressing the number keys</li> <li>Browse the design hierarchy using the panel on the left</li> <li>Right click on a module, click Highlight, select a color</li> </ul> <p>Go ahead and highlight each stage in a different color.</p> <p>You can use the following steps in Cadence Innovus to display where the critical path is on the actual chip.</p> <ul> <li>Choose Timing &gt; Debug Timing from the menu</li> <li>Click OK in the pop-up window</li> <li>Right click on first path in the Path List</li> <li>Choose Highlight &gt; Only This Path &gt; Color</li> </ul> <p>Finally, you can use Klayout to capture a screen shot demonstrating that you have successfully taken a design from RTL to layout.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% klayout -l $ECE6745_STDCELLS/klayout.lyp 04-cadence-innovus-pnr/post-pnr.gds\n</code></pre> <p>You can use Display &gt; Full Hierarchy to show all of the layout including the layout inside the standard cells. You can use Display &gt; Decrement Hierarchy and Display &gt; Decrement Hierarchy to show/hide the layout inside the standard cells to focus on the routing. Consider hiding M7, VIA7, M8, VIA8, and M9 to just show the clock and signal routing. Try toggling View &gt; Show Cell Frames to show/hide the standard cell bounding boxes.</p>"},{"location":"ece6745-sec03-asic-auto/#15-key-reports","title":"1.5. Key Reports","text":"<p>Let's look at some reports. Let's start by looking at the synthesis resources report.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% cat 02-synopsys-dc-synth/resources.rpt\n...\n===============================================================================\n|                    |                  | Current            | Set            |\n| Cell               | Module           | Implementation     | Implementation |\n===============================================================================\n| add_x_1            | DW01_inc         | apparch (area)     |                |\n===============================================================================\n</code></pre> <p>This means that Synopsys DC is using a DesignWare module named <code>DW01_inc</code>. You can read the datasheet here:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/asicdocs/dwbb_datasheets</li> </ul> <p>Notice that DesignWare provides four different microarchitectures: a ripple-carry adder, a carry-look-ahead adder, a delay optimized parallel-prefix adder, and an area-optimized parallel-prefix adder. Synopsys DC has chosen to use the area-optimized parallel-prefix adder in this case.</p> <p>Now let's look at the place-and-route setup and hold time reports.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% cat 04-cadence-innovus-pnr/timing-setup.rpt\n% cat 04-cadence-innovus-pnr/timing-hold.rpt\n</code></pre> <p>We can also look at the detailed area report.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% cat 04-cadence-innovus-pnr/area.rpt\n</code></pre>"},{"location":"ece6745-sec03-asic-auto/#3-case-studies","title":"3. Case Studies","text":"<p>Now that we know how to push a design through the automated flow, let's consider two different case studies: (1) decreasing the clock period constraint; and (2) flattening the design.</p>"},{"location":"ece6745-sec03-asic-auto/#31-decreasing-the-clock-period-constraint","title":"3.1. Decreasing the Clock Period Constraint","text":"<p>We can use pyhflow to regenerate the flow with a different clock period by either: (1) changing the design YAML file (i.e., <code>sec03-regincr.yml</code>); or (2) specifying the clock period on the pyflow command line. Let's use the second approach. If you look at the setup timing report you will see with a 1ns clock period you have maybe 550ps of positive slack. So a good starting point would be to maybe try a clock period of 1ns - 550ps = 450ps. Let's try 400ps.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sec03-regincr-decrease-clk\n% cd $TOPDIR/asic/build-sec03-regincr-decrease-clk\n% pyhflow --one-test --clock_period=0.400 ../designs/sec03-regincr.yml\n% ./run-flow\n</code></pre> <p>Notice how we are working in a new build directory. You can use multiple build directories to build different blocks through the flow and/or for design-space exploration. Also notice how we are using <code>--one-test</code> so we can quickly experiment with pushing the design through the flow with a single test and no evals. You could continue to decrease the clock period in 100ps increments until the design no longer meets timing, but for now we will just stick with the shorter 400ps clock period. Do not be too zealous and push the tools to try and meet a clock period constraint that is way too small! This can cause the tools to freak out and run forever.</p> <p>Now compare the results from the longer and shorter clock periods. Start by looking at the summary statistics. How does the number of standard cells and area compare? We can also look at what kind of adder implementation Synopsys DC chose to meet the shorter clock period constraint.</p> <pre><code>% cd $TOPDIR/asic\n% cat build-sec03-regincr/02-synopsys-dc-synth/resources.rpt\n% cat build-sec03-regincr-decrease-clk/02-synopsys-dc-synth/resources.rpt\n</code></pre> <p>Here we can see Synopsys DC has chosen to use a different version of the parallel-prefix adder which is now optimized for both area and speed.</p> <p>We can also look compare the critical path; you should be able to see that the design with the shorter clock period has many fewer levels of logic on the critical path.</p> <pre><code>% cd $TOPDIR/asic\n% cat build-sec03-regincr/04-cadence-innovus-pnr/timing-setup.rpt\n% cat build-sec03-regincr-decrease-clk/04-cadence-innovus-pnr/timing-setup.rpt\n</code></pre>"},{"location":"ece6745-sec03-asic-auto/#31-flattening-the-design","title":"3.1. Flattening the Design","text":"<p>Let's modify our scripts to flatten our design and see how this impacts various metrics. We can run pyhflow to instantiate the flow scripts and then modify these flow scripts in the build directory. Use the shortest clock period that still meets timing from the previous case study.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sec03-regincr-flatten\n% cd $TOPDIR/asic/build-sec03-regincr-flatten\n% pyhflow --one-test --clock_period=0.400 ../designs/sec03-regincr.yml\n% code 02-synopsys-dc-synth/run.tcl\n</code></pre> <p>Where <code>XX</code> is the shortest clock period which meets timing. We are currently using the following command in <code>02-synopsys-dc-synth/run.tcl</code> to synthesize our design.</p> <pre><code>compile_ultra -no_autoungroup -gate_clock\n</code></pre> <p>Change this by removing <code>-no_autoungroup</code>.</p> <pre><code>compile_ultra -gate_clock\n</code></pre> <p>Now run the flow.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr-flatten\n% ./run-flow\n</code></pre> <p>Revisit the post-synthesis gate-level netlist without flattening.</p> <pre><code>% cd $TOPDIR/asic\n% less build-sec03-regincr-decrease-clk/02-synopsys-dc-synth/post-synth.v\n</code></pre> <p>Notice how the original gate-level netlist preserves the logical hierarchy. Now look at the post-synthesis gate-level netlist with flattening.</p> <pre><code>% cd $TOPDIR/asic\n% less build-sec03-regincr-flatten/02-synopsys-dc-synth/post-synth.v\n</code></pre> <p>Now notice who all of the logical hierarchy is gone and all of the gates are in a single \"flat\" module. Compare the area without and with flattening.</p> <pre><code>% cd $TOPDIR/asic\n% cat build-sec03-regincr-decrease-clk/04-cadence-innovus-pnr/area.rpt\n% cat build-sec03-regincr-flatten/04-cadence-innovus-pnr/area.rpt\n</code></pre> <p>Because the flattened module lacks logical hierarchy we cannot see the hierarchical breakdown. The advantage of flattening is that it can improve the area and also potentially enable a shorter clock period, but the disadvantage is that it significantly complicates our ability to deeply understand the area, energy, and timing of our designs and thus effectively explore an entire design space. So we will primarily turn off flattening in this course.</p> <p>Note that if we wanted to make it easier to experiment with flattening, we could modify the synthesis step template like this:</p> <pre><code>{% if flatten is defined and flatten %}\ncompile_ultra -gate_clock\n{% else %}\ncompile_ultra -no_autoungroup -gate_clock\n{% endif %}\n</code></pre> <p>Then in your design YAML file you can add this to control whether flattening is turned on or off; or we can specify the value of the flatten parameter as a pyhflow command line option (i.e., with <code>--flatten=true</code>).</p> <pre><code>flatten : true\n</code></pre> <p>Students should feel free to modify the step templates and/or the design YAML files for their labs and/or projects to experiment with the ASIC flow.</p>"},{"location":"ece6745-sec04-xcel-rtl/","title":"ECE 6745 Section 4: TinyRV2 Accelerator RTL Design","text":"<p>In this section, we will be discussing how to implement a simple medium-grain accelerator. Fine-grain accelerators are tightly integrated within the processor pipeline (e.g., a specialized functional unit for bit-reversed addressing useful in implementing an FFT), while coarse-grain accelerators are loosely integrated with a processor through the memory hierarchy (e.g., a graphics rendering accelerator sharing the last-level cache with a general-purpose processor). Medium-grain accelerators are often integrated as co-processors: the processor can directly send/receive messages to/from the accelerator with special instructions, but the co-processor is relatively decoupled from the main processor pipeline and can also independently interact with memory. To illustrate how to implement a medium-grain accelerator, we will be working on a simple \"accumulation\" accelerator that adds all of the values in an array stored in memory. More detailed tutorials for a vector-vector-add accelerator including how to push a complete processor, memory, and accelerator system will be posted on the public course website shortly.</p> <p>The first step is to access <code>ecelinux</code>. Use Microsoft Remote Desktop to log into a specific <code>ecelinux</code> server. Then use VS Code to log into the same specific <code>ecelinux</code> server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-sec04-xcel-rtl sec04\n% cd sec04\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-sec04-xcel-rtl/#1-baseline-tinyrv2-processor-fl-and-rtl-models","title":"1. Baseline TinyRV2 Processor FL and RTL Models","text":"<p>The following figure illustrates the overall system we will be using with our TinyRV2 processors. The processor includes eight latency insensitive val/rdy interfaces. The mngr2proc/proc2mngr interfaces are used for the test harness to send data to the processor and for the processor to send data back to the test harness. The imem master/minion interface is used for instruction fetch, and the dmem master/minion interface is used for implementing load/store instructions. The system includes both instruction and data caches. The xcel master/minion interface is used for the processor to send messages to the accelerator. The cache is not ported to work with the ASIC flow so it is not currently included!</p> <p></p> <p>We provide two implementations of the TinyRV2 processor. The FL model in <code>sim/proc/ProcFL.py</code> is essentially an instruction-set-architecture (ISA) simulator; it simulates only the instruction semantics and makes no attempt to model any timing behavior. The RTL model in <code>sim/proc/ProcVRTL.v</code> is similar to the alternative design for lab 2 in ECE 4750. It is a five-stage pipelined processor that implements the TinyRV2 instruction set and includes full bypassing/forwarding to resolve data hazards. There are two important differences from the alternative design for lab 2 of ECE 4750. First, the new processor design uses a single-cycle integer multiplier. Second, the new processor design includes the ability to handle new CSRs for interacting with medium-grain accelerators. The datapath diagram for the processor is shown below.</p> <p></p> <p>We should run all of the unit tests on both the FL and RTL processor models to verify that we are starting with a working processor.</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../proc\n</code></pre>"},{"location":"ece6745-sec04-xcel-rtl/#2-cross-compiling-and-executing-tinyrv2-microbenchmarks","title":"2. Cross-Compiling and Executing TinyRV2 Microbenchmarks","text":"<p>We will write our microbenchmarks in C. Let's start by writing a simple accumulation microbenchmark. Take a look at the code provided in <code>app/ubmark/ubmark-accum.c</code>:</p> <pre><code>__attribute__ ((noinline))\nint accum_scalar( int* src, int size )\n{\n  // ''' SECTION TASK ''''''''''''''''''''''''''''''''''''''''''''''''\n  // Implement a simple C function to add all of the elements in the\n  // source array and then return this result.\n  // '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n}\n</code></pre> <p>Go ahead and implement the <code>accum_scalar</code> function. We will a use microbenchmark test to verify the functionality of our microbenchmark and a microbenchmark eval to evaluate the performance of our microbenchmark. We will run both the microbenchmark test and eval on both FL and RTL TinyRV2 processor models.</p>"},{"location":"ece6745-sec04-xcel-rtl/#21-tinyrv2-microbenchmark-test","title":"2.1. TinyRV2 Microbenchmark Test","text":"<p>Let's go ahead and take a look at the microbenchmark test provided for the accumulation microbenchmark.</p> <pre><code>% cd $TOPDIR/app/ubmark\n% less ubmark-accum-test.c\n</code></pre> <p>Notice how we have various test case functions and then we call these test case functions in <code>main</code>. We have a build system that can compile microbenchmarks tests and evalutions natively for x86 and can also cross-compile these microbenchmarks for TinyRV2 so they can be executed on our simulators. Here is how we compile and execute the tests for the pure-software accumulation microbenchmark natively:</p> <pre><code>% cd $TOPDIR/app\n% mkdir build-native\n% cd build-native\n% ../configure\n% make ubmark-accum-test\n% ./ubmark-accum-test\n</code></pre> <p>You can run a single test case like this:</p> <pre><code>% cd $TOPDIR/app/build-native\n% ./ubmark-accum-test 1\n</code></pre> <p>Once we are confident the microbenchmark test passes on natively, we can cross-compile the microbenchmark test and run it on both FL and RTL TinyRV2 processor models. Let's start by cross-compiling the microbenchmark test.</p> <pre><code>% mkdir -p $TOPDIR/app/build\n% cd $TOPDIR/app/build\n% ../configure --host=riscv32-unknown-elf\n% make ubmark-accum-test\n</code></pre> <p>This will create a <code>ubmark-accum-test</code> binaries which contains TinyRV2 instructions and data. You can disassemble a TinyRV2 binary (i.e., turn a compiled binary back into an assembly text representation) with the <code>riscv32-objdump</code> command like this:</p> <pre><code>% cd $TOPDIR/app/build\n% riscv32-objdump ubmark-accum-test | less -p\"&lt;ubmark_accum&gt;:\"\n</code></pre> <p>Take a look at the <code>ubmark_accum</code> function in the disassembly and see if you can understand how this assembly implements the C function you wrote.</p> <p>We have provided you with a simulator that composes a processor, memory, and accelerator and is capable of executing TinyRV2 binaries. The simulator enables flexibly choosing the processor implementation (FL vs. RTL) and the type and implementation of the accelerator. By default, the simulator uses the processor FL model and a \"null\" accelerator. So let\u2019s execute both TinyRV2 binaries on the instruction-set simulator:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim ./ubmark-accum-test\n</code></pre> <p>The <code>--trace</code> command line option will display each instruction as it is executed on the ISA simulator.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --trace ./ubmark-accum-test &gt; ubmark-accum-test-fl.trace\n% code ubmark-accum-test-fl.trace\n</code></pre> <p>Now that we have verified the microbenchmark works correctly on the ISA simulator, we can run the test on the baseline TinyRV2 pipelined processor RTL model:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl ./ubmark-accum-test\n</code></pre> <p>The simulation should show all tests are passing.</p>"},{"location":"ece6745-sec04-xcel-rtl/#22-tinyrv2-microbenchmark-eval","title":"2.2. TinyRV2 Microbenchmark Eval","text":"<p>Once we are sure the microbenchmark test is working natively, on the FL simulator, and the RTL simulator, we can then turn our focus to the microbenchmark eval.</p> <pre><code>% cd $TOPDIR/app/ubmark\n% less ubmark-accum-eval.c\n</code></pre> <p>The <code>eval_src</code> and <code>eval_ref</code> arrays are all defined in the <code>app/ubmark/ubmark-accum.dat</code> file. The microbenchmark turns stats on, does the actual computation, turns stats off, and finally verifies that the results are as expected. We need the <code>ece6745_stats_on()</code> and <code>ece6745_stats_off()</code> functions to make sure we can keep track of various statistics (e.g., the number of cycles) only during the important part of the microbenchmark. We do not want to count time spent in initialization or verification when comparing the performance of our various microbenchmarks. These two functions are defined in <code>app/ece6745/ece6745-misc.h</code>.</p> <p>Here is how we can compile and execute the evaluation for the accumulation microbenchmark eval natively:</p> <pre><code>% cd $TOPDIR/app/build-native\n% make ubmark-accum-eval\n% ./ubmark-accum-eval\n</code></pre> <p>The microbenchmark should display passed. Once you are sure your microbenchmark eval is working correctly natively, you can cross-compile the microbenchmark eval for TinyRV2 and run it on the FL simulator.</p> <pre><code>% cd $TOPDIR/app/build\n% make ubmark-accum-eval\n% ../../sim/pmx/pmx-sim ./ubmark-accum-eval\n</code></pre> <p>Finally we can run the microbenchmark eval on the baseline TinyRV2 pipelined processor RTL model:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --stats ./ubmark-accum-eval\nnum_cycles = 613\n</code></pre> <p>The number of cycles for your experiment might be difference since you have written your own accumulation microbenchmark. Now generate a line trace to dig into the performance:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --trace \\\n    ./ubmark-accum-eval &gt; ubmark-accum-eval-rtl.trace\n</code></pre> <p>The instructor will walk through and explain the line trace.</p>"},{"location":"ece6745-sec04-xcel-rtl/#3-accumulation-accelerator-fl-and-rtl-models","title":"3. Accumulation Accelerator FL and RTL Models","text":"<p>We will take an incremental approach when designing, implementing, testing, and evaluating accelerators. We can use test sources, sinks, and memories to create a test harness that will enable us to explore the accelerator cycle-level performance and the ASIC area, energy, and timing in isolation. Only after we are sure that we have a reasonable design-point should we consider integrating the accelerator with the processor.</p> <p>We have provided you a FL model of the accumulation accelerator. Our accelerators will include a set of accelerator registers that can be read and written from the processor using special instructions and the xcelreq/xcelresp interface. The accumulator accelerator protocol defines the accelerator registers as follows:</p> <ul> <li>xr0 : go/done</li> <li>xr1 : base address of the array src</li> <li>xr2 : size of the array</li> </ul> <p>The actual protocol involves the following steps:</p> <ol> <li>Write the base address of src to xr1</li> <li>Write the number of elements in the array to xr2</li> <li>Tell accelerator to go by writing xr0</li> <li>Wait for accelerator to finish by reading xr0, result will be sum</li> </ol> <p>You can test this model like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut9_xcel/test/AccumXcelFL_test.py -v\n</code></pre> <p>We are now going to work on the accumulation accelerator RTL model. Our accelerator will use the following FSM:</p> <p></p> <p>While the accelerator is in the XCFG state, it will update its internal registers when it receives accelerator requests from the processor. When the accelerator receives a write to xr0 it moves into the M_RD state. In the M_RD state, the accelerator will send out one memory read request to read the current element from the source array. In the CALC state, the accelerator will wait for the response from memory and then do the actual accumulation. It then will either move back into the M_RD state if there is another element to be processed, or move into the XCFG state if we have processed all elements in the array.</p> <p>Open the accumulation accelerator RTL which is in <code>sim/tut9_xcel/AccumXcel.v</code> and take a look.</p> <pre><code>% cd $TOPDIR/sim/tut9_xcel\n% code AccumXcel.v\n</code></pre> <p>You can test the accelerator like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut9_xcel\n</code></pre> <p>We have also included a simulator for just the accumulation accelerator in isolation which can be used to evaluate its performance.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut9_xcel/accum-xcel-sim --impl rtl --input multiple --stats\nnum_cycles = 810\n</code></pre> <p>We could use the simulator to help evaluate the cycle-level performance of the accelerator on various different datasets as we try out various optimizations.</p>"},{"location":"ece6745-sec04-xcel-rtl/#4-accelerating-a-tinyrv2-microbenchmark","title":"4. Accelerating a TinyRV2 Microbenchmark","text":"<p>Now that we have unit tested and evaluated both the baseline TinyRV2 pipelined processor and the accumulation accelerator in isolation, we are finally ready to compose them. The processor will send messages to the accelerator by reading and writing 32 special CSRs using the standard CSRW and CSRR instructions. These 32 special CSRs are as follows:</p> <pre><code>0x7e0 : accelerator register  0 (xr0)\n0x7e1 : accelerator register  1 (xr1)\n0x7e2 : accelerator register  2 (xr2)\n...\n0x7ff : accelerator register 31 (xr31)\n</code></pre> <p>Here is a simple assembly sequence which will write the value 1 to an accelerator register, read that value back from the accelerator register, and write the value to general-purpose register x2.</p> <pre><code>addi x1, x0, 1\ncsrw 0x7e0, x1\ncsrr x2, 0x7e0\n</code></pre> <p>To use an accelerator from a C microbenchmark, we need to embed assembly instructions directly into a C program. We can do this using the GCC inline assembly extensions. Take a closer look at the accelerated version of the accumulation microbenchmark in <code>app/ubmark/ubmark-accum-xcel.c:</code></p> <pre><code>__attribute__ ((noinline))\nint accum_xcel( int* src, int size )\n{\n  int result = 0;\n\n  asm volatile (\n    \"csrw 0x7e1, %[src]; \\n\"\n    \"csrw 0x7e2, %[size];\\n\"\n    \"csrw 0x7e0, x0     ;\\n\"\n    \"csrr %[result], 0x7e0;\\n\"\n\n    // Outputs from the inline assembly block\n\n    : [result] \"=r\"(result)\n\n    // Inputs to the inline assembly block\n\n    : [src]    \"r\"(src),\n      [size]   \"r\"(size)\n\n    // Tell the compiler this accelerator read/writes memory\n\n    : \"memory\"\n  );\n\n  return result;\n}\n</code></pre> <p>The <code>asm</code> keyword enables embedding assembly into a C program. We have a sequence of strings, and each string is one assembly instruction. <code>%[src]</code> is special syntax that tells GCC to put the register that holds the <code>src</code> C variable into that location in the assembly. So if the compiler ends up allocating the <code>src</code> C variable to <code>x11</code> then it will put <code>x11</code> into the first assembly instruction.</p> <p>Let's compile and test our microbenchmark test and evaluation. Note that you cannot natively compile a microbenchmark that makes use of an accelerator, since x86 does not have any accelerators!</p> <pre><code>% cd $TOPDIR/app/build\n% make ubmark-accum-xcel-test\n% make ubmark-accum-xcel-eval\n% ../../sim/pmx/pmx-sim --xcel-impl accum-fl ./ubmark-accum-xcel-test\n% ../../sim/pmx/pmx-sim --xcel-impl accum-fl ./ubmark-accum-xcel-eval\n</code></pre> <p>Everything looks as expected, so we can now run our accelerated accumulation microbenchmark on the RTL implementation.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --xcel-impl accum-rtl ./ubmark-accum-xcel-test\n% ../../sim/pmx/pmx-sim --proc-impl rtl --xcel-impl accum-rtl \\\n    --stats ./ubmark-accum-xcel-eval\nnum_cycles = 314\n</code></pre> <p>Recall that the pure-software accumulation microbenchmark required 613 cycles. So our accelerator results in a cycle-level speedup of 2x. We might ask, where did this speedup come from? Why isn\u2019t the speedup larger? Let\u2019s look at the line trace.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --xcel-impl accum-rtl \\\n    --trace ./ubmark-accum-xcel-eval &gt; trace-alt.txt\n</code></pre> <p>See if you can figure out exactly what the accelerator is doing. Ideally, the accelerator would be able to sustain one accumulation per cycle for full throughput. Why is it not able to do this? What could we do to further improve the performance of this accelerator?</p>"},{"location":"ece6745-sec05-sram/","title":"ECE 6745 Section 5: SRAM Generators","text":"<p>In this section, we will be learning about SRAM generators. Small memories can be easily synthesized using flip-flop or latch standard cells, but synthesizing large memories can significantly impact the area, energy, and timing of the overall design. ASIC designers often use SRAM generators to \"generate\" arrays of memory bitcells and the corresponding peripheral circuitry (e.g., address decoders, bitline drivers, sense amps) which are combined into what is called an \"SRAM macro\". These SRAM generators are parameterized to enable generating a wide range of SRAM macros with different numbers of rows, columns, and column muxes, as well as optional support for partial writes, built-in self-test, and error correction. Similar to a standard-cell library, an SRAM generator must generate not just layout but also all of the necessary views to capture logical functionality, timing, geometry, and power usage. These views can then by used by the ASIC tools to produce a complete design which includes a mix of both standard cells and SRAM macros. We will first see how to use the open-source OpenRAM memory generator to generate various views of an SRAM macro. Then we will see how to use SRAMs in our RTL designs. Finally, we will put the these two pieces together to combine synthesizable RTL with SRAM macros and push the composition through the ASIC toolflow.</p> <p>The first step is to access <code>ecelinux</code>. Use Microsoft Remote Desktop to log into a specific <code>ecelinux</code> server. Then use VS Code to log into the same specific <code>ecelinux</code> server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-sec05-sram sec05\n% cd sec05\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-sec05-sram/#1-openram-memory-generator","title":"1. OpenRAM Memory Generator","text":"<p>Just as with standard-cell libraries, acquiring real SRAM generators is a complex and potentially expensive process. It requires gaining access to a specific fabrication technology, negotiating with a company which makes the SRAM generator, and usually signing multiple non-disclosure agreements. The OpenRAM memory generator is based on the same \"fake\" 45nm technology that we are using for the Nangate standard-cell library. The \"fake\" technology is representative enough to provide reasonable area, energy, and timing estimates for our purposes. Let's take a look at how to use the OpenRAM memory generator to generate various views of an SRAM macro.</p> <p>An SRAM generator takes as input a configuration file which specifies the various parameters for the desired SRAM macro. Create a configuration file with the following content using your favorite text editor. You should name your file <code>SRAM_32x128_1rw_cfg.py</code> and it should be located in the directory shown below.</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen\n% cat SRAM_32x128_1rw_cfg.py\n</code></pre> <p>The configuration file should look like this:</p> <pre><code>use_conda       = False\n\nnum_rw_ports    = 1\nnum_r_ports     = 0\nnum_w_ports     = 0\n\nword_size       = 32\nnum_words       = 128\nnum_banks       = 1\nwords_per_row   = 4\nwrite_size      = 8\n\ntech_name       = \"freepdk45\"\nprocess_corners = [\"TT\"]\nsupply_voltages = [1.1]\ntemperatures    = [25]\n\nroute_supplies  = True\ncheck_lvsdrc    = False\n\noutput_path     = \"SRAM_32x128_1rw\"\noutput_name     = \"SRAM_32x128_1rw\"\ninstance_name   = \"SRAM_32x128_1rw\"\n</code></pre> <p>In this example, we are generating a single-ported SRAM which has 128 rows and 32 bits per row for a total capacity of 4096 bits or 512B. This size is probably near the cross-over point where you might transition from using synthesized memories to SRAM macros. OpenRAM will take this configuration file as input and generate many different views of the SRAM macro including: schematics (<code>.sp</code>), layout (<code>.gds</code>), a Verilog behavioral model (<code>.v</code>), abstract logical, timing, power view (<code>.lib</code>), and a physical view (<code>.lef</code>). These views can then be used by the ASIC tools.</p> <p>You can use the following command to run the OpenRAM memory generator.</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen\n% openram -v -v SRAM_32x128_1rw_cfg.py\n</code></pre> <p>It will take about 4-5 minutes to generate the SRAM macro. You can see the resulting views here:</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen/SRAM_32x128_1rw\n% ls -1\nSRAM_32x128_1rw.gds\nSRAM_32x128_1rw.lef\nSRAM_32x128_1rw.sp\nSRAM_32x128_1rw_TT_1p1V_25C.lib\nSRAM_32x128_1rw.v\nSRAM_32x128_1rw.html\n</code></pre> <p>You can find more information about the OpenRAM memory generator on the project's webpage here:</p> <ul> <li>https://openram.org</li> </ul> <p>Or in this research paper:</p> <ul> <li>M. Guthaus et. al, \"OpenRAM: An Open-Source Memory Compiler\", Int'l    Conf. on Computer-Aided Design (ICCAD), Nov. 2016.    (https://doi.org/10.1145/2966986.2980098)</li> </ul> <p>The following excerpt from the paper illustrates the microarchitecture used in the single-port SRAM macro.</p> <p></p> <p>The functionality of the pins are as follows:</p> <ul> <li><code>clk</code>: clock</li> <li><code>WEb</code>: write enable (active low)</li> <li><code>OEb</code>: output enable (active low)</li> <li><code>CSb</code>: whole SRAM enable (active low)</li> <li><code>ADDR</code>: address</li> <li><code>DATA</code>: read/write data</li> </ul> <p>Notice that there is a single address, and a single read/write data bus. This SRAM macro has a single read/write port and only supports executing a single transaction at a time. The following excerpt from the paper shows the timing diagram for a read and write transaction.</p> <p></p> <p>Prof. Batten will explain this timing diagram in more detail, especially the important distinction between a synchronous read SRAM and a combinational read register file. Take a few minutes to look at the behavioral verilog. See if you can see how this models a synchronous read SRAM.</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen/SRAM_32x128_1rw\n% less SRAM_32x128_1rw.v\n</code></pre> <p>You can take a look at the generated transistor-level netlist for a single bit-cell like this:</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen/SRAM_32x128_1rw\n% less -p \" cell_1rw \" SRAM_32x128_1rw.sp\n</code></pre> <p>Now let's use Klayout look at the actual layout produced by the OpenRAM memory generator.</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen/SRAM_32x128_1rw\n% klayout -l $ECE6745_STDCELLS/klayout.lyp SRAM_32x128_1rw.gds\n</code></pre> <p>In Klayout, you can show/hide layers by double clicking on them on the right panel. You can show more of the hierarchy by selecting Display &gt; Increment Hierarchy or less of the hierarchy by selecting Display &gt; Decrement Hierarchy from the menu.</p> <p>Take a quick look at the <code>.lib</code> file and the <code>.lef</code> file for the SRAM macro.</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen/SRAM_32x128_1rw\n% less SRAM_32x128_1rw_TT_1p1V_25C.lib\n% less SRAM_32x128_1rw.lef\n</code></pre>"},{"location":"ece6745-sec05-sram/#2-sram-rtl-models","title":"2. SRAM RTL Models","text":"<p>Now that we understand how an SRAM generator works, let's see how to reference an SRAM in Verilog RTL. Our basic SRAMs are located in the <code>sim/sram</code> subdirectory.</p> <pre><code>% cd $TOPDIR/sim/sram\n% ls\n...\nSRAM_generic.v\nSRAM.v\n</code></pre> <p>Take a look the interface of the SRAM in <code>SRAM.v</code>.</p> <pre><code>module sram_SRAM\n#(\n  parameter p_data_nbits  = 32,\n  parameter p_num_entries = 256,\n\n  // Local constants not meant to be set from outside the module\n  parameter c_addr_nbits  = $clog2(p_num_entries),\n  parameter c_data_nbytes = (p_data_nbits+7)/8 // $ceil(p_data_nbits/8)\n)(\n  input  logic                        clk,\n  input  logic                        reset,\n  input  logic                        port0_val,\n  input  logic                        port0_type,\n  input  logic [c_addr_nbits-1:0]     port0_idx,\n  input  logic [(p_data_nbits/8)-1:0] port0_wben,\n  input  logic [p_data_nbits-1:0]     port0_wdata,\n  output logic [p_data_nbits-1:0]     port0_rdata\n);\n</code></pre> <p>The SRAM model is parameterized by the number of words and the bits per word, and has the following pin-level interface:</p> <ul> <li><code>port0_val</code>: port enable</li> <li><code>port0_type</code>: transaction type (0 = read, 1 = write)</li> <li><code>port0_idx</code>: which row to read/write</li> <li><code>port0_wben</code>: write byte enables</li> <li><code>port0_wdata</code>: write data</li> <li><code>port0_rdata</code>: read data</li> </ul> <p>Now look at the implementation of the SRAM. You will see a generate if statement which uses the parameters to either (1) instantiate a specific SRAM macro or (2) instantiate a generic SRAM. It is critical that the name of the specific SRAM macro matches the name generated by OpenRAM. In this discussion section we will be generating an SRAM with 128 words each of which is 32 bits, and we can see that this SRAM macro is already included.</p> <p>Let's run the tests for the specific SRAM we will be using in this discussion section.</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../sram/test/SRAM_test.py -k test_direct_32x128 -s\n</code></pre> <p>You can run the random test like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../sram/test/SRAM_test.py -k test_random[32-128] -s\n</code></pre>"},{"location":"ece6745-sec05-sram/#3-sram-minion-wrapper-rtl","title":"3. SRAM Minion Wrapper RTL","text":"<p>SRAMs use a latency sensitive interface meaning a user must carefully manage the timing for correct operation (i.e., set the read address and then exactly one cycle later use the read data). In addition, the SRAM cannot be \"stalled\". To illustrate how to use SRAM macros, we will create a latency insensitive minion wrapper around an SRAM which enables writing and reading the SRAM using our standard memory messages. The following figure illustrates our approach to implementing this wrapper:</p> <p></p> <p>Here is a pipeline diagram that illustrates how this works.</p> <pre><code> cycle : 0  1  2  3  4  5  6  7  8\n msg a : M0 Mx\n msg b :    M0 Mx\n msg c :       M0 M1 M2 M2 M2\n msg d :          M0 M1 q  q  M2     # msg c is in skid buffer\n msg e :             M0 M0 M0 M0 Mx\n\n cycle M0 M1 [q ] M2\n    0: a\n    1: b  a       a  # a flows through bypass queue\n    2: c  b       b  # b flows through bypass queue\n    3: d  c          # M2 is stalled, c will need to go into bypq\n    4: e  d    c     #\n    5: e      dc     # d skids behind c into the bypq\n    6: e       d  c  # c is dequeued from bypq\n    7: e          d  # d is dequeued from bypq\n    8:    e       e  # e flows through bypass queue\n</code></pre> <p>Take a closer look at the SRAM minion wrapper we provide you.</p> <pre><code>% cd $TOPDIR/sim/tut10_sram\n% less SRAMMinion.v\n</code></pre> <p>To use an SRAM, simply include <code>sram/SRAM.v</code>, instantiate the SRAM, and set the number of words and number of bits per word. Here is what the instantiation of the SRAM looks like in the wrapper.</p> <pre><code>`include \"sram/SRAM.v\"\n...\nsram_SRAM#(32,128) sram\n(\n  .clk         (clk),\n  .reset       (reset),\n  .port0_idx   (sram_addr_M0),\n  .port0_type  (sram_wen_M0),\n  .port0_val   (sram_en_M0),\n  .port0_wben  (sram_wben_M0),\n  .port0_wdata (memreq_msg_data_M0),\n  .port0_rdata (sram_read_data_M1)\n);\n</code></pre> <p>We can run a test on the SRAM minion wrapper like this:</p> <pre><code> % cd $TOPDIR/sim/build\n % pytest ../tut10_sram/test/SRAMMinion_test.py -k random_0_3 -s\n</code></pre> <p>Here is what the trace output should look like.</p> <pre><code>  1r                           &gt; (  (). ) &gt; .\n  2r                           &gt; (  (). ) &gt; .\n  3:                           &gt; (  (). ) &gt; .\n  4: wr:00:00000000:0:55fceed9 &gt; (wr(). ) &gt; .\n  5: wr:01:00000004:0:5bec8a7b &gt; (wr()# ) &gt; #\n  6: #                         &gt; (# ()# ) &gt; #\n  7: #                         &gt; (# ()wr) &gt; wr:00:0:0:\n  8: #                         &gt; (# ()# ) &gt; #\n  9: #                         &gt; (# ()# ) &gt; #\n 10: #                         &gt; (# ()# ) &gt; #\n 11: #                         &gt; (# ()wr) &gt; wr:01:0:0:\n 12: wr:02:00000008:0:b1aa20f1 &gt; (wr(). ) &gt; .\n 13: wr:03:0000000c:0:a5b6b6bb &gt; (wr()# ) &gt; #\n 14: #                         &gt; (# ()# ) &gt; #\n 15: #                         &gt; (# ()wr) &gt; wr:02:0:0:\n</code></pre> <p>The first write transaction takes a single cycle to go through the SRAM minion wrapper, but then the response interface is not ready on cycles 5-6. The second write transaction is still accepted by the SRAM minion wrapper and it will end up in the bypass queue, but the later transactions are stalled because the request interface is not ready. No transactions are lost.</p> <p>Let's now use an interactive simulator to generate the pickled Verilog and a test bench for pushing through the ASIC flow.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut10_sram/sram-sim --impl rtl --input random --translate --dump-vtb\n</code></pre>"},{"location":"ece6745-sec05-sram/#4-asic-front-end-flow-with-sram-macros","title":"4. ASIC Front-End Flow with SRAM Macros","text":"<p>Now we will push our SRAM minion wrapper through the ASIC front-end flow. We have already generated the SRAM macro using OpenRAM at the beginning of the discussion section. We want to move the key generated files to make them easier to use by the ASIC tools.</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen/SRAM_32x128_1rw\n% cp SRAM_32x128_1rw_TT_1p1V_25C.lib ../SRAM_32x128_1rw.lib\n% cp *.gds *.lef *.v ..\n</code></pre> <p>We need to convert the <code>.lib</code> file into a <code>.db</code> file using the Synopsys Library Compiler (LC) tool.</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen\n% lc_shell\nlc_shell&gt; read_lib SRAM_32x128_1rw.lib\nlc_shell&gt; write_lib SRAM_32x128_1rw_TT_1p1V_25C_lib \\\n  -format db -output SRAM_32x128_1rw.db\nlc_shell&gt; exit\n</code></pre> <p>As always, we start by using four-state RTL simulation to further verify our design.</p> <pre><code>% mkdir -p ${TOPDIR}/asic/build-sram/01-synopsys-vcs-rtlsim\n% cd ${TOPDIR}/asic/build-sram/01-synopsys-vcs-rtlsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n   +vcs+dumpvars+waves.vcd \\\n   +incdir+${TOPDIR}/sim/build \\\n   ${TOPDIR}/sim/build/SRAMMinion_noparam__pickled.v \\\n   ${TOPDIR}/sim/build/SRAMMinion_noparam_sram-rtl-random_tb.v\n% ./simv\n</code></pre> <p>Now we can use Synopsys DC to synthesize the logic which goes around the SRAM macro.</p> <pre><code>% mkdir -p ${TOPDIR}/asic/build-sram/02-synopsys-dc-synth\n% cd ${TOPDIR}/asic/build-sram/02-synopsys-dc-synth\n% dc_shell-xg-t\ndc_shell&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db ../00-openram-memgen/SRAM_32x128_1rw.db\"\ndc_shell&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db ../00-openram-memgen/SRAM_32x128_1rw.db\"\ndc_shell&gt; analyze -format sverilog ../../../sim/build/SRAMMinion_noparam__pickled.v\ndc_shell&gt; elaborate SRAMMinion_noparam\ndc_shell&gt; create_clock clk -name ideal_clock1 -period 2.0\ndc_shell&gt; compile\ndc_shell&gt; write -format ddc     -hierarchy -output post-synth.ddc\ndc_shell&gt; write -format verilog -hierarchy -output post-synth.v\ndc_shell&gt; report_area   -hierarchy\ndc_shell&gt; report_timing -nets\ndc_shell&gt; exit\n</code></pre> <p>We are basically using the same steps we used in the ASIC front-end flow section. Notice how we must point Synopsys DC to the <code>.db</code> file generated by the OpenRAM memory generator so Synopsys DC knows the abstract logical and timing views of the SRAM.</p> <p>If you look for the SRAM module in the synthesized gate-level netlist, you will see that it is referenced but not declared. This is what we expect since we are not synthesizing the memory but instead using an SRAM macro.</p> <pre><code>% cd ${TOPDIR}/asic/build-sram/02-synopsys-dc-synth\n% less -p SRAM post-synth.v\n</code></pre> <p>We can use fast-functional gate-level simulation to simulate the gate-level netlist integrated with the Verilog RTL models for the SRAMs.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sram/03-synopsys-vcs-ffglsim\n% cd $TOPDIR/asic/build-sram/03-synopsys-vcs-ffglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +delay_mode_zero \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../00-openram-memgen/SRAM_32x128_1rw.v \\\n    ../02-synopsys-dc-synth/post-synth.v \\\n    ${TOPDIR}/sim/build/SRAMMinion_noparam_sram-rtl-random_tb.v\n% ./simv\n</code></pre>"},{"location":"ece6745-sec05-sram/#4-asic-back-end-flow-with-sram-macros","title":"4. ASIC Back-End Flow with SRAM Macros","text":"<p>Now we can use Cadence Innovus to place the SRAM macro and the standard cells, and then automatically route everything together.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sram/04-cadence-innovus-pnr\n% cd $TOPDIR/asic/build-sram/04-cadence-innovus-pnr\n</code></pre> <p>As in the ASIC back-end flow section, we need to create two files before starting Cadence Innovus. Use VS Code to create a file named <code>constraints.sdc</code>.</p> <pre><code>% cd $TOPDIR/asic/build-sram/04-cadence-innovus-pnr\n% code constraints.sdc\n</code></pre> <p>The file should have the following constraint:</p> <pre><code>create_clock clk -name ideal_clock -period 2.0\n</code></pre> <p>Now use VS Code to create a file named <code>setup-timing.tcl</code>.</p> <pre><code>% cd $TOPDIR/asic/build-sram/04-cadence-innovus-pnr\n% code setup-timing.tcl\n</code></pre> <p>The file should have the following content:</p> <pre><code>create_rc_corner -name typical \\\n   -cap_table \"$env(ECE6745_STDCELLS)/rtk-typical.captable\" \\\n   -T 25\n\ncreate_library_set -name libs_typical \\\n   -timing [list \"$env(ECE6745_STDCELLS)/stdcells.lib\" \\\n                 \"../00-openram-memgen/SRAM_32x128_1rw.lib\" ]\n\ncreate_delay_corner -name delay_default \\\n   -library_set libs_typical \\\n   -rc_corner typical\n\ncreate_constraint_mode -name constraints_default \\\n   -sdc_files [list constraints.sdc]\n\ncreate_analysis_view -name analysis_default \\\n   -constraint_mode constraints_default \\\n   -delay_corner delay_default\n\nset_analysis_view -setup analysis_default -hold analysis_default\n</code></pre> <p>Notice that we are including the <code>.lib</code> file generated by the OpenRAM memory generator. Now let's start Cadence Innovus, load in the design, and complete power routing just as in the previous ASIC back-end section. We recommend working with a partner on this section to avoid overloading the ecelinux servers by running so many copies of Cadence Innovus as the same time.</p> <pre><code>% cd $TOPDIR/asic/build-sram/04-cadence-innovus-pnr\n% innovus\ninnovus&gt; set init_mmmc_file \"setup-timing.tcl\"\ninnovus&gt; set init_verilog   \"../02-synopsys-dc-synth/post-synth.v\"\ninnovus&gt; set init_top_cell  \"SRAMMinion_noparam\"\ninnovus&gt; set init_lef_file  \"$env(ECE6745_STDCELLS)/rtk-tech.lef \\\n                             $env(ECE6745_STDCELLS)/stdcells.lef \\\n                             ../00-openram-memgen/SRAM_32x128_1rw.lef\"\ninnovus&gt; set init_gnd_net   \"VSS\"\ninnovus&gt; set init_pwr_net   \"VDD\"\ninnovus&gt; init_design\ninnovus&gt; floorPlan -d 175 175 4.0 4.0 4.0 4.0\n</code></pre> <p>Now let's place the design.</p> <pre><code>innovus&gt; place_design\n</code></pre> <p>You should be able to see the SRAM macro as a black box in the middle of the layout and then various standard cells placed around the perimeter. Now let's go ahead and do some simple power and signal routing.</p> <pre><code>innovus&gt; globalNetConnect VDD -type pgpin -pin VDD -inst * -verbose\ninnovus&gt; globalNetConnect VSS -type pgpin -pin VSS -inst * -verbose\ninnovus&gt; sroute -nets {VDD VSS}\ninnovus&gt; routeDesign\ninnovus&gt; extractRC\n</code></pre> <p>You can now see all of the routing between the standard cells and the SRAM macro. We can now go ahead and add filler cells.</p> <pre><code>innovus&gt; setFillerMode -core {FILLCELL_X4 FILLCELL_X2 FILLCELL_X1}\ninnovus&gt; addFiller\n</code></pre> <p>Let's now save the final merged GDS file.</p> <pre><code>innovus&gt; streamOut post-pnr.gds \\\n  -merge \"$env(ECE6745_STDCELLS)/stdcells.gds \\\n          ../00-openram-memgen/SRAM_32x128_1rw.gds\" \\\n  -mapFile \"$env(ECE6745_STDCELLS)/rtk-stream-out.map\"\n</code></pre> <p>Notice how we need to provide the GDS for the SRAM macro when doing the final GDS merge. Finally we can look at some timing and area reports.</p> <pre><code>innovus&gt; report_timing -late  -path_type full_clock -net\ninnovus&gt; report_timing -early -path_type full_clock -net\ninnovus&gt; report_area\n</code></pre> <p>While the design should meet the setup time constraint it will likely fail the hold time constraint. A more advanced place-and-route script will include specific steps for fixing hold time violations.</p> <p>Let's exit Cadence Innovus.</p> <pre><code>innovus&gt; exit\n</code></pre> <p>Then we can use Klayout to take a look at the final layout.</p> <pre><code>% cd $TOPDIR/asic/build-sram/04-cadence-innovus-pnr\n% klayout -l ${ECE6745_STDCELLS}/klayout.lyp post-pnr.gds\n</code></pre>"},{"location":"ece6745-tinyflow-180nm-drm/","title":"TinyFlow Design Rules Manual (v0.3)","text":"<p>Adapted from  MOSIS Scalable CMOS (SCMOS) Revision 8.0 (Technology: SCN6M DEEP) (https://www.southampton.ac.uk/~bim/notes/ice/DesignRules/scmos-main.html#tech-codes)</p> <p>Authors: Vayun Tiwari</p> <p>Last updated: January 27th, 2026</p>"},{"location":"ece6745-tinyflow-180nm-drm/#nwell","title":"nwell","text":"Rule Description \\(\\lambda\\) 1.1 Minimum width 12 1.3 Minimum spacing between wells at same potential 6"},{"location":"ece6745-tinyflow-180nm-drm/#active","title":"active","text":"Rule Description \\(\\lambda\\) 2.1 Minimum width 3 2.2 Minimum spacing 3 2.3 Source/drain active to well edge 6 2.4 Substrate/well contact active to well edge 3 2.5 Minimum spacing between non-abutting active of different implant 4"},{"location":"ece6745-tinyflow-180nm-drm/#poly","title":"poly","text":"Rule Description \\(\\lambda\\) 3.1 Minimum width 2 3.2 Minimum spacing over field 3 3.2a Minimum spacing over active 4 3.3 Minimum gate extension of active 3 3.4 Minimum active extension of poly 4 3.5 Minimum field poly to active 1"},{"location":"ece6745-tinyflow-180nm-drm/#pselect-nselect","title":"pselect &amp; nselect","text":"Rule Description \\(\\lambda\\) 4.1 Minimum select spacing to channel of transistor to ensure adequate source/drain width 3 4.2 Minimum select overlap of active 2 4.3 Minimum select overlap of contact 2 4.4 Minimum select width and spacing (P and N-select may coincident, but must not overlap) 4"},{"location":"ece6745-tinyflow-180nm-drm/#contact-to-poly","title":"contact to poly","text":"Rule Description \\(\\lambda\\) 5.1 Exact contact size 2\u00d72 5.2 Minimum poly overlap 2 5.3 Minimum contact spacing 4 5.4 Minimum spacing to gate of transistor 2"},{"location":"ece6745-tinyflow-180nm-drm/#contact-to-active","title":"contact to active","text":"Rule Description \\(\\lambda\\) 6.1 Exact contact size 2\u00d72 6.2 Minimum active overlap 2 6.3 Minimum contact spacing 4 6.4 Minimum spacing to gate of transistor 2"},{"location":"ece6745-tinyflow-180nm-drm/#metal1","title":"metal1","text":"Rule Description \\(\\lambda\\) 7.1 Minimum width 3 7.2 Minimum spacing 3 7.3 Minimum overlap of contact or via 1 7.4 Minimum spacing when either metal line is wider than 10 lambda 6 7.5 Minimum area 25 \\(\\lambda\\)<sup>2</sup>"},{"location":"ece6745-tinyflow-180nm-drm/#metal1-label","title":"metal1 label","text":"Rule Description \\(\\lambda\\) label.1 Track alignment - label.2 Minimum metal1 overlap 4 \\(\\times\\) 4"},{"location":"ece6745-tinyflow-180nm-drm/#prboundary","title":"prboundary","text":"Rule Description \\(\\lambda\\) prboundary.1 Minimum spacing to active (does not apply to well-tap active) 2 prboundary.2 Minimum spacing to metal1 (does not apply to metal1 VDD/VSS rails) 2 prboundary.3 Minimum spacing to poly 2 <p>*these rules ensure DRC-clean abutment between adjacent standard cells during place &amp; route</p> <p></p>"},{"location":"ece6745-tinyflow-180nm-drm/#via12-above","title":"via12 &amp; above","text":"<p>coming in v1</p>"},{"location":"ece6745-tut00-remote-access/","title":"Tutorial 0: ECE Linux Server Remote Access","text":"<p>All of the projects for this course will be completed by remotely logging into a cluster of <code>ecelinux</code> servers. The <code>ecelinux</code> servers all run the Red Hat Enterprise Linux 8 operating system, and they all use an identical setup. You do not need to do anything special to create an <code>ecelinux</code> account. You will be using your NetID and Cornell password to login, and an <code>ecelinux</code> account will be automatically created for you when you first login. Any student enrolled in any ECE class should automatically be granted access to the <code>ecelinux</code> servers. Having said this, if you cannot log into the <code>ecelinux</code> servers please reach out to the course staff for assistance.</p> <p>Later tutorials will discuss how to use the Linux development environment and the Git distributed version control system. In this tutorial, we focus on how to setup remote access to the <code>ecelinux</code> servers by first connecting to the Cornell VPN and then using three different options to remotely access the <code>ecelinux</code> servers. The first remote access option is based on using PowerShell (for Windows OS users) or Mac Terminal (for Mac OS X users) and only supports primitive text-based interaction. We recommend using PowerShell or Mac Terminal as backup options to debug connection issues to the <code>ecelinux</code> servers. The second (and primary) remote access option recommended in this course is through Visual Studio Code (VS Code) which provides a very nice interface with support for working at the command line, graphic text editing, and graphic file browsing. The third remote access option is based on using Microsoft Remote Desktop and is required when executing a Linux application with a graphical user interface.</p>"},{"location":"ece6745-tut00-remote-access/#1-select-an-ecelinux-server","title":"1. Select an <code>ecelinux</code> Server","text":"<p>It is important to keep in mind that we will use <code>ecelinux</code> as shorthand for the entire cluster of 20 servers. These servers are named as follows:</p> <ul> <li><code>ecelinux-01.ece.cornell.edu</code></li> <li><code>ecelinux-02.ece.cornell.edu</code></li> <li><code>ecelinux-03.ece.cornell.edu</code></li> <li>...</li> <li><code>ecelinux-18.ece.cornell.edu</code></li> <li><code>ecelinux-19.ece.cornell.edu</code></li> <li><code>ecelinux-20.ece.cornell.edu</code></li> </ul> <p>At the beginning of the semester, select a server and always use that same server. Do not just log into <code>ecelinux.ece.cornell.edu</code>. Continue to always use the same server unless you have trouble logging in in which case you can try switching to a different server.</p> <p>All of the <code>ecelinux</code> servers are identical. Every tool is available on every <code>ecelinux</code> server. All of your files are available on every <code>ecelinux</code> server.</p>"},{"location":"ece6745-tut00-remote-access/#2-connecting-to-the-cornell-vpn","title":"2. Connecting to the Cornell VPN","text":"<p>If you are logging into the <code>ecelinux</code> servers from on campus (i.e., using the Cornell wired or wireless network), then you do not need to enable the Cornell virtual private network (VPN). However, if you are off campus, then you will need to enable the Cornell VPN whenever you want to log into the <code>ecelinux</code> servers. The VPN provides very secure access to all on-campus network resources. More information about the Cornell VPN is available here:</p> <ul> <li>https://it.cornell.edu/cuvpn</li> </ul> <p>Simply follow the instructions at the following link to install the Cisco VPN software for the appropriate operating system you use on your laptop/workstation:</p> <ul> <li>https://it.cornell.edu/landing-page-kba/2605/5273</li> </ul> <p>Once the Cornell VPN is installed, then connect to the Cornell VPN by following these instructions and using your Cornell NetID and password:</p> <ul> <li>https://it.cornell.edu/landing-page-kba/2605/823</li> </ul> <p>The Cornell VPN uses the Cisco Secure Client shown below.</p> <p></p>"},{"location":"ece6745-tut00-remote-access/#3-remote-access-via-powershell-or-mac-terminal","title":"3. Remote Access via PowerShell or Mac Terminal","text":"<p>PowerShell is part of Windows OS and Mac Terminal is part of Mac OS X. Both enable interacting with your system from the command line (i.e., a powerful text-based environment where users type commands to manipulate files and directories and execute applications). Both also enable remotely accessing other systems (e.g., the <code>ecelinux</code> servers) via the command line using SSH, a highly secure network protocol and associated client/server program. Both will enable you to log into the <code>ecelinux</code> servers and to then manipulate files and directories and execute applications remotely on the <code>ecelinux</code> servers using the Linux command line. You must try logging in using PowerShell or Mac Terminal before attempting to use VS Code!</p>"},{"location":"ece6745-tut00-remote-access/#31-starting-powershell-or-mac-terminal","title":"3.1. Starting PowerShell or Mac Terminal","text":"<p>First, if you are off campus, then you must be connected to the Cornell VPN before attempting to use X2Go to access the <code>ecelinux</code> servers (see Section 1). To start PowerShell click the Start menu then search for Windows PowerShell. To start Mac Terminal go to your Applications folder and choose Utilities &gt; Terminal, or open Spotlight, type Terminal, and press enter.</p>"},{"location":"ece6745-tut00-remote-access/#32-logging-into-ecelinux-servers-with-powershell-or-mac-terminal","title":"3.2. Logging into <code>ecelinux</code> Servers with PowerShell or Mac Terminal","text":"<p>After starting PowerShell or Mac Terminal, type in the following command at the prompt to log into the <code>ecelinux</code> servers using SSH.</p> <pre><code>% ssh netid@ecelinux-XX.ece.cornell.edu\n</code></pre> <p>Replace <code>netid</code> with your Cornell NetID in the command above and replace <code>XX</code> with the number of <code>ecelinux</code> server you plan to use this semester. You should not enter the <code>%</code> character. We use the <code>%</code> character to indicate what commands we should enter on the command line. Executing the command will prompt you to enter your Cornell NetID password, and then you should be connected to the <code>ecelinux</code> servers.</p> <p>The very first time you log into the <code>ecelinux</code> servers you may see a warning like this:</p> <pre><code>The authenticity of host \u2019ecelinux-XX.ece.cornell.edu (128.253.51.206)\u2019\ncan\u2019t be established. ECDSA key fingerprint is\nSHA256:smwMnf9dyhs5zW5I279C5oJBrTFc5FLghIJMfBR1cxI.\nAre you sure you want to continue connecting (yes/no)?\n</code></pre> <p>The very first time you log into the <code>ecelinux</code> servers it is okay to enter yes, but from then on if you continue to receive this warning please contact the course staff.</p> <p>Once you have opened a terminal, the very first thing you need to do after logging into the <code>ecelinux</code> servers is source the course setup script. This will ensure your environment is setup with everything you need for working on the projects. Enter the following command on the command line:</p> <pre><code>% source setup-ece6745.sh\n</code></pre> <p>Again, you should not enter the <code>%</code> character. You should now see a blue <code>ECE 6745</code> in your prompt which means your environment is setup for the course. See the final section of this tutorial for more on how to automatically source the setup script every time you log into the <code>ecelinux</code> servers.</p> <p>You can log out of the <code>ecelinux</code> server with the <code>exit</code> command.</p> <pre><code>% exit\n</code></pre> <p>Try logging in, sourcing the setup script, and loging out multiple times using PowerShell or Mac Terminal. You must make sure you can do this successfully before attempting to setup VS Code!</p>"},{"location":"ece6745-tut00-remote-access/#33-troubleshooting-remote-access-via-powershell-or-mac-terminal","title":"3.3. Troubleshooting Remote Access via PowerShell or Mac Terminal","text":"<p>If you cannot source the setup script it might be because you either took a course in a previous semester which used <code>ecelinux</code> or you are currently taking a course which also uses <code>ecelinux</code> and you modified your <code>.bashrc</code> to automatically source the other course's setup script.</p> <p>You should only source a setup script for a single course at a time. If you modified your <code>.bashrc</code> to source a course setup script you need to remove those lines from your <code>.bashrc</code>. If you are taking two courses which use <code>ecelinux</code> in the same semester then you should make sure not to source either setup script in your <code>.bashrc</code>. You should instead always source the appropriate setup script each time you log into <code>ecelinux</code> for whatever course you are currently working on.</p> <p>You can use the simple <code>nano</code> text editor to edit your <code>.bashrc</code> like this:</p> <pre><code>% nano .bashrc\n</code></pre> <p>Notice that the editor specifies most of the useful commands at the bottom of the terminal screen. The symbol <code>\\^</code> indicates the <code>CONTROL</code> key. To type any text you want, just move the cursor to the required position and use the keyboard. To save your changes press <code>CONTROL+O1 (i.e., press the</code>CONTROL1 key and the <code>O1 key at the same time) and press the</code>1 key after specifying the filename you want to save to. You can quit by pressing <code>CONTROL+X1. Use</code>CONTROL+G1 for help. <p></p> <p>Delete every line which sets up <code>ecelinux</code> for any course. A pristine <code>.bashrc</code> should look like this:</p> <pre><code>if [ -f /etc/bashrc ]; then\n  . /etc/bashrc\nfi\n\nif ! [[ \"$PATH\" =~ \"$HOME/.local/bin:$HOME/bin:\" ]]\nthen\n    PATH=\"$HOME/.local/bin:$HOME/bin:$PATH\"\nfi\nexport PATH\n</code></pre> <p>Log out, log in, source the setup script, and log out multiple times using PowerShell or Mac Terminal. You must make sure you can do this successfully before attempting to setup VS Code!</p>"},{"location":"ece6745-tut00-remote-access/#4-remote-access-via-vs-code","title":"4. Remote Access via VS Code","text":"<p>While it is possible to use simple text editors directly within PowerShell or Mac Terminal, it is not the most productive development setup. We strongly recommend using VS Code as your primary remote access option for code development. VS Code offers a nice balance of productive features while also working well with moderate internet speeds.</p> <p>VS Code uses a unique approach where the GUI interface runs completely on your local laptop/workshop and then automatically handles copying files back and forth between your local laptop/workshop and the <code>ecelinux</code> servers. VS Code is portable across many operating systems and has a thriving ecosystem of extensions and plugins enabling it to function as a full-featured IDE for languages from C to Javascript. More information about VS Code is here:</p> <ul> <li>https://code.visualstudio.com</li> <li>https://code.visualstudio.com/docs</li> </ul>"},{"location":"ece6745-tut00-remote-access/#41-installing-vs-code-on-your-laptopworkstation","title":"4.1. Installing VS Code on Your Laptop/Workstation","text":"<p>You can download VS Code by simply going to the main VS Code webpage:</p> <ul> <li>https://code.visualstudio.com</li> </ul> <p>There should be an obvious link that says <code>Download for Windows'' or</code>Download for MacOS''. Click on that link. On Mac OS X, you will need to drag the corresponding Visual Student Code.app to your Applications folder.</p>"},{"location":"ece6745-tut00-remote-access/#42-starting-and-configuring-vs-code","title":"4.2. Starting and Configuring VS Code","text":"<p>First, if you are off campus, then you must be connected to the Cornell VPN before attempting to use VS Code to access the <code>ecelinux</code> servers (see Section 1). Start by opening VS Code. The exact way you do this will depend on whether you are using a Windows OS or Mac OS X laptop/workstation.</p> <p>The key to VS Code is installing the correct extensions. You will need extensions for the Verilog hardware description language (HDL), the Python programming language, and the C/C++ programming language. We also want to install a special extension which will enable remotely accessing the <code>ecelinux</code> servers using SSH. Choose View &gt; Extensions from the menubar. Enter the name of the extension in the ``Search Extensions in Marketplace'' and then click the blue \\IT{Install} button. Here are the names of the extensions to install:</p> <ul> <li>Remote - SSH (use the one from Microsoft)</li> <li>Verilog (use the one from Masahiro Hiramori)</li> <li>Python (use the one from Microsoft)</li> <li>C/C++ (use the one from Microsoft)</li> <li>Surfer (use the one from surfer-project)</li> </ul> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"ece6745-tut00-remote-access/#43-logging-into-ecelinux-servers-with-vs-code","title":"4.3. Logging into <code>ecelinux</code> Servers with VS Code","text":"<p>After starting VS Code, choose View &gt; Command Palette from the menubar. Enter the following command in the command palette:</p> <pre><code>Remote-SSH: Connect Current Window to Host...\n</code></pre> <p>Do not use Remote-SSH: Add new SSH host... and do not use Connect to Host. Use Remote-SSH: Connect Current Window to Host...</p> <p>VS Code will then ask you to Select configured SSH host or enter user@host, and you should enter the following:</p> <pre><code>netid@ecelinux-XX.ece.cornell.edu\n</code></pre> <p>Replace <code>netid</code> with your Cornell NetID in the command above and replace <code>XX</code> with the number of <code>ecelinux</code> server you plan to use this semester. If you are on a Windows OS laptop/workstation, then you may see a pop-up which stays that the Windows Defender Firewall as blocked some features of this app. This is not a problem. Simply click Cancel.</p> <p>You might also see a drop down which asks you to choose the operating system of the remote server with options like Linux and Windows. Choose Linux.</p> <p>Finally, the very first time you log into the <code>ecelinux</code> servers you may see a warning like this:</p> <pre><code>\"ecelinux-XX.ece.cornell.edu\" has fingerprint\n\"SHA256:YCh2FiadeTXEzuSkC0AOdglBgPciwc8WvcCPncvr2Fs\"\nAre you sure you want to continue?\nContinue\nCancel\n</code></pre> <p>The very first time you log into the <code>ecelinux</code> servers it is okay to enter yes, but from then on if you continue to receive this warning please contact the course staff.</p> <p>Hopefully, VS Code will now prompt you to enter your Cornell NetID password, and then you should be connected to the <code>ecelinux</code> servers.</p> <p>Also the very first time you log into the <code>ecelinux</code> servers you will see a pop up dialog box in the lower right-hand corner which says Setting up SSH host ecelinux-XX.ece.cornell.edu (details) Initializing.... It might take up to a minute for everything to be setup; please be patient! Once the pop up dialog box goes away and you see SSH: ecelinux-XX.ece.cornell.edu in the lower left-hand corner of VS Code then you know you are connected to the <code>ecelinux</code> servers.</p> <p>The final step is to make sure your extensions for the Verilog HDL are also installed on the server. Choose View &gt; Extensions from the menubar. Use the \"Search Extensions in Marketplace\" to search for the same extensions that we installed earlier. Instead of saying Install it should now say Install in SSH: ecelinux-XX.ece.cornell.edu. Install the extensions on the <code>ecelinux</code> servers. You only need to do this once, and then next time this extension will already be installed on the <code>ecelinux</code> servers.</p>"},{"location":"ece6745-tut00-remote-access/#44-using-vs-code","title":"4.4. Using VS Code","text":"<p>VS Code includes an integrated file explorer which makes it very productive to browse and open files. Choose View &gt; Explorer from the menubar, and then click on Open Folder. VS Code will then ask you to Open File Or Folder with a default of <code>/home/netid</code>. Click OK.</p> <p>You might see a pop-up which asks you Do you trust the authors of the files in this folder? Since you will only be browsing your own files on the <code>ecelinux</code> server, it is fine to choose Yes, I trust the authors.</p> <p>This will reload VS Code, and you should now you will see a file explore in the left sidebar. You can easily browse your directory hierarchy, open files by clicking on them, create new files, and delete files.</p> <p>VS Code includes an integrated terminal which will give you access to the Linux command line on the <code>ecelinux</code> servers. Choose Terminal &gt; New Terminal from the menubar. You should see the same kind of Linux command line prompt that you saw when using either PowerShell or Mac Terminal.</p> <p>If you see a course number for a course other than ECE 6745 in your prompt, then stop! This means you likely have sourced the setup script for a different course. You must fix this before you can work on this course. Exit VS Code, follow the instructions in Section 2.3, and then try connecting with VS Code again.</p> <p>The very first thing you need to do after logging into the <code>ecelinux</code> servers is source the setup script for this course. This will ensure your environment is setup with everything you need for working on the projects. Enter the following command on the command line:</p> <pre><code>% source setup-ece6745.sh\n</code></pre> <p>Again, you should not enter the <code>%</code> character. You should now see a blue <code>ECE 6745</code> in your prompt which means your environment is setup for the course. See the final section of this tutorial for more on how to automatically source the setup script every time you log into the <code>ecelinux</code> servers.</p> <p>To experiment with VS Code, we will first grab a text file using the <code>wget</code> command. The next tutorial discusses this command in more detail. Type the following command in the VS Code integrated terminal.</p> <pre><code>% wget http://www.csl.cornell.edu/courses/ece6745/overview.txt\n</code></pre> <p>You can open a file in the integrated text editor using the <code>code</code> command like this:</p> <pre><code>% code overview.txt\n</code></pre> <p>The following figure shows what VS Code should look like if you have sourced the course setup script and opened the <code>overview.txt</code> file. Notice how the <code>overview.txt</code> file opened in a new tab at the top and the terminal remains at the bottom. This enables you to have easy access to editing files and the Linux command line at the same time.</p> <p></p> <p>We highly recommend turnning on auto save so you don't forget to save your work. You can do this by choosing File &gt; Auto Save from the menubar.</p>"},{"location":"ece6745-tut00-remote-access/#45-turning-off-microsoft-copilot","title":"4.5. Turning off Microsoft Copilot","text":"<p>This course uses an \"AI as TA\" policy, which means students can use AI for similar questions they might ask a TA. Microsoft Copilot enables AI to write code automatically for students. Since a student would never ask a TA to write code for them, using Microsoft Copilot is a violation of the Academic Integrity Policy and prohibited in this course. Students will not have access to AI during the prelim/final exams nor the Verilog exam, so students which violate this policy are unlikely to succeed in these assessments.</p> <p>There are two steps turning off AI functionality in VS Code:</p> <ul> <li> <p>If you have already installed the Copilot extensions, you need to    first uninstall the Copilot and Copilot Chat extensions</p> </li> <li> <p>Choose View &gt; Command Palette from the menubar. Enter the following    command in the command palette:</p> <p>Chat: Hide AI Features</p> </li> </ul> <p>If this does not work, you may need to uninstall VS Code and resinstall it from scratch. More information can be found here:</p> <ul> <li>https://code.visualstudio.com/docs/supporting/FAQ#_can-i-disable-ai-functionality-in-vs-code</li> </ul> <p>You should also of course uninstall any other AI extensions such as Cline, Roo Code, etc.</p>"},{"location":"ece6745-tut00-remote-access/#46-troubleshooting-remote-access-via-vs-code","title":"4.6. Troubleshooting Remote Access via VS Code","text":"<p>There may be issues where sometimes VS Code just keeps asking you for your password or VS Code just hangs when you try and connect to the <code>ecelinux</code> servers. This might mean VS Code is getting wedged. You can definitely ask the course staff to help, but you can also try to fix it on your own.</p> <p>You might be out of space on <code>ecelinux</code>. Student home directories have a quota of 10G so you might need to delete some files to free up some space. How can you delete this directory if you cannot use VS Code to access the <code>ecelinux</code> servers? You can use PowerShell or Mac Terminal to log into the <code>ecelinux</code> servers (see Section 3). Then use <code>quota</code> to see how much space you are using and you can also use <code>du -sh *</code> to see how much space each directory is taking up. If you are over 10G you will need to free up some space. You might need to delete the <code>tmp/trash</code> directory.</p> <p>Another thing to try is to kill the VS Code server on the host. Choose View &gt; Command Palette from the menubar. Enter the following command in the command palette:</p> <pre><code>Remote-SSH: Kill VS Code Server on Host...\n</code></pre> <p>You can also try (especially if the <code>code</code> command is not working for you) deleting the <code>.vscode-server</code> directory on the sever. Again, how can you delete this directory if you cannot use VS Code to access the <code>ecelinux</code> servers? You can use PowerShell or Mac Terminal to log into the <code>ecelinux</code> servers (see Section 3).</p> <p>Once you have gained access to the Linux command line on the <code>ecelinux</code> servers using either PowerShell or Mac Terminal, then you can delete the <code>.vscode-server</code> directory like this:</p> <pre><code>% rm -rf .vscode-server\n</code></pre> <p>Be very careful with the <code>rm</code> command since it deletes files permanently!</p> <p>Note that using the <code>Remote-SSH: Add new SSH host...</code> option does not always seem to work on Microsoft Windows OS laptops/workstations. This is why we recommend just using <code>Remote-SSH: Connect Current Window to Host...</code> directly.</p> <p>VS Code can sometimes \"cache\" your <code>.bashrc</code>. This means if you modfiy your <code>.bashrc</code>, log out, and log back in the changes to your <code>.bashrc</code> will not be reflected. If you modify your <code>.bashrc</code> we recommend: (1) using Remote-SSH: Kill VS Code Server on Host... as described above; (2) close all instances of VS Code; (3) either use PowerShell or Mac Terminal to remove the <code>.vscode-server</code> directory as described above; and (4) reconnect VS Code to <code>ecelinux</code>.</p> <p>Sometimes VS Code can take a very long time to save a file. This is usually because VS Code is trying to auto-format the file on the <code>ecelinux</code> servers. To turn off auto-formatting, open the VS Code settings menu. On Windows OS, choose File &gt; Preferences &gt; Settings from the menubar. On Mac OS X, choose Code &gt; Preferences &gt; Settings from the menubar. Click on Text Editor and then Formatting. Make sure Format On Save is not checked.</p>"},{"location":"ece6745-tut00-remote-access/#5-remote-access-via-microsoft-remote-desktop","title":"5. Remote Access via Microsoft Remote Desktop","text":"<p>We will primarily use VS Code for working at the terminal, developing our hardware, and debugging our designs. However, we need to use a different remote accesss option if we want to run a Linux application which has a graphical user interface (GUI). We will be using the Microsoft Remote Desktop application to log into the <code>ecelinux</code> servers to provide us a \"virtual desktop\" which we can then use to interact with Linux GUI applications.</p>"},{"location":"ece6745-tut00-remote-access/#51-installing-microsoft-remote-desktop-on-your-laptopworkstation","title":"5.1. Installing Microsoft Remote Desktop on Your Laptop/Workstation","text":"<p>Start by installing the Microsoft Remote Desktop application. On Windows, simply use the Start Menu to search for Microsoft Remote Desktop. On Mac OS X, download Microsoft Remote Desktop from the App Store:</p> <ul> <li>https://apps.apple.com/us/app/windows-app/id1295203466</li> </ul>"},{"location":"ece6745-tut00-remote-access/#52-starting-and-configuring-microsoft-remote-desktop-from-windows","title":"5.2. Starting and Configuring Microsoft Remote Desktop from Windows","text":"<p>Start Microsoft Remote Desktop. For the Computer you must choose the same <code>ecelinux</code> server you selected in Section 1; do not just use <code>ecelinux.ece.cornell.edu</code>. Then click on Connect. You may see a message like this:</p> <pre><code>The remote computer could not be authenticated due to problems with its\nsecurity certificate. It may be unsafe to proceed.\n</code></pre> <p>If you see this message then take the following steps:</p> <ul> <li>Click Don't ask me again for connections to this computer</li> <li>Click Yes</li> </ul> <p>This should launch a \"virtual desktop\" on <code>ecelinux</code>. You will need to enter your NetID and password in the xrdp login.</p>"},{"location":"ece6745-tut00-remote-access/#53-starting-and-configuring-microsoft-remote-desktop-from-mac-os-x","title":"5.3. Starting and Configuring Microsoft Remote Desktop from Mac OS X","text":"<p>Start Microsoft Remote Desktop and Connections &gt; Add PC from the menu. For the PC name or hostname you must choose the same <code>ecelinux</code> server you selected in Section 1; do not just use <code>ecelinux.ece.cornell.edu</code>. Then use the following setup:</p> <ul> <li>Click the Credential or User Account drop down and choose Add Credentials or Add User Account<ul> <li>Username: netid@cornell.edu (must have @cornell.edu at end!)</li> <li>Password: NetID password</li> <li>Friendly name: ecelinux</li> </ul> </li> <li>Display tab<ul> <li>Uncheck Start session in full screen</li> </ul> </li> <li>Devices &amp; Audio tab<ul> <li>Uncheck Printers and Smart cards</li> </ul> </li> <li>Click Add</li> </ul> <p>To log into <code>ecelinux</code> double click on the corresponding entry in Microsoft Remote Desktop. You may see a message like this:</p> <pre><code>Your are connecting to the RDP host ... The certificate couldn't be\nverified back to a root certificate. Your connection may not be\nsecure. Do you want to continue?\n</code></pre> <p>If you see this message then take the following steps:</p> <ul> <li>Click Show Certificate</li> <li>Click Always trutst XRDP when connecting ...</li> <li>Click Continue</li> </ul> <p>This should launch a \"virtual desktop\" on <code>ecelinux</code>.</p>"},{"location":"ece6745-tut00-remote-access/#54-using-microsoft-remote-desktop","title":"5.4. Using Microsoft Remote Desktop","text":"<p>To use Linux GUI Applications you need to source another setup script in your VS Code terminal like this:</p> <pre><code>% source setup-gui.sh\n</code></pre> <p>If you see an error that the script cannot find a running instance of Xvnc this means you have not connected to your selected <code>ecelinux</code> server using Microsoft Remote Desktop. You cannot source <code>setup-gui.sh</code> in your <code>.bashrc</code>. It will not work.</p> <p>Assuming there are no errors, you can now try starting a Linux GUI application. Try running the <code>xclock</code> program in your VS Code terminal.</p> <pre><code>% xclock\n</code></pre> <p>You should see an analog clock pop up in Microsoft Remote Desktop. Close the analog clock window.</p> <p></p>"},{"location":"ece6745-tut00-remote-access/#6-sourcing-course-setup-script-with-auto-setup","title":"6. Sourcing Course Setup Script with Auto Setup","text":"<p>The previous sections have demonstrated how to remotely access the <code>ecelinux</code> servers, get to the Linux command line, and source the course setup script. Again, you must source the course setup script before doing any work related to this course! The course setup script configures everything so you have the right environment to work on the projects.</p> <p>Since it can be tedious to always remember to source the course setup script, you can also use auto setup which will automatically source the course setup for you when you open a terminal. Note that you should only do this if ECE 6745 is the only course you are taking this semester which is using <code>ecelinux</code>! If you are taking more than one course which is using <code>ecelinux</code>, then you will need to manually source the setup script when you are working on this course. Enter the following command on the command line to use auto setup:</p> <pre><code> % source setup-ece6745.sh --enable-auto-setup\n</code></pre> <p>Then you must kill the VS Code server on the host. Choose View &gt; Command Palette from the menubar. Enter the following command in the command palette:</p> <pre><code>Remote-SSH: Kill VS Code Server on Host...\n</code></pre> <p>Then connect again by choosing View &gt; Command Palette from the menubar. Enter the following command in the command palette:</p> <pre><code>Remote-SSH: Connect Current Window to Host...\n</code></pre> <p>You should see <code>ECE 6745</code> in the prompt meaning your environment is automatically setup for the course. If at anytime you need to disable auto setup you can use the following command:</p> <pre><code> % source setup-ece6745.sh --disable-auto-setup\n</code></pre> <p>Again, if for any reason running the setup script prevents you from using tools for another course, you cannot use the auto setup. You will need to run the setup script manually every time you want to work on a project for this course.</p>"},{"location":"ece6745-tut01-linux/","title":"Tutorial 1: Linux Development Environment","text":"<p>The laboratory assignments for this course are designed assuming you will be using a Linux (or UNIX-like) operating system for development. Basic Linux knowledge is essential to successfully complete this work and a more in-depth understanding enhances productivity. This tutorial covers the computing resources to be used in the course and offers a brisk introduction to the Linux operating system for first time users including some details specific to this course.</p> <p>Before you begin, make sure that you have logged into the <code>ecelinux</code> servers as described in the remote access tutorial. You will need to open a terminal and be ready to work at the Linux command line using VS Code. To follow along with the tutorial, type the commands without the <code>%</code> character. In addition to working through the commands in the tutorial, you should also try the more open-ended activities.</p> <p>Before you begin, make sure that you have sourced the <code>setup-ece6745.sh</code> script as described in the remote access tutorial. Sourcing the setup script sets up the environment required for this tutorial.</p>"},{"location":"ece6745-tut01-linux/#1-the-linux-command-line","title":"1. The Linux Command Line","text":"<p>In this section, we introduce the basics of working at the Linux command line. Our goal is to get you comfortable with commands required to complete the laboratory assignments. The shell is the original Linux user interface which is a text-based command-line interpreter. The default shell on the <code>ecelinux</code> machines is Bash. While there are other shells such as <code>sh</code>, <code>csh</code>, and <code>tcsh</code>, for this course we will always assume you are using Bash. As mentioned above, we use the <code>%</code> character to indicate commands that should be entered at the Linux command line, but you should not include the actual <code>%</code> character when typing in the commands on your own. To make it easier to cut-and-paste commands from this tutorial document onto the command line, you can tell Bash to ignore the <code>%</code> character using the following command:</p> <pre><code>% alias %=\"\"\n</code></pre> <p>Now you can cut-and-paste a sequence of commands from this tutorial document and Bash will not get confused by the <code>%</code> character which begins each line.</p>"},{"location":"ece6745-tut01-linux/#11-hello-world","title":"1.1. Hello World","text":"<p>We begin with the ubiquitous \"Hello, World\" example. To display the message \"Hello, World\" we will use the <code>echo</code> command. The <code>echo</code> command simply \"echoes'' its input to the console.</p> <pre><code>% echo \"Hello, World\"\n</code></pre> <p>The string we provide to the <code>echo</code> command is called a \\IT{command   line argument}. We use command line arguments to tell commands what they should operate on. Although simple, the <code>echo</code> command can very useful for creating simple text files, displaying environment variables, and general debugging.</p> <p>Activity 1: Experiment with <code>echo</code></p> <p>Experiment with using the <code>echo</code> command to display different messages.</p>"},{"location":"ece6745-tut01-linux/#12-manual-pages","title":"1.2. Manual Pages","text":"<p>You can learn more about any Linux command by using the <code>man</code> command. Try using this to learn more about the <code>echo</code> command.</p> <pre><code>% man echo\n</code></pre> <p>You can use the up/down keys to scroll the manual one line at a time, the space bar to scroll down one page at a time, and the <code>q</code> key to quit viewing the manual. You can even learn about the <code>man</code> command itself by using <code>man man</code>. As you follow the tutorial, feel free to use the <code>man</code> command to learn more about the commands we cover.</p> <p>Activity 2: Experiment with <code>man</code></p> <p>Use the <code>man</code> command to learn more about the <code>cat</code> command.</p>"},{"location":"ece6745-tut01-linux/#13-create-view-and-list-files","title":"1.3. Create, View, and List Files","text":"<p>We can use the <code>echo</code> command and a feature called ecommand output redirection to create simple text files. We will discuss command output redirection in more detail later in the tutorial. Command output redirection uses the <code>&gt;</code> operator to take the output from one command and \"redirect\" it to a file. The following commands will create a new file named <code>ece6745-tut01.txt</code> that simply contains the text \"Complex Digital ASIC Design\"</p> <pre><code>% echo \"Complex Digital ASIC Design\" &gt; ece6745-tut01.txt\n</code></pre> <p>We can use the <code>cat</code> command to quickly display the contents of a file.</p> <pre><code>% cat ece6745-tut01.txt\n</code></pre> <p>For larger files, <code>cat</code> will output the entire file to the console so it may be hard to read the file as it streams past. We can use the <code>less</code> command to show one screen-full of text at a time. You can use the up/down keys to scroll the file one line at a time, the space bar to scroll down one page at a time, and the <code>q</code> key to quit viewing the file.</p> <pre><code>% less ece6745-tut01.txt\n</code></pre> <p>You can use the <code>ls</code> command to list the filenames of the files you have created.</p> <pre><code>% ls\n</code></pre> <p>We can provide command line options to the <code>ls</code> command to modify the command's behavior. For example, we can use the <code>-1</code> (i.e., a dash followed by the number one) command line option to list one file per line, and we can we can use the <code>-l</code> (i.e., a dash followed by the letter l) command line option to provide a longer listing with more information about each file.</p> <pre><code>% ls -1\n% ls -l\n</code></pre> <p>You should see the newly created <code>ece6745-tut01.txt</code> file along with some additional directories or folders. We will discuss directories in the next section. Use the following commands to create a few more files using the <code>echo</code> command and command output redirection, and then list the files again.</p> <pre><code>% echo \"Application\" &gt; ece6745-tut01-layer1.txt\n% echo \"Algorithm\"   &gt; ece6745-tut01-layer2.txt\n% ls -1\n</code></pre> <p>Activity 3: Create New File</p> <p>Create a new file named <code>ece6745-tut01-layer3.txt</code> which contains the third layer in the computing systems stack (i.e., programming language). Use <code>cat</code> and <code>less</code> to verify the file contents.</p>"},{"location":"ece6745-tut01-linux/#14-create-change-and-list-directories","title":"1.4. Create, Change, and List Directories","text":"<p>Obviously, having all files in a single location would be hard to manage effectively. We can use directories (also called folders) to logically organize our files, just like one can use physical folders to organize physical pieces of paper. The mechanism for organizing files and directories is called the file system. When you first login to an <code>ecelinux</code> machine, you will be in your home directory. This is your own private space on the server that you can use to work on the laboratory assignments and store your files. You can use the <code>pwd</code> command to print the directory in which you are currently working, which is known as the current working directory.</p> <pre><code>% pwd\n/home/netid\n</code></pre> <p>You should see output similar to what is shown above, but instead of <code>netid</code> it should show your actual NetID. The <code>pwd</code> command shows a directory path. A directory path is a list of nested directory names; it describes a \"path\" to get to a specific file or directory. So the above path indicates that there is a toplevel directory named <code>home</code> that contains a directory named <code>netid</code>. This is the directory path to your home directory. As an aside, notice that Linux uses a forward slash (<code>/</code>) to separate directories, while Windows uses a back slash (<code>\\</code>) for the same purpose.</p> <p>We can use the <code>mkdir</code> command to make new directories. The following command will make a new directory named <code>ece6745</code> within your home directory.</p> <pre><code>% mkdir ece6745\n</code></pre> <p>We can use the <code>cd</code> command to change our current working directory. The following command will change the current working directory to be the newly created <code>ece6745</code> directory, before displaying the current working directory with the <code>pwd</code> command.</p> <pre><code>% cd ece6745\n% pwd\n/home/netid/ece6745\n</code></pre> <p>Use the <code>mkdir</code>, <code>cd</code>, and <code>pwd</code> commands to make another directory.</p> <pre><code>% mkdir tut01\n% cd tut01\n% pwd\n/home/netid/ece6745/tut01\n</code></pre> <p>We sometimes say that <code>tut01</code> is a subdirectory or a child directory of the <code>ece6745</code> directory. We might also say that the <code>ece6745</code> directory is the parent directory of the <code>tut01</code> directory.</p> <p>There are some important shortcuts that we can use with the <code>cd</code> command to simplify navigating the file system. The special directory named <code>.</code> (i.e., one dot) always refers to the current working directory. The special directory named <code>..</code> (i.e., two dots) always refers to the parent of the current working directory. The special directory named <code>~</code> (i.e., a tilde character) always refers to your home directory. The special directory named <code>/</code> (e.g., single forward slash) always refers to the highest-level root directory. The following commands illustrate how to navigate up and down the directory hierarchy we have just created.</p> <pre><code>% pwd\n/home/netid/ece6745/tut01\n% cd .\n% pwd\n/home/netid/ece6745/tut01\n% cd ..\n% pwd\n/home/netid/ece6745\n% cd ..\n% pwd\n/home/netid\n% cd ece6745/tut01\n% pwd\n/home/netid/ece6745/tut01\n% cd\n% pwd\n/home/netid\n% cd /\n% pwd\n/\n% cd ~/ece6745\n% pwd\n/home/netid/ece6745\n</code></pre> <p>Notice how we can use the <code>cd</code> command to change the working directory to another arbitrary directory by simply using a directory path (e.g., <code>ece6745/tut01</code>). These are called relative paths because the path is relative to your current working directory. You can also use an absolute path which always starts with the root directory to concretely specify a directory irrespective of the current working directory. A relative path is analogous to directions to reach a destination from your current location (e.g., How do I get to the coffee shop from my current location?), while an absolute path is analogous to directions to reach a destination from a centralized location (e.g., How do I get to the coffee shop from the center of town?).</p> <pre><code>% pwd\n/home/netid/ece6745\n% cd /home/netid/ece6745/tut01\n% pwd\n/home/netid/ece6745/tut01\n% cd\n% pwd\n/home/netid\n</code></pre> <p>This example illustrates one more useful shortcut. The <code>cd</code> command with no command line arguments always changes the current working directory to your home directory. We can use the <code>ls</code> command to list files as well as directories. Use the following commands to create a new file and directory in the <code>ece6745/tut01</code> subdirectory, and then list the file and directory.</p> <pre><code>% cd ~/ece6745/tut01\n% echo \"Computer Systems Programming\" &gt; ece6745-tut01.txt\n% mkdir dirA\n% ls -1\n</code></pre> <p>You should see both the <code>dirA</code> subdirectory and the newly created <code>ece6745-tut01.txt</code> file listed. Feel free to use the <code>cat</code> command to verify the file contents of the newly created file. We can use the <code>tree</code> command to recursively list the contents of a directory. The following commands create a few more directories before displaying the directory hierarchy.</p> <pre><code>% cd ~/ece6745/tut01\n% mkdir -p dirB/dirB_1\n% mkdir -p dirB/dirB_2\n% mkdir -p dirC/dirC_1\n% cd ~/ece6745/tut01\n% tree\n.\n+-- dirA\n+-- dirB\n|   |-- dirB_1\n|   `-- dirB_2\n|-- dirC\n|   `-- dirC_1\n`-- ece6745-tut01.txt\n</code></pre> <p>Note that we are using the <code>-p</code> command line option with the <code>mkdir</code> command to make multiple nested directories in a single step.</p> <p>Activity 4: Creatring Directories and Files</p> <p>Experiment with creating additional directories and files within the <code>ece6745/tut01</code> subdirectory. Try creating deeper hierarchies with three or even four levels of nesting using the <code>-p</code> option to the <code>mkdir</code> command. Experiment with using the <code>.</code> and <code>..</code> special directories. Use the <code>tree</code> command to display your newly created directory hierarchy.</p>"},{"location":"ece6745-tut01-linux/#15-copy-move-and-remove-files-and-directories","title":"1.5. Copy, Move, and Remove Files and Directories}","text":"<p>We can use the <code>cp</code> command to copy files. The first argument is the name of the file you want to copy, and the second argument is the new name to give to the copy. The following commands will make two copies of the files we created in the previous section.</p> <pre><code>% cd ~/ece6745/tut01\n% cp ece6745-tut01.txt ece6745-tut01-a.txt\n% cp ece6745-tut01.txt ece6745-tut01-b.txt\n% ls -1\n</code></pre> <p>We can also copy one or more files into a subdirectory by using multiple source files and a final destination directory as the arguments to the <code>cp</code> command.</p> <pre><code>% cd ~/ece6745/tut01\n% cp ece6745-tut01.txt dirA\n% cp ece6745-tut01-a.txt ece6745-tut01-b.txt dirA\n% tree\n</code></pre> <p>We can use the <code>-r</code> command line option to enable the <code>cp</code> command to recursively copy an entire directory.</p> <pre><code>% cd ~/ece6745/tut01\n% tree\n% cp -r dirA dirD\n% tree\n</code></pre> <p>If we want to move a file or directory, we can use the <code>mv</code> command. As with the <code>cp</code> command, the first argument is the name of the file you want to move and the second argument is the new name of the file.</p> <pre><code>% cd ~/ece6745/tut01\n% mv ece6745-tut01.txt ece6745-tut01-c.txt\n% ls -1\n</code></pre> <p>Again, similar to the <code>cp</code> command, we can also move one or more files into a subdirectory by using multiple source files and a final destination directory as the arguments to the <code>mv</code> command.</p> <pre><code>% cd ~/ece6745/tut01\n% tree\n% mv ece6745-tut01-a.txt dirB\n% mv ece6745-tut01-b.txt ece6745-tut01-c.txt dirB\n% tree\n</code></pre> <p>We do not need to use the <code>-r</code> command line option to move an entire directory at once.</p> <pre><code>% cd ~/ece6745/tut01\n% tree\n% mv dirD dirE\n% tree\n</code></pre> <p>The following example illustrates how we can use the special <code>.</code> directory to move files from a subdirectory into the current working directory.</p> <pre><code>% cd ~/ece6745/tut01\n% tree\n% mv dirE/ece6745-tut01.txt .\n% tree\n</code></pre> <p>We can use the <code>rm</code> command to remove files. The following command removes a file from within the <code>ece6745/tut01</code> subdirectory.</p> <pre><code>% cd ~/ece6745/tut01\n% ls -1\n% rm ece6745-tut01.txt\n% ls -1\n</code></pre> <p>To clean up, we might want to remove the files we created in your home directory earlier in this tutorial.</p> <pre><code>% cd\n% rm ece6745-tut01.txt\n% rm ece6745-tut01-layer1.txt\n% rm ece6745-tut01-layer2.txt\n% rm ece6745-tut01-layer3.txt\n</code></pre> <p>We can use the <code>-r</code> command line option with the <code>rm</code> command to remove entire directories, but please be careful because it is relatively easy to permanently delete many files at once. See Section 2.3 for a useful command that you might want to use instead of the <code>rm</code> command to avoid accidentally deleting important work.</p> <pre><code>% cd ~/ece6745/tut01\n% ls -1\n% rm -r dirA dirB dirC dirE\n% ls -1\n</code></pre> <p>Activity 5: Copy, Move, and Remove Directories and Files</p> <p>Creating additional directories and files within the <code>ece6745/tut01</code> subdirectory, and then use the <code>cp</code>, <code>mv</code>, and <code>rm</code> commands to copy, move, and remove the newly created directories and files. Use the <code>ls</code> and <code>tree</code> commands to display your file and directory organization.</p>"},{"location":"ece6745-tut01-linux/#16-using-wget-to-download-files","title":"1.6. Using <code>wget</code> to Download Files","text":"<p>We can use the <code>wget</code> command to download files from the internet. For now, this is a useful way to retrieve a text file that we can use in the following examples.</p> <pre><code>% cd ~/ece6745/tut01\n% wget http://www.csl.cornell.edu/courses/ece6745/overview.txt\n% cat overview.txt\n</code></pre>"},{"location":"ece6745-tut01-linux/#17-using-grep-to-search-files","title":"1.7. Using <code>grep</code> to Search Files","text":"<p>We can use the <code>grep</code> command to search and display lines of a file that contain a particular pattern. The <code>grep</code> command can be useful for quickly searching the contents of the source files in your laboratory assignments. The command takes the pattern and the files to search as command line arguments. The following command searches \"chip\" in the <code>overview.txt</code> file downloaded in the previous section.</p> <pre><code>% cd ~/ece6745/tut01\n% grep \"chip\" overview.txt\n</code></pre> <p>You should see just the lines within the <code>overview.txt</code> file that contain the words \"digital logic\". We can use the <code>--line-number</code> command line option with the <code>grep</code> command to display the line number of each match.</p> <pre><code>% cd ~/ece6745/tut01\n% grep --line-number \"chip\" overview.txt\n</code></pre> <p>We can use the <code>-r</code> command line option to recursively search all files within a given directory hierarchy. In the following example, we create a subdirectory, copy the <code>overview.txt</code> file, and illustrate how we can use the <code>grep</code> command to recursively search for the word \"digital logic\".</p> <pre><code>% cd ~/ece6745/tut01\n% mkdir dirA\n% cp overview.txt dirA\n% grep -r --line-number \"chip\" .\n</code></pre> <p>Notice how we specify a directory as a command line argument (in this case the special <code>.</code> directory) to search the current working directory. You should see the three lines from both copies of the <code>overview.txt</code> file. The <code>grep</code> command also shows which file contains the match.</p> <p>As another example, we will search two special files named <code>/proc/cpuinfo</code> and <code>proc/meminfo</code>. These files are present on every modern Linux system, and they contain information about the processor and memory hardware in that system. The following command first uses the <code>less</code> command so you can browse the file, and then uses the <code>grep</code> command to search for <code>processor</code> in the <code>/proc/cpuinfo</code> file. Recall that with the <code>less</code> command, we use the up/down keys to scroll the file one line at a time, the space bar to scroll down one page at a time, and the <code>q</code> key to quit viewing the file.</p> <pre><code>% cd ~/ece6745/tut01\n% less /proc/cpuinfo\n% grep \"processor\" /proc/cpuinfo\n</code></pre> <p>It should be pretty clear that you are using a system with multiple processors. You can also search to find out which company makes the processors and what clock frequency they are running at:</p> <pre><code>% cd ~/ece6745/tut01\n% grep \"vendor_id\" /proc/cpuinfo\n% grep \"cpu MHz\" /proc/cpuinfo\n</code></pre> <p>We can find out how much memory is in the system by searching for <code>MemTotal</code> in the <code>/proc/meminfo</code> file.</p> <pre><code>% cd ~/ece6745/tut01\n% grep \"MemTotal\" /proc/meminfo\n</code></pre> <p>Activity 6: Experimenting with <code>grep</code></p> <p>Try using <code>grep</code> to search for the words \"computer\" in the <code>overview.txt</code> file.</p>"},{"location":"ece6745-tut01-linux/#18-using-find-to-find-files","title":"1.8. Using <code>find</code> to Find Files","text":"<p>We can use the <code>find</code> command to recursively search a directory hierarchy for files or directories that match a specified criteria. While the <code>grep</code> command is useful for searching file contents, the <code>find</code> command is useful for quickly searching the file and directory names in your laboratory assignments. The <code>find</code> command is very powerful, so we will just show a very simple example. First, we create a few new files and directories.</p> <pre><code>% cd ~/ece6745/tut01\n% mkdir -p dirB/dirB_1\n% mkdir -p dirB/dirB_2\n% mkdir -p dirC/dirC_1\n% echo \"test\" &gt; dirA/file0.txt\n% echo \"test\" &gt; dirA/file1.txt\n% echo \"test\" &gt; dirB/dirB_1/file0.txt\n% echo \"test\" &gt; dirB/dirB_1/file1.txt\n% echo \"test\" &gt; dirB/dirB_2/file0.txt\n% tree\n</code></pre> <p>We will now use the <code>find</code> command to find all files named <code>file0.txt</code>. The <code>find</code> command takes one command line argument to specify where we should search and a series of command line options to describe what files and directories we are trying to find. We can also use command line options to describe what action we would like to take when we find the desired files and directories. In this example, we use the <code>--name</code> command line option to specify that we are searching for files with a specific name. We can also use more complicated patterns to search for all files with a specific filename prefix or extension.</p> <pre><code>% cd ~/ece6745/tut01\n% find . -name \"file0.txt\"\n</code></pre> <p>Notice that we are using the special <code>.</code> directory to tell the <code>find</code> command to search the current working directory and all subdirectories. The <code>find</code> command always searches recursively.</p> <p>Activity 7: Experimenting with <code>find</code></p> <p>Create additional files named <code>file2.txt</code> in some of the subdirectories we have already created. Use the <code>find</code> command to search for files named <code>file2.txt</code>.</p>"},{"location":"ece6745-tut01-linux/#19-using-tar-to-archive-files","title":"1.9. Using <code>tar</code> to Archive Files","text":"<p>We can use the <code>tar</code> command to \"pack\" files and directories into a simple compressed archive, and also to \"unpack\" these files and directories from the archive. This kind of archive is sometimes called a tarball. Most open-source software is distributed in this compressed form. It makes it easy to distribute code among collaborators and it is also useful to create backups of files. We can use the following command to create an archive of our tutorial directory and then remove the tutorial directory.</p> <pre><code>% cd ~/ece6745\n% tar -czvf tut01.tgz tut01\n% rm -r tut01\n% ls -l\n</code></pre> <p>Several command line options listed together as a single option (<code>-czvf</code>), where <code>c</code> specifies we want to create an archive, <code>z</code> specifies we should use \"gzip\" compression, <code>v</code> specifies verbose mode, and <code>f</code> specifies we will provide filenames to archive. The first command line argument is the name of the archive to create, and the second command line argument is the directory to archive. We can now extract the contents of the archive to recreate the tutorial directory. We also remove the archive.</p> <pre><code>% cd ~/ece6745\n% tar -xzvf tut01.tgz\n% rm tut01.tgz\n% tree tut01\n</code></pre> <p>Note that we use the <code>x</code> command line option with the <code>tar</code> command to specify that we intend to extract the archive.</p> <p>Activity 8: Experimenting with <code>tar</code></p> <p>Create an example directory within the <code>ece6745/tut01</code> subdirectory. Copy the <code>overview.txt</code> file and rename it to add example files to your new directory. Use the <code>tar</code> command to create and extract an archive of just this one new directory.</p>"},{"location":"ece6745-tut01-linux/#110-using-top-to-view-running-processes","title":"1.10. Using <code>top</code> to View Running Processes","text":"<p>You can use the <code>top</code> command to view what commands are currently running on the Linux system in realtime. This can be useful to see if there are many commands running which are causing the system to be sluggish. When finished you can use the <code>q</code> character to quit.</p> <pre><code>% top\n</code></pre> <p>The first line of the <code>top</code> display shows the number of users currently logged into the system, and the load average. The load average indicates how \"overloaded\" the system was over the last one, five, and 15 minutes. If the load average is greater than the number of processors in the system, it means your system will probably be sluggish. You can always try logging out and then back into the <code>ecelinux</code> servers to see if you get assigned to a different server in the cluster.</p>"},{"location":"ece6745-tut01-linux/#111-environment-variables","title":"1.11. Environment Variables","text":"<p>In the previous sections, we have been using the Bash shell to run various commands, but the Bash shell is actually a full-featured programming language. One aspect of the shell that is similar in spirit to popular programming languages, is the ability to write and read environment variables. The following commands illustrate how to write an environment variable named <code>ece6745_tut01_layer1</code>, and how to read this environment variable using the <code>echo</code> command.</p> <pre><code>% ece6745_tut01_layer1=\"application\"\n% echo ${ece6745_tut01_layer1}\n</code></pre> <p>Keep in mind that the names of environment variables can only contain letters, numbers, and underscores. Notice how we use the <code>${}</code> syntax to read an environment variable. There are a few built-in environment variables that might be useful:</p> <pre><code>% echo ${HOSTNAME}\n% echo ${HOME}\n% echo ${PWD}\n</code></pre> <p>We often use the <code>HOME</code> environment variable in directory paths like this:</p> <pre><code>% cd ${HOME}/ece6745\n</code></pre> <p>The <code>PWD</code> environment variable always holds the current working directory. We can use environment variables as options to commands other than <code>echo</code>. A common example is to use an environment variable to \"remember\" a specific directory location, which we can quickly return to with the <code>cd</code> command like this:</p> <pre><code>% cd ${HOME}/ece6745/tut01\n% TUT01=${PWD}\n% cd\n% pwd\n/home/netid\n% cd ${TUT01}\n% pwd\n/home/netid/ece6745/tut01\n</code></pre> <p>Activity 9: Experimenting with Environment Variables</p> <p>Create a new environment variable named <code>ece6745_tut01_layer2</code> and write it with the second layer in the computer systems stack (i.e., algorithm). Use the <code>echo</code> command to display this environment variable. Experiment with creating a new subdirectory within <code>ece6745/tut01</code> and then using an environment variable to \"remember\" that location.</p>"},{"location":"ece6745-tut01-linux/#112-command-output-redirection","title":"1.12. Command Output Redirection","text":"<p>We have already seen using the <code>echo</code> command and command output redirection to create simple text files. Here is another example:</p> <pre><code>% cd ${HOME}/ece6745/tut01\n% echo \"Application\" &gt; computing-stack.txt\n% cat computing-stack.txt\n</code></pre> <p>The <code>&gt;</code> operator tells the Bash shell to take the output from the command on the left and overwrite the file named on the right. We can use any command on the left. For example, we can save the output from the <code>pwd</code> command or the <code>man</code> command to a file for future reference.</p> <pre><code>% cd ${HOME}/ece6745/tut01\n% pwd &gt; cmd-output.txt\n% cat cmd-output.txt\n% man pwd &gt; cmd-output.txt\n% cat cmd-output.txt\n</code></pre> <p>We can also use the <code>&gt;&gt;</code> operator which tells the Bash shell to take the output from the command on the left and append the file named on the right. We can use this to create multiline text files:</p> <pre><code>% cd ${HOME}/ece6745/tut01\n% echo \"Application\"           &gt; computing-stack.txt\n% echo \"Algorithm\"            &gt;&gt; computing-stack.txt\n% echo \"Programming Language\" &gt;&gt; computing-stack.txt\n% echo \"Operating System\"     &gt;&gt; computing-stack.txt\n% cat computing-stack.txt\n</code></pre> <p>Activity 10: Experimenting with Output Redirection</p> <p>Add the remaining levels of the computing stack (i.e., compiler, instruction-set architecture, microarchitecture, register-transfer-level, gate-level, circuits, devices, technology) to the <code>computing-stack.txt</code> text file. Use the <code>cat</code> command to verify the file contents.</p>"},{"location":"ece6745-tut01-linux/#113-command-chaining","title":"1.13. Command Chaining","text":"<p>We can use the <code>&amp;&amp;</code> operator to specify two commands that we want to chaining together. The second command will only execute if the first command succeeds. Below is an example.</p> <pre><code>% cd ${HOME}/ece6745/tut01 &amp;&amp; cat computing-stack.txt\n</code></pre> <p>Activity 11: Experimenting with Command Chaining</p> <p>Create a single-line command that combines creating a new directory with the <code>mkdir</code> command and then immediately changes into the directory using the <code>cd</code> command.</p>"},{"location":"ece6745-tut01-linux/#114-command-pipelining","title":"1.14. Command Pipelining","text":"<p>The Bash shell allows you to run multiple commands simultaneously, with the output of one command becoming the input to the next command. We can use this to assemble \"pipelines\"; we \"pipe\" the output of one command to another command for further actions using the <code>|</code> operator.</p> <p>The following example uses the <code>grep</code> command to search the special <code>proc/cpuinfo</code> file for lines containing the word \"processor\" and then pipes the result to the <code>wc</code> command. The <code>wc</code> command counts the number of characters, words, or lines of its input. We use the <code>-l</code> command line option with the <code>wc</code> command to count the number of lines.</p> <pre><code>% grep processor /proc/cpuinfo | wc -l\n</code></pre> <p>This is a great example of the Linux philosophy of providing many simple commands that can be combined to create more powerful functionality. Essentially the pipeline we have created is a command that tells us the number of processors in our system.</p> <p>As another example, we will pipe the output of the <code>last</code> command to the <code>grep</code> command. The <code>last</code> command lists the names of all of the users that have logged into the system since the system was rebooted. We can use <code>grep</code> to search for your NetID and thus quickly see how when you previously have logged into this system.</p> <pre><code>% last | grep netid\n</code></pre> <p>We can create even longer pipelines. The following pipeline will report the number of times you have logged into the system since it was rebooted.</p> <pre><code>% last | grep netid | wc -l\n</code></pre> <p>Activity 12: Experimenting with Command Pipelines</p> <p>Use the <code>cat</code> command with the <code>overview.txt</code> file and pipe the output to the <code>grep</code> command to search for the word \"\"memories\". While this is not as fast as using <code>grep</code> directly on the file, it does illustrate how many commands (e.g., <code>grep</code>) can take their input specified as a command line argument or through a pipe.</p>"},{"location":"ece6745-tut01-linux/#114-bash-shell-scripts","title":"1.14. Bash Shell Scripts","text":"<p>If you find yourself continually having to use the same complex commands over and over, consider creating a Bash shell script to automatically execute those commands. A Bash shell script is just a text file with a list of commands that you can run using the <code>source</code> command.</p> <p>For example, let's create a Bash shell script to automatically grep for information about the processor and memory in a single step. Use VS Code to open a new file called <code>get-processor-memory-info.sh</code> (note that by convention we usually use the <code>.sh</code> extension for Bash shell scripts).</p> <pre><code>% cd ${HOME}/ece6745/tut01\n% code get-processor-memory-info.sh\n</code></pre> <p>Then enter the following commands into this new Bash shell script.</p> <pre><code>grep \"processor\" /proc/cpuinfo\ngrep \"vendor_id\" /proc/cpuinfo\ngrep \"cpu MHz\"   /proc/cpuinfo\ngrep \"MemTotal\"  /proc/meminfo\n</code></pre> <p>Then save the Bash shell script and execute it using the <code>source</code> command.</p> <pre><code>% cd ${HOME}/ece6745/tut01\n% source get-processor-memory-info.sh\n</code></pre> <p>Activity 13: Experimenting with Bash Shell Scripts</p> <p>Create a new Bash shell script named <code>wget-and-grep.sh</code>. The Bash shell script should use <code>wget</code> to get the <code>overview.txt</code> file for the course and then uses grep to find instances of the word \"chip\" in this file. See earlier examples in this tutorial for the commands required for both steps. Then use <code>source</code> to execute the new Bash shell script.</p>"},{"location":"ece6745-tut01-linux/#115-aliases-wildcards-command-history-and-tab-completion","title":"1.15. Aliases, Wildcards, Command History, and Tab Completion","text":"<p>In this section, we describe some miscellaneous features of the Bash shell which can potentially be quite useful in increasing your productivity.</p> <p>Aliases are a way to create short names for command sequences to make it easier to quickly execute those command sequences in the future. For example, assume that you frequently want to change to a specific directory. We can create an alias to make this process take just two keystrokes.</p> <pre><code>% alias ct=\"cd ${HOME}/ece6745/tut01\"\n% ct\n% pwd\n/home/academic/netid/ece6745/tut01\n</code></pre> <p>If you always want this alias to be available whenever you login to the system, you can save it in your <code>.bashrc</code> file. The <code>.bashrc</code> is a special Bash script that is run on every invocation of a Bash shell.</p> <pre><code>% echo \"alias ct=\\\"cd ${HOME}/ece6745/tut01\\\"\" &gt;&gt; ${HOME}/.bashrc\n</code></pre> <p>The reason we have to use a back slash (<code>\\</code>) in front of the double quotes is to make sure the <code>echo</code> command sees this command line argument as one complete string.</p> <p>Wildcards make it easy to manipulate many files and directories at once. Whenever we specify a file or directory on the command line, we can often use a wildcard instead. In a wildcard, the asterisk (<code>*</code>) will match any sequence of characters. The following example illustrates how to list all files that end in the suffix <code>.txt</code> and then copies all files that match the wildcard from one directory to another.</p> <pre><code>% cd ${HOME}/ece6745/tut01\n% ls *.txt\n% cp dirA/file*.txt dirB\n% tree\n</code></pre> <p>The Bash shell keeps a history of everything you do at the command line. You can display the history with the <code>history</code> command. To rerun a previous command, you can use the <code>!</code> operator and the corresponding command number shown with the <code>history</code> command.</p> <pre><code>% history\n</code></pre> <p>You can pipe the output of the <code>history</code> command to the <code>grep</code> command to see how you might have done something in the past.</p> <pre><code>% history | grep wc\n</code></pre> <p>If you press the up arrow key at the command line, the Bash shell will show you the previous command you used. Continuing to press the up/down keys will enable you to step through your history. It is very useful to press the up arrow key once to rerun your last command.</p> <p>The Bash shell supports tab completion. When you press the tab key twice after entering the beginning of a filename or directory name, Bash will try to automatically complete the filename or directory name. If there is more than one match, Bash will show you all of these matches so you can continue narrowing your search.</p>"},{"location":"ece6745-tut01-linux/#2-course-specific-linux-commands","title":"2. Course-Specific Linux Commands","text":"<p>In this section, we describe various aspects of the development environment that are specific to the severs used in the course.</p>"},{"location":"ece6745-tut01-linux/#21-course-setup-script","title":"2.1. Course Setup Script","text":"<p>As discussed in the remote access tutorial, the very first thing you need to do after logging into the <code>ecelinux</code> servers is source the course setup script. This will ensure your environment is setup with everything you need for working on the laboratory assignments. Enter the following command on the command line:</p> <pre><code>% source setup-ece6745.sh\n</code></pre> <p>You should now see <code>ECE 6745</code> in your prompt which means your environment is setup for the course.</p> <p>It can be tedious to always remember to source the course setup script. You can also use auto setup which will automatically source the course setup for you when you open a terminal. Note that if the environment for ECE 6745 conflicts with the environment required by a different course then you will need to manually source the setup script when you are working on this course. Enter the following command on the command line to use auto setup:</p> <pre><code>% source setup-ece6745.sh --enable-auto-setup\n</code></pre> <p>Now close the terminal and log out completely from the <code>ecelinux</code> servers. Log back in and you should see <code>ECE 6745</code> in the prompt meaning your environment is automatically setup for the course. If at anytime you need to disable auto setup you can use the following command:</p> <pre><code>% source setup-ece6745.sh --disable-auto-setup\n</code></pre> <p>Again, if for any reason running the setup script prevents you from using tools for another course, you cannot use the auto setup. You will need to run the setup script manually every time you want to work on this course.</p>"},{"location":"ece6745-tut01-linux/#22-using-quota-to-check-your-space-usage","title":"2.2. Using <code>quota</code> to Check Your Space Usage","text":"<p>Students are allocated 10GB of storage on the servers. You can use the following command to show much space you are using:</p> <pre><code>% quota -s\n</code></pre> <p>The <code>blocks</code> column is how much data you are using, and the <code>quota</code> column is your quota. If you have exceed the 10GB quota, you can browse your home directory and list the size of files and the contents of directories with the <code>du</code> command:</p> <pre><code>% cd ${HOME}\n% du -sh *\n</code></pre> <p>By recursively changing directories and examining the sizes of files and directories you can figure out what you need to delete. We can pipe the output of <code>du</code> to the <code>sort</code> and <code>head</code> commands to find the top 20 largest files and directories like this:</p> <pre><code>% cd ${HOME}\n% du -xak . | sort -nr | head --lines=20\n</code></pre> <p>Or just use the following to generate a human readable summary of the size of files/directories in the current working directory. Note that it can take 20--30 seconds for this command to finish, so please be patient.</p>"},{"location":"ece6745-tut01-linux/#23-using-trash-to-safely-remove-files","title":"2.3. Using <code>trash</code> to Safely Remove Files","text":"<p>We have installed a simple program called <code>trash</code> which moves files you wish to delete into a special subdirectory of your home directory located at <code>${HOME}/tmp/trash</code>. The following commands create a file and then deletes it using <code>trash</code>.</p> <pre><code>% cd ${HOME}\n% echo \"This file will be deleted.\" &gt; testing.txt\n% trash testing.txt\n% echo \"This file will also be deleted.\" &gt; testing.txt\n% trash testing.txt\n% ls ${HOME}/tmp/trash\n</code></pre> <p>If you look in <code>${HOME}/tmp/trash</code> you will see subdirectories organized by date. Look in the subdirectory with today's date and you should two files corresponding to the two files you deleted. We highly recommend always using the <code>trash</code> command instead of <code>rm</code> since this avoids accidentally deleting your work.</p>"},{"location":"ece6745-tut02-git/","title":"Tutorial 2: Git Distributed Version Control System","text":"<p>In this course, we will be using Git as our revision control and source code management system. We will be using GitHub for centralized online repository hosting, and GitHub Actions for online continuous integration testing. These tools will enable us to adopt an agile hardware development methodology so your group can rapidly collaborate and iterate on the design, verification, and evaluation of the lab assignments. This tutorial covers how to: setup your GitHub account, use Git for basic incremental development, use GitHub to collaborate with your group, manage Git branches and GitHub pull requests, and use GitHub actions. This tutorial assumes that you have completed the remote access and Linux tutorials.</p> <p>Before you begin, make sure that you have logged into the <code>ecelinux</code> servers as described in the remote access tutorial. You will need to open a terminal and be ready to work at the Linux command line using VS Code. To follow along with the tutorial, type the commands without the <code>%</code> character. In addition to working through the commands in the tutorial, you should also try the more open-ended activities.</p> <p>Before you begin, make sure that you have sourced the setup-ece6745.sh script or that you have enabled auto setup. Sourcing the setup script sets up the environment required for this tutorial.</p>"},{"location":"ece6745-tut02-git/#1-setting-up-your-github-account","title":"1. Setting up Your GitHub Account","text":"<p>GitHub is an online service that hosts centralized Git repositories for a growing number of open-source projects. It has many useful features including a web-based source browser, history browser, branch management, merge requests, code review, issue tracking, and even a built-in wiki attached to every repository. We have created a dedicated GitHub organization for the course located here:</p> <ul> <li>https://github.com/cornell-ece6745</li> </ul> <p>The course staff will add all officially registered students to the course organization. For most of this tutorial you will be using a public repository in your own personal GitHub account, but you will be using a private repository in our course GithHub organization for all of your lab assignments. Note that we will not be using the version of GitHub hosted at Cornell We will instead be using the public version of GitHub at <code>github.com</code>. You can check to see if you have a GitHub account on the public version of GitHub here:</p> <ul> <li>https://github.com/githubid</li> </ul> <p>where <code>githubid</code> is your GitHub username on the public version of GitHub. You must replace <code>githubid</code> with your real GitHub username for this link to work! If the above link still does not work, then you do not have an account on the public version of GitHub. You will need to create one here:</p> <ul> <li>https://github.com/join</li> </ul> <p>Your NetID makes a great GitHub username. If you are creating a new GitHub account, then be sure to use your Cornell email address. If you have an existing account it is fine for it to use a non-Cornell email address. Once your account is setup, please make sure you set your full name so we can know who you are on GitHub. Please also consider uploading a profile photo to GitHub; it makes it more fun to interact on GitHub if we all know what each other look like. Go to the following page and enter your first and last name in the Name field, and then consider uploading a profile photo.</p> <ul> <li>https://github.com/settings/profile</li> </ul> <p>Once you have a GitHub username, please fill out the following form on Canvas so the instructors know the mapping from your NetID to your GitHub username.</p> <ul> <li>http://www.csl.cornell.edu/courses/ece6745/githubid</li> </ul> <p>Before you can begin using GitHub, you need to create an SSH key pair on an <code>ecelinux</code> machine and upload the corresponding SSH public key to GitHub. GitHub uses these keys for authentication. The course setup script takes care of creating an SSH key pair which you can use. Login to an <code>ecelinux</code> machine, source the course setup script, and then view the contents of your public key using the following commands:</p> <pre><code>% source setup-ece6745.sh\n% cat ~/.ssh/ece6745-github.pub\n</code></pre> <p>Use the following page to upload the public key to GitHub:</p> <ul> <li>https://github.com/settings/ssh</li> </ul> <p>Click on New SSH Key, and then cut-and-paste the public key you displayed using <code>cat</code> into the key textbox. Give the key the title \"ece6745-github\". Then click Add SSH key. To test things out try the following on an <code>ecelinux</code> machine.</p> <pre><code>% ssh -T git@github.com\n</code></pre> <p>You may see a warning about the authenticity of the host. Don't worry, this is supposed to happen the first time you access GitHub using your new key. Just enter \"yes\". The GitHub server should output some text including your GitHub username. Verify that the GitHub username is correct, and then you should be all set. There are two good GitHub Guides you might want to take a look at:</p> <ul> <li>https://guides.github.com/activities/hello-world</li> <li>https://guides.github.com/introduction/flow</li> </ul> <p>GitHub has two integrated tools that students might find useful: an issue tracker and a wiki. Consider using the GitHub issue tracker to track bugs you find in your code or to manage tasks required to complete the lab assignment. You can label issues, comment on issues, and attach them to commits. See the following links for more information about GitHub issues:</p> <ul> <li>https://help.github.com/articles/about-issues</li> </ul> <p>Consider using the GitHub per-repository wiki to create task lists, brainstorm design ideas, rapidly collaborate on text for the lab assignment report, or keep useful command/code snippets. See the following links for more information about GitHub wikis:</p> <ul> <li>https://help.github.com/articles/about-github-wikis</li> </ul>"},{"location":"ece6745-tut02-git/#2-git-and-github","title":"2. Git and GitHub","text":"<p>In this section, we begin with a basic single-user workflow before demonstrating how Git and Github can be used for effective collaboration among multiple users. We discuss how to resolve conflicts and how to manage branches and pull requests.</p>"},{"location":"ece6745-tut02-git/#21-single-user-workflow","title":"2.1. Single-User Workflow","text":"<p>In this section, we cover some basic Git commands and illustrate a simple Git workflow. We have created a Git repository that we will be using as an initial template, so the first step is to fork this tutorial repository. Forking is the process of making a personal copy of someone else's repository on GitHub. Start by going to the GitHub page for the tutorial repository located here:</p> <ul> <li>https://github.com/cornell-ece6745/ece6745-tut02-git</li> </ul> <p></p> <p>Click on Fork in the upper right-hand corner. If asked where to fork this repository, choose your personal GitHub account. After a few seconds, you should have a brand new repository in your account:</p> <ul> <li>https://github.com/githubid/ece6745-tut02-git</li> </ul> <p>Where <code>githubid</code> is your GitHub username on the public version of GitHub. Now that you have your own copy of the tutorial repository, the next step is to clone this repository to an <code>ecelinux</code> machine so you can manipulate the content within the repository. We call the repository on GitHub the remote repository and we call the repository on the <code>ecelinux</code> machine the local repository. A local repository is a first-class mirror of the remote repository with the entire history of the repository, and thus almost all operations are essentially local requiring no communication with GitHub. The following commands write an environment variable with your GitHub username, create a subdirectory for this tutorial in your home directory before using the <code>git clone</code> command to clone the remote repository and thus create a local repository.</p> <pre><code>% source setup-ece6745.sh\n% GITHUBID=\"githubid\"\n% mkdir -p ${HOME}/ece6745\n% cd ${HOME}/ece6745\n% git clone git@github.com:${GITHUBID}/ece6745-tut02-git tut02\n% cd tut02\n% TUTROOT=${PWD}\n</code></pre> <p>Where again <code>githubid</code> is your GitHub username on the public version of GitHub. The <code>git clone</code> command takes two command line arguments. The first argument specifies the remote repository on GitHub you would like to clone, and the second argument specifies the name to give to the new local repository. Note that we created an environment variable with the directory path to the local repository to simplify navigating the file system in the rest of this tutorial.</p> <p>The repository currently contains two files: a <code>README</code> file, and <code>overview.txt</code> which contains an overview of the course. These files are contained within what we call the working directory. The repository also includes a special directory named <code>.git</code> which contains all of the extra repository metadata. You should never directly manipulate anything within the <code>.git</code> directory.</p> <pre><code>% cd ${TUTROOT}\n% ls -la\n</code></pre> <p>Let's assume we want to create a new file that contains a list of fruits, and that we want to manage this file using Git version control. First, we create the new file.</p> <pre><code>% cd ${TUTROOT}\n% echo \"apple\" &gt; fruit.txt\n</code></pre> <p>To manage a file using Git, we need to first use the <code>git add</code> command to tell Git that it should track this file from now on. We can then use <code>git commit</code> to commit our changes to this file into the repository, and <code>git log</code> to confirm the result.</p> <pre><code>% cd ${TUTROOT}\n% git add fruit.txt\n% git commit -m \"initial fruit list\"\n% git log\n</code></pre> <p>The <code>-m</code> command line option with the <code>git commit</code> command enables you to specify a commit message that describes this commit. All commit messages should include a \"subject line\" which is a single short line briefly describing the commit. Many commits will just include a subject line (e.g., the above commit). If you want to include more information in your commit message then skip the <code>-m</code> command line option and Git will launch Nano. You still want to include a subject line at the top of your commit message, but now you can include more information separated from the subject line by a blank line.</p> <p>Note, you can learn about any Git command and its usage by typing <code>git help command</code>, where <code>command</code> should be substituted by the actual name of the command. This would display the output similar to the manual pages for a Linux command, as seen in Tutorial 1. Students are encouraged to learn more about each Git command beyond the details covered in this tutorial.</p> <p>The <code>git log</code> command displays information about the commit history. The beginning of the output from <code>git log</code> should look something like this:</p> <pre><code>commit a8ac41ea8dba1371888ec7a2341f79de20521a4d (HEAD -&gt; main)\nAuthor: cb &lt;cb535@cornell.edu&gt;\nDate:   Mon Sep 2 13:17:32 2024 -0400\n\n    initial fruit list\n</code></pre> <p>Conceptually, we should think of each commit as a copy of all of the tracked files in the project at the time of the commit. This commit just included changes to one file, but as we add more files each commit will include more and more information. The history of a git repository is just a long sequence of commits that track how the files in the repository have evolved over time. Notice that Git has recorded the name of who made the commit, the date and time of the commit, and the log message. The first line is the commit id which uniquely identifies this commit. Git does not use monotonically increasing revision numbers like other version control systems, but instead uses a 40-digit SHA1 hash as the commit id. This is a hash of all the files included as part of this commit (not just the changes). We can refer to a commit by the full hash or by just the first few digits as long as we provide enough digits to unambiguously reference the commit. Now let's add a fruit to our list and commit the change.</p> <pre><code>% cd ${TUTROOT}\n% echo \"mango\" &gt;&gt; fruit.txt\n% git commit -m \"added mango to fruit list\"\n</code></pre> <p>Unfortunately, this doesn't work. The output from <code>git commit</code> indicates that there have been no changes since the last commit so there is no need to create a new commit. Git has a concept of an index which is different compared to other version control systems. We must \"stage\" files (really we stage content not files) into the index, and then <code>git commit</code> will commit that content into the repository. We can see this with the <code>git status</code> command.</p> <pre><code>% cd ${TUTROOT}\n% git status\n</code></pre> <p>which should show that <code>fruit.txt</code> is modified but not added to the index. We stage files in the index with <code>git add</code> like this:</p> <pre><code>% cd ${TUTROOT}\n% git add fruit.txt\n% git status\n</code></pre> <p>Now <code>git status</code> should show that the file is modified and also added to the index. Our commit should now complete correctly.</p> <pre><code>% cd ${TUTROOT}\n% git commit -m \"added mango to fruit list\"\n% git status\n</code></pre> <p>So even though Git is tracking <code>fruit.txt</code> and knows it has changed, we still must explicitly add the files we want to commit. You definitely want to avoid using something like <code>git add .</code> to add all files, since this will inevitably end up adding files that you don't really want to commit. There is a short cut which uses the <code>-a</code> command line option with the <code>git commit</code> command. This command line option tells Git to add any file which has changed and was previously added to the repository before doing the commit.</p> <pre><code>% cd ${TUTROOT}\n% echo \"orange\" &gt;&gt; fruit.txt\n% git commit -a -m \"added orange to fruit list\"\n% git status\n</code></pre> <p>Staging files is a useful way to preview what we will commit before we actually do the commit. This helps when we have many changes in our working directory but we don't want to commit them all at once. Instead we might want to break them into smaller, more meaningful commits or we might want to keep working on some of the modified files while committing others.</p> <p>The following figure illustrates how the commands we have used so far create a single-user development workflow. The <code>git clone</code> command copies the remote repository to create a local repository which includes both the working directory and the special <code>.git</code> directory. The <code>git add</code> command adds files to the index from the working directory. The <code>git commit</code> command moves files from the index into the special <code>.git</code> directory. The <code>-a</code> command line option with the <code>git commit</code> command can commit files directly from the working directory to the special <code>.git</code> directory.</p> <p></p> <p>Now that we have made some changes, we can use <code>git log</code> to view the history of last few commits and then add another line to the <code>fruit.txt</code> file.</p> <pre><code>% cd ${TUTROOT}\n% git log\n% echo \"plum\" &gt;&gt; fruit.txt\n% cat fruit.txt\n</code></pre> <p>Imagine you didn't like your changes and want to revert the changes, you would use the <code>git checkout</code> command as below.</p> <pre><code>% cd ${TUTROOT}\n% git checkout fruit.txt\n% cat fruit.txt\n</code></pre> <p>As illustrated in the above single-user development workflow figure, the <code>git checkout</code> command resets any a file or directory to the state it was in at the time of the last commit. The output from the <code>git status</code> command should look something like this:</p> <pre><code>% cd ${TUTROOT}\n% git status\n On branch main\n Your branch is ahead of 'origin/main' by 3 commits.\n   (use \"git push\" to publish your local commits)\n nothing to commit, working directory clean\n</code></pre> <p>The <code>git status</code> command is telling us that the local clone of the repository now has more commits than the remote repository on GitHub. If you visit the GitHub page for this repository you will not see any changes. This is a critical difference from other centralized version control systems. In Git, when we use the <code>git commit</code> command it only commits these changes to your local repository.</p> <p>If we have done some local work that we are happy with, we can push these changes to the remote repository on GitHub using the <code>git push</code> command.</p> <pre><code>% cd ${TUTROOT}\n% git push\n% git status\n</code></pre> <p>Notice that the output of the <code>git status</code> command indicates that our local repository is up-to-date with the remote repository on GitHub. The above single-user development workflow figure shows visually the idea that the <code>git push</code> command moves commits from your local repository to the remote repository on GitHub. Visit the GitHub page to verify that our new commits have been pushed to the remote repository:</p> <ul> <li>https://github.com/githubid/ece6745-tut02-git</li> </ul> <p>Click on commits at the top of the GitHub page to view the log of commits. You can browse who made each commit, what changed in each commit, and the state of the repository at each commit. Return to the main GitHub page for the repository and click on the <code>fruit.txt</code> file to view it.</p> <p>Activity 1: Experiment with Commiting Files</p> <p>Create a new file called <code>shapes.txt</code> that includes a list of different shapes. Commit the new file, make some edits, and commit these edits. Use <code>git status</code> and <code>git log</code> to keep track of your changes. Push your changes to GitHub and browse the updated files on GitHub.</p>"},{"location":"ece6745-tut02-git/#22-multi-user-workflow","title":"2.2. Multi-User Workflow","text":"<p>Since your tutorial repository is public on GitHub, any other user can also clone this repository. If you would like to collaborate with another GitHub user, you would need to give that user read/write permission. The instructors will take care of setting up the appropriate teams for the lab assignments when you work with a partner. To emulate how collaboration with GitHub works, we will \"pretend\" to be different users by cloning extra copies of the tutorial repository.</p> <pre><code>% cd ${HOME}/ece6745\n% git clone git@github.com:${GITHUBID}/ece6745-tut02-git tut02-alice\n% cd tut02-alice\n% ALICE=${PWD}\n% cd ${HOME}/ece6745\n% git clone git@github.com:${GITHUBID}/ece6745-tut02-git tut02-bob\n% cd tut02-bob\n% BOB=${PWD}\n</code></pre> <p>We can now emulate different users by simply working in these different local repositories: when we work in <code>ALICE</code> we will be acting as the user Alice, and when we work in <code>BOB</code> we will be acting as the user Bob. The following figure illustrates a multi-user development environment: both Alice and Bob have their own separate local repositories (including their own working directories, index, and special <code>.git</code> directories), yet they will both communicate with the same centralized remote repository on GitHub.</p> <p></p> <p>Let's have Alice add another entry to the <code>fruit.txt</code> file, commit her changes to her local repository, and then push those commits to the remote repository on GitHub:</p> <pre><code>% cd ${ALICE}\n% echo \"banana\" &gt;&gt; fruit.txt\n% git commit -a -m \"ALICE: added banana to fruit list\"\n% git log --oneline\n% git push\n% cat fruit.txt\n</code></pre> <p>If you view the GitHub page for this repository it will appear that you are the one making the commit (remember we are just pretending to be Alice), which is why we used <code>ALICE:</code> as a prefix in the commit message.</p> <p>Now let's assume Bob wants to retrieve the changes that Alice just made to the repository. Bob can use the <code>git pull</code> command to pull all new commits from the remote repository into his local repository. The <code>git pull</code> command performs two actions, it first fetches all the updates and then merges or applies them to the local project. If there are no conflicts in the file contents, the command executes successfully. If there are conflicts, the command does not merge all the changes and reports the conflicting content. We will learn how to resolve conflicts in a later section.</p> <pre><code>% cd ${BOB}\n% git pull\n% git log --oneline\n% cat fruit.txt\n</code></pre> <p>The multi-user development workflow figure shows visually the idea that the <code>git pull</code> command moves commits from the remote repository on GitHub to your local repository. Bob's copy of tutorial repository should contain Alice's most recent commit and his copy of the <code>fruits.txt</code> file should include <code>banana</code>. Now let's assume Bob also wants to make some changes and push those changes to the remote repository on GitHub:</p> <pre><code>% cd ${BOB}\n% echo \"peach\" &gt;&gt; fruit.txt\n% git commit -a -m \"BOB: added peach to fruit list\"\n% git log --oneline\n% git push\n% cat fruit.txt\n</code></pre> <p>Similar to before, Alice can now retrieve the changes that Bob just made to the repository using the <code>git pull</code> command.</p> <pre><code>% cd ${ALICE}\n% git pull\n% git log --oneline\n% cat fruit.txt\n</code></pre> <p>This process is at the key to collaborating via GitHub. Each student works locally on his or her part of the lab assignment and periodically pushes/pulls commits to synchronize with the remote repository on GitHub.</p> <p>Activity 2: Experimenting with a Multi-User Workflow</p> <p>Create a new file called <code>letters.txt</code> in Bob's local repository that includes a list of letters from A to M, one per line. Commit the new file, make some edits to add say more letters from say M to Z, and commit these edits. Use <code>git push</code> to push these commits to the centralized repository. Switch to Alice's local repository and use <code>git pull</code> to pull in the new commits. Verify that all of your files and commits are in both Bob's and Alice's local repositories.</p>"},{"location":"ece6745-tut02-git/#23-resolving-conflicts","title":"2.3. Resolving Conflicts","text":"<p>Of course the real challenge occurs when both Alice and Bob modify content at the same time. There are two possible scenarios: Alice and Bob modify different content such that it is possible to combine their commits without issue, or Alice and Bob have modified the exact same content resulting in a conflict. We will address how to resolve both scenarios.</p> <p>Let us assume that Alice wants to add <code>lemon</code> to the list and Bob would like to create a new file named <code>vegetables.txt</code>. Alice would go ahead and first pull from the central repository to grab any new commits from the remote repository on GitHub. On seeing that there are no new commits, she edits the file, commits, and pushes this new commit.</p> <pre><code>% cd ${ALICE}\n% git pull\n% echo \"lemon\" &gt;&gt; fruit.txt\n% git commit -a -m \"ALICE: added lemon to fruit list\"\n% git push\n</code></pre> <p>Since Bob recently pulled from the remote repository on GitHub, let's say he assumes that there have been no new commits. He would then go ahead and create his new file, commit, and attempt to push this new commit.</p> <pre><code>% cd ${BOB}\n% echo \"spinach\"  &gt;  vegetables.txt\n% echo \"broccoli\" &gt;&gt; vegetables.txt\n% echo \"turnip\"   &gt;&gt; vegetables.txt\n% git add vegetables.txt\n% git commit -m \"BOB: initial vegetable list\"\n% git push\n To git@github.com:githubid/ece6745-tut02-git\n  ! [rejected]        main -&gt; main (fetch first)\n error: failed to push some refs to 'git@github.com:githubid/ece6745-tut02-git'\n hint: Updates were rejected because the remote contains work that you do\n hint: not have locally. This is usually caused by another repository pushing\n hint: to the same ref. You may want to first integrate the remote changes\n hint: (e.g., 'git pull ...') before pushing again.\n hint: See the 'Note about fast-forwards' in 'git push --help' for details.\n</code></pre> <p>On executing the sequence of commands above, you should notice that Git does not allow Bob to push his changes to the central repository as the version of the central repository has been updated by Alice. You should see a message similar to the one above. Git suggests us to merge the remote commits before pushing the local commits. We can do so by first using the <code>git pull</code> command to merge the local commits.</p> <pre><code>% cd ${BOB}\n% git pull\n</code></pre> <p>Git will launch Nano because we need to merge your local commits and the remote commits. You will need to enter a commit message, although usually the default message provided by Git is fine. We can take a look at the Git history using <code>git log</code> to see what happened.</p> <pre><code>% cd ${BOB}\n% git log --oneline --graph\n *   f5c1361 (HEAD -&gt; main) Merge branch 'main' of github.com:githubid/ece6745-tut02-git\n |\\\n | * c13f30e (origin/main, origin/HEAD) ALICE: added lemon to fruit list\n * | 3ef8c85 BOB: initial vegetable list\n |/\n * 5877142 BOB: added peach to fruit list\n * 7896fff ALICE: added banana to fruit list\n</code></pre> <p>The <code>--graph</code> command line option with the <code>git log</code> command will display a visual graph of the commit history. You can see that Bob and Alice worked on two different commits at the same time. Alice worked on commit <code>c13f30e</code> while Bob was working on commit <code>3ef8c85</code>. Bob then merged these two sets of commits using a new commit <code>f5c1361</code>. Your exact commit hashes might be different. Bob can now push his changes to the remote repository in GitHub.</p> <pre><code>% cd ${BOB}\n% git push\n</code></pre> <p>GitHub has a nice commit history viewer which shows a similar commit graph as we saw above:</p> <ul> <li>https://github.com/githubid/ece6745-tut02-git/network</li> </ul> <p>Sometimes Alice and Bob are editing the exact same lines in the exact same file. In this case, Git does not really know how to resolve this conflict. It does not know how to merge the two sets of commits to create a consistent view of the repository. The user will have to manually resolve the conflict. Let's explore what happens when Alice and Bob want to add a new fruit to the <code>fruits.txt</code> file at the exact same time. First, Alice adds <code>kiwi</code> and pushes her updates to the remote repository on GitHub.</p> <pre><code>% cd ${ALICE}\n% git pull\n% echo \"kiwi\" &gt;&gt; fruit.txt\n% git commit -a -m \"ALICE: added kiwi to fruit list\"\n% git push\n</code></pre> <p>Now Bob adds <code>date</code> and tries to push his update to the remote repository on GitHub.</p> <pre><code>% cd ${BOB}\n% echo \"date\" &gt;&gt; fruit.txt\n% git commit -a -m \"BOB: added date to fruit list\"\n% git push\n To git@github.com:githubid/ece6745-tut02-git\n  ! [rejected]        main -&gt; main (fetch first)\n</code></pre> <p>Let's see what happens if Bob uses the <code>git pull</code> command to pull and merge the commits from the remote repository on GitHub.</p> <pre><code>% cd ${BOB}\n% git pull\n Unpacking objects: 100% (3/3), done.\n From github.com:cbatten/ece6745-tut02-git\n    f5c1361..3d43934  main     -&gt; origin/main\n Auto-merging fruit.txt\n CONFLICT (content): Merge conflict in fruit.txt\n Automatic merge failed; fix conflicts and then commit the result.\n</code></pre> <p>Git indicates that it was not able to complete the merge. There is a conflict in the <code>fruit.txt</code> file. We can also use the <code>git status</code> command to see which files have conflicts. They will be marked as <code>both modified</code>:</p> <pre><code>% cd ${BOB}\n% git status\n</code></pre> <p>Git instructs Bob to first resolve the conflict and then use the <code>git commit</code> command to finish the merge. If you take a look at the <code>fruit.txt</code> file you will see that it now includes conflict markers showing exactly where the conflict occurred.</p> <pre><code>% cd ${BOB}\n% cat fruit.txt\n apple\n mango\n orange\n banana\n peach\n lemon\n &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n date\n =======\n kiwi\n &gt;&gt;&gt;&gt;&gt;&gt;&gt; 3d43934f045d6ab3c354893a97fd4967997bcb35\n</code></pre> <p>This shows that the commit from the local repository has <code>date</code> on the last line in the file, while the remote repository on GitHub has <code>kiwi</code> as the last line in the file. To resolve the conflict we can directly edit this file so that it reflects how we want to merge. We can choose one fruit over the other, choose to include neither fruit, or choose to include both fruit. Edit the file using VS Code to remove the lines with markers <code>&lt;&lt;&lt;&lt;</code>, <code>===</code>, and <code>&gt;&gt;&gt;&gt;</code> so that the file includes both fruit.</p> <pre><code>% cd ${BOB}\n% code fruit.txt\n% cat fruit.txt\n apple\n mango\n orange\n banana\n peach\n lemon\n date\n kiwi\n</code></pre> <p>Now that we have resolved the conflict we just need to commit these new changes.</p> <pre><code>% cd ${BOB}\n% git status\n% git commit -a -m \"fixed conflict\"\n% git push\n% git status\n% git log --oneline --graph\n</code></pre> <p>Resolving conflicts is tedious, so to avoid conflicts you should communicate with your group members which student is going to be executing which files. Try to avoid having multiple students working on the same file at the same time, or at least avoid having multiple students working on the same lines of the same file at the same time.</p> <p>Activity 3: Experimenting with Resolving Conflicts</p> <p>Experiment with both Alice and Bob editing the same lines in the <code>overview.txt</code> file at the same time. Try to force a conflict, and then carefully resolve the conflict.</p>"},{"location":"ece6745-tut02-git/#24-branches-and-pull-requests","title":"2.4. Branches and Pull Requests","text":"<p>In this section, we describe branches and pull requests which are slightly more advanced topics but tremendously useful. Students could probably skim this section initially, and then revisit this information later in the semester. Branches and pull requests enable different students to work on different aspects at the project at the same time while keeping their commits separated in the remote repository on GitHub. So far, all of our work has been on the main branch. The main branch is the primary default branch. Creating additional branches can enable one student to work on a new feature while also fixing bugs on the main branch, or branches can enable students to experiment with some more advanced ideas but easily revert back to the \"stable\" main branch.</p> <p>Let's say that Alice wants to work on a new list of animals in Alice and Bob's shared repository, but she wants to keep her work separate from the primary work they are focusing on. Alice can create a branch called <code>alice-animals</code> and commit her new ideas on that branch. It is usually good practice to prefix branch names with your NetID to ensure that branch names are unique. The following commands will first display the branches in the local repository using the <code>git branch</code> command before creating a new branch called <code>alice-animals</code>.</p> <pre><code>% cd ${ALICE}\n% git pull\n% git branch\n% git checkout -b alice-animals\n% git branch\n% git status\n</code></pre> <p>The <code>git branch</code> command uses an asterisk (<code>*</code>) to indicate the current branch. The <code>git status</code> command also indicates the current branch. Alice can now create a new file and commit her changes to this new branch.</p> <pre><code>% cd ${ALICE}\n% git branch\n% echo \"cow\"  &gt; animals.txt\n% echo \"pig\" &gt;&gt; animals.txt\n% echo \"dog\" &gt;&gt; animals.txt\n% git add animals.txt\n% git commit -m \"ALICE: initial animal list\"\n% git log --oneline --graph\n</code></pre> <p>It should be clear that the <code>alice-animals</code> branch is one commit ahead of the <code>main</code> branch. Pushing this branch to the remote repository on GitHub requires a slightly more complicated syntax. We need to specify which branch to push to which remote repository:</p> <pre><code>% cd ${ALICE}\n% git push -u origin alice-animals\n% cat animals.txt\n</code></pre> <p>The name <code>origin</code> refers to the remote repository that the local repository was originally cloned from (i.e., the remote repository on GitHub). You can now see this new branch on GitHub here:</p> <ul> <li>https://github.com/githubid/ece6745-tut02-git/branches</li> </ul> <p>You can browse the commits and source code in the <code>alice-animals</code> just like the <code>main</code> branch. If Bob wants to checkout Alice's new branch, he needs to use a slightly different syntax.</p> <pre><code>% cd ${BOB}\n% git pull\n% git checkout --track origin/alice-animals\n% git branch\n% cat animals.txt\n</code></pre> <p>Alice and Bob can switch back to the <code>main</code> branch using the <code>git checkout</code> command.</p> <pre><code>% cd ${ALICE}\n% git checkout main\n% git branch\n% ls\n% cd ${BOB}\n% git checkout main\n% git branch\n% ls\n</code></pre> <p>The <code>git branch</code> command should indicate that both Alice and Bob are now on the <code>main</code> branch, and there should no longer be an <code>animals.txt</code> file in the working directory. One strength of Git is that it makes it very easy to switch back and forth between branches.</p> <p>Once Alice has worked on her new branch, she might be ready to merge that branch back into the <code>main</code> branch so it becomes part of the primary project. GitHub has a nice feature called pull requests that simply this process. To create a pull request, Alice would first go to the branch page on GitHub for this repository.</p> <ul> <li>https://github.com/githubid/ece6745-tut02-git/branches</li> </ul> <p>She then just needs to click on the three dots next to her branch and choose New pull request. You must carefully select the base fork! If you simply choose the default you will try to merge your branch into the repository that is part of the <code>cornell-ece6745</code> GitHub organization. Click on base fork and select githubid/ece6745-tut02-git. Alice can leave a comment about what this new branch does. Other students can use the pull request page on GitHub to comment on and monitor the new branch.</p> <ul> <li>https://github.com/githubid/ece6745-tut02-git/pull/1</li> </ul> <p>Users can continue to develop and work on the branch until it is ready to be merged into <code>main</code>. When the pull request is ready to be accepted, a user simply clicks on Merge pull request on the GitHub pull request page. When this is finished the Git history for this example would look like this:</p> <pre><code>% cd ${ALICE}\n% git pull\n% git log --oneline --graph\n*   3e523c8 (HEAD -&gt; main, origin/main, origin/HEAD) Merge pull request #1 fr&gt;\n|\\\n| * 651eb8c (origin/alice-animals, alice-animals) ALICE: initial animal list\n|/\n*   e6c85c3 fixed conflict\n|\\\n| * 3d43934 ALICE: added kiwi to fruit list\n* | 9d12ba9 BOB: added date to fruit list\n|/\n*   f5c1361 Merge branch 'main' of github.com:cbatten/ece6745-tut02-git\n|\\\n| * c13f30e ALICE: added lemon to fruit list\n* | 3ef8c85 BOB: initial vegetable list\n|/\n* 5877142 BOB: added peach to fruit list\n* 7896fff ALICE: added banana to fruit list\n* bf6a25f added orange to fruit list\n* bc0e024 added mango to fruit list\n* a8ac41e initial fruit list\n* bb9506b initial import\n</code></pre> <p>Activity 4: Experimenting with Branches</p> <p>Have Bob create his own branch for development, and then create a new file named <code>states.txt</code> with the names of states. Have Bob commit his changes to a new branch and push this branch to the remote repository on GitHub. Finally, have Alice pull this new branch into her local repository.</p>"},{"location":"ece6745-tut02-git/#3-github-actions-for-continuous-integration","title":"3. GitHub Actions for Continuous Integration","text":"<p>GitHub Actions is an online continuous integration service that is integrated within GitHub. GitHub Actions will automatically run all tests for a student's lab assignment every time the students push their code to GitHub. We will be using the results reported by GitHub Actions to evaluate the code functionality of the lab assignments. In this section, we do a small experiment to illustrate how GitHub Actions work.</p> <p>GitHub Actions looks for specials file in the <code>.github/workflows</code> subdirectory in the top of your repository to determine how to build and test your project. We have already created one of those files for you, and you can see it here:</p> <pre><code>% cd ${TUTROOT}\n% cat .github/workflows/git-tutorial.yml\n</code></pre> <p>The <code>git-tutorial.yml</code> file for this tutorial is very simple. It just uses the <code>grep</code> command to check if the fruit <code>blueberry</code> is in the <code>fruit.txt</code> file. If the <code>blueberry</code> is present then the test passes, otherwise the test fails. Click on the Actions tab in your repository on GitHub and click I understand my workflows, go ahead and enable them as shown in the following figure.</p> <p></p> <p>Let's add <code>melon</code> to the list of fruits in our local repository and then push the corresponding commit to the remote repository on GitHub.</p> <pre><code>% cd ${TUTROOT}\n% git pull\n% echo \"melon\" &gt;&gt; fruit.txt\n% git commit -a -m \"added melon to fruit list\"\n% git push\n</code></pre> <p>Notice how we first use the <code>git pull</code> command to ensure our local repository has all of the commits from the remote repository on GitHub. To see the results of the workflow run go to the Actions tab for the corresponding repository on GitHub. You can also use a link like this:</p> <ul> <li>https://github.com/githubid/ece6745-tut02-git/actions</li> </ul> <p>where <code>githubid</code> is your GitHub username on the public version of GitHub. You should be able to see a list of workflow runs as illustrated below.</p> <p></p> <p>Each run corresponds to a push to GitHub. A green checkmark means that run passed, while a red X means that run failed. If you click on the name of a run, and then click on check you can see a list of steps that GitHub actions ran. Click on the little <code>&gt;</code> next to Run grep blueberry fruit.txt to see the output from running <code>grep</code>.</p> <p></p> <p>The test should fail because <code>blueberry</code> is not currently in the <code>fruit.txt</code> file. Now let's add <code>blueberry</code> and then push the corresponding to commit to trigger another build on GitHub Actions.</p> <pre><code>% cd ${TUTROOT}\n% echo \"blueberry\" &gt;&gt; fruit.txt\n% git commit -a -m \"added blueberry to fruit list\"\n% git push\n</code></pre> <p>If you revisit the GitHub Actions page for this repository, you should now see that the check has passed!</p> <p>Using GitHub Actions to perform continuous integration testing is a key component of an agile development methodology. It means the entire group can quickly spot commits which break certain tests, and always be certain that their <code>main</code> branch is passing all tests before submitting the lab assignment. The course staff will actually be using GitHub Actions to grade your lab assignments. The staff will be able to look at the build log in GitHub Actions to see if your assignment is passing your own test suite, and then the staff can add more tests to see if your assignment passes a more exhaustive test suite.</p> <p>Activity 5: Experimenting with GitHub Actions</p> <p>Edit the <code>git-tutorial.yml</code> file to search for <code>apple</code> instead. Experiment with removing and adding <code>apple</code> from the <code>fruits.txt</code> file to see the tests on GitHub Actions pass and fail.</p>"},{"location":"ece6745-tut02-git/#4-course-specific-git-scripts","title":"4. Course-Specific Git Scripts","text":"<p>This section describes some useful scripts we have installed that make it easier to use Git. Each script is invoked by typing the name along with the standard <code>git</code> command.</p>"},{"location":"ece6745-tut02-git/#41-using-git-xstatus-to-compactly-see-status-information","title":"4.1. Using <code>git xstatus</code> to Compactly See Status Information","text":"<p>The <code>git xstatus</code> command produces a status output somewhat similar to subversion's status command. It first shows the status of all tracked files which are modified, deleted, or added, then shows the status of all files in the index (marked with an asterisk), and finally shows which files and directories are untracked. Here is an example output:</p> <pre><code>% cd ${TUTROOT}\n% echo \"cyan\" &gt;&gt; colors.txt\n% echo \"rabbit\" &gt;&gt; animals.txt\n% git add colors.txt animals.txt\n% git commit -m \"added some colors and animals\"\n% echo \"grape\" &gt;&gt; fruit.txt\n% git add fruit.txt\n% echo \"strawberry\" &gt;&gt; fruit.txt\n% echo \"bird\" &gt;&gt; animals.txt\n% echo \"tulip\"  &gt;&gt; flowers.txt\n% rm colors.txt\n% git xstatus\n  M animals.txt\n  D colors.txt\n  M fruit.txt\n *M fruit.txt\n  ? flowers.txt\n</code></pre> <p>This shows that the file <code>colors.txt</code> has been deleted from the working directory, but this deletion has not been added to the index yet (<code>colors.txt</code> is not listed with an asterisk). The file <code>animals.txt</code> has been modified buy not added to the index yet. Note that the file named <code>fruit.txt</code> has been modified and added to the index, but it has been modified since it was added to the index as indicated by its double listing. The file named <code>flowers.txt</code> is currently untracked.</p> <p>The possible status codes are as follows:</p> <pre><code> - A : addition of a file\n - C : copy of a file into a new one\n - D : deletion of a file\n - M : modification of the contents or mode of a file\n - R : renaming of a file\n - T : change in the type of the file\n - U : file is unmerged (you must complete the merge before commit)\n - ? : file is untracked (you need to add it if you want to track it)\n</code></pre>"},{"location":"ece6745-tut02-git/#42-using-git-xadd-to-add-all-changed-files","title":"4.2. Using <code>git xadd</code> to Add All Changed Files","text":"<p>The <code>git xadd</code> command adds all files which are currently tracked and display the new status in a format similar to the <code>git xstatus</code> command. You can use this to quickly stage files for commit and see what would be committed before actually executing the commit.</p> <pre><code>% cd ${TUTROOT}\n% git xstatus\n% git xadd\n</code></pre>"},{"location":"ece6745-tut02-git/#43-using-git-xlog-to-compactly-see-log-information","title":"4.3. Using <code>git xlog</code> to Compactly See Log Information","text":"<p>The <code>git xlog</code> command displays a compact log format with one commit per line and a graph representing the commit history. This script passes along whatever the additional options are included straight onto <code>git log</code>. Here is a simple example of the log output.</p> <pre><code>% cd ${TUTROOT}\n% git xlog\n* be57e36 cb added some colors and animals\n* d2c0ecd cb added blueberry to fruit list\n* 1e4792f cb added melon to fruit list\n*   3e523c8 cb Merge pull request #1 from cbatten/alice-animals\n|\\\n| * 651eb8c cb ALICE: initial animal list\n|/\n*   e6c85c3 cb fixed conflict\n|\\\n| * 3d43934 cb ALICE: added kiwi to fruit list\n* | 9d12ba9 cb BOB: added date to fruit list\n|/\n*   f5c1361 cb Merge branch 'main' of github.com:cbatten/ece6745-tut02-git\n|\\\n| * c13f30e cb ALICE: added lemon to fruit list\n</code></pre> <p>You can see one line per commit along with the commit hash, the committer's name, and the short commit message. The graph shows a merge between commits <code>3d43934</code> and <code>6ee31c69d12ba9</code>.</p>"},{"location":"ece6745-tut05-asic-stdcells/","title":"ECE 6745 Tutorial 5: ASIC Standard Cells","text":"<p>A standard-cell library is a collection of combinational and sequential logic gates that adhere to a standardized set of logical, electrical, and physical policies. For example, all standard cells are usually the same height, include pins that align to a predetermined vertical and horizontal grid, include power/ground rails and nwells in predetermined locations, and support a predetermined number of drive strengths. A standard-cell-based ASIC toolflow involves using automated tools to transform register-transfer-level (RTL) designs into placed and routed standard cells on a chip. This tutorial will explore the specific standard-cell library we will use in this course along with the various \"views\" of the standard-cell library. This tutorial assumes you have already completed the tutorials on Linux, Git, and Verilog.</p> <p>The first step is to access <code>ecelinux</code>. Use VS Code to log into a specific <code>ecelinux</code> server and then use Microsoft Remote Desktop to log into the same server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut05-asic-stdcells tut05\n% cd tut05\n% TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut05-asic-stdcells/#1-freepdk45-process-design-kit","title":"1. FreePDK45 Process Design Kit","text":"<p>Before you can gain access to a standard-cell library, you need to gain access to a \"physical design kit\" (PDK). A PDK includes all of the design files required for full-custom circuit design for a specific technology. So this will include a design-rule manual as well as SPICE circuit models for transistors and other devices. Gaining access to a real PDK is difficult. It requires negotiating with the foundry and signing multiple non-disclosure agreements. So in this course we will be using the FreePDK45 PDK:</p> <ul> <li>https://eda.ncsu.edu/freepdk/freepdk45</li> </ul> <p>This is an open PDK for a \"fake\" technology. It was created by universities using publically available data on several different commercial 45nm processes. This means you cannot actually tapeout a chip using this PDK, but the technology is representative enough to provide reasonable area, energy, and timing estimates for research and teaching purposes. You can find the FreePDK45 PDK installed here:</p> <pre><code>% cd ${ECE6745_INSTALL}/adks/freepdk-45nm/pkgs/FreePDK45-1.4\n</code></pre>"},{"location":"ece6745-tut05-asic-stdcells/#2-nangate-standard-cell-library","title":"2. NanGate Standard-Cell Library","text":"<p>A standard-cell designer will use the PDK to implement the standard-cell library. A standard-cell designer will usually create a high-level behavioral specification (in Verilog), circuit schematics (in SPICE), and the actual layout (in <code>.gds</code> format) for each logic gate. The standard-cell-based ASIC tools do not actually use these low-level implementations, since they are actually too detailed. Instead these tools use abstract views of the standard cells, which capture logical functionality, timing, geometry, and power usage at a much higher level.</p> <p>Just like with a PDK, gaining access to a real standard-cell library is difficult. It requires gaining access to the PDK first, negotiating with a company which makes standard cells, and usually signing more non-disclosure agreements. In this course, we will be using the Nangate 45nm standard-cell library which is based on the open FreePDK45 PDK.</p> <p>Nangate is a company which makes a tool to automatically generate standard-cell libraries, so they have made this library publically available a way to demonstrate their tool. Since it is an open library it is a great resource for research and teaching. Even though the standard-cell library is based on a \"fake\" 45nm PDK, the library provides a very reasonable estimate of a real commercial standard library in a real 45nm technology. In this section, we will take a look at both the low-level implementations and high-level views of the Nangate standard-cell library.</p> <p>A standard-cell library distribution can contain gigabytes of data in thousands of files. For example, here is the distribution for the Nangate standard-cell library.</p> <pre><code>% cd ${ECE6745_INSTALL}/adks/freepdk-45nm/pkgs/NangateOpenCellLibrary_PDKv1_3_v2010_12\n</code></pre> <p>To simplify using the Nangate standard-cell library in this course, we have created a much smaller set of well-defined symlinks which point to just the key files we want to use in this course. We call this collection of symlinks an \"ASIC design kit\" (ADK). Here is the directory which contains these symlinks.</p> <pre><code>% cd ${ECE6745_STDCELLS}\n% ls\npdk-models.sp          # spice models for transistors\n\nrtk-stream-out.map     # gds layer map\nrtk-tech.lef           # interconnect technology information\nrtk-tech.tf            # interconnect technology information\nrtk-typical.captable   # interconnect technology information\n\nstdcells.spi           # circuit schematics for each cell\nstdcells.gds           # layout for each cell\nstdcells.v             # behavioral specification for each cell\n\nstdcells-lpe.spi       # circuit schematics with parasitics for each cell\nstdcells.lib           # abstract logical, timing, power view for each cell (typical)\nstdcells-bc.lib        # best case .lib\nstdcells-wc.lib        # worst case .lib\nstdcells.lef           # abstract physical view for each cell\n\nstdcells.db            # binary compiled version of .lib file\nstdcells.mwlib         # Milkyway database built from .lef file\n\nstdcells-databook.pdf  # standard-cell library databook\n\nklayout.lyp            # layer settings for Klayout\n</code></pre> <p>A standard-cell library will always include a databook, which is a document that describes the details of every cell in the library. Take a few minutes to browse through the Nangate standard-cell library databook located on the course webpage here:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/resources/nangate-freepdk45nm-stdcell-databook.pdf</li> </ul>"},{"location":"ece6745-tut05-asic-stdcells/#21-verilog-behavioral-view","title":"2.1. Verilog Behavioral View","text":"<p>Let's begin by looking at the Verilog behavioral view for a 3-input NAND standard cell which is named NAND3_X1.</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells.v\nmodule NAND3_X1 (A1, A2, A3, ZN);\n  input A1;\n  input A2;\n  input A3;\n  output ZN;\n\n  not(ZN, i_8);\n  and(i_8, i_9, A3);\n  and(i_9, A1, A2);\n\n  specify\n    (A1 =&gt; ZN) = (0.1, 0.1);\n    (A2 =&gt; ZN) = (0.1, 0.1);\n    (A3 =&gt; ZN) = (0.1, 0.1);\n  endspecify\n\nendmodule\n</code></pre> <p>Note that the Verilog implementation of the 3-input NAND standard cell looks nothing like the Verilog we used in ECE 4750. This cell is implemented using Verilog primitive gates (e.g., <code>not</code>, <code>and</code>) and it includes a <code>specify</code> block which is used for advanced gate-level simulation with back-annotated delays.</p> <p>Let's use <code>iverilog</code> to simulate the Verilog behavorial view of the 3-input NAND standard cell. Take a look at the provided Verilog test bench.</p> <pre><code>% cd $TOPDIR\n% cat nand3-test.v\n</code></pre> <p>The test bench looks as follows.</p> <pre><code>`include \"/classes/ece6745/install/adks/freepdk-45nm/stdview/stdcells.v\"\n\nmodule top();\n\n  logic a;\n  logic b;\n  logic c;\n  logic y;\n\n  NAND3_X1 nand3( a, b, c, y );\n\n  initial begin\n    $dumpfile(\"nand3-test.vcd\");\n    $dumpvars;\n\n    a = 0; b = 0; c = 0;\n    #10;\n    $display( \"a=%b, b=%b, c=%b, y=%b\", a, b, c, y );\n\n    a = 1; b = 1; c = 1;\n    #10;\n    $display( \"a=%b, b=%b, c=%b, y=%b\", a, b, c, y );\n\n    a = 0; b = 1; c = 0;\n    #10;\n    $display( \"a=%b, b=%b, c=%b, y=%b\", a, b, c, y );\n\n    a = 1; b = 1; c = 1;\n    #10;\n    $display( \"a=%b, b=%b, c=%b, y=%b\", a, b, c, y );\n\n  end\n\nendmodule\n</code></pre> <p>The test bench simply tries four different combinations of input values. Run the simulation and view the result using Surfer.</p> <pre><code>% cd $TOPDIR/sim\n% iverilog -g2012 -s top -o nand3-test nand3-test.v\n% ./nand3-test\n% code nand3-test.vcd\n</code></pre> <p>The waveforms should look similar to what is shown below. Because this is a Verilog behavioral view all signals change immediately without any kind of delay.</p> <p></p>"},{"location":"ece6745-tut05-asic-stdcells/#22-spice-schematic-view","title":"2.2. SPICE Schematic View","text":"<p>Now that we understand the Verilog behavioral view, let's look at how we would implement this same standard cells at the transistor level. We can look at the SPICE schematic view for a 3-input NAND cell (NAND3_X1).</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells.spi\n.SUBCKT NAND3_X1 A1 A2 A3 ZN VDD VSS\n*.PININFO A1:I A2:I A3:I ZN:O VDD:P VSS:G\n*.EQN ZN=!((A1 * A2) * A3)\nM_i_2 net_1 A3 VSS   VSS NMOS_VTL W=0.415000U L=0.050000U\nM_i_1 net_0 A2 net_1 VSS NMOS_VTL W=0.415000U L=0.050000U\nM_i_0 ZN    A1 net_0 VSS NMOS_VTL W=0.415000U L=0.050000U\nM_i_5 ZN    A3 VDD   VDD PMOS_VTL W=0.630000U L=0.050000U\nM_i_4 VDD   A2 ZN    VDD PMOS_VTL W=0.630000U L=0.050000U\nM_i_3 ZN    A1 VDD   VDD PMOS_VTL W=0.630000U L=0.050000U\n.ENDS\n</code></pre> <p>For students with a circuits background, there should be no surprises here, and for those students with less circuits background we will cover basic static CMOS gate design later in the course. Essentially, this schematic includes three NMOS transistors arranged in series in the pull-down network, and three PMOS transistors arranged in parallel in the pull-up network. The PMOS transistors are larger than the NMOS transistors (see <code>W=</code> parameter) because the mobility of holes is less than the mobility of electrons.</p> <p>Let's use ngspice to simulate the SPICE schematic view of the 3-input NAND standard cell. Take a look at the provided SPICE test bench.</p> <pre><code>% cd $TOPDIR/sim\n% cat nand3-test.sp\n</code></pre> <p>Although it is not too important for you to understand how to write a SPICE test bench, it can still be fun to look at one.</p> <pre><code>* Simple NAND3_X1 simulation\n* ------------------------------------------------------------------------\n\n.param VDD='1.1V'\n.temp  70\n.inc   \"/classes/ece6745/install/adks/freepdk-45nm/stdview/pdk-models.sp\"\n.inc   \"/classes/ece6745/install/adks/freepdk-45nm/stdview/stdcells.spi\"\n\n* Instantiate a voltage supply, standard cell, and output load\n* ------------------------------------------------------------------------\n\nVdd vdd gnd VDD\n\nX1 a b c y vdd gnd NAND3_X1\n\nCload y gnd 7fF\n\n* Instantiate three input sources\n* ------------------------------------------------------------------------\n\nA1 [a_ b_] nand3_source\n.model nand3_source d_source (input_file=\"nand3-source.txt\")\n\nAa [a_] [a] dac_a\n.model dac_a dac_bridge (out_low=0V out_high='VDD' t_rise=0.2ns t_fall=0.2ns)\n\nAb [b_] [b] dac_b\n.model dac_b dac_bridge (out_low=0V out_high='VDD' t_rise=0.2ns t_fall=0.2ns)\n\nAc [b_] [b] dac_c\n.model dac_c dac_bridge (out_low=0V out_high='VDD' t_rise=0.2ns t_fall=0.2ns)\n\n* Run a simulation\n* ------------------------------------------------------------------------\n\n.ic   V(y)=VDD\n.tran 0.01ns 4ns\n\n.control\nrun\nset color0=white\nset color1=black\nset color2=red\nset xbrushwidth=2\nplot V(a) V(b) V(c) V(y)\n.endc\n\n.end\n</code></pre> <p>See Tutorial 8 for much more detail on SPICE simulation. You can run the simulation using ngspice like this:</p> <pre><code>% cd $TOPDIR/sim\n% ngspice nand3-test.sp\n</code></pre> <p>Note that if we use ngspice to display plots, then it is a Linux GUI application so you will need to use Microsoft Remote Desktop. The waveforms should look similar to what is shown below. The input signals ramp up and down based on the <code>t_rise</code> and <code>t_fall</code> parameters above. Because this is a SPICE schematic view you can see the output does not change instantly but instead takes some amount of time due to the parasitic resistance and capacitances associated with the transistors in the schematic.</p> <p></p>"},{"location":"ece6745-tut05-asic-stdcells/#23-gds-layout-view","title":"2.3. GDS Layout View","text":"<p>Now that we understand the SPICE schematic view, let's look at the actual layout for the 3-input NAND cell using the open-source Klayout GDS viewer. Note that since Klayout is a Linux GUI application you will need to use Microsoft Remote Desktop.</p> <pre><code>% klayout -l ${ECE6745_STDCELLS}/klayout.lyp ${ECE6745_STDCELLS}/stdcells.gds\n</code></pre> <p>Note that we are using the <code>.lyp</code> file which is a predefined layer color scheme that makes it easier to view GDS files. To view the 3-input NAND cell, find the NAND3_X1 cell in the left-hand cell list, and then choose Display &gt; Show as New Top from the menu. Here is a picture of the layout for this cell.</p> <p></p> <p>Diffusion is green, polysilicon is red, contacts are solid dark blue, metal 1 (M1) is blue, and the nwell is the large gray rectangle over the top half of the cell. All standard cells will be the same height and have the nwell in the same place. Notice the three NMOS transistors arranged in series in the pull-down network, and three PMOS transistors arranged in parallel in the pull-up network. The power rail is the horizontal strip of M1 at the top, and the ground rail is the horizontal strip of M1 at the bottom. All standard cells will have the power and ground rails in the same place so they will connect via abutment if these cells are arranged in a row. Although it is difficult to see, the three input pins and one output pin are labeled squares of M1, and these pins are arranged to be on a predetermined grid.</p>"},{"location":"ece6745-tut05-asic-stdcells/#24-spice-extracted-schematic-view","title":"2.4. SPICE Extracted Schematic View","text":"<p>The SPICE schematic view was saw earlier includes just the transistors. We can use sophisticated tools to extract detailed parasitic resistance and capacitance values from the layout, and then we can add these parasitics to the circuit schematic to create a much more accurate model for experimenting with the circuit timing and power. Let's look at a snippet of the extracted circuit for the 3-input NAND cell:</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells-lpe.spi\n.SUBCKT NAND3_X1 VDD VSS A3 ZN A2 A1\n*.PININFO VDD:P VSS:G A3:I ZN:O A2:I A1:I\n*.EQN ZN=!((A1 * A2) * A3)\nM_M3 N_ZN_M0_d  N_A3_M0_g N_VDD_M0_s VDD PMOS_VTL W=0.630000U L=0.050000U\nM_M4 N_VDD_M1_d N_A2_M1_g N_ZN_M0_d  VDD PMOS_VTL W=0.630000U L=0.050000U\nM_M5 N_ZN_M2_d  N_A1_M2_g N_VDD_M1_d VDD PMOS_VTL W=0.630000U L=0.050000U\nM_M0 net_1      N_A3_M3_g N_VSS_M3_s VSS NMOS_VTL W=0.415000U L=0.050000U\nM_M1 net_0      N_A2_M4_g net_1      VSS NMOS_VTL W=0.415000U L=0.050000U\nM_M2 N_ZN_M5_d  N_A1_M5_g net_0      VSS NMOS_VTL W=0.415000U L=0.050000U\nC_x_PM_NAND3_X1%VDD_c0 x_PM_NAND3_X1%VDD_39 VSS 3.704e-17\nC_x_PM_NAND3_X1%VDD_c1 x_PM_NAND3_X1%VDD_36 VSS 2.74884e-18\nC_x_PM_NAND3_X1%VDD_c2 x_PM_NAND3_X1%VDD_26 VSS 2.61603e-16\nC_x_PM_NAND3_X1%VDD_c3 N_VDD_M1_d           VSS 6.57971e-17\nC_x_PM_NAND3_X1%VDD_c4 x_PM_NAND3_X1%VDD_19 VSS 1.89932e-17\nC_x_PM_NAND3_X1%VDD_c5 x_PM_NAND3_X1%VDD_18 VSS 3.74888e-17\nC_x_PM_NAND3_X1%VDD_c6 N_VDD_M0_s           VSS 3.64134e-17\n...\n.ENDS\n</code></pre> <p>The full model is a couple of hundred lines long, so you can see how detailed this model is!</p>"},{"location":"ece6745-tut05-asic-stdcells/#25-lib-logical-view","title":"2.5. LIB Logical View","text":"<p>The ASIC tools do not actually interact with the low-level SPICE schematic views and GDS layour views. We can use a special set of tools to create a much higher level abstract view of the timing and power of this circuit suitable for use by the ASIC tools. Essentially, these tools run many, many circuit-level simulations to create characterization data stored in a <code>.lib</code> (Liberty) file. Let's look at snippet of the <code>.lib</code> file for the 3-input NAND cell.</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells.lib\ncell (NAND3_X1) {\n drive_strength          : 1;\n area                    : 1.064000;\n cell_leakage_power      : 18.104768;\n leakage_power () {\n   when                  : \"!A1 &amp; !A2 &amp; !A3\";\n   value                 : 3.318854;\n }\n ...\n pin (A1) {\n   direction             : input;\n   related_power_pin     : \"VDD\";\n   related_ground_pin    : \"VSS\";\n   capacitance           : 1.590286;\n   fall_capacitance      : 1.562033;\n   rise_capacitance      : 1.590286;\n }\n ...\n pin (ZN) {\n   direction             : output;\n   related_power_pin     : \"VDD\";\n   related_ground_pin    : \"VSS\";\n   max_capacitance       : 58.364900;\n   function              : \"!((A1 &amp; A2) &amp; A3)\";\n\n   timing () {\n\n     related_pin         : \"A1\";\n     timing_sense        : negative_unate;\n\n     cell_fall(Timing_7_7) {\n       index_1 (\"0.00117378,0.00472397,0.0171859,0.0409838,0.0780596,0.130081,0.198535\");\n       index_2 (\"0.365616,1.823900,3.647810,7.295610,14.591200,29.182500,58.364900\");\n       values (\"0.0106270,0.0150189,0.0204521,0.0312612,0.0528211,0.0959019,0.182032\", \\\n               \"0.0116171,0.0160692,0.0215549,0.0324213,0.0540285,0.0971429,0.183289\", \\\n               \"0.0157475,0.0207077,0.0261030,0.0369216,0.0585239,0.101654,0.187820\", \\\n               \"0.0193780,0.0263217,0.0337702,0.0462819,0.0677259,0.110616,0.196655\", \\\n               \"0.0218025,0.0305247,0.0399593,0.0560603,0.0822203,0.125293,0.210827\", \\\n               \"0.0229784,0.0334449,0.0447189,0.0640615,0.0959700,0.146382,0.231434\", \\\n               \"0.0227986,0.0349768,0.0480836,0.0705081,0.107693,0.167283,0.259623\");\n     }\n     ...\n\n     internal_power () {\n       related_pin       : \"A1\";\n       fall_power(Power_7_7) {\n         index_1 (\"0.00117378,0.00472397,0.0171859,0.0409838,0.0780596,0.130081,0.198535\");\n         index_2 (\"0.365616,1.823900,3.647810,7.295610,14.591200,29.182500,58.364900\");\n         values (\"0.523620,0.538965,0.551079,0.556548,0.561151,0.564018,0.564418\", \\\n                 \"0.459570,0.484698,0.509668,0.529672,0.543887,0.554682,0.559331\", \\\n                 \"0.434385,0.457202,0.470452,0.498312,0.517651,0.538469,0.550091\", \\\n                 \"0.728991,0.630651,0.581024,0.559124,0.551408,0.553714,0.557387\", \\\n                 \"1.306597,1.153240,1.010684,0.831268,0.727155,0.657699,0.616287\", \\\n                 \"2.170611,1.965158,1.760932,1.459438,1.140559,0.930355,0.781393\", \\\n                 \"3.276307,3.084566,2.831754,2.426623,1.913607,1.439055,1.113950\");\n       }\n       ...\n     }\n ...\n}\n</code></pre> <p>This is just a small subset of the information included in the <code>.lib</code> file for this cell. We will talk more about the details of such <code>.lib</code> files later in the course, but you can see that the <code>.lib</code> file contains information about area, leakage power, capacitance of each input pin, logical functionality, and timing. Units for all data is provided at the top of the <code>.lib</code> file. In this snippet you can see that the area of the cell is 1.064 square micron and the leakage power is 18.1nW. The capacitance for the input pin <code>A1</code> is 1.59fF, although there is additional data that captures how the capacitance changes depending on whether the input is rising or falling. The output pin <code>ZN</code> implements the logic equation <code>!((A1 &amp; A2) &amp; A3)</code> (i.e., a three-input NAND gate). Data within the <code>.lib</code> file is often represented using one- or two-dimensional lookup tables (i.e., a <code>values</code> table). You can see two such tables in the above snippet.</p> <p>Let's start by focusing on the first table. This table captures the delay from input pin <code>A1</code> to output pin <code>ZN</code> as a function of two parameters: the input transition time (horizontal direction in lookup table) and the load capacitance (vertical direction in lookup table). Note that this delay is when <code>ZN</code> is \"falling\" (i.e., when it is transitioning from high to low). There is another table for the delay when <code>ZN</code> is rising, and there are additional tables for every input. Gates are slower when the inputs take longer to transition and/or when they are driving large output loads. Each entry in the lookup table reflects characterization of one or more detailed circuit-level simulations. So in this example the delay from input pin <code>A1</code> to output pin <code>ZN</code> is 16ps when the input transition rate is 4.7ps and the output load is 1.82fF. This level of detail can enable very accurate static timing analysis of our designs.</p> <p>Let's now focus on the second table. This table captures the internal power, which is the power consumed within the gate itself, again as a function of two paramers: the input transition time (horizontal direction in lookup table) and the load capacitance (vertical direction in lookup table). Each entry in the lookup table is calculated by measuring the current drawn from the power supply during a detailed SPICE simulation and subtracting any current used to charge the output load. In other words all of the energy that is not consumed charging up the output load is considered internal energy. Note that sometimes the internal power is negative. This is simply due to how we account for energy. We can either assume all energy is consumed only when the output node is charged and no energy is consumed when the output node is discharged, or we can assume half the energy is consumed when the output is node is charged and half the energy is consumed when the output node is discharged in which case you will sometimes see negative internal power.</p> <p>Note that some of the ASIC tools actually do not use the <code>.lib</code> file directly, but instead use a pre-compiled binary version of the <code>.lib</code> file stored in <code>.db</code> format. The binary <code>.db</code> file is usually much more compact that the text <code>.lib</code> file. The <code>.lib</code> file captures the abstract logical, timing, and power aspects of the standard-cell library, but it does not capture the physical aspects of the standard-cell library.</p>"},{"location":"ece6745-tut05-asic-stdcells/#26-lef-physical-view","title":"2.6. LEF Physical View","text":"<p>While the ASIC tools could potentially use the <code>.gds</code> file directly, the ASIC tools do not really need this much detail. We can use a special set of tools to create a much higher level abstract view of the physical aspects of the cell suitable for use by the ASIC tools. These tools create <code>.lef</code> files. Let's look at snippet of the the <code>.lef</code> file for the 3-input NAND cell.</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells.lef\nMACRO NAND3_X1\n  CLASS core ;\n  FOREIGN NAND3_X1 0.0 0.0 ;\n  ORIGIN 0 0 ;\n  SYMMETRY X Y ;\n  SITE FreePDK45_38x28_10R_NP_162NW_34O ;\n  SIZE 0.76 BY 1.4 ;\n\n  PIN A1\n    DIRECTION INPUT ;\n    ANTENNAPARTIALMETALAREA 0.0175 LAYER metal1 ;\n    ANTENNAPARTIALMETALSIDEAREA 0.0715 LAYER metal1 ;\n    ANTENNAGATEAREA 0.05225 ;\n    PORT\n      LAYER metal1 ;\n        POLYGON 0.44 0.525 0.54 0.525 0.54 0.7 0.44 0.7  ;\n    END\n  END A1\n\n  PIN ZN\n    DIRECTION OUTPUT ;\n    ANTENNAPARTIALMETALAREA 0.1352 LAYER metal1 ;\n    ANTENNAPARTIALMETALSIDEAREA 0.4992 LAYER metal1 ;\n    ANTENNADIFFAREA 0.197925 ;\n    PORT\n      LAYER metal1 ;\n        POLYGON 0.235 0.8 0.605 0.8 0.605 0.15 0.675 0.15\n         0.675 1.25 0.605 1.25 0.605 0.87 0.32 0.87 0.32 1.25 0.235 1.25  ;\n    END\n  END ZN\n\n  PIN VDD\n    DIRECTION INOUT ;\n    USE power ;\n    SHAPE ABUTMENT ;\n    PORT\n      LAYER metal1 ;\n        POLYGON 0 1.315 0.04 1.315 0.04 0.975 0.11 0.975 0.11 1.315\n         0.415 1.315 0.415 0.975 0.485 0.975 0.485 1.315 0.76 1.315 0.76 1.485 0 1.485  ;\n    END\n  END VDD\n\n  ...\nEND NAND3_X1\n</code></pre> <p>This is just a small subset of the information included in the <code>.lef</code> file for this cell. You can see the <code>.lef</code> file includes information on the dimensions of the cell and the location and dimensions of both power/ground and signal pins. The file also includes information on \"obstructions\" (or blockages) indicated with a <code>OBS</code> entry. Take a look at the NAND4_X4 gate to see an obstruction. These are regions of the cell which should not be used by the ASIC tools. For example, if a cell needs to use metal 2 (M2), it would create a blockage on M2 so that the ASIC tools know not to route any M2 wires in that area. You can use Klayout to view <code>.lef</code> files as well.</p> <pre><code>% klayout ${ECE6745_STDCELLS}/stdcells.lef\n</code></pre> <p>Here is a picture of the <code>.lef</code> for the 3-input NAND gate.</p> <p></p> <p>If you compare the <code>.lef</code> to the <code>.gds</code> you can see that the <code>.lef</code> is a much simpler representation that only captures the boundary, pins, and obstructions.</p>"},{"location":"ece6745-tut05-asic-stdcells/#27-routing-technology-files","title":"2.7. Routing Technology Files","text":"<p>The standard-cell library also includes several files (e.g., <code>rtk-tech.tf</code>, <code>rtk-tech.lef</code>, <code>rtk-typical.captable</code>) that capture information about the metal interconnect including the wire width, pitch, and parasitics. For example, let's take a look at the <code>.captable</code> file:</p> <pre><code>% less -p M1 ${ECE6745_STDCELLS}/rtk-typical.captable\nLAYER M1\n  MinWidth              0.07000\n  MinSpace              0.06500\n  Height                0.37000\n  Thickness             0.13000\n  TopWidth              0.07000\n  BottomWidth           0.07000\n  WidthDev              0.00000\n  Resistance            0.38000\nEND\n...\nM1\nwidth(um)  space(um) Ctot(Ff/um)  Cc(Ff/um)    Carea(Ff/um) Cfrg(Ff/um)\n0.070       0.052       0.1986       0.0723       0.0311       0.0115\n0.070       0.065       0.1705       0.0509       0.0311       0.0143\n0.070       0.200       0.1179       0.0115       0.0311       0.0319\n0.070       0.335       0.1150       0.0030       0.0311       0.0388\n0.070       0.470       0.1148       0.0009       0.0311       0.0409\n0.070       0.605       0.1147       0.0002       0.0311       0.0416\n0.070       0.740       0.1147       0.0001       0.0311       0.0417\n</code></pre> <p>This file contains information about the minimum dimenisions of wires on M1 and the resistance of these wires. It also contains a table of wire capacitances with different rows for different wire widths and spacings. The ASIC tools can use this kind of technology information to optimize and analyze the design.</p>"},{"location":"ece6745-tut05-asic-stdcells/#3-to-do-on-your-own","title":"3. To Do On Your Own","text":"<p>Great ASIC designers spend time getting to know their standard cell library. Spend some time exploring other important standard cells in the NanGate standard cell library. We recommend you look at:</p> <ul> <li>NAND3_X2: Three-input NAND gate with 2x drive strength</li> <li>NAND3_X4: Three-input NAND gate with 4x drive strength</li> <li>MUX2_X1: Two-input 1-bit multiplexor</li> <li>INV_X1: Inverter</li> <li>FA: 1-bit full adder</li> <li>DFF_X1: D flip-flop</li> </ul> <p>Compare the GDS layout views and LIB logic views for the three different three-input NAND gates each with a different drive strength. Look at the SPICE schematic view to see if you can figure out how the MUX2 gate is implemented at the transistor level (i.e., try to draw a transistor-level schematic diagram). Compare the complexity of the full adder and D flip-flop to a basic inverter by looking at the Verilog behavioral views and the GDS layout.</p>"},{"location":"ece6745-tut06-asic-front-end/","title":"ECE 6745 Tutorial 6: ASIC Front-End Flow","text":"<p>The tutorial will discuss the key tools used for ASIC front-end flow which includes RTL simulation, synthesis, and fast-functional gate-level simulation. This tutorial requires entering commands manually for each of the tools to enable students to gain a better understanding of the detailed steps involved in this process. A later tutorial will illustrate how this process can be automated to facilitate rapid design-space exploration. This tutorial assumes you have already completed the tutorials on Linux, Git, and Verilog.</p> <p>The following diagram illustrates the five primary tools we will be using in ECE 6745 along with a few smaller secondary tools. The tools that make-up the ASIC front-end flow are highlighted in red. Notice that the ASIC tools all require various views from the standard-cell library. Before starting this tutorial, you must complete the ASIC standard-cell tutorial so you can understand all of these views.</p> <p></p> <ol> <li> <p>We write our RTL models in Verilog, and we use the PyMTL framework to     test, verify, and evaluate the execution time (in cycles) of our     design. This part of the flow is very similar to the flow used in     ECE 4750. Once we are sure our design is working correctly, we can     then start to push the design through the flow.</p> </li> <li> <p>We use Synopsys VCS to compile and run both 4-state RTL and     gate-level simulations. These simulations help us to build confidence     in our design as we push our designs through different stages of the     flow. From these simulations, we also generate waveforms in <code>.vcd</code>     (Verilog Change Dump) format, and per-net average activity factors     stored in <code>.saif</code> format. These activity factors will be used for     power analysis. Gate-level simulation is an valuable tool for     ensuring the tools did not optimize something away which impacts the     correctness of the design, and also provides an avenue for obtaining     a more accurate power analysis than RTL simulation. While static     timing analysis (STA) analyzes all paths, GL simulation can also     serve as a backup to check for hold and setup time violations (chip     designers must be paranoid!)</p> </li> <li> <p>We use Synopsys Design Compiler (DC) to synthesize our design,     which means to transform the Verilog RTL model into a Verilog     gate-level netlist where all of the gates are selected from the     standard-cell library. We need to provide Synopsys DC with abstract     logical and timing views of the standard-cell library in <code>.db</code>     format. In addition to the Verilog gate-level netlist, Synopsys DC     can also generate a <code>.ddc</code> file which contains information about the     gate-level netlist and timing, and this <code>.ddc</code> file can be inspected     using Synopsys Design Vision (DV). We will also use Synopsys DC to     generate a <code>.sdc</code> which captures timing constraints which can then be     used as input to the place-and-route tool.</p> </li> <li> <p>We use Cadence Innovus to place-and-route our design, which means     to place all of the gates in the gate-level netlist into rows on the     chip and then to generate the metal wires that connect all of the     gates together. We need to provide Cadence Innovus with the same     abstract logical and timing views used in Synopsys DC, but we also     need to provide Cadence Innovus with technology information in     <code>.lef</code>, and <code>.captable</code> format and abstract physical views of the     standard-cell library also in <code>.lef</code> format. Cadence Innovus will     generate an updated Verilog gate-level netlist, a <code>.spef</code> file which     contains parasitic resistance/capacitance information about all nets     in the design, and a <code>.gds</code> file which contains the final layout. The     <code>.gds</code> file can be inspected using the open-source Klayout GDS     viewer. Cadence Innovus also generates reports which can be used to     accurately characterize area and timing.</p> </li> <li> <p>We use Synopsys PrimeTime (PT) to perform power analysis of our     design. We need to provide Synopsys PT with the same abstract     logical, timing, and power views used in Synopsys DC and Cadence     Innovus, but in addition we need to provide switching activity     information for every net in the design (which comes from the <code>.saif</code>     file), and capacitance information for every net in the design (which     comes from the <code>.spef</code> file). Synopsys PT puts the switching     activity, capacitance, clock frequency, and voltage together to     estimate the power consumption of every net and thus every module in     the design, and these estimates are captured in various reports.</p> </li> </ol> <p>Extensive documentation is provided by Synopsys and Cadence for these ASIC tools. We have organized this documentation and made it available to you on the public course webpage:</p> <ul> <li>https://www.csl.cornell.edu/courses/ece6745/asicdocs</li> </ul> <p>The first step is to access <code>ecelinux</code>. Use VS Code to log into a specific <code>ecelinux</code> server and then use Microsoft Remote Desktop to log into the same server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut06-asic-front-end tut06\n% cd tut06\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#1-pymtl3-based-testing-simulation-translation","title":"1. PyMTL3-Based Testing, Simulation, Translation","text":"<p>Our goal in this tutorial is to generate a gate-level netlist for the sort unit from the Verilog tutorial using the ASIC tools. As a reminder, the sort unit takes as input four integers and a valid bit and outputs those same four integers in increasing order with the valid bit. The sort unit is implemented using a three-stage pipelined, bitonic sorting network and the datapath is shown below.</p> <p></p>"},{"location":"ece6745-tut06-asic-front-end/#11-implement-test-and-translate-a-sort-unit","title":"1.1. Implement, Test, and Translate a Sort Unit","text":"<p>Let's start by running the tests for the sort unit and note that the tests for the <code>SortUnitStruct</code> will fail.</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/sort\n</code></pre> <p>You can just copy over your implementation of the <code>MinMaxUnit</code> from when you completed the Verilog tutorial. If you have not completed the Verilog tutorial then you might want to go back and do that now. Basically the <code>MinMaxUnit</code> should look like this:</p> <pre><code>module tut3_verilog_sort_MinMaxUnit\n#(\n  parameter p_nbits = 1\n)(\n  input  logic [p_nbits-1:0] in0,\n  input  logic [p_nbits-1:0] in1,\n  output logic [p_nbits-1:0] out_min,\n  output logic [p_nbits-1:0] out_max\n);\n\n  always_comb begin\n\n    // Find min/max\n\n    if ( in0 &gt;= in1 ) begin\n      out_max = in0;\n      out_min = in1;\n    end\n    else if ( in0 &lt; in1 ) begin\n      out_max = in1;\n      out_min = in0;\n    end\n\n    // Handle case where there is an X in the input\n\n    else begin\n      out_min = 'x;\n      out_max = 'x;\n    end\n\n  end\n\nendmodule\n</code></pre> <p>Once you have your design working rerun the tests with the <code>--test-verilog</code> and <code>--dump-vtb</code> command line options.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/sort --test-verilog --dump-vtb\n</code></pre> <p>The <code>--test-verilog</code> and <code>--dump-vtb</code> command line options tells the PyMTL3 framework to dump a Verilog testbench. While PyMTL3 enables combining Python testbenches with Verilator Verilog simulation, we need to translate our testbenches to Verilog so that we can use Synopsys VCS to do 4-state and gate-level simulation. Let's look at a testbench cases file generated from using the <code>--dump-vtb</code> flag.</p> <pre><code>% cd $TOPDIR/sim/build\n% cat SortUnitStruct__p_nbits_8_test_basic_tb.v.cases\n\n `T('h00,'h00,'h00,'h00,'h0,'h00,'h00,'h00,'h00,'h0);\n `T('h04,'h02,'h03,'h01,'h1,'h00,'h00,'h00,'h00,'h0);\n `T('h00,'h00,'h00,'h00,'h0,'h00,'h00,'h00,'h00,'h0);\n `T('h00,'h00,'h00,'h00,'h0,'h00,'h00,'h00,'h00,'h0);\n `T('h00,'h00,'h00,'h00,'h0,'h01,'h02,'h03,'h04,'h1);\n `T('h00,'h00,'h00,'h00,'h0,'h00,'h00,'h00,'h00,'h0);\n `T('h00,'h00,'h00,'h00,'h0,'h00,'h00,'h00,'h00,'h0);\n `T('h00,'h00,'h00,'h00,'h0,'h00,'h00,'h00,'h00,'h0);\n `T('h00,'h00,'h00,'h00,'h0,'h00,'h00,'h00,'h00,'h0);\n</code></pre> <p>This file is generated by logging the inputs and outputs of the Verilator RTL simulation each cycle. It will be passed into a Verilog testbench runner that will use these values to set the inputs each cycle and to verify the outputs each cycle. So note that when we utilize these testbenches later on, we are running a simulation that is simply confirming that we acheive the same behavior as the Verilator RTL simulation we ran using PyMTL3, and it is not actually using any assertions you wrote in your Python tests for your design. Therefore, it is important that your RTL simulations pass using PyMTL3 and Verilator before you move on to other simulations. Also take a look at the testbench itself to get a sense for how it works. It essentially instantiates your top module as <code>DUT</code>, sets the inputs, and performs a check every cycle on the outputs.</p> <pre><code>% cd $TOPDIR/sim/build\n% less SortUnitStruct__p_nbits_8_test_basic_tb.v\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#22-interactive-simulator-for-sort-unit","title":"2.2. Interactive Simulator for Sort Unit","text":"<p>After running the tests we use the interactive simulator for the sort unit to do the final evaluation.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut3_verilog/sort/sort-sim --short-mname --impl rtl-struct --stats \\\n                                --translate --dump-vtb\nnum_cycles          = 106\nnum_cycles_per_sort = 1.06\n</code></pre> <p>Take a moment to open up the translated Verilog which should be in a file named <code>SortUnitStruct__pickled.v</code>. The Verilog module name includes a suffix to make it unique for a specific set of parameters.</p>"},{"location":"ece6745-tut06-asic-front-end/#2-synopsys-vcs-for-4-state-rtl-simulation","title":"2. Synopsys VCS for 4-state RTL simulation","text":"<p>Using the PyMTL simulation framework can give us a good foundation in verifying a design. However, the Verilator RTL simulator is only a 2-state simulation, meaning a signal can only be <code>0</code> or <code>1</code>. An alternative form of RTL simulation is a 4-state simulation, in which signals can be <code>0</code>, <code>1</code>, <code>x</code>, or <code>z</code>.</p> <p>It is important to note a key difference between 2-state and 4-state simulation. In 2-state simulation, each variable is initialized to a predetermined value. This initial condition assumption may or may not be what happens in actual silicon! As a result, a different initial condition could introduce a bug that was not caught by our 2-state Verilator RTL simulation. In 4-state simulations no such assumptions are made. Instead, every signal begins as <code>x</code>, and only resolves to a <code>0</code> or <code>1</code> after it is driven or resolved using x-propagation. Consider the following pseudocode:</p> <pre><code>always @(*)\nbegin\n  if ( control_signal )\n    // set signal \"signal_a\", but bug causes chip to fail\n  else\n    // set signal \"signal_a\" such that everything works fine\nend\n</code></pre> <p>If <code>control_signal</code> is not reset, then in 2-state simulation if you initialize all state to zero it will look like the chip works fine, but this is not a safe assumption! The real chip does not guarantee that all state is initialized to zero, so we can model that in four state simulation as an <code>x</code>. Since the control signal could initialize to 1, this could non-deterministically cause the chip to fail! What you would see in simulation is that <code>signal_a</code> would become an <code>x</code>, because we do not know the value of <code>control_signal</code> on reset. This <code>x</code> is propagated through the design, and some simulators are more optimistic/pessimistic about x's than others. For example, a pessimistic simulator may just assume that any piece of logic that has an x on the input, outputs an x. This is pessimistic because it is possible that you can still resolve the output (imagine a mux where two inputs are the same but the select bit is an <code>x</code>). Optimism is the opposite, resolving signals to <code>0</code> or <code>1</code> that should remain an <code>x</code>.</p> <p>If your design is passing every 2-state simulation, but failing every 4-state simulation, it may be because invalid fields are being set to <code>x</code>'s. Our test harnesses require all outputs to always be <code>0</code> or <code>1</code> even if a field is invalid. So you may need to force invalid fields to zero and ensure that during a correct execution the outputs of your module are never <code>x</code>'s. You can see this in the implementation of <code>SortUnitStruct</code>:</p> <pre><code>assign out_val = val_S3;\nassign out0    = elm0_S3         &amp; {p_nbits{val_S3}};\nassign out1    = mmuA_out_min_S3 &amp; {p_nbits{val_S3}};\nassign out2    = mmuA_out_max_S3 &amp; {p_nbits{val_S3}};\nassign out3    = elm3_S3         &amp; {p_nbits{val_S3}};\n</code></pre> <p>We run Synopsys VCS to compile a simulation, and <code>./simv</code> to run the simulation. Let's run a 4-state simulation for <code>test_basic</code> using the design <code>SortUnitStruct__pickled.v</code>.</p> <pre><code>% cd $TOPDIR/asic/build-sort/01-synopsys-vcs-rtlsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${TOPDIR}/sim/build/SortUnitStruct__p_nbits_8_test_basic_tb.v \\\n    ${TOPDIR}/sim/build/SortUnitStruct__p_nbits_8__pickled.v\n% ./simv\n</code></pre> <p>Here some of the key command line options for Synopsys VCS:</p> <pre><code>-sverilog                     indicates we are using SystemVerilog\n-xprop=tmerge                 use more advanced X propoagation\n-override_timescale=1ns/1ps   changes the timescale. Units/precision\n-top Top                      name of the top module (located within the VTB)\n+vcs+dumpvars+filename.vcd    dump VCD in current dir with the name filename.vcd\n+incdir+$TOPDIR/sim/build     specifies directories to search for `include\n</code></pre> <p>Synopsys VCS is a sophisticated tool with many command line options. If you want to learn more on your own about other options that are available to you with Synopsys VCS, you can look at the user guides on the course webpage:</p> <ul> <li>https://www.csl.cornell.edu/courses/ece6745/asicdocs</li> </ul> <p>Open up the resulting VCD filea and notice how all of the input ports start as X values and then eventually become non-X values after reset. Notice how the pipeline registers are not reset so it takes a few cycles for them to be output non-X values.</p> <p></p> <p>Let's run another 4-state simulation, this time using the testbench from the sort-rtl simulator run that we ran earlier. Note that while we can use this VCD for power analysis, for the purposes of this tutorial we will only be doing power analysis using the gate-level netlist.</p> <pre><code>% cd $TOPDIR/asic/build-sort/01-synopsys-vcs-rtlsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n      +vcs+dumpvars+waves.vcd \\\n      +incdir+${TOPDIR}/sim/build \\\n      ${TOPDIR}/sim/build/SortUnitStruct_random_tb.v \\\n      ${TOPDIR}/sim/build/SortUnitStruct__pickled.v\n% ./simv\n</code></pre> <p>To simplify rerunning a simulation, we can put the above command lines in a shell script. We have created such a run script for you. Let's take a look to confirm these scripts match the manual commands we used above.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./01-synopsys-vcs-rtlsim/run\n</code></pre> <p>You can rerun four-state RTL simulation as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% ./01-synopsys-vcs-rtlsim/run\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#3-synopsys-design-compiler-for-synthesis","title":"3. Synopsys Design Compiler for Synthesis","text":"<p>We use Synopsys Design Compiler (DC) to synthesize Verilog RTL models into a gate-level netlist where all of the gates are from the standard cell library. So Synopsys DC will synthesize the Verilog <code>+</code> operator into a specific arithmetic block at the gate-level. Based on various constraints it may synthesize a ripple-carry adder, a carry-look-ahead adder, or even more advanced parallel-prefix adders.</p> <p>We start by creating a subdirectory for our work, and then launching Synopsys DC.</p> <pre><code>% cd $TOPDIR/asic/build-sort/02-synopsys-dc-synth\n% dc_shell-xg-t\n</code></pre> <p>To make it easier to copy-and-paste commands from this document, we tell Synopsys DC to ignore the prefix <code>dc_shell&gt;</code> using the following:</p> <pre><code>dc_shell&gt; alias \"dc_shell&gt;\" \"\"\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#31-initial-setup","title":"3.1. Initial Setup","text":"<p>There are two important variables we need to set before starting to work in Synopsys DC. The <code>target_library</code> variable specifies the standard cells that Synopsys DC should use when synthesizing the RTL. The <code>link_library</code> variable should search the standard cells, but can also search other cells (e.g., SRAMs) when trying to resolve references in our design. These other cells are not meant to be available for Synopsys DC to use during synthesis, but should be used when resolving references. Including <code>*</code> in the <code>link_library</code> variable indicates that Synopsys DC should also search all cells inside the design itself when resolving references.</p> <pre><code>dc_shell&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db\"\ndc_shell&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db\"\n</code></pre> <p>Note that we can use <code>$env(ECE6745_STDCELLS)</code> to get access to the <code>$ECE6745_STDCELLS</code> environment variable which specifies the directory containing the standard cells, and that we are referencing the abstract logical and timing views in the <code>.db</code> format.</p> <p>We also need to tell Synopsys DC not use scan flip-flops and clock-gating cells which are included in our standard-cell library. If Synopsys DC uses these cells it can cause isses with gate-level simulation. We can do this using the <code>set_dont_use</code> command as follows.</p> <pre><code>dc_shell&gt; set_dont_use -power {\n  NangateOpenCellLibrary/SDFF_X1\n  NangateOpenCellLibrary/SDFF_X2\n  NangateOpenCellLibrary/SDFFS_X1\n  NangateOpenCellLibrary/SDFFS_X2\n  NangateOpenCellLibrary/SDFFR_X1\n  NangateOpenCellLibrary/SDFFR_X2\n  NangateOpenCellLibrary/SDFFRS_X1\n  NangateOpenCellLibrary/SDFFRS_X2\n  NangateOpenCellLibrary/CLKGATETST_X1\n  NangateOpenCellLibrary/CLKGATETST_X2\n  NangateOpenCellLibrary/CLKGATETST_X4\n  NangateOpenCellLibrary/CLKGATETST_X8\n}\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#32-inputs","title":"3.2. Inputs","text":"<p>As an aside, if you want to learn more about any command in any Synopsys tool, you can simply type <code>man toolname</code> at the shell prompt. We are now ready to read in the Verilog file which contains the top-level design and all referenced modules. We do this with two commands. The <code>analyze</code> command reads the Verilog RTL into an intermediate internal representation. The <code>elaborate</code> command recursively resolves all of the module references starting from the top-level module, and also infers various registers and/or advanced data-path components.</p> <pre><code>dc_shell&gt; analyze -format sverilog ../../../sim/build/SortUnitStruct__pickled.v\ndc_shell&gt; elaborate SortUnitStruct\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#33-timing-constraints","title":"3.3. Timing Constraints","text":"<p>We need to create a clock constraint to tell Synopsys DC what our target cycle time is. Synopsys DC will not synthesize a design to run \"as fast as possible\". Instead, the designer gives Synopsys DC a target cycle time and the tool will try to meet this constraint while minimizing area and power. The <code>create_clock</code> command takes the name of the clock signal in the Verilog (which in this course will always be <code>clk</code>), the label to give this clock (i.e., <code>ideal_clock1</code>), and the target clock period in nanoseconds. So in this example, we are asking Synopsys DC to see if it can synthesize the design to run at 1.4GHz (i.e., a cycle time of 700ps).</p> <pre><code>dc_shell&gt; create_clock clk -name ideal_clock1 -period 0.7\n</code></pre> <p>In addition to the clock constraint we also need to constrain the max transition time to ensure no net takes a very long time to transition. Here we constrain the max transition to be 250ps.</p> <pre><code>dc_shell&gt; set_max_transition 0.250 SortUnitStruct\n</code></pre> <p>We need to constrain what kind of cells are expected to drive the input pins and what kind of load is expected at the output pin so Synopsys DC can properly synthesize the design. here we constrain the input cells to be inverters with 2x drive strength and the output load to be 7fF.</p> <pre><code>dc_shell&gt; set_driving_cell -no_design_rule -lib_cell INV_X2 [all_inputs]\ndc_shell&gt; set_load -pin_load 7 [all_outputs]\n</code></pre> <p>In an ideal world, all inputs would change immediately with the clock edge. In reality, this is not the case since there will be some logic before this block on the chip as shown in the following figure.</p> <p></p> <p>We need to include reasonable propagation and contamination delays for the input ports so Synopsys DC can factor these into its timing analysis. Here, we choose the max input delay constraint to be 50ps (i.e., the block needs to meet the setup time constraints even if the inputs change 50ps after the rising edge of the clock), and we choose the min input delay constraint to be 0ps (i.e., the block needs to meet the hold time constraints even if the inputs change right on the rising edge clock).</p> <pre><code>dc_shell&gt; set_input_delay -clock ideal_clock1 -max 0.050 [all_inputs -exclude_clock_ports]\ndc_shell&gt; set_input_delay -clock ideal_clock1 -min 0.000 [all_inputs -exclude_clock_ports]\n</code></pre> <p>We also need to constrain the output ports since there will be some logic after this block on the chip as shown in the following figure.</p> <p></p> <p>We need to include reasonable setup and hold time constraints for the output ports so Synopsys DC can factor these into into its timing analysis. Here we choose a setup time constraint of 50ps meaning the output data must be stable 50ps before the rising edge of the clock, and we choose a hold time constraint of 0ps meaning the outputs can change right on the rising edge of the clock.</p> <pre><code>dc_shell&gt; set_output_delay -clock ideal_clock1 -max 0.050 [all_outputs]\ndc_shell&gt; set_output_delay -clock ideal_clock1 -min 0.000 [all_outputs]\n</code></pre> <p>Finally we also need to constraint any combinational paths which go directly from the input ports to the output ports. Here we constrain such paths to be no longer than one cycle cycle.</p> <pre><code>dc_shell&gt; set_max_delay 0.7 -from [all_inputs -exclude_clock_ports] -to [all_outputs]\n</code></pre> <p>Once we have finished setting all of the constraints we can use <code>check_timing</code> to make sure there are no unconstrained paths or other issues.</p>"},{"location":"ece6745-tut06-asic-front-end/#34-synthesis","title":"3.4. Synthesis","text":"<p>We can use the <code>check_design</code> command to make sure there are no obvious errors in our Verilog RTL.</p> <pre><code>dc_shell&gt; check_design\n</code></pre> <p>It is critical that you carefully review all warnings and errors when you analyze and elaborate a design with Synopsys DC. There may be many warnings, but you should still skim through them. Often times there will be something very wrong in your Verilog RTL which means any results from using the ASIC tools is completely bogus. Synopsys DC will output a warning, but Synopsys DC will usually just keep going, potentially producing a completely incorrect gate-level model!</p> <p>Finally, the <code>compile</code> command will do the synthesis.</p> <pre><code>dc_shell&gt; compile\n</code></pre> <p>During synthesis, Synopsys DC will display information about its optimization process. It will report on its attempts to map the RTL into standard-cells, optimize the resulting gate-level netlist to improve the delay, and then optimize the final design to save area.</p> <p>The <code>compile</code> command does not flatten your design. Flatten means to remove module hierarchy boundaries; so instead of having module A and module B within module C, Synopsys DC will take all of the logic in module A and module B and put it directly in module C. You can enable flattening with the <code>-ungroup_all</code> option. Without extra hierarchy boundaries, Synopsys DC is able to perform more optimizations and potentially achieve better area, energy, and timing. However, an unflattened design is much easier to analyze, since if there is a module A in your RTL design that same module will always be in the synthesized gate-level netlist.</p> <p>The <code>compile</code> command does not perform many optimizations. Synopsys DC also includes <code>compile_ultra</code> which does many more optimizations and will likely produce higher quality of results. Keep in mind that the <code>compile</code> command will not flatten your design by default, while the <code>compile_ultra</code> command will flattened your design by default. You can turn off flattening by using the <code>-no_autoungroup</code> option with the <code>compile_ultra</code> command. <code>compile_ultra</code> also has the option <code>-gate_clock</code> which automatically performs clock gating on your design, which can save quite a bit of power. Once you finish this tutorial, feel free to go back and experiment with this command.</p> <pre><code>dc_shell&gt; compile_ultra -no_autoungroup -gate_clock`\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#34-outputs","title":"3.4. Outputs","text":"<p>Now that we have synthesized the design, we output the resulting gate-level netlist in two different file formats: <code>.ddc</code> (which we will use with Synopsys DesignVision) and Verilog. We also output an <code>.sdc</code> file which contains the constraint information we gave Synopsys DC. We will pass this same constraint information to Cadence Innovus during the place and route portion of the flow.</p> <pre><code>dc_shell&gt; write -format ddc     -hierarchy -output post-synth.ddc\ndc_shell&gt; write -format verilog -hierarchy -output post-synth.v\ndc_shell&gt; write_sdc post-synth.sdc\n</code></pre> <p>We can use various commands to generate reports about timing and area. The <code>report_timing</code> command will show the critical path through the design. Part of the report is displayed below.</p> <pre><code>dc_shell&gt; report_timing -nets\n Point                                      Fanout Incr  Path\n ---------------------------------------------------------------\n clock ideal_clock1 (rise edge)                    0.00  0.00\n clock network delay (ideal)                       0.00  0.00\n v/elm1_S0S1/q_reg[1]/CK (DFF_X1)                  0.00  0.00 r\n v/elm1_S0S1/q_reg[1]/Q (DFF_X1)                   0.08  0.08 f\n v/elm1_S0S1/q[1] (net)                     2      0.00  0.08 f\n v/elm1_S0S1/q[1] (vc_Reg_p_nbits8_11)             0.00  0.08 f\n v/elm1_S1[1] (net)                                0.00  0.08 f\n v/mmuA_S1/in1[1] (MinMaxUnit)                     0.00  0.08 f\n v/mmuA_S1/in1[1] (net)                            0.00  0.08 f\n v/mmuA_S1/U10/ZN (INV_X1)                         0.04  0.12 r\n v/mmuA_S1/n22 (net)                        3      0.00  0.12 r\n v/mmuA_S1/U45/ZN (AOI21_X1)                       0.03  0.15 f\n v/mmuA_S1/n8 (net)                         1      0.00  0.15 f\n v/mmuA_S1/U46/ZN (AOI222_X1)                      0.09  0.24 r\n v/mmuA_S1/n9 (net)                         1      0.00  0.24 r\n v/mmuA_S1/U9/ZN (NOR3_X1)                         0.03  0.27 f\n v/mmuA_S1/n10 (net)                        1      0.00  0.27 f\n v/mmuA_S1/U6/ZN (NOR3_X1)                         0.06  0.33 r\n v/mmuA_S1/n11 (net)                        1      0.00  0.33 r\n v/mmuA_S1/U3/ZN (NOR3_X1)                         0.03  0.36 f\n v/mmuA_S1/n12 (net)                        1      0.00  0.36 f\n v/mmuA_S1/U47/ZN (AOI221_X1)                      0.08  0.44 r\n v/mmuA_S1/n13 (net)                        1      0.00  0.44 r\n v/mmuA_S1/U48/ZN (OAI22_X1)                       0.05  0.49 f\n v/mmuA_S1/n15 (net)                        2      0.00  0.49 f\n v/mmuA_S1/U27/ZN (OAI21_X1)                       0.04  0.53 r\n v/mmuA_S1/N1 (net)                         1      0.00  0.53 r\n v/mmuA_S1/U49/ZN (INV_X2)                         0.06  0.59 f\n v/mmuA_S1/n23 (net)                        6      0.00  0.59 f\n v/mmuA_S1/U43/ZN (OAI22_X1)                       0.06  0.65 r\n v/mmuA_S1/out_max[7] (net)                 1      0.00  0.65 r\n v/mmuA_S1/out_max[7] (MinMaxUnit)                 0.00  0.65 r\n v/mmuA_out_max_S1[7] (net)                        0.00  0.65 r\n v/elm1_S1S2/d[7] (vc_Reg_p_nbits8_7)              0.00  0.65 r\n v/elm1_S1S2/d[7] (net)                            0.00  0.65 r\n v/elm1_S1S2/q_reg[7]/D (DFF_X1)                   0.01  0.66 r\n data arrival time                                       0.66\n\n clock ideal_clock1 (rise edge)                    0.70  0.70\n clock network delay (ideal)                       0.00  0.70\n v/elm1_S1S2/q_reg[7]/CK (DFF_X1)                  0.00  0.70 r\n library setup time                               -0.04  0.66\n data required time                                      0.66\n ---------------------------------------------------------------\n data required time                                      0.66\n data arrival time                                       0.66\n ---------------------------------------------------------------\n slack (MET)                                             0.00\n</code></pre> <p>This timing report uses static timing analysis to find the critical path. Static timing analysis checks the timing across all paths in the design (regardless of whether these paths can actually be used in practice) and finds the longest path. For more information about static timing analysis, consult Chapter 1 of the Synopsys Timing Constraints and Optimization User Guide. The report clearly shows that the critical path starts at bit 1 of a pipeline register in between the S0 and S1 stages (<code>elm1_S0S1</code>), goes into an input of a <code>MinMaxUnit</code>, comes out the <code>out_max</code> port of the <code>MinMaxUnit</code>, and ends at the pipeline register between the S1 and S2 stages (`elm1_S1S21). The report shows the delay through each logic gate (e.g., the clk-to-q delay of the initial DFF is 80ps, the propagation delay of a AOI21_X1 gate is 150ps) and the total delay for the critical path which in this case is 0.66ns.</p> <p>The difference between the required arrival time and the actual arrival time is called the slack. In the above report we just meet timing with zero slack. Positive slack means the path arrived before it needed to while negative slack means the path arrived after it needed to. If you end up with negative slack, then you need to rerun the tools with a longer target clock period until you can meet timing with no negative slack. The process of tuning a design to ensure it meets timing is called \"timing closure\". In this course, we are primarily interested in design-space exploration as opposed to meeting some externally defined target timing specification. So you will need to sweep a range of target clock periods. Your goal is to choose the shortest possible clock period which still meets timing without any negative slack! This will result in a well-optimized design and help identify the \"fundamental\" performance of the design. Alternatively, if you are comparing multiple designs, sometimes the best situation is to tune the baseline so it meets timing and then ensure the alternative designs have similar cycle times. This will enable a fair comparison since all designs will be running at the same cycle time.</p> <p>The <code>report_area</code> command will show how much area is required to implement each module in the design.</p> <pre><code>                    Global cell area          Local cell area\n                    ------------------  ---------------------------\nHierarchical cell   Absolute   Percent  Combi-    Noncombi-  Black-\n                    Total      Total    national  national   boxes   Design\n------------------  ---------  -------  --------  ---------  ------  -----------------------------------------\nSortUnitStruct       745.0660    100.0    0.0000     0.0000  0.0\n  SortUnitStruct\nv                    745.0660    100.0   35.9100     0.0000  0.0000  tut3_verilog_sort_SortUnitStruct_p_nbits8\nv/elm0_S0S1           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_0\nv/elm0_S1S2           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_8\nv/elm0_S2S3           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_4\nv/elm1_S0S1           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_11\nv/elm1_S1S2           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_7\nv/elm1_S2S3           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_3\nv/elm2_S0S1           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_10\nv/elm2_S1S2           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_6\nv/elm2_S2S3           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_2\nv/elm3_S0S1           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_9\nv/elm3_S1S2           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_5\nv/elm3_S2S3           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_1\nv/mmuA_S1             50.0080      6.7   50.0080     0.0000  0.0000  tut3_verilog_sort_MinMaxUnit_p_nbits8_0\nv/mmuA_S2             50.0080      6.7   50.0080     0.0000  0.0000  tut3_verilog_sort_MinMaxUnit_p_nbits8_3\nv/mmuA_S3             57.1900      7.7   57.1900     0.0000  0.0000  tut3_verilog_sort_MinMaxUnit_p_nbits8_1\nv/mmuB_S1             50.2740      6.7   50.2740     0.0000  0.0000  tut3_verilog_sort_MinMaxUnit_p_nbits8_4\nv/mmuB_S2             50.0080      6.7   50.0080     0.0000  0.0000  tut3_verilog_sort_MinMaxUnit_p_nbits8_2\nv/val_S0S1             5.8520      0.8    1.3300     4.5220  0.0000  vc_ResetReg_p_nbits1_0\nv/val_S1S2             5.8520      0.8    1.3300     4.5220  0.0000  vc_ResetReg_p_nbits1_2\nv/val_S2S3             5.8520      0.8    1.3300     4.5220  0.0000  vc_ResetReg_p_nbits1_1\n------------------  ---------  -------  --------  ---------  ------  -----------------------------------------\nTotal                                   297.3880   447.6780  0.0000\n</code></pre> <p>The design requires 745um^2. Each pipeline register requires about 5% of the total area and each min/max unit requires about 7% of the total area. The area required for all 12 pipeline registers is about 60% of the total area, and the area required for all five of the min/max units is about 35% of the total area.</p> <p>Finally, we go ahead and exit Synopsys DC.</p> <pre><code>dc_shell&gt; exit\n</code></pre> <p>Take a few minutes to examine the resulting Verilog gate-level netlist. Notice that the module hierarchy is preserved and also notice that the <code>MinMaxUnit</code> synthesizes into a large number of basic logic gates.</p> <pre><code>% cd $TOPDIR/asic/build-sort/02-synopsys-dc-synth\n% more post-synth.v\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#35-synopsys-design-vision","title":"3.5. Synopsys Design Vision","text":"<p>We can use the Synopsys Design Vision (DV) tool for browsing the resulting gate-level netlist, plotting critical path histograms, and generally analyzing our design. Start Synopsys DV and setup the <code>target_library</code> and <code>link_library</code> variables as before.</p> <pre><code>% cd $TOPDIR/asic/build-sort/02-synopsys-dc-synth\n% design_vision-xg\ndesign_vision&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db\"\ndesign_vision&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db\"\n</code></pre> <p>You can use the following steps to open the <code>.ddc</code> file generated during synthesis.</p> <ul> <li>Choose File &gt; Read from the menu</li> <li>Open the <code>post-synth.dcc</code> file</li> </ul> <p>You can then use the following steps to browse the gate-level schematic. First select a module in the Logical Hierarchy panel. Then choose Schematic &gt; New Schematic View. You can double click on modules to expand them. You might also want to try this approach to see the entire design at once:</p> <ul> <li>Select the <code>SortUnitStruct__p_nbits_8</code> module in the Logical Hierarchy panel</li> <li>Choose Select &gt; Cells &gt; Leaf Cells of Selected Cells from the menu</li> <li>Choose Schematic &gt; New Schematic View from the menu</li> <li>Choose Select &gt; Clear from the menu</li> </ul> <p>You can use the following steps to view a histogram of path slack, and also to open a gave-level schematic of just the critical path.</p> <ul> <li>Choose Timing &gt; Path Slack from the menu</li> <li>Click OK in the pop-up window</li> <li>Select the left-most bar in the histogram to see list of most critical paths</li> <li>Select one of the paths in the path list to highlight the path in the schematic view</li> </ul> <p>Or you can right click on a path and choose Path Schematic to see just the gates that lie on the critical path. Notice that there eight levels of logic (including the register at the start) on the critical path. The number of levels of logic on the critical path can provide some very rough first-order intuition on whether or not we might want to explore a more aggressive clock constraint and/or adding more pipeline stages. If there are just a few levels of logic on the critical path then our design is probably very simple (as in this case!), while if there are more than 50 levels of logic then there is potentially room for signficant improvement. The following screen capture illutrates using Synopsys Design Vision to explore the post-synthesis results. While this can be interesting, in this course, we almost always prefer exploring the post-place-and-route results, so we will not really use Synopsys DV that often.</p> <p></p>"},{"location":"ece6745-tut06-asic-front-end/#36-automating-synthesis","title":"3.6. Automating Synthesis","text":"<p>You can automate the above steps by putting a sequence of commands in a <code>.tcl</code> file and run Synopsys DC using those commands in one step like this:</p> <pre><code>% cd $TOPDIR/asic/build-sort/02-synopsys-dc-synth\n% dc_shell-xg-t -f run.tcl\n</code></pre> <p>To further simplify rerunning this step, we can put the above command line in its own shell script. We have created such run scripts for you. Let's take a look to confirm these scripts match the manual commands we used above.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./02-synopsys-dc-synth/run\n% cat ./02-synopsys-dc-synth/run.tcl\n</code></pre> <p>You can rerun synthesis as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% ./02-synopsys-dc-synth/run\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#4-synopsys-vcs-for-fast-functional-gate-level-simulation","title":"4. Synopsys VCS for Fast-Functional Gate-Level Simulation","text":"<p>Before synthesis, we used Synopsys VCS to do a 4-state simulation. This time, we'll be using VCS to perform a gate-level simulation, since we now have a gate-level netlist available to us. Gate-level simulation provides an advantage over RTL simulation because it more precisely represents the specification of the true hardware generated by the tools. This sort of simulation could propogate X's into the design that were not found by the 4-state RTL simulation, and it also verifies that the tools did not optimize anything away during synthesis. We will use Synopsys VCS to run our gate-level simulation on the <code>sort-rtl-struct-random</code> simulator testbench:</p> <pre><code>% cd $TOPDIR/asic/build-sort/03-synopsys-vcs-ffglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n   +delay_mode_zero \\\n   +vcs+dumpvars+waves.vcd \\\n   +incdir+$TOPDIR/sim/build \\\n   ${ECE6745_STDCELLS}/stdcells.v \\\n   ${TOPDIR}/sim/build/SortUnitStruct_random_tb.v \\\n   ../02-synopsys-dc-synth/post-synth.v\n% ./simv\n</code></pre> <p>Notice there are some differences in the Synopsys VCS command we ran here, and the one we ran for 4-state RTL simulation. In this version, we use the gate-level netlist <code>post-synth.v</code> instead of the pickled file. We also include the option <code>+delay_mode_zero</code> which tells Synopsys VCS to run a fast-functional simulation in which no delays are considered. This is similar to RTL simulation, and you should notice that all signals will change on the clock edge. We also include the macros <code>CYCLE_TIME</code>, <code>VTB_INPUT_DELAY</code> , <code>VTB_OUTPUT_ASSERT_DELAY</code>. These values control how long after the rising edge we change the inputs and how long after the rising edge we check the outputs.</p> <p>To simplify rerunning a simulation, we can put the above command lines in a shell script. We have created such a run script for you. Let's take a look to confirm these scripts match the manual commands we used above.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./03-synopsys-vcs-ffglsim/run\n</code></pre> <p>You can rerun fast-functional gate-level simulation as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% ./03-synopsys-vcs-ffglsim/run\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#5-to-do-on-your-own","title":"5. To-Do On Your Own","text":"<p>Now we can use what you have learned so far to push the GCD unit through the ASIC front-end flow. First, run a simulation of the GCD unit.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut3_verilog/gcd/gcd-sim --short-mname --impl rtl --input random --stats \\\n                              --translate --dump-vtb\n% less GcdUnit__pickled.v\n</code></pre> <p>Now create a new ASIC build directory and copy the scripts we used to push the sort unit through the ASIC front-end flow.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-gcd/01-synopsys-vcs-rtlsim\n% mkdir -p $TOPDIR/asic/build-gcd/02-synopsys-dc-synth\n% mkdir -p $TOPDIR/asic/build-gcd/03-synopsys-vcs-ffglsim\n\n% cp $TOPDIR/asic/build-sort/01-synopsys-vcs-rtlsim/run   $TOPDIR/asic/build-gcd/01-synopsys-vcs-rtlsim\n% cp $TOPDIR/asic/build-sort/02-synopsys-dc-synth/run.tcl $TOPDIR/asic/build-gcd/02-synopsys-dc-synth\n% cp $TOPDIR/asic/build-sort/02-synopsys-dc-synth/run     $TOPDIR/asic/build-gcd/02-synopsys-dc-synth\n% cp $TOPDIR/asic/build-sort/03-synopsys-vcs-ffglsim/run  $TOPDIR/asic/build-gcd/03-synopsys-vcs-ffglsim\n</code></pre> <p>Now open up each of these files and modify so they push the GCD unit instead of the sort unit through the flow. You will need to update the name of the Verilog source files and the top module name as follows:</p> <ul> <li>Verilog source file name: <code>GcdUnit__pickled.v</code></li> <li>Verilog test source file name: <code>GcdUnit_random_tb.v</code></li> <li>Top module name for synthesis: <code>GcdUnit</code></li> </ul> <p>Basically, you just need to change <code>SortUnitStruct</code> to <code>GcdUnit</code> in all of the run scripts. You can use <code>sed</code> to do this:</p> <pre><code>% cd $TOPDIR/asic/build-gcd\n% find . -type f -exec sed -i.bak 's/SortUnitStruct/GcdUnit/' {} \\;\n</code></pre> <p>Keep the cycle time constraint as 700ps and the other constraints as before. Once you have updated the scripts you can then push the GCD unit through the flow like this:</p> <pre><code>% cd $TOPDIR/asic/build-gcd\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% ./03-synopsys-vcs-ffglsim/run\n</code></pre> <p>Carefully look at the post-synthesis timing report to ensure your design meetings timing:</p> <pre><code>% cd $TOPDIR/asic/build-gcd\n% cat 02-synopsys-dc-synth/timing.rpt\n</code></pre> <p>If your design does not meet timing, increase the cycle time constraint and try again until it does meet timing. Spend time looking at the post-synthesis gate-level netlist in <code>post-synth.v</code> and load the design into Synopsys Design Vision to examine the critical path. Carefully look and the results from running the fast-functional gate-level simulation to verify that the design is passing the test. Convince yourself that the GCD unit was successfully pushed through the ASIC front-end flow.</p>"},{"location":"ece6745-tut07-asic-back-end/","title":"ECE 6745 Tutorial 6: ASIC Back-End Flow","text":"<p>The tutorial will discuss the key tools used for ASIC back-end flow which includes place-and-route, back-annotated gate-level simulation, and power analysis. This tutorial requires entering commands manually for each of the tools to enable students to gain a better understanding of the detailed steps involved in this process. A later tutorial will illustrate how this process can be automated to facilitate rapid design-space exploration. This tutorial assumes you have already completed the tutorials on Linux, Git, and Verilog.</p> <p>The following diagram illustrates the five primary tools we will be using in ECE 6745 along with a few smaller secondary tools. The tools that make-up the ASIC back-end flow are highlighted in red. Notice that the ASIC tools all require various views from the standard-cell library. Before starting this tutorial, you must complete the ASIC standard-cell tutorial so you can understand all of these views and you must complete the ASIC front-end flow tutorial.</p> <p></p> <ol> <li> <p>We write our RTL models in Verilog, and we use the PyMTL framework to     test, verify, and evaluate the execution time (in cycles) of our     design. This part of the flow is very similar to the flow used in     ECE 4750. Once we are sure our design is working correctly, we can     then start to push the design through the flow.</p> </li> <li> <p>We use Synopsys VCS to compile and run both 4-state RTL and     gate-level simulations. These simulations help us to build confidence     in our design as we push our designs through different stages of the     flow. From these simulations, we also generate waveforms in <code>.vcd</code>     (Verilog Change Dump) format, and per-net average activity factors     stored in <code>.saif</code> format. These activity factors will be used for     power analysis. Gate-level simulation is an valuable tool for     ensuring the tools did not optimize something away which impacts the     correctness of the design, and also provides an avenue for obtaining     a more accurate power analysis than RTL simulation. While static     timing analysis (STA) analyzes all paths, GL simulation can also     serve as a backup to check for hold and setup time violations (chip     designers must be paranoid!)</p> </li> <li> <p>We use Synopsys Design Compiler (DC) to synthesize our design,     which means to transform the Verilog RTL model into a Verilog     gate-level netlist where all of the gates are selected from the     standard-cell library. We need to provide Synopsys DC with abstract     logical and timing views of the standard-cell library in <code>.db</code>     format. In addition to the Verilog gate-level netlist, Synopsys DC     can also generate a <code>.ddc</code> file which contains information about the     gate-level netlist and timing, and this <code>.ddc</code> file can be inspected     using Synopsys Design Vision (DV). We will also use Synopsys DC to     generate a <code>.sdc</code> which captures timing constraints which can then be     used as input to the place-and-route tool.</p> </li> <li> <p>We use Cadence Innovus to place-and-route our design, which means     to place all of the gates in the gate-level netlist into rows on the     chip and then to generate the metal wires that connect all of the     gates together. We need to provide Cadence Innovus with the same     abstract logical and timing views used in Synopsys DC, but we also     need to provide Cadence Innovus with technology information in     <code>.lef</code>, and <code>.captable</code> format and abstract physical views of the     standard-cell library also in <code>.lef</code> format. Cadence Innovus will     generate an updated Verilog gate-level netlist, a <code>.spef</code> file which     contains parasitic resistance/capacitance information about all nets     in the design, and a <code>.gds</code> file which contains the final layout. The     <code>.gds</code> file can be inspected using the open-source Klayout GDS     viewer. Cadence Innovus also generates reports which can be used to     accurately characterize area and timing.</p> </li> <li> <p>We use Synopsys PrimeTime (PT) to perform power analysis of our     design. We need to provide Synopsys PT with the same abstract     logical, timing, and power views used in Synopsys DC and Cadence     Innovus, but in addition we need to provide switching activity     information for every net in the design (which comes from the <code>.saif</code>     file), and capacitance information for every net in the design (which     comes from the <code>.spef</code> file). Synopsys PT puts the switching     activity, capacitance, clock frequency, and voltage together to     estimate the power consumption of every net and thus every module in     the design, and these estimates are captured in various reports.</p> </li> </ol> <p>Extensive documentation is provided by Synopsys and Cadence for these ASIC tools. We have organized this documentation and made it available to you on the public course webpage:</p> <ul> <li>https://www.csl.cornell.edu/courses/ece6745/asicdocs</li> </ul> <p>The first step is to access <code>ecelinux</code>. Use VS Code to log into a specific <code>ecelinux</code> server and then use Microsoft Remote Desktop to log into the same server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut07-asic-back-end tut07\n% cd tut07\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#1-revisiting-the-asic-flow-front-end","title":"1. Revisiting the ASIC Flow Front-End","text":"<p>Our goal in this tutorial is to generate layout for the sort unit from the Verilog tutorial using the ASIC tools. As a reminder, the sort unit takes as input four integers and a valid bit and outputs those same four integers in increasing order with the valid bit. The sort unit is implemented using a three-stage pipelined, bitonic sorting network and the datapath is shown below.</p> <p></p> <p>Before we can place and route a gate-level netlist, we need to synthesize that netlist. This is what we learned about in the last section. Here are the steps to test and then synthesize the design using Synopsys DC.</p>"},{"location":"ece6745-tut07-asic-back-end/#11-test-simulate-translate","title":"1.1. Test, Simulate, Translate","text":"<p>Always run the tests before pushing anything through the ASIC flow. There is no sense in running the flow if the design is incorrect!</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/sort\n</code></pre> <p>The tests are for verification. When we push a design through the flow we want to use a simulator which is focused on evaluation. You can run the simulator for our sort unit like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut3_verilog/sort/sort-sim --short-mname --impl rtl-struct --stats \\\n                                --translate --dump-vtb\nnum_cycles          = 106\nnum_cycles_per_sort = 1.06\n</code></pre> <p>You should now have the Verilog that we want to push through the ASIC flow.</p>"},{"location":"ece6745-tut07-asic-back-end/#12-simulate-synthesize-simulate","title":"1.2. Simulate, Synthesize, Simulate","text":"<p>Let's take a look at each script to confirm it matches the manual commands we used in the previous discussion section. Here is the run script for four-start RTL simulation.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./01-synopsys-vcs-rtlsim/run\n</code></pre> <p>Here is the run script for synthesis.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./02-synopsys-dc-synth/run\n</code></pre> <p>Notice that this script simply executes <code>dc_shell-xg-t</code> with a TCL script which contains the commands to: configure the standard cell library, analyze and elaborate the design; setup timing constraints; synthesize the design; write outputs; and write final outputs (i.e., Verilog and DDC) and reports (i.e., timing report and area report).</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./02-synopsys-dc-synth/run.tcl\n</code></pre> <p>Finally, here is the run script for fast-functional gate-level simulation. The key difference from four-state RTL simulation is that this simulation takes as input the Verilog for the standard-cell library and the Verilog for the post-synthesis gate-level netlist.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./03-synopsys-vcs-ffglsim/run\n</code></pre> <p>You can run these steps as follows:</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% ./03-synopsys-vcs-ffglsim/run\n</code></pre> <p>Verify that your design passes four-state RTL simulation and fast-functional gate-level simulation. Then take a look at the synthesis reports.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% less ./02-synopsys-dc-synth/timing.rpt\n% less ./02-synopsys-dc-synth/area.rpt\n</code></pre> <p>Finally, take a few minutes to examine the resulting Verilog gate-level netlist. Notice that the module hierarchy is preserved.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% less ./02-synopsys-dc-synth/post-synth.v\n</code></pre> <p>This is the gate-level netlist that we now want to push through the ASIC back-end flow.</p>"},{"location":"ece6745-tut07-asic-back-end/#2-cadence-innovus-for-place-and-route","title":"2. Cadence Innovus for Place-and-Route","text":"<p>We use Cadence Innovus for placing standard cells in rows and then automatically routing all of the nets between these standard cells. We also use Cadence Innovus to route the power and ground rails in a grid and connect this grid to the power and ground pins of each standard cell, and to automatically generate a clock tree to distribute the clock to all sequential state elements with hopefully low skew.</p> <p>We will be running Cadence Innovus in a separate directory to keep the files separate from the other tools.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sort/04-cadence-innovus-pnr\n% cd $TOPDIR/asic/build-sort/04-cadence-innovus-pnr\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#21-timing-analysis-setup-file","title":"2.1. Timing Analysis Setup File","text":"<p>Before starting Cadence Innovus, we need to create a file to setup the timing analysis. This file specifies what \"corner\" to use for our timing analysis. A corner is a characterization of the standard cell library and technology with specific assumptions about the process, temperature, and voltage (PVT). So we might have a \"fast\" corner which assumes best-case process variability, low temperature, and high voltage, or we might have a \"slow\" corner which assumes worst-case variability, high temperature, and low voltage. To ensure our design will work across a range of operating conditions, we need to evaluate our design across a range of corners. In this course, we will keep things simple by only considering a \"typical\" corner (i.e., average PVT). Use VS Code to create a file named <code>setup-timing.tcl</code>.</p> <pre><code>% cd $TOPDIR/asic/04-cadence-innovus-pnr\n% code setup-timing.tcl\n</code></pre> <p>The file should have the following content:</p> <pre><code>create_rc_corner -name typical \\\n   -cap_table \"$env(ECE6745_STDCELLS)/rtk-typical.captable\" \\\n   -T 25\n\ncreate_library_set -name libs_typical \\\n   -timing [list \"$env(ECE6745_STDCELLS)/stdcells.lib\"]\n\ncreate_delay_corner -name delay_default \\\n   -library_set libs_typical \\\n   -rc_corner typical\n\ncreate_constraint_mode -name constraints_default \\\n   -sdc_files [list ../02-synopsys-dc-synth/post-synth.sdc]\n\ncreate_analysis_view -name analysis_default \\\n   -constraint_mode constraints_default \\\n   -delay_corner delay_default\n\nset_analysis_view -setup analysis_default -hold analysis_default\n</code></pre> <p>The <code>create_rc_corner</code> command loads in the <code>.captable</code> file that we examined earlier. This file includes information about the resistance and capacitance of every metal layer. Notice that we are loading in the \"typical\" captable and we are specifying an \"average\" operating temperature of 25 degC. The <code>create_library_set</code> command loads in the <code>.lib</code> file that we examined earlier. This file includes information about the input/output capacitance of each pin in each standard cell along with the delay from every input to every output in the standard cell. The <code>create_delay_corner</code> specifies a specific corner that we would like to use for our timing analysis by putting together a <code>.captable</code> and a <code>.lib</code> file. In this specific example, we are creating a typical corner by putting together the typical <code>.captable</code> and typical <code>.lib</code> we just loaded. The <code>create_constraint_mode</code> command loads in the post-synthesis <code>.sdc</code> file which captures all of the timing constraints after synthesis. The <code>create_analysis_view</code> command puts together constraints with a specific corner, and the <code>set_analysis_view</code> command tells Cadence Innovus that we would like to use this specific analysis view for both setup and hold time analysis.</p>"},{"location":"ece6745-tut07-asic-back-end/#22-initial-setup","title":"2.2. Initial Setup","text":"<p>Now that we have created our <code>setup-timing.tcl</code> file we can start Cadence Innovus:</p> <pre><code>% cd $TOPDIR/asic/04-cadence-innovus-pnr\n% innovus\n</code></pre> <p>As we enter commands we will be able use the GUI to see incremental progress towards a fully placed-and-routed design. We need to set various variables before starting to work in Cadence Innovus. These variables tell Cadence Innovus the location of the MMMC file, the location of the Verilog gate-level netlist, the name of the top-level module in our design, the location of the <code>.lef</code> files, and finally the names of the power and ground nets.</p> <pre><code>innovus&gt; set init_mmmc_file \"setup-timing.tcl\"\ninnovus&gt; set init_verilog   \"../02-synopsys-dc-synth/post-synth.v\"\ninnovus&gt; set init_top_cell  \"SortUnitStruct\"\ninnovus&gt; set init_lef_file  \"$env(ECE6745_STDCELLS)/rtk-tech.lef $env(ECE6745_STDCELLS)/stdcells.lef\"\ninnovus&gt; set init_gnd_net   \"VSS\"\ninnovus&gt; set init_pwr_net   \"VDD\"\n</code></pre> <p>We are now ready to use the <code>init_design</code> command to read in the verilog, set the design name, setup the timing analysis views, read the technology <code>.lef</code> for layer information, and read the standard cell <code>.lef</code> for physical information about each cell used in the design.</p> <pre><code>innovus&gt; init_design\n</code></pre> <p>We also need to tell Cadence Innovus the process node are using so it can roughly estimate specific technology parameters.</p> <pre><code>innovus&gt; setDesignMode -process 45\n</code></pre> <p>Cadence Innovus includes many advanced timing-driven optimizations by default. Two examples include signal integrity analysis (e.g., capacitive coupling across signal wires) and useful clock skew (e.g., purposefully introducing clock skew to give more time for critical paths at the expense of other paths). To simply our timing analysis we will turn these optimizations off as follows.</p> <pre><code>innovus&gt; setDelayCalMode -SIAware false\ninnovus&gt; setOptMode -usefulSkew false\n</code></pre> <p>Cadence Innovus can fix hold-time violations by inserting extra buffers to delay certain paths. We add an extra hold-time target slack so that Cadence Innovus will work extra hard to meet the hold-time, and we need to tell Cadence Innovus which standard cells to use when fixing hold-time violations as follows.</p> <pre><code>innovus&gt; setOptMode -holdTargetSlack 0.010\ninnovus&gt; setOptMode -holdFixingCells {\n  BUF_X1 BUF_X1 BUF_X2 BUF_X4 BUF_X8 BUF_X16 BUF_X32\n}\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#23-floorplanning","title":"2.3. Floorplanning","text":"<p>The next substep is floorplaning. This is where we broadly organize the chip in terms of its overall dimensions and the placement of any previously designed blocks. For now we just do some very simple floorplanning using the <code>floorPlan</code> command.</p> <pre><code>innovus&gt; floorPlan -r 1.0 0.70 4.0 4.0 4.0 4.0\n</code></pre> <p>In this example, we have chosen the aspect ratio to be 1.0 and a target cell utilization to be 70%. The cell utilization is the percentage of the final chip that will actually contain useful standard cells as opposed to just \"filler\" cells (i.e., empty cells). Ideally, we would like the cell utilization to be 100% but this is simply not reasonable. If the cell utilization is too high, Cadence Innovus will spend way too much time trying to optimize the design and will eventually simply give up. A target cell utilization of 70% makes it more likely that Cadence Innovus can successfuly place and route the design. We have also added 4.0um of margin around the top, bottom, left, and right of the chip to give us room for the power ring which will go around the entire chip.</p> <p>The following screen capture illustrates what you should see: a square floorplan with rows where the standard cells will eventually be placed. You can use the View &gt; Fit menu option to see the entire chip.</p> <p></p>"},{"location":"ece6745-tut07-asic-back-end/#24-placement","title":"2.4. Placement","text":"<p>The next substep is cell placement. We can do the placement and initial routing of the standard cells using the <code>place_opt_design</code> command:</p> <pre><code>innovus&gt; place_opt_design\n</code></pre> <p>The following screen capture illustrates what you should see: the gates have been placed underneath a sea of wiring on the various metal layers.</p> <p></p> <p>Note that Cadence Innovus has only done a very preliminary routing, primarily to help improve placement. You can use the Amobea workspace to help visualize how modules are mapped across the chip. Choose Windows &gt; Workspaces &gt; Amoeba from the menu. However, we recommend using the design browser to help visualize how modules are mapped across the chip. Here are the steps:</p> <ul> <li>Choose Windows &gt; Workspaces &gt; Design Browser + Physical from the menu</li> <li>Hide all of the metal layers by pressing the number keys</li> <li>Browse the design hierarchy using the panel on the left</li> <li>Right click on a module, click Highlight, select a color</li> </ul> <p>In this way you can view where various modules are located on the chip. The following screen capture illustrates the location of the five min/max units.</p> <p></p> <p>Notice how Cadence Innovus has grouped each module together. The placement algorithm tries to keep connected standard cells close together to minimize wiring.</p> <p>If our design has any constant values, then we need to insert special standard cells to \"tie\" those constant values to either VDD or ground using the <code>addTieHiLo</code> command.</p> <pre><code>innovus&gt; addTieHiLo -cell \"LOGIC1_X1 LOGIC0_X1\"\n</code></pre> <p>After placement and tie cell insertion, we can assign IO pin locations for our block-level design. Since this is not a full chip with IO pads, or a hierarchical block, we don't really care exactly where all of the pins line up, so we'll let the tool assign the location for all of the pins.</p> <pre><code>innovus&gt; assignIoPins -pin *\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#25-power-routing","title":"2.5. Power Routing","text":"<p>The next substep is power routing. Recall that each standard cell has internal M1 power and ground rails which will connect via abutment when the cells are placed into rows. If we were just to supply power to cells using these rails we would likely have large IR drop and the cells in the middle of the chip would effectively be operating at a much lower voltage. During power routing, we create a grid of power and ground wires on the top metal layers and then connect this grid down to the M1 power rails in each row. We also create a power ring around the entire floorplan. Before doing the power routing, we need to use the <code>globalNetCommand</code> command to tell Cadence Innovus which nets are power and which nets are ground (there are many possible names for power and ground!).</p> <pre><code>innovus&gt; globalNetConnect VDD -type pgpin -pin VDD -all -verbose\ninnovus&gt; globalNetConnect VSS -type pgpin -pin VSS -all -verbose\ninnovus&gt; globalNetConnect VDD -type tiehi -pin VDD -all -verbose\ninnovus&gt; globalNetConnect VSS -type tielo -pin VSS -all -verbose\n</code></pre> <p>We can now draw M1 \"rails\" for the power and ground rails that go along each row of standard cells.</p> <pre><code>innovus&gt; sroute -nets {VDD VSS}\n</code></pre> <p>We now create a power ring around our chip using the <code>addRing</code> command. A power ring ensures we can easily get power and ground to all standard cells. The command takes parameters specifying the width of each wire in the ring, the spacing between the two rings, and what metal layers to use for the ring. We will put the power ring on M7 and M8; we often put the power routing on the top metal layers since these are fundamentally global routes and these top layers have low resistance which helps us minimize static IR drop and di/dt noise. These top layers have high capacitance but this is not an issue since the power and ground rails are not switching (and indeed this extra capacitance can serve as a very modest amount of decoupling capacitance to smooth out time variations in the power supply).</p> <pre><code>innovus&gt; addRing \\\n  -nets {VDD VSS} -width 0.8 -spacing 0.8 \\\n  -layer [list top 9 bottom 9 left 8 right 8]\n</code></pre> <p>We have power and ground rails along each row of standard cells and a power ring, so now we need to hook these up. We can use the <code>addStripe</code> command to draw wires and automatically insert vias whenever wires cross. First, we draw the horizontal \"stripes\".</p> <pre><code>innovus&gt; addStripe \\\n  -nets {VSS VDD} -layer 9 -direction horizontal \\\n  -width 0.8 -spacing 4.8 \\\n  -set_to_set_distance 11.2 -start_offset 2.4\n</code></pre> <p>And then we draw the vertical \"stripes\".</p> <pre><code>innovus&gt; addStripe \\\n  -nets {VSS VDD} -layer 8 -direction vertical \\\n  -width 0.8 -spacing 4.8 \\\n  -set_to_set_distance 11.2 -start_offset 2.4\n</code></pre> <p>The following screen capture illustrates what you should see: a power ring and grid on M7 and M8 connected to the horizontal power and ground rails on M1.</p> <p></p> <p>You can toggle the visibility of metal layers by using the panel on the right. Click the checkbox in the V column to toggle the visibility of the corresponding layer. You can also simply use the number keys on your keyboard. Pressing the 7 key will toggle M7 and pressing the 8 key will toggle M8. Zoom in on a via and toggle the visibility of the metal layers to see how Cadence Innovus has automatically inserted a via stack that goes from M1 all the way up to M7 or M8.</p>"},{"location":"ece6745-tut07-asic-back-end/#26-clock-tree-synthesis","title":"2.6. Clock-Tree Synthesis","text":"<p>The next substep is clock-tree synthesis. First, let's display the preliminary clock tree created in the previous step so we can clearly see the impact of optimized clock tree routing. In the right panel click on Net and then deselect the checkbox in the V column next to Signal, Special Net, Power, and Ground so that only Clock is selected. You should be able to see the clock snaking around the chip connecting the clock port of all of the registers. Now use the <code>ccopt_design</code> command to optimize the clock tree routing.</p> <pre><code>innovus&gt; create_ccopt_clock_tree_spec\ninnovus&gt; set_ccopt_property update_io_latency false\ninnovus&gt; clock_opt_design\n</code></pre> <p>By default, Cadence Innovus can optimize the clock tree by adding a \"clock source insertion latency\". Essentially this means that Cadence Innovus might decide that the top-level chip should adjust the delay between the input pins and the clock. Unfortunately, this makes it more difficult for us to perform block-level back-annotated gate-level simulation so for now we will disable this optimization.</p> <p>If you watch closely you should see a significant difference in the clock tree routing before and after optimization. The following screen capture illustrates the optimized clock tree routing.</p> <p></p> <p>The routes are straighter, shorter, and well balanced. This will result in much lower clock skew.</p> <p>We should now use the <code>optDesign</code> command to try and fix both setup time violations (e.g., by choosing different standard cells to reduce the delay of the critical path) and hold time violations (e.g., by inserting buffers to increase the delay of certain fast paths).</p> <pre><code>innovus&gt; optDesign -postCTS -setup\ninnovus&gt; optDesign -postCTS -hold\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#27-routing","title":"2.7. Routing","text":"<p>The next substep is routing. Although we already did a preliminary routing during the placement substep, we now want to optimize this signal routing. Display just the signals but not the power and ground routing by clicking on the checkbox in the V column next to Signal in the left panel. Then use the <code>routeDesign</code> command to optimize the signal routing. We follow this with another iteration of <code>optDesign</code> to fix any violating paths that were created during <code>routeDesign</code>.</p> <pre><code>innovus&gt; routeDesign\n</code></pre> <p>If you watch closely you should see a significant difference in the signal routing before and after optimization. The following screen capture illustrates the optimized signal routing.</p> <p></p> <p>Again the routes are straighter and shorter. This will reduce the interconnect resistance and capacitance and thus improve the delay and energy of our design.</p> <p>Once again, we can now use the <code>optDesign</code> command to try and fix both setup time violations (e.g., by choosing different standard cells to reduce the delay of the critical path) and hold time violations (e.g., by inserting buffers to increase the delay of certain fast paths).</p> <pre><code>innovus&gt; optDesign -postRoute -setup\ninnovus&gt; optDesign -postRoute -hold\n</code></pre> <p>Now that our design is fully placed and routed, we can extract the parasitic resistance and capacitances to enable more accurate timing and power analysis.</p> <pre><code>innovus&gt; extractRC\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#28-finishing","title":"2.8. Finishing","text":"<p>One final step is to insert \"filler\" cells. Filler cells are essentially empty standard cells whose sole purpose is to connect the wells across each standard cell row.</p> <pre><code>innovus&gt; setFillerMode -core {FILLCELL_X4 FILLCELL_X2 FILLCELL_X1}\ninnovus&gt; addFiller\n</code></pre> <p>Zoom in to see some of the detailed routing and take a moment to appreciate how much effort the tools have done for us automatically to synthesize, place, and route this design. The following screen capture shows some of this detailed routing.</p> <p></p> <p>Notice how each metal layer always goes in the same direction. So M2 is always vertical, M3 is always horizontal, M4 is always vertical, etc. This helps reduce capacitive coupling across layers and also simplifies the routing algorithm. Actually, if you look closely in the above screen shot you can see situations on M2 (red) and M3 (green) where the router has generated a little \"jog\" meaning that on a single layer the wire goes both vertically and horizontally. This is an example of the sophisticated algorithms used in these tools.</p> <p>Another final step do is verify that the gate-level netlist matches what is really in the final layout. We can do this using the <code>verifyConnectivity</code> command. We can also do a preliminary \"design rule check\" to make sure that the generated metal interconnect does not violate any design rules with the <code>verify_drc</code> command.</p> <pre><code>innovus&gt; verifyConnectivity\ninnovus&gt; verify_drc\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#29-outputs-and-reports","title":"2.9. Outputs and Reports","text":"<p>Now we can generate various output files and reports. We start by saving the design so we can reload the design into Cadence Innovus for later analysis using the GUI.</p> <pre><code>innovus&gt; saveDesign post-pnr.enc\n</code></pre> <p>We also need to save the final gate-level netlist to enable back-annotated gate-level simulation, since Cadence Innovus will often insert new cells or change cells during its optimization passes.</p> <pre><code>innovus&gt; saveNetlist post-pnr.v\n</code></pre> <p>We can write parasitic information to a special <code>.spef</code> file. This file can be used for later power analysis.</p> <pre><code>innovus&gt; rcOut -rc_corner typical -spef post-pnr.spef\n</code></pre> <p>You may get an error regarding open nets. This is actually more of a warning message, and for the purposes of RC extraction we can ignore this.</p> <p>We also need to extract delay information and write this to an <code>.sdf</code> (Standard Delay Format) file, which we'll use for our back-annotated gate-level simulations.</p> <pre><code>innovus&gt; write_sdf post-pnr.sdf\n</code></pre> <p>Finally, we of course need to generate the real layout as a <code>.gds</code> file. This is what we will send to the foundry when we are ready to tapeout the chip.</p> <pre><code>innovus&gt; streamOut post-pnr.gds \\\n  -merge \"$env(ECE6745_STDCELLS)/stdcells.gds\" \\\n  -mapFile \"$env(ECE6745_STDCELLS)/rtk-stream-out.map\"\n</code></pre> <p>We can also use Cadence Innovus to do timing, area, and power analysis similar to what we did with Synopsys DC. These post-pnr results will be much more accurate than the preliminary post-synthesis results. Let's start with a basic setup timing report.</p> <pre><code>innovus&gt; report_timing -late -path_type full_clock -net\n...\nOther End Arrival Time          0.000\n- External Delay                0.050\n+ Phase Shift                   0.700\n= Required Time                 0.650\n- Arrival Time                  0.607\n= Slack Time                    0.043\n     Clock Rise Edge                      0.000\n     + Drive Adjustment                   0.008\n     = Beginpoint Arrival Time            0.008\n     +---------------------------------------------------------------------------------------------------------------------+\n     |               Pin               | Edge |             Net              |      Cell      | Delay | Arrival | Required |\n     |                                 |      |                              |                |       |  Time   |   Time   |\n     |---------------------------------+------+------------------------------+----------------+-------+---------+----------|\n     | clk[0]                          |  ^   | clk[0]                       |                |       |   0.008 |    0.052 |\n     | v/CTS_ccl_a_buf_00001/A         |  ^   | clk[0]                       | CLKBUF_X3      | 0.000 |   0.008 |    0.052 |\n     | v/CTS_ccl_a_buf_00001/Z         |  ^   | v/CTS_1                      | CLKBUF_X3      | 0.059 |   0.068 |    0.111 |\n     | v/elm2_S2S3/q_reg[1]/CK         |  ^   | v/CTS_1                      | DFF_X1         | 0.002 |   0.069 |    0.113 |\n     | v/elm2_S2S3/q_reg[1]/Q          |  ^   | v/elm2_S3[1]                 | DFF_X1         | 0.101 |   0.170 |    0.213 |\n     | v/mmuA_S3/FE_DBTC2_elm2_S3_1/A  |  ^   | v/elm2_S3[1]                 | INV_X1         | 0.000 |   0.170 |    0.213 |\n     | v/mmuA_S3/FE_DBTC2_elm2_S3_1/ZN |  v   | v/mmuA_S3/FE_DBTN2_elm2_S3_1 | INV_X1         | 0.014 |   0.184 |    0.227 |\n     | v/mmuA_S3/U62/B2                |  v   | v/mmuA_S3/FE_DBTN2_elm2_S3_1 | AOI21_X1       | 0.000 |   0.184 |    0.227 |\n     | v/mmuA_S3/U62/ZN                |  ^   | v/mmuA_S3/n22                | AOI21_X1       | 0.030 |   0.214 |    0.257 |\n     | v/mmuA_S3/U17/A1                |  ^   | v/mmuA_S3/n22                | NAND2_X1       | 0.000 |   0.214 |    0.257 |\n     | v/mmuA_S3/U17/ZN                |  v   | v/mmuA_S3/n13                | NAND2_X1       | 0.017 |   0.231 |    0.274 |\n     | v/mmuA_S3/U8/A2                 |  v   | v/mmuA_S3/n13                | NAND3_X1       | 0.000 |   0.231 |    0.274 |\n     | v/mmuA_S3/U8/ZN                 |  ^   | v/mmuA_S3/n5                 | NAND3_X1       | 0.019 |   0.250 |    0.293 |\n     | v/mmuA_S3/U6/A1                 |  ^   | v/mmuA_S3/n5                 | NAND3_X1       | 0.000 |   0.250 |    0.293 |\n     | v/mmuA_S3/U6/ZN                 |  v   | v/mmuA_S3/n4                 | NAND3_X1       | 0.017 |   0.267 |    0.310 |\n     | v/mmuA_S3/U3/A3                 |  v   | v/mmuA_S3/n4                 | AND3_X1        | 0.000 |   0.267 |    0.310 |\n     | v/mmuA_S3/U3/ZN                 |  v   | v/mmuA_S3/n23                | AND3_X1        | 0.035 |   0.302 |    0.345 |\n     | v/mmuA_S3/U2/A1                 |  v   | v/mmuA_S3/n23                | NOR2_X1        | 0.000 |   0.302 |    0.345 |\n     | v/mmuA_S3/U2/ZN                 |  ^   | v/mmuA_S3/n24                | NOR2_X1        | 0.025 |   0.326 |    0.370 |\n     | v/mmuA_S3/U36/A1                |  ^   | v/mmuA_S3/n24                | NOR3_X1        | 0.000 |   0.326 |    0.370 |\n     | v/mmuA_S3/U36/ZN                |  v   | v/mmuA_S3/n25                | NOR3_X1        | 0.011 |   0.337 |    0.381 |\n     | v/mmuA_S3/U32/A1                |  v   | v/mmuA_S3/n25                | OAI22_X1       | 0.000 |   0.337 |    0.381 |\n     | v/mmuA_S3/U32/ZN                |  ^   | v/mmuA_S3/n27                | OAI22_X1       | 0.037 |   0.374 |    0.418 |\n     | v/mmuA_S3/U13/A                 |  ^   | v/mmuA_S3/n27                | OAI21_X1       | 0.000 |   0.374 |    0.418 |\n     | v/mmuA_S3/U13/ZN                |  v   | v/mmuA_S3/n16                | OAI21_X1       | 0.023 |   0.397 |    0.441 |\n     | v/mmuA_S3/FE_OFC1_n16/A         |  v   | v/mmuA_S3/n16                | CLKBUF_X1      | 0.000 |   0.397 |    0.441 |\n     | v/mmuA_S3/FE_OFC1_n16/Z         |  v   | v/mmuA_S3/FE_OFN5_n16        | CLKBUF_X1      | 0.095 |   0.492 |    0.535 |\n     | v/mmuA_S3/U57/B1                |  v   | v/mmuA_S3/FE_OFN5_n16        | OAI22_X1       | 0.001 |   0.493 |    0.537 |\n     | v/mmuA_S3/U57/ZN                |  ^   | v/mmuA_out_max_S3[2]         | OAI22_X1       | 0.059 |   0.553 |    0.596 |\n     | v/U11/A1                        |  ^   | v/mmuA_out_max_S3[2]         | AND2_X1        | 0.000 |   0.553 |    0.596 |\n     | v/U11/ZN                        |  ^   | out2[2]                      | AND2_X1        | 0.054 |   0.606 |    0.650 |\n     | out2[2]                         |  ^   | out2[2]                      | SortUnitStruct | 0.000 |   0.607 |    0.650 |\n     +---------------------------------------------------------------------------------------------------------------------+\n</code></pre> <p>Note that for these results we used a target clock period of 700ps. From the above report we can see that our design is still meeting timing even after place-and-route. This critical path is from the last pipeline register to the <code>out2[2]</code> output pin. Recall the setup time for all output ports was set to be 50ps in our timing constraints. So this path must be less than 700ps - 50ps = 650ps to meet the setup time constraint. The actual arrive time is 607ps and includes 69ps from the input clock pin to the CK pin of the DFF, 101ps for the clock-to-q delay, 383ps to get through the min/max unit, and 54ps to go through a final AND gate before reaching the <code>out2[2]</code> output pin for a total delay of 607ps. The total delay (607ps) is less than the required time (650ps) by 43ps of positive slack.</p> <p>Note that it is very likely that the critical path identified by Synsopsys DC after synthesis will not be the same critical path identified by Cadence Innovus after place-and-route. This is because Synopsys DC can only guess the final placement of the cells and interconnect during static timing analysis, while Cadence Innovus can use the real placement of the cells and interconnect during static timing analysis. For the same reason, there is no guarantee that if your design meets timing after synthesis that it will still meet timing after place-and-route! It is very possible that your design will meet timing after synthesis and then will not meet timing after place-and-route. If your design does not meet timing after place-and-route you must go back and use a longer target clock period for synthesis!</p> <p>You can use the following steps in Cadence Innovus to display where the critical path is on the actual chip.</p> <ul> <li>Choose Timing &gt; Debug Timing from the menu</li> <li>Click OK in the pop-up window</li> <li>Right click on first path in the Path List</li> <li>Choose Highlight &gt; Only This Path &gt; Color</li> </ul> <p>You can also use the Design Browser to highlight specific modules to visualize how the critical path is routed across the chip between these modules. The following screen capture illustrates the critical path in our three-stage sort unit. From the above timing report we know the critical path basically goes through the <code>mmuA_S3</code> module, so we have highlighted that module in red using the Design Browser. Cadence Innovus has worked hard in both placement and routing to keep the critical path short. If your critical path stretches across the entire chip you may need to take extra steps such as explicit floorplanning or hierarchical design to help the tools produce a better quality of result.</p> <p></p> <p>In addition to checking to see if we met our setup time constraints, we also must check to see if we have met our hold time constraints.</p> <pre><code>innovus&gt; report_timing -early -path_type full_clock -net\nOther End Arrival Time          0.070\n+ Hold                          0.015\n+ Phase Shift                   0.000\n= Required Time                 0.085\n  Arrival Time                  0.085\n  Slack Time                    0.000\n     Clock Rise Edge                      0.000\n     + Input Delay                        0.000\n     + Drive Adjustment                   0.004\n     = Beginpoint Arrival Time            0.004\n     Timing Path:\n     +--------------------------------------------------------------------------------------------------------+\n     |             Pin              | Edge |            Net             |  Cell  | Delay | Arrival | Required |\n     |                              |      |                            |        |       |  Time   |   Time   |\n     |------------------------------+------+----------------------------+--------+-------+---------+----------|\n     | in3[6]                       |  ^   | in3[6]                     |        |       |   0.004 |    0.004 |\n     | FE_PHC106_in3_6/A            |  ^   | in3[6]                     | BUF_X1 | 0.000 |   0.004 |    0.004 |\n     | FE_PHC106_in3_6/Z            |  ^   | FE_PHN106_in3_6            | BUF_X1 | 0.020 |   0.024 |    0.024 |\n     | FE_PHC81_in3_6/A             |  ^   | FE_PHN106_in3_6            | BUF_X1 | 0.000 |   0.024 |    0.024 |\n     | FE_PHC81_in3_6/Z             |  ^   | FE_PHN81_in3_6             | BUF_X1 | 0.021 |   0.045 |    0.045 |\n     | FE_PHC46_in3_6/A             |  ^   | FE_PHN81_in3_6             | BUF_X1 | 0.000 |   0.045 |    0.045 |\n     | FE_PHC46_in3_6/Z             |  ^   | FE_PHN46_in3_6             | BUF_X1 | 0.020 |   0.065 |    0.065 |\n     | v/elm3_S0S1/FE_PHC28_in3_6/A |  ^   | FE_PHN46_in3_6             | BUF_X1 | 0.000 |   0.065 |    0.065 |\n     | v/elm3_S0S1/FE_PHC28_in3_6/Z |  ^   | v/elm3_S0S1/FE_PHN28_in3_6 | BUF_X1 | 0.020 |   0.085 |    0.085 |\n     | v/elm3_S0S1/q_reg[6]/D       |  ^   | v/elm3_S0S1/FE_PHN28_in3_6 | DFF_X1 | 0.000 |   0.085 |    0.085 |\n     +--------------------------------------------------------------------------------------------------------+\n     Clock Rise Edge                      0.000\n     + Drive Adjustment                   0.008\n     = Beginpoint Arrival Time            0.008\n     Other End Path:\n     +-----------------------------------------------------------------------------------+\n     |           Pin           | Edge |   Net   |   Cell    | Delay | Arrival | Required |\n     |                         |      |         |           |       |  Time   |   Time   |\n     |-------------------------+------+---------+-----------+-------+---------+----------|\n     | clk[0]                  |  ^   | clk[0]  |           |       |   0.008 |    0.009 |\n     | v/CTS_ccl_a_buf_00002/A |  ^   | clk[0]  | CLKBUF_X3 | 0.000 |   0.008 |    0.009 |\n     | v/CTS_ccl_a_buf_00002/Z |  ^   | v/CTS_2 | CLKBUF_X3 | 0.061 |   0.069 |    0.069 |\n     | v/elm3_S0S1/q_reg[6]/CK |  ^   | v/CTS_2 | DFF_X1    | 0.001 |   0.070 |    0.070 |\n     +-----------------------------------------------------------------------------------+\n</code></pre> <p>In our original design, there was basically no logic on the path from the input pin <code>in2[3]</code> and the <code>D</code> input of the DFF in the <code>elm2_S0S1</code> pipeline register. This makes this path a \"fast path\" which might cause a hold time violation. Indeed, in the above timing report, we can see that Cadence Innovus has inserted buffers (i.e., with the <code>FE_PHC</code> prefix) to delay the data to meet the hold time constraint. The timing report shows that the delay from the block's clock pin to the CK pin of the DFF (i.e., clock tree insertion delay) is 70ps and the contamination delay from the block's <code>in2[3]</code> pin to the D pin of the DFF is 85ps. Since 85ps - 75ps is 15ps which is greater than or equal to the hold time of 15ps this path now meets the hold time constraint.</p> <p>As in Synopsys DC, the <code>report_area</code> command can show the area each module uses and can enable detailed area breakdown analysis. These area results will be far more accurate than the post-synthesis results.</p> <pre><code>innovus&gt; report_area\n    Hinst Name   Module Name                         Inst Count Tot Area\n------------------------------------------------------------------------\nSortUnitStruct                                              520  841.890\n  v              tut3_verilog_sort_SortUnitStruct_p_nbits8  424  765.282\n    v/elm0_S0S1  vc_Reg_p_nbits8_0                           16   42.560\n    v/elm0_S1S2  vc_Reg_p_nbits8_8                            8   36.176\n    v/elm0_S2S3  vc_Reg_p_nbits8_4                            8   36.176\n    v/elm1_S0S1  vc_Reg_p_nbits8_11                          16   42.560\n    v/elm1_S1S2  vc_Reg_p_nbits8_7                            8   36.176\n    v/elm1_S2S3  vc_Reg_p_nbits8_3                            8   36.176\n    v/elm2_S0S1  vc_Reg_p_nbits8_10                          16   42.560\n    v/elm2_S1S2  vc_Reg_p_nbits8_6                            8   36.176\n    v/elm2_S2S3  vc_Reg_p_nbits8_2                            8   36.176\n    v/elm3_S0S1  vc_Reg_p_nbits8_9                           16   42.560\n    v/elm3_S1S2  vc_Reg_p_nbits8_5                            8   36.176\n    v/elm3_S2S3  vc_Reg_p_nbits8_1                            8   36.176\n    v/mmuA_S1    tut3_verilog_sort_MinMaxUnit_p_nbits8_0     48   48.678\n    v/mmuA_S2    tut3_verilog_sort_MinMaxUnit_p_nbits8_3     48   48.678\n    v/mmuA_S3    tut3_verilog_sort_MinMaxUnit_p_nbits8_1     57   53.466\n    v/mmuB_S1    tut3_verilog_sort_MinMaxUnit_p_nbits8_4     47   47.082\n    v/mmuB_S2    tut3_verilog_sort_MinMaxUnit_p_nbits8_2     49   49.742\n    v/val_S0S1   vc_ResetReg_p_nbits1_0                       6    8.246\n    v/val_S1S2   vc_ResetReg_p_nbits1_2                       3    5.852\n    v/val_S2S3   vc_ResetReg_p_nbits1_1                       3    5.852\n</code></pre> <p>The <code>Inst Count</code> column indicates the number of non-filler cells in that module. There are a total of 520 standard cells in the design. Each register should have eight standard cells; eight flip-flops since it is an eight-bit register. However, notice that some of the pipeline registers have 16 standard cells. You can look in the post-pnr gate-level netlist to see why. This is because these pipeline registers have inserted extra buffers to fix hold-time violations. The min/max units have a different number of cells since they have been optimized differently. The min/max units consume about ~47% of the area.</p> <p>Finally, we go ahead and exit Cadence Innovus.</p> <pre><code>innovus&gt; exit\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#210-final-layout","title":"2.10. Final Layout","text":"<p>We can now look at the actual <code>.gds</code> file for our design to see the final layout including all of the cells and the interconnect using the open-source Klayout GDS viewer. Choose Display &gt; Full Hierarchy from the menu to display the entire design. Zoom in and out to see the individual transistors as well as the entire chip.</p> <pre><code>% cd $TOPDIR/asic/build-sort/04-cadence-innovus-pnr\n% klayout -l ${ECE6745_STDCELLS}/klayout.lyp post-pnr.gds\n</code></pre> <p>The following screen capture illutrates using Klayout to view the layout for the entire sort unit.</p> <p></p> <p>The following figure shows a zoomed portion of the layout. You can clearly see the active layer inside the standard cells along with the signal routing on the lower metal layers. The power routing on the upper metal layers has been hiddent for clarity.</p> <p></p>"},{"location":"ece6745-tut07-asic-back-end/#211-automating-place-and-route","title":"2.11. Automating Place and Route","text":"<p>You can automate the above steps by putting a sequence of commands in a <code>.tcl</code> file and run Cadence Innovus using those commands in one step like this:</p> <pre><code>% cd $TOPDIR/asic/build-sort/04-cadence-innovus-pnr\n% innovus -no_gui -files run.tcl\n</code></pre> <p>To further simplify rerunning this step, we can put the above command line in its own a shell script. We have created such run scripts for you. Let's take a look to confirm these scripts match the manual commands we used above.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./04-cadence-innovus-pnr/run\n% cat ./04-cadence-innovus-pnr/run.tcl\n</code></pre> <p>You can rerun synthesis as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% ./04-cadence-innovus-pnr/run\n</code></pre> <p>And you can then open up the Cadence Innovus design in the GUI as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sort/04-cadence-innovus-pnr\n% innovus\ninnovus&gt; source post-pnr.enc\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#3-using-synopsys-vcs-for-back-annotated-gate-level-simulation","title":"3. Using Synopsys VCS for Back-Annotated Gate-Level Simulation","text":"<p>In the previous tutorial, we used Synopsys VCS to do 4-state simulation and gate-level simulation. This time, we'll be using VCS to perform back-annotated gate-level simulation. The key difference between fast-functional and back-annotated gate-level simulation, is that we can now use an <code>.sdf</code> file to annotate delays in the gate-level simulation. In previous simulations, we only see signals change on the clock edge; however, with a back-annotated simulation, we'll know more precisely when signals are arriving by using the delay information provided by the <code>.sdf</code>. This means that running a back-annotated simulation with a cycle time that is too fast can potentially cause setup time violations or fast paths can potentially cause hold time violations. Back-annotated gate-level simulation is the primary way we will verify that our final design is functionally correct.</p> <p>We will be running Synopsys VCS in a separate directory to keep the files separate from the other tools.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sort/05-synopsys-vcs-baglsim\n% cd $TOPDIR/asic/build-sort/05-synopsys-vcs-baglsim\n</code></pre> <p>Given the more realistic timing implications of a back-annotated simulation, we need to be more careful about the cycle time, input delays, and output delays that we provide to Synopsys VCS. Notice the differences between the following command and the fast-functional gate-level simulation command from the previous tutorial.</p> <pre><code>% cd $TOPDIR/asic/build-sort/05-synopsys-vcs-baglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +neg_tchk +sdfverbose \\\n    -sdf max:Top.DUT:../04-cadence-innovus-pnr/post-pnr.sdf \\\n    +define+CYCLE_TIME=0.400 \\\n    +define+VTB_INPUT_DELAY=0.025 \\\n    +define+VTB_OUTPUT_DELAY=0.025 \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../04-cadence-innovus-pnr/post-pnr.v \\\n    ${TOPDIR}/sim/build/SortUnitStruct_random_tb.v\n% ./simv\n</code></pre> <p>This time, we add the flag <code>+neg_tchk</code>, which enables negative values in timing checks. Negative values in timing checks are important for cells which have negative hold times, for example. We also include the <code>+sdfverbose</code> flag which reads in the <code>post-pnr.sdf</code>. Note that we also assign non-zero values for <code>+define+VTB_INPUT_DELAY</code> and <code>+define+VTB_OUTPUT_DELAY</code>. These values are based on the input and output delay timing constraints during the Synopsys DC synthesis step. All inputs from the test bench will be set 25ps after the rising edge; recall that we used an input min delay of 0ps and max delay of 50ps so changing the inputs 25ps after the rising edge should meet hold and setup time constraints. All outputs will be checked 25ps before the next rising edge; recall that we used an output max delay of 50ps which corresponds to the setup time of the output pin so the output data should be stable by 25ps before the rising edge.</p> <p>The above command uses a cycle time of 400ps but recall that we used a cycle time constraint of 700ps. You should see a failing timing check and testbench failure similar to below.</p> <pre><code>\"/classes/ece6745/install/adks/freepdk-45nm/stdview/stdcells.v\", 2122:\n  Timing violation in Top.DUT.v.elm0_S1S2.\\q_reg[4]\n  $setuphold( posedge CK:2265, posedge D:2271, limits: (32,23) );\n\n...\n\nThe test bench received a value containing X/Z's! Please note\nthat the VTB is pessmistic about X's and you should make sure\nall output ports of your DUT does not produce X's after reset.\n- Timestamp      : 3 (default unit: ns)\n- Cycle number   : 5 (variable: cycle_count)\n- line number    : line 4 in SortUnitStruct_random_tb.v.cases\n- port name      : out[1] (out1 in Verilog)\n- expected value : 0x77\n- actual value   : 0xxX\n</code></pre> <p>The timing check is failing because the clock is rising at 2265ps and the data input is changing at 2271ps for the <code>elm0_S1S2.q_reg[4]</code> DFF; this means the data is changing 6ps after the rising edge but the hold time for this specific flip-flop is 23ps. If you open up the resulting waveforms and look at these signals at 2265ps you should be able to see this exact scenario.</p> <p>Let's rerun the simulation with our actual target cycle time of 700ps and verify back-annotated gate-level simulation passes the simulation.</p> <pre><code>% cd $TOPDIR/asic/build-sort/05-synopsys-vcs-baglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +neg_tchk +sdfverbose \\\n    -sdf max:Top.DUT:../04-cadence-innovus-pnr/post-pnr.sdf \\\n    +define+CYCLE_TIME=0.700 \\\n    +define+VTB_INPUT_DELAY=0.025 \\\n    +define+VTB_OUTPUT_DELAY=0.025 \\\n    +define+VTB_DUMP_SAIF=waves.saif \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../04-cadence-innovus-pnr/post-pnr.v \\\n    ${TOPDIR}/sim/build/SortUnitStruct_random_tb.v\n% ./simv\n</code></pre> <p>The <code>.vcd</code> file contains information about the state of every net in the design on every cycle. This can make these <code>.vcd</code> files very large and thus slow to analyze. For average power analysis, we only need to know the activity factor on each net, so we also dump out an <code>.saif</code> file that only contains a single average activity factor for every net.</p> <p>Take a look at the vcd file from this simulation. Here we can see some subcycle delays that shows us how long it takes for data to stabilize before the following cycle. This is showing the first stage of the sort unit pipeline. It shows the input and output of one of the stage 0 min/max units.</p> <p></p> <p>To simplify rerunning a simulation, we can put the above command lines in a shell script. We have created such a run script for you. Let's take a look to confirm these scripts match the manual commands we used above.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./05-synopsys-vcs-baglsim/run\n</code></pre> <p>You can rerun back-annotated gate-level simulation as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% ./05-synopsys-vcs-baglsim/run\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#4-synopsys-primetime-for-power-analysis","title":"4. Synopsys PrimeTime for Power Analysis","text":"<p>Synopsys PrimeTime (PT) is primarily used for very accurate \"sign-off\" static timing analysis (more accurate than the analysis performed by Synopsys DC and Cadence Innovus), but in this course, we will only use Synopsys PT for power analysis. There are many ways to perform power analysis. We can use Synopsys DC and Cadence Innovus for statistical power analysis where we simply assume some toggle probability on each net. For more accurate power analysis we need to find out the actual activity for every net for a given experiment, which is exactly what the <code>.saif</code> file from the previous section provides.</p> <p>We will be running Synopsys PT in a separate directory to keep the files separate from the other tools.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sort/06-synopsys-pt-pwr\n% cd $TOPDIR/asic/build-sort/06-synopsys-pt-pwr\n% pt_shell\n</code></pre> <p>To make it easier to copy-and-paste commands from this document, we tell Synopsys PT to ignore the prefix <code>pt_shell&gt;</code> using the following:</p> <pre><code>pt_shell&gt; alias \"pt_shell&gt;\" \"\"\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#41-initial-setup","title":"4.1. Initial Setup","text":"<p>We begin by setting the <code>target_library</code> and <code>link_library</code> variables as before.</p> <pre><code>pt_shell&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db\"\npt_shell&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db\"\n</code></pre> <p>Since Synopsys PT is primarily used for static timing analysis, we need to explicitly tell Synopsys PT that we want to use it for power analysis.</p> <pre><code>pt_shell&gt; set_app_var power_enable_analysis true\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#42-inputs","title":"4.2. Inputs","text":"<p>We need to read in the gate-level netlist, tell Synopsys PT we want to do power analysis for the top-level module, and link the design (i.e., recursively resolve all of the module references starting from the top-level module).</p> <pre><code>pt_shell&gt; read_verilog ../04-cadence-innovus-pnr/post-pnr.v\npt_shell&gt; current_design SortUnitStruct\npt_shell&gt; link_design\n</code></pre> <p>We need to read in the actual activity factors which will be used for power analysis. The <code>.saif</code> file comes from a <code>.vcd</code> file which in turn came from running a simulation with a test harness. We need to strip off part of the instance names in the <code>.saif</code> file since the gate-level netlist does not have this test harness.</p> <pre><code>pt_shell&gt; read_saif ../05-synopsys-vcs-baglsim/waves.saif -strip_path Top/DUT\n</code></pre> <p>The <code>.db</code> file includes parasitic capacitance estimates for every pin of every standard cell, but to improve the accuracy of power analysis, we also need to include parasitic capacitances from the interconnect. Recall that we used Cadence Innovus to generate exactly this information in a <code>.spef</code> file. So we now read in these additional parasitic capacitance values for every net in the gate-level netlist.</p> <pre><code>pt_shell&gt; read_parasitics -format spef ../04-cadence-innovus-pnr/post-pnr.spef\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#43-timing-constraints","title":"4.3. Timing Constraints","text":"<p>In order to do power analysis, Synopsys PT needs to know the clock period. Here we will set the clock frequency to be the same as the initial clock constraint, but note that this is only valid if our design actually met timing. If our design has negative slack, then this means we cannot actually run the design at the target clock frequency and we will need to iterate to meet timing.</p> <pre><code>pt_shell&gt; create_clock clk -name ideal_clock1 -period 0.7\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#44-power-analysis","title":"4.4. Power Analysis","text":"<p>We now have everything we need to perform the power analysis: (1) the activity factor of a subset set of the nets, (2) the capacitance of every net/port, (3) the supply voltage, and (4) the clock frequency. We use the <code>update_power</code> command to propagate activity factors to unannotated nest and to estimate the power of our design.</p> <pre><code>pt_shell&gt; update_power\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#45-outputs","title":"4.5. Outputs","text":"<p>We can use the <code>report_power</code> command to show a high-level overview of how much power the sort unit consumes.</p> <pre><code>pt_shell&gt; report_power\n ...\n                Internal  Switching  Leakage    Total\n Power Group    Power     Power      Power      Power   (     %)  Attrs\n -----------------------------------------------------------------------\n clock_network  5.871e-04 2.163e-04 9.175e-08 8.035e-04 (29.22%)  i\n register       6.058e-04 1.292e-04 7.822e-06 7.428e-04 (27.01%)\n combinational  6.564e-04 5.365e-04 1.092e-05 1.204e-03 (43.77%)\n sequential        0.0000    0.0000    0.0000    0.0000 ( 0.00%)\n memory            0.0000    0.0000    0.0000    0.0000 ( 0.00%)\n io_pad            0.0000    0.0000    0.0000    0.0000 ( 0.00%)\n black_box         0.0000    0.0000    0.0000    0.0000 ( 0.00%)\n\n  Net Switching Power  = 8.819e-04   (32.07%)\n  Cell Internal Power  = 1.849e-03   (67.25%)\n  Cell Leakage Power   = 1.884e-05   ( 0.68%)\n                         ---------\nTotal Power            = 2.750e-03  (100.00%)\n</code></pre> <p>These numbers are in Watts. We can see that the sort unit consumes ~2.75mW of power when processing random input data. Power is the rate change of energy (i.e., energy divided by execution time), so the total energy is just the product of the total power, the number of cycles, and the cycle time. When we ran the sort unit simulator at the beginning of the tutorial, we saw that the simulation required 106 cycles. Assuming our sort unit runs as 0.7ns, this means the total energy is 2.5mW * 106 * 0.7ns = 185pJ. Since we are doing 100 sorts, this corresponds to about 1.8pJ per sort.</p> <p>The power is broken down into internal, switching, and leakage power. Internal and switching power are both forms of dynamic power, while leakage power is a form of static power. Notice that in this case, the dynamic power is much more significant than the static power. Internal power was described earlier in this tutorial, so you may want to revisit that section. Note that internal power includes short circuit power, but it can also include the local clock power internal to the cell. In this overview, the power is also broken down by the power consumed in the global clock network, registers, and combinational logic. Switching power is the power dissipated by the charging and discharging of the load capacitance at the output of each cell. Leakage power is the constant power due to subthreshold leakage. Sometimes we might want to factor out the static leakage power and focus more on the dynamic energy since including leakage power would mix energy and performance (i.e., using more cycles requires more leakage power even if we are not doing any more work during those cycles).</p> <p>Although the above breakdown is somewhat useful, it is even more useful to use the <code>report_power</code> command to show how much power each module consumes in the design.</p> <pre><code>pt_shell&gt; report_power -hierarchy\n ...\n                                      Int      Switch   Leak     Total\nHierarchy                             Power    Power    Power    Power    %\n----------------------------------------------------------------------------------\nSortUnitStruct                        1.85e-03 8.82e-04 1.88e-05 2.75e-03 100.0\n  v (SortUnitStruct_p_nbits8)         1.68e-03 8.12e-04 1.62e-05 2.51e-03  91.2\n    mmuA_S1 (MinMaxUnit_p_nbits8_0)   7.75e-05 8.51e-05 1.21e-06 1.64e-04   6.0\n    mmuA_S2 (MinMaxUnit_p_nbits8_3)   7.83e-05 9.41e-05 1.26e-06 1.74e-04   6.3\n    elm3_S2S3 (vc_Reg_p_nbits8_1)     9.39e-05 3.49e-06 6.31e-07 9.80e-05   3.6\n    elm2_S2S3 (vc_Reg_p_nbits8_2)     9.37e-05 1.25e-05 6.33e-07 1.07e-04   3.9\n    mmuA_S3 (MinMaxUnit_p_nbits8_1)   7.77e-05 8.44e-05 1.31e-06 1.63e-04   5.9\n    elm1_S2S3 (vc_Reg_p_nbits8_3)     9.71e-05 1.17e-05 6.31e-07 1.09e-04   4.0\n    elm3_S0S1 (vc_Reg_p_nbits8_9)     1.01e-04 1.63e-05 8.07e-07 1.18e-04   4.3\n    elm0_S2S3 (vc_Reg_p_nbits8_4)     9.42e-05 3.24e-06 6.30e-07 9.81e-05   3.6\n    elm2_S0S1 (vc_Reg_p_nbits8_10)    1.04e-04 1.57e-05 8.04e-07 1.20e-04   4.4\n    elm1_S0S1 (vc_Reg_p_nbits8_11)    1.01e-04 1.64e-05 8.04e-07 1.18e-04   4.3\n    val_S2S3 (vc_ResetReg_p_nbits1_1) 9.19e-06 7.25e-07 1.17e-07 1.00e-05   0.4\n    elm0_S0S1 (vc_Reg_p_nbits8_0)     1.01e-04 1.34e-05 8.04e-07 1.15e-04   4.2\n    val_S0S1 (vc_ResetReg_p_nbits1_0) 1.02e-05 3.57e-07 4.51e-07 1.10e-05   0.4\n    elm3_S1S2 (vc_Reg_p_nbits8_5)     9.34e-05 1.62e-05 6.32e-07 1.10e-04   4.0\n    elm2_S1S2 (vc_Reg_p_nbits8_6)     9.46e-05 1.25e-05 6.32e-07 1.08e-04   3.9\n    elm1_S1S2 (vc_Reg_p_nbits8_7)     9.67e-05 1.24e-05 6.31e-07 1.10e-04   4.0\n    mmuB_S1 (MinMaxUnit_p_nbits8_4)   7.48e-05 8.74e-05 1.19e-06 1.63e-04   5.9\n    mmuB_S2 (MinMaxUnit_p_nbits8_2)   7.12e-05 8.76e-05 1.27e-06 1.60e-04   5.8\n    elm0_S1S2 (vc_Reg_p_nbits8_8)     9.50e-05 1.19e-05 6.32e-07 1.08e-04   3.9\n    val_S1S2 (vc_ResetReg_p_nbits1_2) 9.18e-06 7.81e-08 1.17e-07 9.38e-06   0.3\n</code></pre> <p>From this breakdown, you can see that each min/max unit consumes about 6% of the total power and each register consumes about 4% of the total power. There are five min/max units so overall they consume about 30% of the total power and there are 12 registers so overall they consume 48% of the total power. So while each min/max unit consumes more energy than each register, there are more registers than min/max units such that overall more energy is consumed in the registers than the min/max units.</p> <p>Finally, we go ahead and exit Synopsys PT.</p>"},{"location":"ece6745-tut07-asic-back-end/#46-automating-power-analysis","title":"4.6. Automating Power Analysis","text":"<pre><code>pt_shell&gt; exit\n</code></pre> <p>You can automate the above steps by putting a sequence of commands in a <code>.tcl</code> file and run Synopsys PT using those commands in one step like this:</p> <pre><code>% cd $TOPDIR/asic/build-sort/06-synopsys-pt-pwr\n% pt_shell -f run.tcl\n</code></pre> <p>To further simplify rerunning this step, we can put the above command line in its own shell script. We have created such run scripts for you. Let's take a look to confirm these scripts match the manual commands we used above.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./06-synopsys-pt-pwr/run\n% cat ./06-synopsys-pt-pwr/run.tcl\n</code></pre> <p>You can rerun power analysis as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% ./06-synopsys-pt-pwr/run\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#5-to-do-on-your-own","title":"5. To-Do On Your Own","text":"<p>Now we can use what you have learned so far to push the GCD unit through the ASIC front-end and back-end flow. First, run a simulation of the GCD unit.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut3_verilog/gcd/gcd-sim --short-mname --impl rtl --input random --stats \\\n                              --translate --dump-vtb\n% less GcdUnit__pickled.v\n</code></pre> <p>Now create a new ASIC build directory and copy the scripts we used to push the sort unit through the ASIC front-end flow.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-gcd/01-synopsys-vcs-rtlsim\n% mkdir -p $TOPDIR/asic/build-gcd/02-synopsys-dc-synth\n% mkdir -p $TOPDIR/asic/build-gcd/03-synopsys-vcs-ffglsim\n% mkdir -p $TOPDIR/asic/build-gcd/04-cadence-innovus-pnr\n% mkdir -p $TOPDIR/asic/build-gcd/05-synopsys-vcs-baglsim\n% mkdir -p $TOPDIR/asic/build-gcd/06-synopsys-pt-pwr\n\n% cp $TOPDIR/asic/build-sort/01-synopsys-vcs-rtlsim/run              $TOPDIR/asic/build-gcd/01-synopsys-vcs-rtlsim\n% cp $TOPDIR/asic/build-sort/02-synopsys-dc-synth/run.tcl            $TOPDIR/asic/build-gcd/02-synopsys-dc-synth\n% cp $TOPDIR/asic/build-sort/02-synopsys-dc-synth/run                $TOPDIR/asic/build-gcd/02-synopsys-dc-synth\n% cp $TOPDIR/asic/build-sort/03-synopsys-vcs-ffglsim/run             $TOPDIR/asic/build-gcd/03-synopsys-vcs-ffglsim\n% cp $TOPDIR/asic/build-sort/04-cadence-innovus-pnr/setup-timing.tcl $TOPDIR/asic/build-gcd/04-cadence-innovus-pnr/setup-timing.tcl\n% cp $TOPDIR/asic/build-sort/04-cadence-innovus-pnr/run              $TOPDIR/asic/build-gcd/04-cadence-innovus-pnr/run\n% cp $TOPDIR/asic/build-sort/04-cadence-innovus-pnr/run.tcl          $TOPDIR/asic/build-gcd/04-cadence-innovus-pnr/run.tcl\n% cp $TOPDIR/asic/build-sort/05-synopsys-vcs-baglsim/run             $TOPDIR/asic/build-gcd/05-synopsys-vcs-baglsim/run\n% cp $TOPDIR/asic/build-sort/06-synopsys-pt-pwr/run                  $TOPDIR/asic/build-gcd/06-synopsys-pt-pwr/run\n% cp $TOPDIR/asic/build-sort/06-synopsys-pt-pwr/run.tcl              $TOPDIR/asic/build-gcd/06-synopsys-pt-pwr/run.tcl\n</code></pre> <p>Now open up each of these files and modify so they push the GCD unit instead of the sort unit through the flow. You will need to update the name of the Verilog source files and the top module name as follows:</p> <ul> <li>Verilog source file name: <code>GcdUnit__pickled.v</code></li> <li>Verilog test source file name: <code>GcdUnit_random_tb.v</code></li> <li>Top module name for synthesis: <code>GcdUnit</code></li> </ul> <p>Basically, you just need to change <code>SortUnitStruct</code> to <code>GcdUnit</code> in all of the run scripts. You can use <code>sed</code> to do this:</p> <pre><code>% cd $TOPDIR/asic/build-gcd\n% find . -type f -exec sed -i.bak 's/SortUnitStruct/GcdUnit/' {} \\;\n</code></pre> <p>Keep the cycle time constraint as 700ps and the other constraints as before. Once you have updated the scripts you can then push the GCD unit through the flow like this:</p> <pre><code>% cd $TOPDIR/asic/build-gcd\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% ./03-synopsys-vcs-ffglsim/run\n% ./04-cadence-innovus-pnr/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n</code></pre> <p>Carefully look at the post-synthesis and post-pnr timing reports to ensure your design meetings timing.</p> <pre><code>% cd $TOPDIR/asic/build-gcd\n% cat 02-synopsys-dc-synth/timing.rpt\n% cat 04-cadence-innovus-pnr/timing-setup.rpt\n% cat 04-cadence-innovus-pnr/timing-hold.rpt\n</code></pre> <p>If your design does not meet timing post-pnr, increase the cycle time constraint and try again until it does meet timing. If your design does not meet timing post-synthesis but does meet timing post-pnr this is means your overall design does meet timing. It just means the timing analysis used by Synopsys DC was overly conservative and/or Cadence Innovus was able to further optimize your design to meet timing. Carefully look and the results from running the four-state RTL simulation, fast-functional gate-level simulation, and back-annotated gate-level simulation to verify that the design is passing the simulations. Spend time looking at the post-synthesis gate-level netlist in <code>post-pnr.v</code> and load the design into Cadence Innovus to examine the placement. Convince yourself that the GCD unit was successfully pushed through the entire ASIC flow.</p>"},{"location":"ece6745-tut08-asic-auto/","title":"ECE 6745 Tutorial 8: ASIC Automated Flow","text":"<p>The previous tutorials demonstrated how to take a design from RTL to layout by both manually entering commands for each tool and also writing flow scripts. Flow scripts can help automate the process but copying and modifying these flow scripts for every design is tedious and error prone. An agile hardware design flow demands automation to simplify rapidly exploring the area, energy, timing design space of one or more designs. In this tutorial we will introduce a simple tool called pyhflow which takes as input a step templates and a design YAML and generates appropriate flow scripts. This tutorial assumes you have already completed the tutorials on Linux, Git, and Verilog.</p> <p>The following diagram illustrates the five primary tools we will be using in ECE 6745 along with a few smaller secondary tools. Notice that the ASIC tools all require various views from the standard-cell library. Before starting this tutorial, you must complete the ASIC standard-cell tutorial, the ASIC front-end flow tutorial, and the ASIC back-end flow tutorial.</p> <p></p> <ol> <li> <p>We write our RTL models in Verilog, and we use the PyMTL framework to     test, verify, and evaluate the execution time (in cycles) of our     design. This part of the flow is very similar to the flow used in     ECE 4750. Once we are sure our design is working correctly, we can     then start to push the design through the flow.</p> </li> <li> <p>We use Synopsys VCS to compile and run both 4-state RTL and     gate-level simulations. These simulations help us to build confidence     in our design as we push our designs through different stages of the     flow. From these simulations, we also generate waveforms in <code>.vcd</code>     (Verilog Change Dump) format, and per-net average activity factors     stored in <code>.saif</code> format. These activity factors will be used for     power analysis. Gate-level simulation is an valuable tool for     ensuring the tools did not optimize something away which impacts the     correctness of the design, and also provides an avenue for obtaining     a more accurate power analysis than RTL simulation. While static     timing analysis (STA) analyzes all paths, GL simulation can also     serve as a backup to check for hold and setup time violations (chip     designers must be paranoid!)</p> </li> <li> <p>We use Synopsys Design Compiler (DC) to synthesize our design,     which means to transform the Verilog RTL model into a Verilog     gate-level netlist where all of the gates are selected from the     standard-cell library. We need to provide Synopsys DC with abstract     logical and timing views of the standard-cell library in <code>.db</code>     format. In addition to the Verilog gate-level netlist, Synopsys DC     can also generate a <code>.ddc</code> file which contains information about the     gate-level netlist and timing, and this <code>.ddc</code> file can be inspected     using Synopsys Design Vision (DV). We will also use Synopsys DC to     generate a <code>.sdc</code> which captures timing constraints which can then be     used as input to the place-and-route tool.</p> </li> <li> <p>We use Cadence Innovus to place-and-route our design, which means     to place all of the gates in the gate-level netlist into rows on the     chip and then to generate the metal wires that connect all of the     gates together. We need to provide Cadence Innovus with the same     abstract logical and timing views used in Synopsys DC, but we also     need to provide Cadence Innovus with technology information in     <code>.lef</code>, and <code>.captable</code> format and abstract physical views of the     standard-cell library also in <code>.lef</code> format. Cadence Innovus will     generate an updated Verilog gate-level netlist, a <code>.spef</code> file which     contains parasitic resistance/capacitance information about all nets     in the design, and a <code>.gds</code> file which contains the final layout. The     <code>.gds</code> file can be inspected using the open-source Klayout GDS     viewer. Cadence Innovus also generates reports which can be used to     accurately characterize area and timing.</p> </li> <li> <p>We use Synopsys PrimeTime (PT) to perform power analysis of our     design. We need to provide Synopsys PT with the same abstract     logical, timing, and power views used in Synopsys DC and Cadence     Innovus, but in addition we need to provide switching activity     information for every net in the design (which comes from the <code>.saif</code>     file), and capacitance information for every net in the design (which     comes from the <code>.spef</code> file). Synopsys PT puts the switching     activity, capacitance, clock frequency, and voltage together to     estimate the power consumption of every net and thus every module in     the design, and these estimates are captured in various reports.</p> </li> </ol> <p>Extensive documentation is provided by Synopsys and Cadence for these ASIC tools. We have organized this documentation and made it available to you on the public course webpage:</p> <ul> <li>https://www.csl.cornell.edu/courses/ece6745/asicdocs</li> </ul> <p>The first step is to access <code>ecelinux</code>. Use VS Code to log into the same specific <code>ecelinux</code> server and then use Microsoft Remote Desktop to log into the same server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut08-asic-auto tut08\n% cd tut08\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut08-asic-auto/#1-testing-simulation-and-translation","title":"1. Testing, Simulation, and Translation","text":"<p>As in the previous tutorial, our goal is to characterize the area, energy, and timing for the sort unit from the Verilog tutorial using the ASIC tools. As a reminder, the sort unit takes as input four integers and a valid bit and outputs those same four integers in increasing order with the valid bit. The sort unit is implemented using a three-stage pipelined, bitonic sorting network and the datapath is shown below.</p> <p></p> <p>Before using the ASIC tools we need to verify that our design passes all of our tests and use an interactive simulator to drive our design-space exploration.</p>"},{"location":"ece6745-tut08-asic-auto/#11-testing-the-sort-unit","title":"1.1. Testing the Sort Unit","text":"<p>As always, we can use our Python-based testing framework combined with the Verilator two-state RTL simulator to verify our design's functionality. We need to use the <code>--test-verilog</code> and <code>--dump-vtb</code> command line options to generate Verilog test benches which can then be used for four-state RTL simulation, fast-functional gate-level simulation, and back-annotated gate-level simulation.</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/sort --test-verilog --dump-vtb\n</code></pre> <p>Verify the test benches have been generated.</p> <pre><code>% cd $TOPDIR/sim/build\n% ls SortUnitStruct*tb.v\n</code></pre>"},{"location":"ece6745-tut08-asic-auto/#12-evaluating-the-sort-unit","title":"1.2. Evaluating the Sort Unit","text":"<p>We can use the provided interactive simulator to run two experiments each with a different dataset.</p> <pre><code>% ../tut3_verilog/sort/sort-sim --impl rtl-struct --input random --stats --translate --dump-vtb\n% ../tut3_verilog/sort/sort-sim --impl rtl-struct --input zeros  --stats --translate --dump-vtb\n</code></pre> <p>Verify the Verilog RTL and test benches have been generated.</p> <pre><code>% cd $TOPDIR/sim/build\n% ls SortUnitStruct__p_nbits_8__pickled.v\n% ls SortUnitStruct__p_nbits_8_sort-sim-rtl-struct-random_tb.v\n% SortUnitStruct__p_nbits_8_sort-sim-rtl-struct-zeros_tb.v\n</code></pre>"},{"location":"ece6745-tut08-asic-auto/#2-pyhflow-for-generating-flows","title":"2. pyhflow For Generating Flows","text":"<p>pyflow is based on the idea of step templates which are located in the <code>asic/steps</code> directory.</p> <pre><code>% cd $TOPDIR/asic/steps\n% tree\n.\n\u251c\u2500\u2500 01-synopsys-vcs-rtlsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 02-synopsys-dc-synth\n\u2502   \u251c\u2500\u2500 run\n\u2502   \u2514\u2500\u2500 run.tcl\n\u251c\u2500\u2500 03-synopsys-vcs-ffglsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 04-cadence-innovus-pnr\n\u2502   \u251c\u2500\u2500 run\n\u2502   \u251c\u2500\u2500 run.tcl\n\u2502   \u2514\u2500\u2500 setup-timing.tcl\n\u251c\u2500\u2500 05-synopsys-vcs-baglsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 06-synopsys-pt-pwr\n\u2502   \u251c\u2500\u2500 run\n\u2502   \u2514\u2500\u2500 run.tcl\n\u2514\u2500\u2500 07-summarize-results\n    \u251c\u2500\u2500 run\n    \u2514\u2500\u2500 summarize-results\n</code></pre> <p>Each step is a directory with a run script and possibly other scripts. The key difference from the scripts we used in the previous tutorials, is that these scripts are templated using the Jinja2 templating system:</p> <ul> <li>https://jinja.palletsprojects.com</li> </ul> <p>So for example, the Synopsys DC run.tcl script is templated based on the design name and the target clock period as follows</p> <pre><code>analyze -format sverilog $env(TOPDIR)/sim/build/{{design_name}}__pickled.v\nelaborate {{design_name}}\n\ncreate_clock clk -name ideal_clock1 -period {{clock_period}}\n</code></pre> <p>The <code>{{ }}</code> directive is the standard syntax for template variable substitution using Jinja2. As another example, the RTL, FFGL, and BAGL simulation scripts are all templated by the list of tests and evaluations.</p> <pre><code>{% for item in tests_and_evals -%}\nrun_sim {{item}}\n{% endfor %}\n</code></pre> <p>The <code>{% %}</code> directive is the standard syntax for more complex templating using Jinja2.</p> <p>The pyhflow program takes as input a design YAML file which specifies:</p> <ul> <li>what steps make up the flow</li> <li>key/value pairs for variables to substitute into scripts</li> <li>list of tests</li> <li>list of evals</li> </ul> <p>Take a look at the provided design YAML file for the sort unit.</p> <pre><code>% cd $TOPDIR/asic/designs\n% cat tut08-sort.yml\n\nsteps:\n - 01-synopsys-vcs-rtlsim\n - 02-synopsys-dc-synth\n - 03-synopsys-vcs-ffglsim\n - 04-cadence-innovus-pnr\n - 05-synopsys-vcs-baglsim\n - 06-synopsys-pt-pwr\n - 07-summarize-results\n\nsrc_dir      : ../../../sim/build\ndesign_name  : SortUnitStruct__p_nbits_8\nclock_period : 0.7\ndump_vcd     : true\n\ntests:\n - SortUnitStruct__p_nbits_8_test_basic\n - SortUnitStruct__p_nbits_8_test_stream\n - SortUnitStruct__p_nbits_8_test_dups\n - SortUnitStruct__p_nbits_8_test_sorted\n - SortUnitStruct__p_nbits_8_test_random_8\n\nevals:\n - SortUnitStruct__p_nbits_8_sort-sim-rtl-struct-random\n</code></pre> <p>This design YAML file specifies the generated flow should use all seven steps. Currently the only parameters are the source directory, design name, and the clock period. We run RTL sim, FFGL sim, and BAGL sim on all tests and evals, but we only do energy analysis on the evals. The evals usually come from running an interactive simulator like <code>sort-sim</code>. All pyhflow does is use the YAML file to figure out what to substitute into the templated steps and then copy the run scripts into the current working directory. You can also override parameters on pyhflow command line.</p>"},{"location":"ece6745-tut08-asic-auto/#21-running-asic-flow-with-one-test","title":"2.1. Running ASIC Flow with One Test","text":"<p>Let's go ahead and use pyhflow to generate the flow scripts for the sort unit.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut08-sort\n% cd $TOPDIR/asic/build-tut08-sort\n% pyhflow --one-test ../designs/tut08-sort.yml\n</code></pre> <p>The <code>--one-test</code> command line option tells pyhflow to only include the first test and no evals in the flow scripts. This is a useful way to get started with a single test and reduces the overall runtime of the flow. Once we know that everything works with one test we can circle back and regenerate the flow scripts with all of the tests and evals.</p> <p>Let's see how the step template has been filled in for the Verilog RTL simulation step.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% cat 01-synopsys-vcs-rtlsim/run\n...\nrun_sim SortUnitStruct__p_nbits_8_test_basic\n</code></pre> <p>Notice how the name of the first test has been filled in. Let's also see how the step template has been filled in for the Synopsys DC synthesis step.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% cat 02-synopsys-dc-synth/run.tcl\n...\nanalyze -format sverilog $env(TOPDIR)/sim/build/SortUnitStruct__p_nbits_8__pickled.v\nelaborate SortUnitStruct__p_nbits_8\ncreate_clock clk -name ideal_clock1 -period 0.7\n</code></pre> <p>Notice how the name of the source Verilog RTL File, the top-level modulename, and the clock period have all been filled in.</p> <p>After generating a flow, we always recommend explicitly running at least the first two steps to ensure there are no errors. You can run the four-state RTL simulation as follows.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% ./01-synopsys-vcs-rtlsim/run\n</code></pre> <p>Make sure the step can find the source files and passes the test. Then run synthesis as follows.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% ./02-synopsys-dc-synth/run\n</code></pre> <p>Carefully look at the output from the synthesis step (also stored in the <code>run.log</code> file). Look for the output after <code>Running PRESTO HDLC</code> for any warnings to ensure that all of your Verilog RTL is indeed synthesizable. Scan through the rest of the logs to ensure there are no worrying warnings or errors.</p> <p>Once you have explicitly run the first two steps to ensure there are no errors, you can run the remaning steps.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% 03-synopsys-vcs-ffglsim\n% 04-cadence-innovus-pnr\n% 05-synopsys-vcs-baglsim\n% 06-synopsys-pt-pwr\n% 07-summarize-results\n</code></pre>"},{"location":"ece6745-tut08-asic-auto/#22-running-asic-flow-with-all-tests-and-evals","title":"2.2. Running ASIC Flow with All Tests and Evals","text":"<p>If all looks good, then you can regenerate the with all of the tests and evals. pyhflow will also create a <code>run-flow</code> script which will run all of the steps in sequence for you, but only use this if you are confident there are no errors!</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% pyhflow ../designs/tut08-sort.yml\n% ./run-flow\n\n timestamp          = 2025-02-19 22:14:30\n design_name        = SortUnitStruct__p_nbits_8\n clock_period       = 0.7\n rtlsim             = 7/7 passed\n synth_setup_slack  = 0.0089 ns\n synth_num_stdcells = 461\n synth_area         = 785.498 um^2\n ffglsim            = 7/7 passed\n pnr_setup_slack    = 0.0683 ns\n pnr_hold_slack     = 0.0102 ns\n pnr_num_stdcells   = 609\n pnr_area           = 930.202 um^2\n baglsim            = 7/7 passed\n\n SortUnitStruct__p_nbits_8_sort-sim-rtl-struct-random\n  - exec_time = 106 cycles\n  - exec_time = 74.5750 ns\n  - power     = 2.9100 mW\n  - energy    = 0.2170 nJ\n</code></pre> <p>The final step summarizes the results and includes the following information.</p> <ul> <li>Timestamp</li> <li>Design name</li> <li>Clock period in ns</li> <li>Four-state RTL simulation results</li> <li>Synthesis setup slack in ns</li> <li>Synthesis num stdcells</li> <li>Synthesis area in um^2</li> <li>Fast-functional gate-level simulation results</li> <li>Place-and-route setup slack in ns</li> <li>Place-and-route hold slack in ns</li> <li>Place-and-route num stdcells</li> <li>Place-and-route area in um^2</li> <li>Back-annotated gate-level simulation results</li> <li>For each evaluation<ul> <li>Execution time in cycles</li> <li>Execution time in ns</li> <li>Power in mW</li> <li>Energy in nJ</li> </ul> </li> </ul> <p>For the results to be valid, the following must be true:</p> <ul> <li>all four-state RTL simulations pass</li> <li>all fast-functional gate-level simulations pass</li> <li>all back-annotated gate-level simulations pass</li> <li>place-and-route setup slack is positive</li> <li>place-and-route hold slack is positive</li> </ul> <p>If your design does not meet timing after synthesis but does meet timing after place-and-route then these are still valid results. It just means Synopsys DC was conservative and/or Cadence Innovus did a good job further optimizing the design.</p>"},{"location":"ece6745-tut08-asic-auto/#23-debugging-issues","title":"2.3. Debugging Issues","text":"<p>Every step logs its output to a <code>run.log</code> file. The four-state RTL simulation, fast-functional gate-level simulation, and back-annotated gate-level simulation save the output of each simulation in a separate log file and also save a VCD file.</p> <p>If you pass two-state RTL simulation but fail four-state RTL simulation then the likely cause is either Verilog syntax that Synopsys VCS does not like (e.g., using signals before they are declared), mishandling register initialization, not handling inputs which are X correctly, and/or not forcing the outputs to always be known values (i.e., you cannot produces Xs on the outputs of your block after reset). Use Surfer and start from the observable error and work backwards through your design in both space and time. If you are seeing Xs in the output work backwards to try and figure out where these Xs are coming from.</p> <p>If you pass two-state RTL simulation and four-state RTL simulation but fail fast-functional gate-level simulation then the likely cause is some kind of synthesis issue such as inferred latches, parts of your design are being optimized away incorrectly, or the Synopsys DC TCL script has an issue. While you can look at waveforms for gate-level simulation it is not fun; it might be best to carefully look through the <code>run.log</code> file for the synthesis step first.</p> <p>If you pass two-state RTL simulation, four-state RTL simulation, fast-functional gate-level simulation, and your design has positive setup and hold slack after place-and-route then the likely cause is the Cadence Innovus TCL script has an issue. While you can look at waveforms for gate-level simulation it is not fun; it might be best to carefully look through the <code>run.log</code> file for the place-and-route step first.</p>"},{"location":"ece6745-tut08-asic-auto/#24-interactive-debugging","title":"2.4. Interactive Debugging","text":"<p>You can use Synopsys DV to look at the synthesis results as follows.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% design_vision-xg\ndesign_vision&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db\"\ndesign_vision&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db\"\n</code></pre> <p>You can use the following steps to open the <code>.ddc</code> file generated during synthesis.</p> <ul> <li>Choose File &gt; Read from the menu</li> <li>Open the <code>02-synopsys-dc-synth/post-synth.dcc</code> file</li> </ul> <p>However, we don't usually find using Synopsys DV to be that helpful.</p> <p>It is far more helpful to use Cadence Innovus to debug your physical design including highlighting modules and paths to see where they are located in the block. You can reload the design into Cadence Innovus as follows.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% innovus\ninnovus&gt; source 04-cadence-innovus-pnr/post-pnr.enc\n</code></pre> <p>You can use the Amobea workspace to help visualize how modules are mapped across the chip. Choose Windows &gt; Workspaces &gt; Amoeba from the menu. However, we recommend using the design browser to help visualize how modules are mapped across the chip. Here are the steps:</p> <ul> <li>Choose Windows &gt; Workspaces &gt; Design Browser + Physical from the menu</li> <li>Hide all of the metal layers by pressing the number keys</li> <li>Browse the design hierarchy using the panel on the left</li> <li>Right click on a module, click Highlight, select a color</li> </ul> <p>You can use the following steps in Cadence Innovus to display where the critical path is on the actual chip.</p> <ul> <li>Choose Timing &gt; Debug Timing from the menu</li> <li>Click OK in the pop-up window</li> <li>Right click on first path in the Path List</li> <li>Choose Highlight &gt; Only This Path &gt; Color</li> </ul> <p>Finally, you can use Klayout to capture a screen shot demonstrating that you have successfully taken a design from RTL to layout.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% klayout -l $ECE6745_STDCELLS/klayout.lyp 04-cadence-innovus-pnr/post-pnr.gds\n</code></pre>"},{"location":"ece6745-tut08-asic-auto/#25-key-reports","title":"2.5. Key Reports","text":"<p>Here is a list of key reports.</p> <ul> <li>02-synopsys-dc-synth/timing.rpt</li> <li>02-synopsys-dc-synth/area.rpt</li> <li>02-synopsys-dc-synth/resources.rpt</li> <li>04-cadence-innovus-pnr/timing-setup.rpt</li> <li>04-cadence-innovus-pnr/timing-hold.rpt</li> <li>04-cadence-innovus-pnr/area.rpt</li> <li>06-synopsys-pt-pwr/*-summary.rpt</li> <li>06-synopsys-pt-pwr/*-detailed.rpt</li> </ul> <p>You can use the synthesis resources report to determine if Synospys DC has used DesignWare components to optimize parts of your design. You can learn more about all of the DesignWare components here:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/asicdocs/dwbb_datasheets</li> </ul> <p>You can use the place-and-route timing setup report to determine the critical path in your design and the delay of every component along this critical path. You can use the place-and-route area reprot to determine the area of every module in your design. You can use the detailed power reports to determine the power consumption of every module in your design.</p>"},{"location":"ece6745-tut08-asic-auto/#3-to-do-on-your-own","title":"3. To Do On Your Own","text":"<p>Now we can use what you have learned so far to push the GCD unit through the ASIC automted flow. First, run all of the tests for theGCD unit.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/gcd/test --test-verilog --dump-vtb\n</code></pre> <p>Then run three interactive simulations for our evaluation.</p> <pre><code>% ../tut3_verilog/gcd/gcd-sim --impl rtl --input random --stats --translate --dump-vtb\n% ../tut3_verilog/gcd/gcd-sim --impl rtl --input small  --stats --translate --dump-vtb\n% ../tut3_verilog/gcd/gcd-sim --impl rtl --input zeros  --stats --translate --dump-vtb\n</code></pre> <p>Then you can use pyhflow to push the GCD unit through the flow.</p> <pre><code>% mkdir -p ${TOPDIR}/asic/build-tut08-gcd\n% cd ${TOPDIR}/asic/build-tut08-gcd\n% pyhflow ../designs/tut08-gcd.yml\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% ./03-synopsys-vcs-ffglsim/run\n% ./04-cadence-innovus-pnr/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n% ./07-summarize-results/run\n</code></pre> <p>Or use the <code>run-flow</code> script to run the entire flow with a single command.</p> <pre><code>% mkdir -p ${TOPDIR}/asic/build-tut08-gcd\n% cd ${TOPDIR}/asic/build-tut08-gcd\n% pyhflow ../designs/tut08-gcd.yml\n% ./run-flow\n</code></pre> <p>Compare the energy of the three evaluations. Look at the following reports to understand the critical path and area breakdown.</p> <pre><code>% cd ${TOPDIR}/asic/build-tut08-gcd\n% cat 04-cadence-innovus-pnr/timing-setup.rpt\n% cat 04-cadence-innovus-pnr/area.rpt\n</code></pre> <p>Use the Cadence Innovus GUI to highlight the datapath vs control modules. Use klayout to look at the final layout. Then try to push the clock period lower to see if the block can operate at a higher clock frequency while still meeting timing and passing all of the tests.</p>"},{"location":"ece6745-tut09-xcel-rtl/","title":"ECE 6745 Tutorial 9: TinyRV2 Accelerator RTL Design","text":"<p>The infrastructure for the ECE 6745 lab assignments and projects has support for implementing medium-grain accelerators. Fine-grain accelerators are tightly integrated within the processor pipeline (e.g., a specialized functional unit for bit-reversed addressing useful in implementing an FFT), while coarse-grain accelerators are loosely integrated with a processor through the memory hierarchy (e.g., a graphics rendering accelerator sharing the last-level cache with a general-purpose processor). Medium-grain accelerators are often integrated as co-processors: the processor can directly send/receive messages to/from the accelerator with special instructions, but the co-processor is relatively decoupled from the main processor pipeline and can also independently interact with memory.</p> <p>This tutorial will use the vector-vector-add (vvadd) microbenchmark as an example. We will explore the area and timing of a baseline TinyRV2 pipelined processor and the energy and performance when this processor is used to execute a pure-software version of the vvadd microbenchmark. We will then implement a vvadd accelerator, integrate it with the TinyRV2 pipelined processor, and determine the potential benefit of hardware acceleration for this simple microbenchmark. This tutorial assumes you have already completed the tutorials on Linux, Git, Verilog, ASIC front-end flow, ASIC back-end flow, and ASIC automated ASIC flow.</p> <p>The first step is to access <code>ecelinux</code>. Use VS Code to log into the same specific <code>ecelinux</code> server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut09-xcel-rtl tut09\n% cd tut09\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut09-xcel-rtl/#1-baseline-tinyrv2-processor-fl-and-rtl-models","title":"1. Baseline TinyRV2 Processor FL and RTL Models","text":"<p>The following figure illustrates the overall system we will be using with our TinyRV2 processors. The processor includes eight latency insensitive val/rdy interfaces. The mngr2proc/proc2mngr interfaces are used for the test harness to send data to the processor and for the processor to send data back to the test harness. The imem master/minion interface is used for instruction fetch, and the dmem master/minion interface is used for implementing load/store instructions. The system includes both instruction and data caches. The xcel master/minion interface is used for the processor to send messages to the accelerator. The mngr2proc/proc2mngr and memreq/memresp interfaces were all introduced in ECE 4750. For now we will largely ignore the accelerator, and we will defer discussion of the xcel master/minion interfaces to later in this tutorial. The cache is not ported to work with the ASIC flow so it is not currently included!</p> <p></p> <p>We provide two implementations of the TinyRV2 processor. The FL model in <code>sim/proc/ProcFL.py</code> is essentially an instruction-set-architecture (ISA) simulator; it simulates only the instruction semantics and makes no attempt to model any timing behavior. As a reminder, the TinyRV2 instruction set is defined here:</p> <ul> <li>http://www.csl.cornell.edu/courses/ece6745/handouts/ece6745-tinyrv-isa.txt</li> </ul> <p>The RTL model in <code>sim/proc/ProcPRTL.py</code> is similar to the alternative design for lab 2 in ECE 4750. It is a five-stage pipelined processor that implements the TinyRV2 instruction set and includes full bypassing/forwarding to resolve data hazards. There are two important differences from the alternative design for lab 2 of ECE 4750. First, the new processor design uses a single-cycle integer multiplier. We can push the design through the flow and verify that the single-cycle integer multiplier does not adversely impact the overall processor cycle time. Second, the new processor design includes the ability to handle new CSRs for interacting with medium-grain accelerators. The datapath diagram for the processor is shown below.</p> <p></p> <p>We should run all of the unit tests on both the FL and RTL processor models to verify that we are starting with a working processor.</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../proc\n</code></pre> <p>See the handout for lab 2 from ECE 4750 for more information about how we use <code>pytest</code> and the mngr2proc/proc2mngr interfaces to test the TinyRV2 processor.</p>"},{"location":"ece6745-tut09-xcel-rtl/#2-testing-and-evaluating-tinyrv2-microbenchmarks","title":"2. Testing and Evaluating TinyRV2 Microbenchmarks","text":"<p>We will write our microbenchmarks in C. Take a closer look at the vvadd microbenchmark which is located in <code>app/ubmark/ubmark-vvadd.c</code>:</p> <pre><code>__attribute__ ((noinline))\nvoid vvadd_scalar( int *dest, int *src0, int *src1, int size )\n{\n  for ( int i = 0; i &lt; size; i++ )\n    dest[i] = src0[i] + src1[i];\n}\n</code></pre> <p>We will a use microbenchmark test to verify the functionality of our microbenchmark and a microbenchmark eval to evaluate the performance of our microbenchmark. We will run both the microbenchmark test and eval on both FL and RTL TinyRV2 processor models.</p>"},{"location":"ece6745-tut09-xcel-rtl/#21-tinyrv2-vvadd-test","title":"2.1. TinyRV2 VVADD Test","text":"<p>Let's go ahead and take a look at the microbenchmark test provided for the vvadd microbenchmark.</p> <pre><code>% cd $TOPDIR/app/ubmark\n% less ubmark-vvadd-test.c\n</code></pre> <p>Here is a snippet from the microbenchmark test.</p> <pre><code>#include \"ece6745.h\"\n#include \"ubmark-vvadd.h\"\n#include \"ubmark-vvadd.dat\"\n\nvoid test_case_1_pos()\n{\n  ECE6745_CHECK( L\"test_case_1_pos\" );\n\n  int src0[] = {  1,  2,  3,  4 };\n  int src1[] = {  5,  6,  7,  8 };\n  int dest[] = {  0,  0,  0,  0 };\n  int ref[]  = {  6,  8, 10, 12 };\n\n  ubmark_vvadd( dest, src0, src1, 4 );\n\n  for ( int i = 0; i &lt; 4; i++ )\n    ECE6745_CHECK_INT_EQ( dest[i], ref[i] );\n}\n\n...\n\nint main( int argc, char** argv )\n{\n  __n = ( argc == 1 ) ? 0 : ece6745_atoi( argv[1] );\n\n  if ( (__n &lt;= 0) || (__n == 1) ) test_case_1_pos();\n  ...\n\n  ece6745_wprintf( L\"\\n\\n\" );\n  return ece6745_check_status;\n}\n</code></pre> <p>The test harness includes several test case functions and then we call these test case functions in <code>main</code>. We wave a build system that can compile C code natively for x86 and can also cross-compile these microbenchmarks for TinyRV2 so they can be executed on our simulators. When developing and testing C code, we should always try to compile the code natively to ensure the code is functionally correct before we attempt to cross-compile the code for TinyRV2. Debugging code natively is much easier compared to debugging code on our simulators. Here is how we compile and execute the tests for the vvadd microbenchmark natively:</p> <pre><code>% cd $TOPDIR/app\n% mkdir build-native\n% cd build-native\n% ../configure\n% make ubmark-vvadd-test\n% ./ubmark-vvadd-test\n</code></pre> <p>You can run a single test case like this:</p> <pre><code>% cd $TOPDIR/app/build-native\n% ./ubmark-vvadd-test 1\n</code></pre> <p>Once we are confident the microbenchmark test passes on natively, we can cross-compile the microbenchmark test and run it on both FL and RTL TinyRV2 processor models. Let's start by cross-compiling the microbenchmark test.</p> <pre><code>% mkdir -p $TOPDIR/app/build\n% cd $TOPDIR/app/build\n% ../configure --host=riscv32-unknown-elf\n% make ubmark-vvadd-test\n</code></pre> <p>This will create a <code>ubmark-vvadd-test</code> binary which contains TinyRV2 instructions and data. You can disassemble a TinyRV2 binary (i.e., turn a compiled binary back into an assembly text representation) with the <code>riscv32-objdump</code> command like this:</p> <pre><code>% cd $TOPDIR/app/build\n% riscv32-objdump ubmark-vvadd-test | less -p \"&lt;ubmark_vvadd&gt;:\"\n00000fac &lt;ubmark_vvadd&gt;:\n    fac: bge    x0,  x13, fd8\n    fb0: slli   x13, x13, 0x2\n    fb4: add    x13, x11, x13\n    fb8: lw     x15, 0(x11)   # &lt;-.\n    fbc: lw     x14, 0(x12)   #   |\n    fc0: addi   x11, x11, 4   #   |\n    fc4: addi   x12, x12, 4   #   |\n    fc8: add    x15, x15, x14 #   |\n    fcc: sw     x15, 0(x10)   #   |\n    fd0: addi   x10, x10, 4   #   |\n    fd4: bne    x11, x13, fb8 # --'\n    fd8: jalr   x0,  x1,  0\n</code></pre> <p>You can also redirect the output from <code>riscv32-objdump</code> to a text file for viewing with VS Code. The disassembly shows the address and assembly text for each instruction in the binary.</p> <p>The assembly code for the <code>ubmark_vvadd</code> function is similar to what we saw in ECE 4750 although with some additional optimizations. I have added some comments to show the backwards branch for the vvadd loop. The loop has eight instructions. Four instructions do useful work (i.e., two LW instructions, the actual ADDU instruction, one SW instruction) and three ADDI instructions generate the array addresses by bumping the array pointers. Notice that there is no explicit loop counter. The compiler has instead calculated the address of one past the last element in the first source array, and placed this value in <code>x13</code>. Each iteration, the BNE instruction compares the current pointer to see if we have reached the end of the array.</p> <p>We have provided you with a simulator that composes a processor, cache, memory, and accelerator and is capable of executing TinyRV2 binaries. The simulator enables flexibly choosing the processor implementation (FL vs. RTL), the cache implementation (no cache vs. RTL), and the type and implementation of the accelerator. By default, the simulator uses the processor FL model, no cache model, and a null accelerator which we will discuss later. So let's execute the vvadd TinyRV2 binary on the instruction-set simulator:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim ./ubmark-vvadd-test\n</code></pre> <p>The simulator should display the same test output that we saw when executing the microbenchmark test natively. You can run a single test case like this:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim ./ubmark-vvadd-test 1\n</code></pre> <p>The <code>--trace</code> command line option will display each instruction as it is executed on the ISA simulator.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --trace \\\n    ./ubmark-vvadd-test 1 &gt; ubmark-vvadd-test-fl.trace\n</code></pre> <p>When dumping out large line traces, it is usually much faster to save them to a file and then open the file in VS Code. Here is what the beginning of the line trace looks like.</p> <pre><code>cycle PC       instruction                                          FL memory\n----------------------------------------------------------------------------------\n  1r  #                                |              ()                 |     |\n  2r  #                                |              ()                 |     |\n  3:  #                                |              ()            rd&gt;  |     |\n  4:  #                                |              ()              &gt;rd|     |\n  5:  00000200 auipc  x03, 0x00003     |              ()                 |     |\n  6:  #                                |              ()            rd&gt;  |     |\n  7:  #                                |              ()              &gt;rd|     |\n  8:  00000204 addi   x03, x03, 0x9f0  |              ()                 |     |\n  9:  #                                |              ()            rd&gt;  |     |\n 10:  #                                |              ()              &gt;rd|     |\n 11:  00000208 addi   x01, x00, 0x000  |              ()                 |     |\n 12:  #                                |              ()            rd&gt;  |     |\n 13:  #                                |              ()              &gt;rd|     |\n 14:  0000020c addi   x02, x00, 0x000  |              ()                 |     |\n 15:  #                                |              ()            rd&gt;  |     |\n 16:  #                                |              ()              &gt;rd|     |\n 17:  00000210 addi   x04, x00, 0x000  |              ()                 |     |\n 18:  #                                |              ()            rd&gt;  |     |\n 19:  #                                |              ()              &gt;rd|     |\n</code></pre> <p>You can see the beginning of the program is initializing the registers to zero. Since this is an ISA simulator, instructions can functionally execute in a single cycle, although technically they take multiple \"cycles\" to interact with the memory system. These cycles are not really modeling any kind of realistic timing, but can instead be thought of as the \"steps\" required for functional simulation.</p> <p>Now that we have verified the microbenchmark test works correctly on the ISA simulator, we can run the microbenchmark test on the baseline TinyRV2 pipelined processor RTL model:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl ./ubmark-vvadd-test\n</code></pre> <p>Again the simulator should display the same test output that we saw when executing the microbenchmark test natively and on the FL simulator. You can run a single test case like this:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl ./ubmark-vvadd-test 1\n</code></pre> <p>Let's use the <code>--trace</code> command line option to dump out the trace.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --trace \\\n    ./ubmark-vvadd-test 1 &gt; ubmark-vvadd-test-rtl.trace\n</code></pre> <p>Here is what the first few cycles of the simulation look like.</p> <pre><code>cycle F        D                       X    M    W     imem  dmem\n-------------------------------------------------------------------\n  1r          |                       |    |    |    |      |     |\n  2r          |                       |    |    |    |      |     |\n  3:          |                       |    |    |    | rd&gt;  |     |\n  4:  00000200|                       |    |    |    | rd&gt;rd|     |\n  5:  00000204|auipc  x03, 0x00003    |    |    |    | rd&gt;rd|     |\n  6:  00000208|addi   x03, x03, 0x9f0 |auiP|    |    | rd&gt;rd|     |\n  7:  0000020c|addi   x01, x00, 0x000 |addi|auiP|    | rd&gt;rd|     |\n  8:  00000210|addi   x02, x00, 0x000 |addi|addi|auiP| rd&gt;rd|     |\n  9:  00000214|addi   x04, x00, 0x000 |addi|addi|addi| rd&gt;rd|     |\n 10:  00000218|addi   x05, x00, 0x000 |addi|addi|addi| rd&gt;rd|     |\n 11:  0000021c|addi   x06, x00, 0x000 |addi|addi|addi| rd&gt;rd|     |\n</code></pre> <p>We can see the five stages of the processor pipeline. The PC is displayed in the F stage, the full instruction is displayed in the D stage, and a shorter version of the instruction is displayed in the X, M, and W stages. We are using a single-cycle magic memory, so we can see instruction memory requests being sent and the responses being returned the next cycle. Again you can see the beginning of the program is initializing the registers to zero.</p>"},{"location":"ece6745-tut09-xcel-rtl/#22-tinyrv2-vvadd-eval","title":"2.2. TinyRV2 VVADD Eval","text":"<p>Once we are sure the microbenchmark test is working natively, on the FL simulator, and the RTL simulator, we can then turn our focus to the microbenchmark eval.</p> <pre><code>% cd $TOPDIR/app/ubmark\n% less ubmark-vvadd-eval.c\n</code></pre> <p>Here is the microbenchmark eval.</p> <pre><code>#include \"ece6745.h\"\n#include \"ubmark-vvadd.h\"\n#include \"ubmark-vvadd.dat\"\n\nint main( void )\n{\n  // Allocate destination array for results\n\n  int* dest = ece6745_malloc( eval_size * (int)sizeof(int) );\n\n  // Run the evaluation\n\n  ece6745_stats_on();\n  ubmark_vvadd( dest, eval_src0, eval_src1, eval_size );\n  ece6745_stats_off();\n\n  // Verify the results\n\n  for ( int i = 0; i &lt; eval_size; i++ ) {\n    if ( dest[i] != eval_ref[i] ) {\n      ece6745_wprintf( L\"\\n FAILED: dest[%d] != eval_ref[%d] (%d != %d)\\n\\n\",\n                       i, i, dest[i], eval_ref[i] );\n      ece6745_exit(1);\n    }\n  }\n\n  // Free destination array\n\n  ece6745_free(dest);\n\n  // Check for no memory leaks\n\n  if ( ece6745_get_heap_usage() != 0 ) {\n    ece6745_wprintf( L\"\\n FAILED: memory leak of %d bytes!\\n\\n\",\n                     ece6745_get_heap_usage() );\n    ece6745_exit(1);\n  }\n\n  // Otherwise we passed\n\n  ece6745_wprintf( L\"\\n **PASSED** \\n\\n\" );\n\n  return 0;\n}\n</code></pre> <p>The <code>eval_src0</code>, <code>eval_src1</code>, and <code>eval_ref</code> arrays are all defined in the <code>app/ubmark/ubmark-vvadd.dat</code> file. The microbenchmark first allocates the destination array on the heap, turns stats on, does the actual vvadd computation, turns stats off, verifies that the results are as expected, and makes sure there are no memory leaks. We need the <code>ece6745_stats_on()</code> and <code>ece6745_stats_off()</code> functions to make sure we can keep track of various statistics (e.g., the number of cycles) only during the important part of the microbenchmark. We do not want to count time spent in initialization or verification when comparing the performance of our various microbenchmarks. The <code>ece6745_stats_on</code> function is defined in <code>app/ece6745/ece6745-misc.h</code> as follows:</p> <pre><code>#ifdef _RISCV\n\ninline\nvoid ece6745_stats_on()\n{\n  int status = 1;\n  __asm__ ( \"csrw 0x7c1, %0\" :: \"r\"(status) );\n}\n\n#else\n\ninline\nvoid ece6745_stats_on()\n{ }\n\n#endif\n</code></pre> <p>Notice that if <code>_RISCV</code> is not defined (i.e., we are compiling the microbenchmark eval natively on x86) this function is empty. If <code>_RISCV</code> is defined (i.e., we are cross-compilng the microbenchmark eval for TinyRV2) then this function uses GCC inline assembly to insert a CSRW instruction into the program. You can find out more about inline assembly syntax here:</p> <ul> <li>https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html</li> </ul> <p>At a high level, <code>%0</code> acts as a place holder for whatever register specifier the compiler ends up allocating for the <code>status</code> variable. The TinyRV2 instruction set defines CSR number 0x7c1 as the <code>stats_en</code> control/status register, which is why we use <code>0x7c1</code> in the inline assembly. Refer to the TinyRV2 instruction set for a list of the CSRs.</p> <ul> <li>http://www.csl.cornell.edu/courses/ece6745/handouts/ece6745-tinyrv-isa.txt</li> </ul> <p>The idea is that the microarchitecture and/or simulator can monitor for writes to the <code>stats_en</code> register to determine when to start and stop keeping statistics. For more on writing microbenchmarks, please review the handout for lab 5 from ECE 4750.</p> <p>Here is how we compile and execute the evaluation for the vvadd microbenchmark natively:</p> <pre><code>% cd $TOPDIR/app/build-native\n% make ubmark-vvadd-eval\n% ./ubmark-vvadd-eval\n</code></pre> <p>The microbenchmark eval should display <code>passed</code>. Once you are sure your microbenchmark eval is working correctly natively, you can cross-compile the microbenchmark eval for TinyRV2 and look at the main function.</p> <pre><code>% cd $TOPDIR/app/build\n% make ubmark-vvadd-eval\n% riscv32-objdump ./ubmark-vvadd-eval | less -p \"&lt;main&gt;:\"\n</code></pre> <p>If you look in the disassembly for the main function you should be able to see the two CSRW instructions used to turn stats on and off.</p> <pre><code> 6f8:   addi    x15,x0,1              # \\\n 6fc:   csrw    0x7c1,x15             # / turn stats on\n 700:   lui     x12,0x1               # \\\n 704:   lw      x13,-2048(x3)         # | setup arguments\n 708:   addi    x9,x12,-1072          # |\n 70c:   addi    x11,x9,400            # |\n 710:   addi    x12,x12,-1072         # /\n 714:   jal     x1,2fc &lt;ubmark_vvadd&gt; # call the ubmark_vvadd function\n 718:   addi    x15,x0,0              # \\\n 71c:   csrw    0x7c1,x15             # / turn stats off\n</code></pre> <p>Now let's run the microbenchmark eval on the FL simulator.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim ./ubmark-vvadd-eval\n</code></pre> <p>The microbenchmark eval should display <code>passed</code>. Once you are sure your microbenchmark eval is working correctly natively and on the FL simulator you are finally ready to run it on the actual RTL simulator to do a real performance evaluation.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --stats ./ubmark-vvadd-eval\n **PASSED**\n\n num_cycles        = 1013\n num_inst          = 812\n CPI               = 1.25\n</code></pre> <p>Now let's look in more detail at the trace.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --trace ./ubmark-vvadd-eval &gt; ubmark-vvadd-eval-rtl.trace\n</code></pre> <p>Open up the trace in VS code and search for 0fbc which is the address of the first instruction in the loop.</p> <pre><code>cycle F        D                       X    M    W     imem  dmem\n-------------------------------------------------------------------\n841:  00000fbc|lw     x15, 0x000(x11) |add |slli|bge | rd&gt;rd|     |\n842:  00000fc0|lw     x14, 0x000(x12) |lw  |add |slli| rd&gt;rd|rd&gt;  |\n843:  00000fc4|addi   x11, x11, 0x004 |lw  |lw  |add | rd&gt;rd|rd&gt;rd|\n844:  00000fc8|addi   x12, x12, 0x004 |addi|lw  |lw  | rd&gt;rd|  &gt;rd|\n845:  00000fcc|add    x15, x15, x14   |addi|addi|lw  | rd&gt;rd|     |\n846:  00000fd0|sw     x15, 0x000(x10) |add |addi|addi| rd&gt;rd|     |\n847:  00000fd4|addi   x10, x10, 0x004 |sw  |add |addi| rd&gt;rd|wr&gt;  |\n848:  00000fd8|bne    x11, x13, 0x1fe4|addi|sw  |add | rd&gt;rd|  &gt;wr|\n849:  /       |/                      |bne |addi|sw  | rd&gt;rd|     |\n850:  00000fb8|                       |    |bne |addi| rd&gt;rd|     |\n851:  00000fbc|lw     x15, 0x000(x11) |    |    |bne | rd&gt;rd|     |\n852:  00000fc0|lw     x14, 0x000(x12) |lw  |    |    | rd&gt;rd|rd&gt;  |\n853:  00000fc4|addi   x11, x11, 0x004 |lw  |lw  |    | rd&gt;rd|rd&gt;rd|\n854:  00000fc8|addi   x12, x12, 0x004 |addi|lw  |lw  | rd&gt;rd|  &gt;rd|\n</code></pre> <p>We can see the eight instructions in the loop going through the five stages of the pipeline. We can see the memory requests for the two loads and store going to the data memory and the responses coming back on the next cycle. We can also see the branch misprediction squashing two instructions. The <code>eval_size</code> is 100 so there are 100 iterations of the loop and 800 instructions, which should take a total of 1000 cycles resulting in a CPI of 1.25.</p> <p>When we used <code>--stats</code> the instruction count and number of cycles was slightly higher due to the extra instructions required to setup the arguments before calling <code>ubmark_vvadd</code> and the extra instructions within <code>ubmark_vvadd</code> before we start the loop.</p>"},{"location":"ece6745-tut09-xcel-rtl/#3-testing-and-evaluating-accelerators-in-isolation","title":"3. Testing and Evaluating Accelerators in Isolation","text":"<p>We will take an incremental approach when designing, implementing, testing, and evaluating accelerators. We can use test sources, sinks, and memories to create a test harness that will enable us to explore the accelerator cycle-level performance and the ASIC area, energy, and timing in isolation. Only after we are sure that we have a reasonable design-point should we consider integrating the accelerator with the processor.</p> <p>All accelerators have an xcel minion interface along with a standard mem master interface. The messages sent over the xcel minion interface allows the test harness or processor to read and write accelerator registers. These accelerator registers can be real registers that hold configuration information and/or results, or these accelerator registers can just be used to trigger certain actions. The messages sent over the xcel.req interface from the test harness or processor to the accelerator have the following format:</p> <pre><code>   1b     5b      32b\n +------+-------+-----------+\n | type | raddr | data      |\n +------+-------+-----------+\n</code></pre> <p>The 1-bit <code>type</code> field indicates if this messages if for reading (0) or writing (1) an accelerator register, the 5-bit <code>raddr</code> field specifies which accelerator register to read or write, and the 32-bit <code>data</code> field is the data to be written. For every accelerator request, the accelerator must send back a corresponding accelerator response over the xcel.resp interface. These response messages have the following format:</p> <pre><code>   1b     32b\n +------+-----------+\n | type | data      |\n +------+-----------+\n</code></pre> <p>The 1-bit <code>type</code> field gain indicates if this response is from if for reading (0) or writing (1) an accelerator register, and the 32-bit <code>data</code> field is the data read from the corresponding accelerator register. Every accelerator is free to design its own accelerator protocol by defining the meaning of reading/writing the 32 accelerator registers.</p> <p>We have implemented a null accelerator which we can use when we don't want to integrate a \"real\" accelerator, but this null accelerator is also useful in illustrating the basic accelerator interface. The null accelerator has a single accelerator register (xr0) which can be read and written. Take a closer look at this null accelerator in <code>sim/proc/NullXcel.v</code>.</p> <pre><code>  always_comb begin\n\n    // Mux to force xcelresp data to zero on a write\n    // Enable xr0 only upon write requests and both val/rdy on resp side\n\n    if ( xcelreq_deq_msg.type_ == `VC_XCEL_REQ_MSG_TYPE_WRITE ) begin\n      xr0_en = xcel_respstream_val &amp;&amp; xcel_respstream_rdy;\n      xcel_respstream_msg.data = '0;\n    end\n    else begin\n      xr0_en = 0;\n      xcel_respstream_msg.data = xr0;\n    end\n\n  end\n</code></pre> <p>The null accelerator simply waits for a xcel.req message to arrive. If that message is a read, then it reads the <code>xr0</code> register into the xcelresp message. If that message is a write, then it sets the enable of the <code>xr0</code> register so that the new value is flopped in at the end of the cycle. Here is a unit test which writes a value to the null accelerator's xr0 register and then reads it back:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../proc/test/NullXcel_test.py -k basic -s\n\n  1r                &gt;               |.           &gt; .\n  2r                &gt;               |.           &gt; .\n  3:                &gt;               |.           &gt; .\n  4:                &gt;               |.           &gt; .\n  5:                &gt;               |.           &gt; .\n  6:                &gt;               |.           &gt; .\n  7: wr:00:0000000a &gt; wr:00:0000000a|            &gt;\n  8: rd:00:         &gt; rd:00:        |wr:         &gt; wr:\n  9:                &gt;               |rd:0000000a &gt; rd:0000000a\n 10:                &gt;               |            &gt;\n</code></pre> <p>From the line trace, you can see the write request message (with write data 0x0a) going into the accelerator, and then the write response being returned on the next cycle. You can also see the read request message going into the accelerator, and then the read response being returned (with read data 0x0a) again on the next cycle.</p> <p>The vvadd accelerator is obviously more sophisticated. Accelerator protocols are usually defined as a comment at the top of the FL model, so take a closer look at the vvadd accelerator FL model in <code>sim/tut9_xcel/VvaddXcelFL.py</code>. The vvadd accelerator protocol defines the accelerator registers as follows:</p> <ul> <li>xr0 : go/done</li> <li>xr1 : base address of the array src0</li> <li>xr2 : base address of the array src1</li> <li>xr3 : base address of the array dest</li> <li>xr4 : size of the array</li> </ul> <p>The actual protocol involves the following steps:</p> <ol> <li>Write the base address of src0 to xr1</li> <li>Write the base address of src1 to xr2</li> <li>Write the base address of dest to xr3</li> <li>Write the number of elements in the array to xr4</li> <li>Tell accelerator to go by writing xr0</li> <li>Wait for accelerator to finish by reading xr0, result will be 1</li> </ol> <p>A close look at the vvadd accelerator FL model shows that most of the work is really in managing this accelerator protocol. The accelerator waits for accelerator requests, updates its internal state registers, and when it receives a write to xr0 it starts doing the actual vvadd computation. The FL model makes use of method-based interfaces to simplify interacting with the memory system. Let's run the unit tests on the FL model first:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut9_xcel/test/VvaddXcelFL_test.py -v\n</code></pre> <p>The vvadd accelerator CL model is actually very close to the RTL implementation largely due to the need to carefully interact with the latency insensitive memory interface. CL modeling may or may not be useful in this context. The vvadd accelerator RTL model is in <code>sim/tut9_xcel/VvaddXcelPRTL.py</code> and (roughly) implements the following FSM:</p> <p></p> <p>While the accelerator is in the XCFG state, it will update its internal registers when it receives accelerator requests. When the accelerator receives a write to xr0 it moves into the M_RD state. While in the M_RD state, the accelerator will send out two memory read requests to read the current element from each source array. In the ADD state, the accelerator will do the actual addition, and in the M_WR state, the accelerator will send out the memory write request to write the result to the destination array. The accelerator will wait in the final WAIT state until it receives the memory write response, and then will either move back into the M_RD state if there is another element to be processed, or move into the XCFG state if we have processed all elements in the array.</p> <p>The accelerator is not implemented with a control/datapath split because the accelerator is almost entirely control logic; it was just simpler to implement the accelerator as a single model. When a model is almost all control logic or almost all datapath logic, then a control/datapath split may be more trouble than its worth.</p> <p>Let's run the unit tests for all of the vvadd accelerator models:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut9_xcel\n% pytest ../tut9_xcel --test-verilog\n</code></pre> <p>We have also included a simulator for just the vvadd accelerator in isolation which can be used to evaluate its performance.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut9_xcel/vvadd-xcel-sim --impl rtl --input multiple --stats\n  num_cycles = 1058\n</code></pre> <p>We could use the simulator to help evaluate the cycle-level performance of the accelerator on various different datasets as we try out various optimizations.</p>"},{"location":"ece6745-tut09-xcel-rtl/#4-testing-and-evaluating-tinyrv2-microbenchmarks-with-accelerators","title":"4. Testing and Evaluating TinyRV2 Microbenchmarks with Accelerators","text":"<p>Now that we have unit tested and evaluated both the baseline TinyRV2 pipelined processor and the vvadd accelerator in isolation, we are finally ready to compose them. We will start by looking at a basic null accelerator to understand how we will integrate processors and accelerators before looking at the vvadd accelerator in the next section.</p>"},{"location":"ece6745-tut09-xcel-rtl/#41-integrating-the-tinyrv2-processor-and-a-null-accelerator","title":"4.1. Integrating the TinyRV2 Processor and a Null Accelerator","text":"<p>The key way the processor interacts with an accelerator is by sending messages that read and write 32 special accelerator registers using the standard CSRW and CSRR instructions. These 32 special CSRs are as follows:</p> <pre><code>  0x7e0 : accelerator register  0 (xr0)\n  0x7e1 : accelerator register  1 (xr1)\n  0x7e2 : accelerator register  2 (xr2)\n  ...\n  0x7ff : accelerator register 31 (xr31)\n</code></pre> <p>When the processor uses a CSRW instruction to write an accelerator register, it first reads the general-purpose register file to get the source value, creates a new accelerator request message, then sends this message to the accelerator through the xcel.req interface in the X stage. The processor waits for the response message to be returned through the xcel.resp interface in the M stage. The processor uses a CSRR instruction to read an accelerator register in a similar way, except that when the response message is returned in the M stage, the data from the accelerator is sent down the pipeline and written into the general-purpose register file in the W stage.</p> <p>Here is a simple assembly sequence which will write the value <code>1</code> to the null accelerator's only accelerator register, read that value back from the accelerator register, and write the value to general-purpose register <code>x2</code>.</p> <pre><code>  addi x1, x0, 1\n  csrw 0x7e0, x1\n  csrr x2, 0x7e0\n</code></pre> <p>You can run a simple test of using the CSRW/CSRR instructions to write/read an accelerator register like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../proc/test/ProcFL_xcel_test.py\n% pytest ../proc/test/Proc_xcel_test.py\n% pytest ../proc/test/Proc_xcel_test.py -k [bypass -s\n\n     src        F-stage   D-stage                 X    M    W    xcelreq         xcelresp    sink\n ------------------------------------------------------------------------------------------------------\n  1r .        &gt;          |                       |    |    |    |              ().           &gt;\n  2r .        &gt;          |                       |    |    |    |              ().           &gt;\n  3: .        &gt;          |                       |    |    |    |              ().           &gt;\n  4: #        &gt;  00000200|                       |    |    |    |              ().           &gt;\n  5: deadbeef &gt;  00000204|csrr   x02, mngr2proc  |    |    |    |              ().           &gt;\n  6: #        &gt;  00000208|nop                    |csrr|    |    |              ().           &gt;\n  7: #        &gt;  0000020c|nop                    |nop |csrr|    |              ().           &gt;\n  8: #        &gt;  00000210|nop                    |nop |nop |csrr|              ().           &gt;\n  9: #        &gt;  00000214|csrw   0x7e0, x02      |nop |nop |nop |              ().           &gt;\n 10: #        &gt;  00000218|csrr   x03,     0x7e0  |csrw|nop |nop |wr:00:deadbeef().           &gt;\n 11: #        &gt;  0000021c|nop                    |csrr|csrw|nop |rd:00:        ()wr:         &gt;\n 12: #        &gt;  00000220|nop                    |nop |csrr|csrw|              ()rd:deadbeef &gt;\n 13: #        &gt;  00000224|nop                    |nop |nop |csrr|              ().           &gt;\n 14: #        &gt;  00000228|csrw   proc2mngr, x03  |nop |nop |nop |              ().           &gt;\n 15: deadbe00 &gt;  0000022c|csrr   x02, mngr2proc  |csrw|nop |nop |              ().           &gt;\n 16: #        &gt;  00000230|nop                    |csrr|csrw|nop |              ().           &gt;\n 17: #        &gt;  00000234|nop                    |nop |csrr|csrw|              ().           &gt; deadbeef\n 18: #        &gt;  00000238|csrw   0x7e0, x02      |nop |nop |csrr|              ().           &gt;\n 19: #        &gt;  0000023c|csrr   x03,     0x7e0  |csrw|nop |nop |wr:00:deadbe00().           &gt;\n 20: #        &gt;  00000240|nop                    |csrr|csrw|nop |rd:00:        ()wr:         &gt;\n 21: #        &gt;  00000244|nop                    |nop |csrr|csrw|              ()rd:deadbe00 &gt;\n 22: #        &gt;  00000248|csrw   proc2mngr, x03  |nop |nop |csrr|              ().           &gt;\n 23: 00adbe00 &gt;  0000024c|csrr   x02, mngr2proc  |csrw|nop |nop |              ().           &gt;\n 24: #        &gt;  00000250|nop                    |csrr|csrw|nop |              ().           &gt;\n 25: #        &gt;  00000254|csrw   0x7e0, x02      |nop |csrr|csrw|              ().           &gt; deadbe00\n 26: #        &gt;  00000258|csrr   x03,     0x7e0  |csrw|nop |csrr|wr:00:00adbe00().           &gt;\n 27: #        &gt;  0000025c|nop                    |csrr|csrw|nop |rd:00:        ()wr:         &gt;\n 28: #        &gt;  00000260|csrw   proc2mngr, x03  |nop |csrr|csrw|              ()rd:00adbe00 &gt;\n 29: dea00eef &gt;  00000264|csrr   x02, mngr2proc  |csrw|nop |csrr|              ().           &gt;\n 30: .        &gt;  00000268|csrw   0x7e0, x02      |csrr|csrw|nop |              ().           &gt;\n 31: .        &gt;  0000026c|csrr   x03,     0x7e0  |csrw|csrr|csrw|wr:00:dea00eef().           &gt; 00adbe00\n 32: .        &gt;  #       |#                      |csrr|csrw|csrr|rd:00:        ()wr:         &gt;\n 33: .        &gt;  00000270|csrw   proc2mngr, x03  |    |csrr|csrw|              ()rd:dea00eef &gt;\n 34: .        &gt;  #       |#                      |csrw|    |csrr|              ().           &gt;\n 35: .        &gt;  #       |#                      |    |csrw|    |              ().           &gt;\n 36: .        &gt;  #       |#                      |    |    |csrw|              ().           &gt; dea00eef\n 37: .        &gt;  #       |#                      |    |    |    |              ().           &gt;\n</code></pre> <p>I have cleaned up the line trace a bit to annotate the columns and make it more compact. You can see the processor executing CSRW/CSRR instructions to 0x7e0 which is accelerator register 0. This results in the processor sending accelerator requests to the null accelerator, and then the accelerator sending the corresponding accelerator responses back to the processor.</p> <p>Also notice the need for the processor to add new RAW dependency stall logic. CSRR instructions which read from accelerator registers send out the xcel.req in the X stage and receive the xcelresp in the M stage. This means we cannot bypass data from a CSRR instruction if it is in the X stage since the data has not returned from the accelerator yet. In cycle 32, the CSRW instruction in the decode stage needs to stall to wait for the CSRR instruction in the X stage to move into the M stage.</p> <p>To use an accelerator from a C microbenchmark, we can use the same GCC inline assembly extensions we used to write the <code>stats_en</code> CSR earlier in the tutorial. Take a closer look at the <code>app/ubmark/ubmark-null-xcel-test.c</code> example:</p> <pre><code> __attribute__ ((noinline))\n int ubmark_null_xcel( int in )\n {\n   int result;\n   __asm__ (\n     \"csrw 0x7E0,     %[in];\\n\"\n     \"csrr %[result], 0x7E0;\\n\"\n\n     // Outputs from the inline assembly block\n\n     : [result] \"=r\"(result)\n\n     // Inputs to the inline assembly block\n\n     : [in] \"r\"(in)\n\n   );\n   return result;\n }\n</code></pre> <p>We are inserting a CSRW instruction to copy the value passed to this function through the <code>in</code> argument, and then we are using an CSRR instruction to retrieve the same value from the null accelerator. Notice that unlike the inline assembly we used when setting the <code>stats_en</code> CSR, here we also need to handle outputs from the assembly block. Again, you can find out more about inline assembly syntax here:</p> <ul> <li>https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html</li> </ul> <p>Let's cross-compile this microbenchmark. Note that you cannot natively compile a microbenchmark that makes use of an accelerator, since x86 does not have any accelerators!</p> <pre><code>% cd $TOPDIR/app/build\n% make ubmark-null-xcel-test\n% riscv32-objdump ubmark-null-xcel-test | less -p\"&lt;ubmark_null_xcel&gt;:\"\n000002fc &lt;ubmark_null_xcel&gt;:\n    2fc:  csrw 0x7e0,x10\n    300:  csrr x10,0x7e0\n    304:  jalr x0,x1,0\n</code></pre> <p>Always a good idea to use <code>riscv32-objdump</code> so you can verify your C code is compiling as expected. Here we can see that the <code>null_xcel</code> function compiles into a CSRW, CSRR, and JALR instruction as expected. We should now run this microbenchmark on our ISA simulator to verify it works, and then we can run it on our RTL simulator.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../pmx/pmx-sim ../../app/build/ubmark-null-xcel\n% ../pmx/pmx-sim --proc-impl rtl --cache-impl rtl --xcel-impl null-rtl \\\n     --trace ../../app/build/ubmark-null-xcel\n</code></pre>"},{"location":"ece6745-tut09-xcel-rtl/#42-tinyrv2-vvadd-xcel-test","title":"4.2. TinyRV2 VVADD Xcel Test","text":"<p>Let's turn out attention to our vvadd accelerator. Take a closer look at the accelerated version of the vvadd microbenchmark in <code>app/ubmark/ubmark-vvadd-xcel.c</code>:</p> <pre><code> __attribute__ ((noinline))\n void vvadd_xcel( int *dest, int *src0, int *src1, int size )\n {\n   asm volatile (\n     \"csrw 0x7E1, %[src0];\\n\"\n     \"csrw 0x7E2, %[src1];\\n\"\n     \"csrw 0x7E3, %[dest];\\n\"\n     \"csrw 0x7E4, %[size];\\n\"\n     \"csrw 0x7E0, x0     ;\\n\"\n     \"csrr x0,    0x7E0  ;\\n\"\n\n     // Outputs from the inline assembly block\n\n     :\n\n     // Inputs to the inline assembly block\n\n     : [src0] \"r\"(src0),\n       [src1] \"r\"(src1),\n       [dest] \"r\"(dest),\n       [size] \"r\"(size)\n\n     // Tell the compiler this accelerator read/writes memory\n\n     : \"memory\"\n   );\n }\n</code></pre> <p>Notice that our use of the CSRW/CSRR instructions corresponds exactly to the accelerator protocol described above. We first write the source base pointers, the destination base pointer, and the size before starting the accelerator by writing to <code>xr0</code> and then waiting for the accelerator to finish by reading <code>xr0</code>. We need a final <code>\"memory\"</code> argument in our inline assembly block to tell the compiler that this accelerator reads and writes memory. Let's cross-compile the test for the vvadd microbenchmark:</p> <pre><code>% cd $TOPDIR/app/build\n% make ubmark-vvadd-xcel-test\n% riscv32-objdump ubmark-vvadd-xcel-test | less -p\"&lt;ubmark_vvadd_xcel&gt;:\"\n00000fac &lt;ubmark_vvadd_xcel&gt;:\n    fac:  csrw 0x7e1, x11\n    fb0:  csrw 0x7e2, x12\n    fb4:  csrw 0x7e3, x10\n    fb8:  csrw 0x7e4, x13\n    fbc:  csrw 0x7e0, x0\n    fc0:  csrr x0, 0x7e0\n    fc4:  jalr x0, x1, 0\n</code></pre> <p>Everything looks as expected, so we can now test our accelerated vvadd microbenchmark on the ISA simulator.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --xcel-impl vvadd-fl ./ubmark-vvadd-xcel-test\n</code></pre> <p>Notice that we needed to specify the accelerator implementation as a command line option. If we forgot to include this option, then the simulator would use the null accelerator and clearly the accelerated vvadd microbenchmark does not work with the null accelerator!</p> <p>Finally, we can run the test on the RTL implementation of the processor and accelerator.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --xcel-impl vvadd-rtl \\\n    ./ubmark-vvadd-xcel-test\n</code></pre> <p>All of the tests should pass.</p>"},{"location":"ece6745-tut09-xcel-rtl/#43-tinyrv2-vvadd-xcel-eval","title":"4.3. TinyRV2 VVADD Xcel Eval","text":"<p>We are now ready to run the microbenchmark eval. We first make sure it works on the FL simulator.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --xcel-impl vvadd-fl ./ubmark-vvadd-xcel-eval\n</code></pre> <p>Finally, we can run the accelerated vvadd microbenchmark on the RTL implementation of the processor augmented with the RTL implementation of the vvadd accelerator:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --xcel-impl vvadd-rtl \\\n     --stats ./ubmark-vvadd-xcel-eval\n **PASSED**\n\n num_cycles        = 818\n num_inst          = 15\n CPI               = 54.53\n</code></pre> <p>The CPI is so large because there are only a few CSR instructions. All of the work is done by the vvadd accelerator. Recall that the pure-software vvadd microbenchmark required 1013 cycles. So our accelerator results in a cycle-level speedup of 1.23x. We might ask, where did this speedup come from? Why isn't the speedup larger? Let's look at the line trace.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --xcel-impl vvadd-rtl \\\n     --trace ./ubmark-vvadd-xcel-eval &gt; ubmark-vvadd-xcel-eval-rtl.trace\n</code></pre> <p>Here is what the line trace looks like for the initial configuration of the accelerator and the first two iterations of the vvadd loop:</p> <pre><code>cyc   F-stage  D-stage                 X    M    W    xcelreq        ST xcelresp    imem  dmem  xmem\n-----------------------------------------------------------------------------------------------------\n186:  000006ec|csrw   stats_en , x15  |addi|addi|    |              (X ).           rd&gt;rd|     |\n187:  000006f0|lui    x12, 0x00001    |csrw|addi|addi|              (X ).           rd&gt;rd|     |\n188:  000006f4|lw     x13, 0x800(x03) |lui |csrw|addi|              (X ).           rd&gt;rd|     |\n189:  000006f8|addi   x09, x12, 0xbc0 |lw  |lui |csrw|              (X ).           rd&gt;rd|rd&gt;  |\n190: *000006fc|addi   x11, x09, 0x190 |addi|lw  |lui |              (X ).           rd&gt;rd|  &gt;rd|\n191: *00000700|addi   x12, x12, 0xbc0 |addi|addi|lw  |              (X ).           rd&gt;rd|     |\n192: */       |jal    x01, 0x1ffbfc   |addi|addi|addi|              (X ).           rd&gt;rd|     |\n193: *000002fc|                       |jal |addi|addi|              (X ).           rd&gt;rd|     |\n194: *00000300|csrw   0x7e1, x11      |    |jal |addi|              (X ).           rd&gt;rd|     |\n195: *00000304|csrw   0x7e2, x12      |csrw|    |jal |wr:01:00000d50(X ).           rd&gt;rd|     |\n196: *00000308|csrw   0x7e3, x10      |csrw|csrw|    |wr:02:00000bc0(X )wr:         rd&gt;rd|     |\n197: *0000030c|csrw   0x7e4, x13      |csrw|csrw|csrw|wr:03:000010c4(X )wr:         rd&gt;rd|     |\n198: *00000310|csrw   0x7e0, x00      |csrw|csrw|csrw|wr:04:00000064(X )wr:         rd&gt;rd|     |\n199: *00000314|csrr   x00,     0x7e0  |csrw|csrw|csrw|wr:00:00000000(X )wr:         rd&gt;rd|     |\n200: *00000318|jalr   x00, x01, 0x000 |csrr|csrw|csrw|rd:00:        (X )wr:         rd&gt;rd|     |\n201: *#       |#                      |#   |#   |csrw|.             (RD).                |     |rd&gt;\n202: *#       |#                      |#   |#   |    |.             (RD).                |     |rd&gt;rd\n203: *#       |#                      |#   |#   |    |.             (RD).                |     |  &gt;rd\n204: *#       |#                      |#   |#   |    |.             (RD).                |     |\n205: *#       |#                      |#   |#   |    |.             (+ ).                |     |\n206: *#       |#                      |#   |#   |    |.             (WR).                |     |wr&gt;\n207: *#       |#                      |#   |#   |    |.             (W ).                |     |  &gt;wr\n208: *#       |#                      |#   |#   |    |.             (W ).                |     |\n209: *#       |#                      |#   |#   |    |.             (RD).                |     |rd&gt;\n210: *#       |#                      |#   |#   |    |.             (RD).                |     |rd&gt;rd\n211: *#       |#                      |#   |#   |    |.             (RD).                |     |  &gt;rd\n212: *#       |#                      |#   |#   |    |.             (RD).                |     |\n213: *#       |#                      |#   |#   |    |.             (+ ).                |     |\n214: *#       |#                      |#   |#   |    |.             (WR).                |     |wr&gt;\n215: *#       |#                      |#   |#   |    |.             (W ).                |     |  &gt;wr\n216: *#       |#                      |#   |#   |    |.             (W ).                |     |\n217: *#       |#                      |#   |#   |    |.             (RD).                |     |rd&gt;\n218: *#       |#                      |#   |#   |    |.             (RD).                |     |rd&gt;rd\n219: *#       |#                      |#   |#   |    |.             (RD).                |     |  &gt;rd\n220: *#       |#                      |#   |#   |    |.             (RD).                |     |\n</code></pre> <p>I have cleaned up the line trace a bit to annotate the columns and make it more compact. The ST column is the current state of the vvadd accelerator FSM. You can see the processor executing the CSRW instructions to configure the accelerator, and these instructions then turn into messages over the xcel.req interface. The accelerator is in the XCFG state receiving these messages until it receives the write to <code>xr0</code> which causes the accelerator to move into the RD stage. The accelerator sends memory read requests into the memory system, then does the vvadd, then writes the result back to the memory system. We know that every iteration should look like the first iteration (8 cycles). Since there are 100 iterations, this means the total number of cycles should be about 800 cycles, but our simulator reported 818 cycles. Again, the discrepancy is due to the extra cycles required to call and return from the <code>ubmark_vvadd_xcel</code> function. So the accelerator is a little faster than the processor since it requires fewer cycles per iteration.</p> <p>There is certainly room for improvement. We can probably remove some of the bubbles and improve the accelerator performance by a couple more cycles. The accelerator could also potentially use wide accesses to the data cache to retrieve four words at a time and then process all four words in parallel. The accelerator could also potentially achieve better performance by issuing multiple memory requests to a non-blocking cache. Eventually we should be able to optimize such an accelerator so that it is memory bandwidth limited (i.e., we are doing a memory request every cycle).</p>"},{"location":"ece6745-tut10-sram/","title":"ECE 6745 Tutorial 10: SRAM Generators","text":"<p>Small memories can be easily synthesized using flip-flop or latch standard cells, but synthesizing large memories can significantly impact the area, energy, and timing of the overall design. ASIC designers often use SRAM generators to \"generate\" arrays of memory bitcells and the corresponding peripheral circuitry (e.g., address decoders, bitline drivers, sense amps) which are combined into what is called an \"SRAM macro\". These SRAM generators are parameterized to enable generating a wide range of SRAM macros with different numbers of rows, columns, and column muxes, as well as optional support for partial writes, built-in self-test, and error correction. Similar to a standard-cell library, an SRAM generator must generate not just layout but also all of the necessary views to capture logical functionality, timing, geometry, and power usage. These views can then by used by the ASIC tools to produce a complete design which includes a mix of both standard cells and SRAM macros.</p> <p>The tutorial will first describe how to use the open-source OpenRAM memory generator to generate various views of an SRAM macro. You will then see how to use an SRAM in an RTL model, how to generate the corresponding SRAM macro, and then how to push a design which uses an SRAM macro through the manual ASIC flow. Finally, you will see how to use pyhflow to automate this process. This tutorial assumes you have already completed the tutorials on Linux, Git, PyMTL, Verilog, ASIC front-end flow, ASIC back-end flow, and ASIC automated ASIC flow.</p> <p>The first step is to access <code>ecelinux</code>. Use VS Code to log into a specific <code>ecelinux</code> server and then use Microsoft Remote Desktop to log into the same server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut10-sram tut10\n% cd tut10\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut10-sram/#1-openram-memory-generator","title":"1. OpenRAM Memory Generator","text":"<p>Just as with standard-cell libraries, acquiring real SRAM generators is a complex and potentially expensive process. It requires gaining access to a specific fabrication technology, negotiating with a company which makes the SRAM generator, and usually signing multiple non-disclosure agreements. The OpenRAM memory generator is based on the same \"fake\" 45nm technology that we are using for the Nangate standard-cell library. The \"fake\" technology is representative enough to provide reasonable area, energy, and timing estimates for our purposes. In this section, we will take a look at how to use the OpenRAM memory generator to generate various views of an SRAM macro.</p> <p>An SRAM generator takes as input a configuration file which specifies the various parameters for the desired SRAM macro. Let's go ahead and create such a configuration file for a small SRAM. For this section of the tutorial, we will work in the <code>openram</code> subdirectory. The name of the configuration file should be <code>SRAM_32x128_1rw_cfg.py</code>.</p> <pre><code>% mkdir -p $TOPDIR/openram\n% code SRAM_32x128_1rw_cfg.py\n</code></pre> <p>The configuration file should look like this:</p> <pre><code>use_conda       = False\n\nnum_rw_ports    = 1\nnum_r_ports     = 0\nnum_w_ports     = 0\n\nword_size       = 32\nnum_words       = 128\nnum_banks       = 1\nwords_per_row   = 4\nwrite_size      = 8\n\ntech_name       = \"freepdk45\"\nprocess_corners = [\"TT\"]\nsupply_voltages = [1.1]\ntemperatures    = [25]\n\nroute_supplies  = True\ncheck_lvsdrc    = False\n\noutput_path     = \"SRAM_32x128_1rw\"\noutput_name     = \"SRAM_32x128_1rw\"\ninstance_name   = \"SRAM_32x128_1rw\"\n</code></pre> <p>In this example, we are generating a single-ported SRAM which has 128 rows and 32 bits per row for a total capacity of 4096 bits or 512B. This size is probably near the cross-over point where you might transition from using synthesized memories to SRAM macros. OpenRAM will take this configuration file as input and generate many different views of the SRAM macro including: schematics (<code>.sp</code>), layout (<code>.gds</code>), a Verilog behavioral model (<code>.v</code>), abstract logical, timing, power view (<code>.lib</code>), and a physical view (<code>.lef</code>). These views can then be used by the ASIC tools.</p> <p>You can use the following command to run the OpenRAM memory generator.</p> <pre><code>% cd -p $TOPDIR/openram\n% openram -v -v SRAM_32x128_1rw_cfg.py\n</code></pre> <p>It will take about 4-5 minutes to generate the SRAM macro. You can see the resulting views here:</p> <pre><code>% cd $TOPDIR/openram/SRAM_32x128_1rw\n% ls -1\nSRAM_32x128_1rw.v\nSRAM_32x128_1rw.sp\nSRAM_32x128_1rw.gds\nSRAM_32x128_1rw.lef\nSRAM_32x128_1rw_TT_1p1V_25C.lib\nSRAM_32x128_1rw.html\n</code></pre> <p>You can find more information about the OpenRAM memory generator on the project's webpage here:</p> <ul> <li>https://openram.org</li> </ul> <p>Or in this research paper:</p> <ul> <li>M. Guthaus et. al, \"OpenRAM: An Open-Source Memory Compiler\", Int'l    Conf. on Computer-Aided Design (ICCAD), Nov. 2016.    (https://doi.org/10.1145/2966986.2980098)</li> </ul> <p>The following excerpt from the paper illustrates the microarchitecture used in the single-port SRAM macro in the original OpenRAM implementation.</p> <p></p> <p>The functionality of the pins are as follows:</p> <ul> <li><code>clk</code>: clock</li> <li><code>WEb</code>: write enable (active low)</li> <li><code>OEb</code>: output enable (active low)</li> <li><code>CSb</code>: whole SRAM enable (active low)</li> <li><code>ADDR</code>: address</li> <li><code>DATA</code>: read/write data</li> </ul> <p>Notice that there is a single address, and a single read/write data bus. In the new version of OpenRAM that we are currently using, this has been changed to use a separate read data and write data bus. However, this SRAM macro still only supports executing a single transaction at a time. The new version of OpenRAM has also removed the output enable control signal. The diagram shows a bank select which is used when a single SRAM macro is built out of multiple lower-level \"physical banks\" to produce a more efficient layout (by means of reducing the length of bitlines and wordlines, hence improving delay and energy efficiency). To achieve similar results, we instead use a column muxing factor, which allows us to read multiple lines and select the data we want via a MUX, hence also creating a more efficient layout. We will see what the column muxing looks like a little later in the tutorial.</p> <p>The following excerpt from the paper shows the timing diagram for a read and write transaction in the old OpenRAM implementation, which for the most part holds for the most recent version.</p> <p></p> <p>In order to execute any kind of transaction in the SRAM, we need to set the <code>CSb</code> pin low (note that <code>CSb</code> is active low). Let's start by focusing on the read transaction shown on the left. For the read transaction on the left, the <code>WEb</code> pin is set high (note that <code>WEB</code> is active low). The <code>ADDR</code> pins are used to set the row address. Note that this is a row address not a byte address. From the block diagram, we can see that the address first goes into the \"Address MS-Flop\". This is an array of flip-flops which store the address on the rising edge of the clock. After the rising edge, the address is decoded to drive the word lines and enable the desired row. The read data is driven from the bit cell array through the column muxing and into the sense amp array. The <code>OEb</code> pin was used to determine whether the read data should be driven onto the data bus. This can enable multiple SRAM macros to be arranged on a distributed bus with only one SRAM driving that bus on any given cycle. The <code>OEb</code> pin has since been removed in OpenRAM, and its functionality was tied to the <code>CSb</code> pin. Assuming <code>CSb</code> is low, then the read data is driven out the <code>DATA</code> pins. Since we set the address before the edge and the data is valid after the edge, this is a synchronous read SRAM. Compare this to a register file which often provides a combinational read where the address is set and the data is valid sometime later during the same cycle. Most SRAM generators produce synchronous read SRAM macros. For the write transaction on the right, the <code>WEb</code> pin is set low and the <code>DATA</code> pins are driven with the write data.</p> <p>You can look at the behavioral Verilog produced by the OpenRAM memory generator like this:</p> <pre><code>% cd $TOPDIR/openram/SRAM_32x128_1rw\n% less SRAM_32x128_1rw.v\n</code></pre> <p>The Verilog file should look like this:</p> <pre><code>module SRAM_32x128_1rw(\n    clk0,csb0,web0,wmask0,addr0,din0,dout0\n  );\n\n  parameter NUM_WMASKS = 4 ;\n  parameter DATA_WIDTH = 32 ;\n  parameter ADDR_WIDTH = 7 ;\n  parameter RAM_DEPTH = 1 &lt;&lt; ADDR_WIDTH;\n  // FIXME: This delay is arbitrary.\n  parameter DELAY = 3 ;\n  parameter VERBOSE = 0 ; //Set to 0 to only display warnings\n  parameter T_HOLD = 1 ; //Delay to hold dout value after posedge. Value is arbitrary\n\n  input  clk0; // clock\n  input   csb0; // active low chip select\n  input  web0; // active low write control\n  input [ADDR_WIDTH-1:0]  addr0;\n  input [NUM_WMASKS-1:0]   wmask0; // write mask\n  input [DATA_WIDTH-1:0]  din0;\n  output [DATA_WIDTH-1:0] dout0;\n\n  reg [DATA_WIDTH-1:0]    mem [0:RAM_DEPTH-1];\n\n  reg  csb0_reg;\n  reg  web0_reg;\n  reg [NUM_WMASKS-1:0]   wmask0_reg;\n  reg [ADDR_WIDTH-1:0]  addr0_reg;\n  reg [DATA_WIDTH-1:0]  din0_reg;\n  reg [DATA_WIDTH-1:0]  dout0;\n\n  // All inputs are registers\n  always @(posedge clk0)\n  begin\n    csb0_reg &lt;= csb0;\n    web0_reg &lt;= web0;\n    wmask0_reg &lt;= wmask0;\n    addr0_reg &lt;= addr0;\n    din0_reg &lt;= din0;\n    dout0 &lt;= 32'bx;\n    if ( !csb0_reg &amp;&amp; web0_reg &amp;&amp; VERBOSE )\n      $display($time,\" Reading %m addr0=%b dout0=%b\",addr0_reg,mem[addr0_reg]);\n    if ( !csb0_reg &amp;&amp; !web0_reg &amp;&amp; VERBOSE )\n      $display($time,\" Writing %m addr0=%b din0=%b wmask0=%b\",addr0_reg,din0_reg,wmask0_reg);\n  end\n\n  // Memory Write Block Port 0\n  // Write Operation : When web0 = 0, csb0 = 0\n  always @ (negedge clk0)\n  begin : MEM_WRITE0\n    if ( !csb0_reg &amp;&amp; !web0_reg ) begin\n        if (wmask0_reg[0])\n                mem[addr0_reg][7:0] &lt;= din0_reg[7:0];\n        if (wmask0_reg[1])\n                mem[addr0_reg][15:8] &lt;= din0_reg[15:8];\n        if (wmask0_reg[2])\n                mem[addr0_reg][23:16] &lt;= din0_reg[23:16];\n        if (wmask0_reg[3])\n                mem[addr0_reg][31:24] &lt;= din0_reg[31:24];\n    end\n  end\n\n  // Memory Read Block Port 0\n  // Read Operation : When web0 = 1, csb0 = 0\n  always @ (negedge clk0)\n  begin : MEM_READ0\n    if (!csb0_reg &amp;&amp; web0_reg)\n       dout0 &lt;= mem[addr0_reg];\n  end\n\nendmodule\n</code></pre> <p>This is a simple behavior Verilog model which could be used for RTL or gate-level simulation. If you study this behavioral model you should be able to see the timing diagrams it implements, and the slight variations from the original OpenRAM implementation described in the paper. Again, notice that all inputs are registered on the positive edge, and the read operation is modeled using an <code>always @(negedge clk)</code> block to reflect the fact that this SRAM uses a sequential read based on the clock.</p> <p>You can take a look at the generated transistor-level netlist like this:</p> <pre><code>% cd $TOPDIR/openram/SRAM_32x128_1rw\n% less -p \" cell_1rw \" SRAM_32x128_1rw.sp\n</code></pre> <p>The netlist for the bitcell should look like this:</p> <pre><code>.SUBCKT cell_1rw bl br wl vdd gnd\n * Inverter 1\n MM0 Q_bar Q gnd gnd NMOS_VTG W=205.00n L=50n\n MM4 Q_bar Q vdd vdd PMOS_VTG W=90n     L=50n\n\n * Inverter 2\n MM1 Q Q_bar gnd gnd NMOS_VTG W=205.00n L=50n\n MM5 Q Q_bar vdd vdd PMOS_VTG W=90n     L=50n\n\n * Access transistors\n MM3 bl wl Q gnd NMOS_VTG W=135.00n L=50n\n MM2 br wl Q_bar gnd NMOS_VTG W=135.00n L=50n\n.ENDS cell_1rw\n</code></pre> <p>This is showing the netlist for one bitcell in the SRAM. This is a classic 6T SRAM bitcell with two cross-coupled inverters (<code>MM0</code>, <code>MM4</code>, <code>MM1</code>, <code>MM5</code>) and two access transistors (<code>MM2</code>, <code>MM3</code>). Note that the transistors must be carefully sized to ensure correct operation of an SRAM bitcell!</p> <p>Now let's use Klayout look at the actual layout produced by the OpenRAM memory generator.</p> <pre><code>% cd $TOPDIR/openram/SRAM_32x128_1rw\n% klayout -l $ECE6745_STDCELLS/klayout.lyp SRAM_32x128_1rw.gds\n</code></pre> <p>The following figure shows the layout for the SRAM macro. In Klayout, you can show/hide layers by double clicking on them on the right panel. You can show more of the hierarchy by selecting Display &gt; Increment Hierarchy from the menu.</p> <p></p> <p>Use a ruler in Klayout to measure the height and width of the SRAM macro. It should be about 140um wide by 75um tall.</p> <p>On the left we have flops for the row addresses, which are then fed into a decoder. The decoder activates a certain wordline driver, which will then read out the data through the circuitry below (with the column muxing and sense amps shown in more detail in the following image). Also note that in the above image, the circuitry at the bottom are the flops for the read data.</p> <p>Notice how at the bottom of the SRAM, above the data flops, we have circuitry distributed every four rows of the SRAM. This is the column muxing circuitry that we added in our configuration file and mentioned previously. The following figure shows a closer look at this column muxing circuitry and the sense amps.</p> <p></p> <p>The following figure shows the layout for a single SRAM bitcell.</p> <p></p> <p>The word line is routed horizontally on M1 (blue) and the bit lines are routed vertically on M2 (green). It looks like power and ground are routed both vertically and horizontally. See if you can map the layout to the canonical 6T SRAM bitcell transistor-level implementation.</p> <p>Let\u2019s look at snippet of the <code>.lib</code> file for the SRAM macro.</p> <pre><code>% cd $TOPDIR/openram/SRAM_32x128_1rw\n% less SRAM_32x128_1rw_TT_1p1V_25C.lib\n</code></pre> <p>The <code>.lib</code> should look like this:</p> <pre><code> cell (SRAM_32x128_1rw) {\n   ...\n   area : 10711.8116;\n   ...\n   bus (dout0) {\n     bus_type        : data;\n     direction       : output;\n     max_capacitance : 0.0008364000000000001;\n     min_capacitance : 5.2275000000000003e-05;\n     memory_read() {\n       address : addr0;\n     }\n     pin(dout0[31:0]) {\n       timing(){\n         timing_sense : non_unate;\n         related_pin  : \"clk0\";\n         timing_type  : falling_edge;\n         cell_rise(CELL_TABLE) {\n           values(\"0.293, 0.293, 0.294\",\\\n                  \"0.293, 0.293, 0.294\",\\\n                  \"0.293, 0.293, 0.294\");\n         }\n         cell_fall(CELL_TABLE) {\n           values(\"0.293, 0.293, 0.294\",\\\n                  \"0.293, 0.293, 0.294\",\\\n                  \"0.293, 0.293, 0.294\");\n         }\n         rise_transition(CELL_TABLE) {\n           values(\"0.001, 0.001, 0.001\",\\\n                  \"0.001, 0.001, 0.001\",\\\n                  \"0.001, 0.001, 0.001\");\n         }\n         fall_transition(CELL_TABLE) {\n           values(\"0.001, 0.001, 0.001\",\\\n                  \"0.001, 0.001, 0.001\",\\\n                  \"0.001, 0.001, 0.001\");\n         }\n       }\n     }\n   }\n   ...\n }\n</code></pre> <p>As with the standard-cell library, the <code>.lib</code> includes information about the area of the block, the capacitance on all pins, and power of the circuit. By default OpenRAM will use analytical models to estimate this characterization data which is probably why the timing values are not varying too much within a look-up table. OpenRAM can also use SPICE simulations to estimate this characterization data. These simulations will result in the memory compiler taking significantly longer to generate the SRAM macros, but will also result in much more accurate characterization data.</p> <p>The <code>.lef</code> file will mostly contain large rectangular blockages which mean that the ASIC tools should not route any M1, M2, M3 wires over the SRAM (because they would accidentally create short circuits with the M1, M2, M3 wires already in the SRAM macro). The <code>.lef</code> file also identifies where all of the pins are physically located so the ASIC tools can correctly connect to the SRAM macro.</p>"},{"location":"ece6745-tut10-sram/#2-srams-rtl-models","title":"2. SRAMs RTL Models","text":"<p>Now that we understand how an SRAM generator works, let's see how to actually use an SRAM in your RTL models. Our basic SRAMs are located in the <code>sim/sram</code> subdirectory.</p> <pre><code>% cd $TOPDIR/sim/sram\n% ls\n...\nSRAM_generic.v\nSRAM.v\n</code></pre> <p>Take a look the interface of the SRAM in <code>SRAM.v</code>.</p> <pre><code>module sram_SRAM\n#(\n  parameter p_data_nbits  = 32,\n  parameter p_num_entries = 256,\n\n  // Local constants not meant to be set from outside the module\n  parameter c_addr_nbits  = $clog2(p_num_entries),\n  parameter c_data_nbytes = (p_data_nbits+7)/8 // $ceil(p_data_nbits/8)\n)(\n  input  logic                        clk,\n  input  logic                        reset,\n  input  logic                        port0_val,\n  input  logic                        port0_type,\n  input  logic [c_addr_nbits-1:0]     port0_idx,\n  input  logic [(p_data_nbits/8)-1:0] port0_wben,\n  input  logic [p_data_nbits-1:0]     port0_wdata,\n  output logic [p_data_nbits-1:0]     port0_rdata\n);\n</code></pre> <p>The SRAM model is parameterized by the number of words and the bits per word, and has the following pin-level interface:</p> <ul> <li><code>port0_val</code>: port enable</li> <li><code>port0_type</code>: transaction type (0 = read, 1 = write)</li> <li><code>port0_idx</code>: which row to read/write</li> <li><code>port0_wben</code>: write byte enables</li> <li><code>port0_wdata</code>: write data</li> <li><code>port0_rdata</code>: read data</li> </ul> <p>Now look at the implementation of the SRAM. You will see a generate if statement which uses the parameters to either: (1) instantiate an SRAM macro RTL model or (2) instantiate an SRAM generic RTL model. Although you can instantiate an SRAM with any number of words and bits per word, this SRAM will only result in a real SRAM macro if these parameters match one of the existing SRAM macros in the generate statement. If the parameters do not match one of the existing SRAM macros, then the SRAM RTL model will still behave correctly in simulation but will result in synthesizing the memory out of flip-flops. Note that it is critical that the name of any specific SRAM macro matches the exact name generated by OpenRAM.</p>"},{"location":"ece6745-tut10-sram/#21-testing-existing-sram-rtl-models","title":"2.1. Testing Existing SRAM RTL Models","text":"<p>Let's test an SRAM with 256 words and 32 bits per word. You can see the corresponding test case in <code>SRAM_test.py</code>.</p> <pre><code>% cd $TOPDIR/sim/sram/test\n% cat SRAM_test.py\n</code></pre> <p>The test case should look as follows.</p> <pre><code>def test_direct_32x256( cmdline_opts ):\n  run_test_vector_sim( SRAM(32, 256), [ header_str,\n    # val type idx  wben    wdata       rdata\n    [ 1,  1,  0x00, 0b1111, 0x00000000, '?'        ], # write 0x00\n    [ 1,  0,  0x00, 0b1111, 0x00000000, '?'        ], # read  0x00\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0x00000000 ], # check read data\n    [ 1,  1,  0x00, 0b1111, 0xdeadbeef, '?'        ], # write 0x00\n    [ 1,  0,  0x00, 0b1111, 0x00000000, '?'        ], # read  0x00\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0xdeadbeef ], # check read data\n    [ 1,  1,  0x01, 0b1111, 0xcafecafe, '?'        ], # write 0x01\n    [ 1,  0,  0x01, 0b1111, 0x00000000, '?'        ], # read  0x01\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0xcafecafe ], # check read data\n    [ 1,  1,  0x1f, 0b1111, 0x0a0a0a0a, '?'        ], # write 0x1f\n    [ 1,  0,  0x1f, 0b1111, 0x00000000, '?'        ], # read  0x1f\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0x0a0a0a0a ], # check read data\n...\n]```\n\nEach row represents the inputs and expected outputs for that cycle. In\nthe first cycle, we write 0x00000000 to address 0x00. In the second\ncycle, we read address 0x00. In the first cycle, we check to ensure the\nread data is correct. Since the SRAM supports synchronous read, the read\ndata is returned the cycle _after_ we specify the read address! Let's run\nthe tests for this SRAM.\n\n```bash\n% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../sram/test/SRAM_test.py -k test_direct_32x256 -s\n</code></pre> <p>You can run the random test like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../sram/test/SRAM_test.py -k test_random[32-256] -s\n</code></pre>"},{"location":"ece6745-tut10-sram/#22-adding-a-new-sram-rtl-model","title":"2.2. Adding a New SRAM RTL Model","text":"<p>As mentioned above, the SRAM module is parameterized to enable initial design space exploration, but just because we choose a specific SRAM configuration does not mean the files we need to create the corresponding SRAM macro exist yet. Once we have finalized the SRAM size, we need to go through a five step process to ensure we can run OpenRAM and generate the corresponding SRAM macro.</p> <p>Step 1: See if SRAM configuration already exists</p> <p>The first step is to see if your desired SRAM configuration already exists. You can do this by looking at the names of the <code>_cfg.py</code> files in the <code>sim/sram</code> subdirectory.</p> <pre><code>% cd $TOPDIR/sim/sram\n% ls *_cfg.py\nSRAM_128x256_1rw-cfg.py\nSRAM_32x256_1rw-cfg.py\n</code></pre> <p>This means there are two SRAM configurations already available. One SRAM has 256 words each with 128 bits and the other SRAM has 256 words each with 32 bits. If the SRAM configuration you need already exists then you are done and can skip the remaining steps.</p> <p>Step 2: Create SRAM configuration file</p> <p>The next step is to create a new SRAM configuration file. You must use a very specific naming scheme. An SRAM with <code>N</code> words and <code>M</code> bits per word must be named <code>SRAM_MxN_1rw_cfg.py</code>. Go ahead and create a new SRAM configuration file named <code>SRAM_32x128_1rw_cfg.py</code>.</p> <pre><code>% cd $TOPDIR/sim/sram\n% code SRAM_32x128_1rw-cfg.py\n</code></pre> <p>The SRAM configuration file should contain the following contents:</p> <pre><code>use_conda       = False\n\nnum_rw_ports    = 1\nnum_r_ports     = 0\nnum_w_ports     = 0\n\nword_size       = 32\nnum_words       = 128\nnum_banks       = 1\nwords_per_row   = 4\nwrite_size      = 8\n\ntech_name       = \"freepdk45\"\nprocess_corners = [\"TT\"]\nsupply_voltages = [1.1]\ntemperatures    = [25]\n\nroute_supplies  = True\ncheck_lvsdrc    = False\n\noutput_path     = \"SRAM_32x128_1rw\"\noutput_name     = \"SRAM_32x128_1rw\"\ninstance_name   = \"SRAM_32x128_1rw\"\n</code></pre> <p>Step 3: Create an SRAM macro RTL model</p> <p>The next step is to create an SRAM macro RTL model. This new RTL model should have the same name as the configuration file except with <code>.v</code> instead of <code>_cfg.py</code>. You can use the SRAM generic RTL model to implement the SRAM macro RTL model. Go ahead and create an SRAM macro RTL model for the 32x128 configuration.</p> <pre><code>% cd $TOPDIR/sim/sram\n% code SRAM_32x128_1rw.v\n</code></pre> <p>The SRAM macro RTL model should contain the following contents.</p> <pre><code>`ifndef SRAM_32x128_1rw\n`define SRAM_32x128_1rw\n\n`include \"sram/SramGenericVRTL.v\"\n\n`ifndef SYNTHESIS\n\nmodule SRAM_32x128_1rw\n(\n  input  logic        clk0,\n  input  logic        web0,\n  input  logic        csb0,\n  input  logic [3:0]  wmask0,\n  input  logic [6:0]  addr0,\n  input  logic [31:0] din0,\n  output logic [31:0] dout0\n);\n\n  sram_SRAM_generic\n  #(\n    .p_data_nbits  (32),\n    .p_num_entries (128)\n  )\n  sram_generic\n  (\n    .clk0   (clk0),\n    .web0   (web0),\n    .csb0   (csb0),\n    .wmask0 (wmask0),\n    .addr0  (addr0),\n    .din0   (din0),\n    .dout0  (dout0)\n  );\n\nendmodule\n\n`endif /* SYNTHESIS */\n\n`endif /* SRAM_32x128_1rw */\n</code></pre> <p>Notice how this is simply a wrapper around <code>sram_SRAM_generic</code> instantiated with the desired number of words and bits per word.</p> <p>Step 4: Use new SRAM macro RTL model in top-level SRAM model</p> <p>The final step is to modify the top-level SRAM model to select the proper SRAM macro RTL model. You will need to modify <code>SRAM.v</code>.</p> <pre><code>% cd $TOPDIR/sim/sram\n% code SRAM.v\n</code></pre> <p>You need to add a new condition to the generate if statement as follows.</p> <pre><code>// Add this at the top of the file\n`include \"sram/SRAM_32x128_1rw.v\"\n\n...\n\n  generate\n    if      ( p_data_nbits == 32  &amp;&amp; p_num_entries == 256 ) SRAM_32x256_1rw  sram (.*);\n    else if ( p_data_nbits == 128 &amp;&amp; p_num_entries == 256 ) SRAM_128x256_1rw sram (.*);\n\n    // Add the following to choose a new SRAM configuration RTL model\n    else if ( p_data_nbits == 32  &amp;&amp; p_num_entries == 128 ) SRAM_32x128_1rw  sram (.*);\n\n    else\n      sram_SRAM_generic#(p_data_nbits,p_num_entries) sram (.*);\n  endgenerate\n</code></pre> <p>One might ask what is the point of going through all of the trouble of creating an SRAM macro RTL model that is for a specific size if we already have a SRAM generic RTL model. The key reason is that the ASIC flow will use the name of the SRAM to figure out where to swap in the SRAM macro. So we need a explicit module name for every different SRAM configuration to enable using SRAM macros in the ASIC flow.</p> <p>Step 5: Test new SRAM configuration</p> <p>The final step is to test the new configuration and verify everything works. We start by adding a simple directed test to the <code>SRAM_test.py</code> test script. Here is an example:</p> <pre><code>def test_direct_32x128( cmdline_opts ):\n  run_test_vector_sim( SRAM(32, 128), [ header_str,\n    # val type idx  wben    wdata       rdata\n    [ 1,  1,  0x00, 0b1111, 0x00000000, '?'        ], # one at a time\n    [ 1,  0,  0x00, 0b1111, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0x00000000 ],\n    [ 1,  1,  0x00, 0b1111, 0xdeadbeef, '?'        ],\n    [ 1,  0,  0x00, 0b1111, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0xdeadbeef ],\n    [ 1,  1,  0x01, 0b1111, 0xcafecafe, '?'        ],\n    [ 1,  0,  0x01, 0b1111, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0xcafecafe ],\n    [ 1,  1,  0x1f, 0b1111, 0x0a0a0a0a, '?'        ],\n    [ 1,  0,  0x1f, 0b1111, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0x0a0a0a0a ],\n\n    [ 1,  1,  0x1e, 0b1111, 0x0b0b0b0b, '?'        ], # streaming reads\n    [ 1,  0,  0x1e, 0b1111, 0x00000000, '?'        ],\n    [ 1,  0,  0x1f, 0b1111, 0x00000000, 0x0b0b0b0b ],\n    [ 1,  0,  0x01, 0b1111, 0x00000000, 0x0a0a0a0a ],\n    [ 1,  0,  0x00, 0b1111, 0x00000000, 0xcafecafe ],\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0xdeadbeef ],\n\n    [ 1,  1,  0x1d, 0b1111, 0x0c0c0c0c, '?'        ], # streaming writes/reads\n    [ 1,  0,  0x1d, 0b1111, 0x00000000, '?'        ],\n    [ 1,  1,  0x1c, 0b1111, 0x0d0d0d0d, 0x0c0c0c0c ],\n    [ 1,  0,  0x1c, 0b1111, 0x00000000, '?'        ],\n    [ 1,  1,  0x1b, 0b1111, 0x0e0e0e0e, 0x0d0d0d0d ],\n    [ 1,  0,  0x1b, 0b1111, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0x0e0e0e0e ],\n\n    [ 1,  1,  0x00, 0b1111, 0x00000000, '?'        ], # partial writes\n    [ 1,  1,  0x01, 0b1111, 0x00000000, '?'        ],\n    [ 1,  1,  0x0f, 0b1111, 0x00000000, '?'        ],\n    [ 1,  1,  0x00, 0b0001, 0xdeadbeef, '?'        ],\n    [ 1,  0,  0x00, 0b0000, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b0000, 0x00000000, 0x000000ef ],\n    [ 1,  1,  0x01, 0b0100, 0xcafecafe, '?'        ],\n    [ 1,  0,  0x01, 0b0000, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b0000, 0x00000000, 0x00fe0000 ],\n    [ 1,  1,  0x0f, 0b0000, 0x0a0a0a0a, '?'        ],\n    [ 1,  0,  0x0f, 0b0000, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b0000, 0x00000000, 0x00000000 ],\n  ], cmdline_opts )\n</code></pre> <p>This directed test writes a value to a specific word and then reads that word to verify the value was written correctly. We test writing the first word, the last word, and other words. We also test using the write byte enables for partial writes. We can run the directed test like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../sram/test/SRAM_test.py -k test_direct_32x128\n</code></pre> <p>We have included a helper function that simplifies random testing. All you need to do is add the configuration to the <code>sram_configs</code> variable in the test script like this:</p> <pre><code>sram_configs = [ (16, 32), (32, 256), (128, 256), (32, 128) ]\n</code></pre> <p>Then you can run the random test like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../sram/test/SRAM_test.py -k test_random[32-128]\n</code></pre> <p>And of course we should run all of the tests to ensure we haven't broken anything when adding this new configuration.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../sram\n</code></pre>"},{"location":"ece6745-tut10-sram/#3-sram-minion-wrapper-rtl","title":"3. SRAM Minion Wrapper RTL","text":"<p>SRAMs use a latency sensitive interface meaning a user must carefully manage the timing for correct operation (i.e., set the read address and then exactly one cycle later use the read data). In addition, the SRAM cannot be \"stalled\". To illustrate how to use SRAM macros, we will create a latency insensitive val/rdy wrapper around an SRAM which enables writing and reading the SRAM using our standard memory messages. The following figure illustrates a naive approach to implementing the SRAM val/rdy wrapper.</p> <p></p> <p>Consider what might happen if we use a single-element bypass queue. The following pipeline diagram illustrates what can go wrong.</p> <pre><code> cycle : 0  1  2  3  4  5  6  7  8\n msg a : M0 Mx\n msg b :    M0 Mx\n msg c :       M0 M1 M2 M2 M2       # M2 stalls on cycles 3-5\n msg d :          M0 M1 M1 M1 M2    # but wait, we cannot stall in M1!\n msg e :             M0 M0 M0 M0 Mx\n\n cycle M0 M1 [q] M2\n    0: a\n    1: b  a      a  # a flows through bypass queue\n    2: c  b      b  # b flows through bypass queue\n    3: d  c         # M2 is stalled, c will need to go into bypq\n    4: e  d   c     # q is full at beginning of cycle, enq_rdy = 0\n    5: e  ?   c     # what happens to d? cannot stall in M1!\n</code></pre> <p>Here we are using Mx to indicate when a transaction goes through M1 and M2 in the same cycle because it flows straight through the bypass queue. So on cycle 3, the response interface is stalled and as a consequence message c must be enqueued into the memory response queue. On cycle 4, the response queue is full (<code>enq_rdy</code> = 0) so <code>memreq_rdy</code> = 0 and message e will stall in M0 (i.e., will stall waiting to be accepted by the SRAM wrapper). The critical question is what happens to message d? It cannot stall in M1 because we cannot stall the SRAM. So basically we just drop it. Increasing the amount of the buffering in the bypass queue will not solve the problem. The key issue is that by the time we realize the bypass queue is full we can potentially already have a transaction executing in the SRAM, and this transaction cannot be stalled.</p> <p>This is a classic situation where the need more skid buffering. A correct solution will have two or more elements of buffering in the memory response queue and stall M0 if there are less than two free elements in the queue. Thus in the worst case, if M2 stalls we have room for two messages in the response queue: the message currently in M1 and the message currently in M0. Here is the updated design:</p> <p></p> <p>Here is the updated pipeline diagram.</p> <pre><code> cycle : 0  1  2  3  4  5  6  7  8\n msg a : M0 Mx\n msg b :    M0 Mx\n msg c :       M0 M1 M2 M2 M2\n msg d :          M0 M1 q  q  M2     # msg c is in skid buffer\n msg e :             M0 M0 M0 M0 Mx\n\n cycle M0 M1 [q ] M2\n    0: a\n    1: b  a       a  # a flows through bypass queue\n    2: c  b       b  # b flows through bypass queue\n    3: d  c          # M2 is stalled, c will need to go into bypq\n    4: e  d    c     #\n    5: e      dc     # d skids behind c into the bypq\n    6: e       d  c  # c is dequeued from bypq\n    7: e          d  # d is dequeued from bypq\n    8:    e       e  # e flows through bypass queue\n</code></pre> <p>Note, with a pipe queue you still need two elements of buffering. There could be a message in the response queue when M2 stalls and then you still don't have anywhere to put the message currently in M1.</p> <p>Take a closer look at the SRAM val/rdy wrapper we provide you.</p> <pre><code>% cd $TOPDIR/sim/tut8_sram\n% code SRAMMinion.v\n</code></pre> <p>Notice how we are instantiating the SRAM within the SRAM val/rdy wrapper. We are using an SRAM corresponding to the newly created SRAM macro configuration/RTL from the previous section.</p> <pre><code>`include \"sram/SRAM.v\"\n...\nsram_SRAM#(32,128) sram\n (\n   .clk         (clk),\n   .reset       (reset),\n   .port0_idx   (sram_addr_M0),\n   .port0_type  (sram_wen_M0),\n   .port0_val   (sram_en_M0),\n   .port0_wben  (sram_wben_M0),\n   .port0_wdata (memreq_msg_data_M0),\n   .port0_rdata (sram_read_data_M1)\n );\n</code></pre> <p>To use an SRAM, simply import <code>sram/SRAM.v</code>, instantiate the SRAM, and set the number of words and number of bits per word. We can run a test on the SRAM val/rdy wrapper like this:</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut10_sram/test/SRAMMinion_test.py -k random_0_3 -s\n</code></pre> <p>The trace output should look like this:</p> <pre><code> ...\n  3:                           &gt; (  (). ) &gt; .\n  4: wr:00:00000000:0:55fceed9 &gt; (wr(). ) &gt; .\n  5: wr:01:00000004:0:5bec8a7b &gt; (wr()# ) &gt; #\n  6: #                         &gt; (# ()# ) &gt; #\n  7: #                         &gt; (# ()wr) &gt; wr:00:0:0:\n  8: #                         &gt; (# ()# ) &gt; #\n  9: #                         &gt; (# ()# ) &gt; #\n 10: #                         &gt; (# ()# ) &gt; #\n 11: #                         &gt; (# ()wr) &gt; wr:01:0:0:\n 12: wr:02:00000008:0:b1aa20f1 &gt; (wr(). ) &gt; .\n 13: wr:03:0000000c:0:a5b6b6bb &gt; (wr()# ) &gt; #\n 14: #                         &gt; (# ()# ) &gt; #\n 15: #                         &gt; (# ()wr) &gt; wr:02:0:0:\n 16: #                         &gt; (# ()# ) &gt; #\n 17: #                         &gt; (# ()# ) &gt; #\n 18: #                         &gt; (# ()# ) &gt; #\n 19: #                         &gt; (# ()wr) &gt; wr:03:0:0:\n</code></pre> <p>The first write transaction takes a single cycle to go through the SRAM val/rdy wrapper (and is held up in the SRAM), but the SRAM response interface is not ready on cycles 5-6. The second write transaction is still accepted by the SRAM val/rdy wrapper and will end up in the bypass queue, but the third write transaction is stalled because the request interface is not ready. No transactions are lost.</p> <p>Let's now rerun the tests and run the interactive simulator to create the Verilog test benches which we can use for four-state RTL, fast-functional gate-level, and back-annotated gate-level simulation.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut10_sram/test/SRAMMinion_test.py --test-verilog --dump-vtb\n% ../tut10_sram/sram-sim --impl rtl --input random --translate --dump-vtb\n% ls\n...\nSRAMMinion_noparam__pickled.v\n</code></pre> <p>As you can see, the simulator will generate a Verilog file <code>SRAMMinion_noparam__pickled.v</code> which is what we use with the ASIC tools.</p>"},{"location":"ece6745-tut10-sram/#4-asic-front-end-flow-with-sram-macros","title":"4. ASIC Front-End Flow with SRAM Macros","text":"<p>Now we will push our SRAM minion wrapper through the ASIC front-end flow. In this section, we will go through the steps manually. Later in the tutorial we will use the ASIC automated flow.</p>"},{"location":"ece6745-tut10-sram/#41-sram-generation","title":"4.1. SRAM Generation","text":"<p>The first step is to run the OpenRAM memory generator to generate the SRAM macro corresponding to the desired 32x128 configuration.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut10-sram/00-openram-memgen\n% cd $TOPDIR/asic/build-tut10-sram/00-openram-memgen\n% openram -v -v ../../../sim/sram/SRAM_32x128_1rw_cfg.py\n% cd SRAM_32x128_1rw\n% cp SRAM_32x128_1rw_TT_1p1V_25C.lib ../SRAM_32x128_1rw.lib\n% cp *.gds *.lef *.v ..\n</code></pre> <p>We need to convert the <code>.lib</code> file into a <code>.db</code> file using the Synopsys Library Compiler (LC) tool.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram/00-openram-memgen\n% lc_shell\nlc_shell&gt; read_lib SRAM_32x128_1rw.lib\nlc_shell&gt; write_lib SRAM_32x128_1rw_TT_1p1V_25C_lib \\\n  -format db -output SRAM_32x128_1rw.db\nlc_shell&gt; exit\n</code></pre> <p>Check that the <code>.db</code> file now exists.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram/00-openram-memgen\n% ls\n...\nSRAM_32x128_1rw.db\n</code></pre>"},{"location":"ece6745-tut10-sram/#42-four-state-rtl-simulation","title":"4.2. Four-State RTL Simulation","text":"<p>We now need to use four-state RTL simulation to further verify our design.</p> <pre><code>% mkdir -p ${TOPDIR}/asic/build-tut10-sram/01-synopsys-vcs-rtlsim\n% cd ${TOPDIR}/asic/build-tut10-sram/01-synopsys-vcs-rtlsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${TOPDIR}/sim/build/SRAMMinion_noparam__pickled.v \\\n    ${TOPDIR}/sim/build/SRAMMinion_noparam_sram-rtl-random_tb.v\n% ./simv\n</code></pre>"},{"location":"ece6745-tut10-sram/#43-synthesis","title":"4.3. Synthesis","text":"<p>Now we can use Synopsys DC to synthesize the logic which goes around the SRAM macro.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut10-sram/02-synopsys-dc-synth\n% cd $TOPDIR/asic/build-tut10-sram/02-synopsys-dc-synth\n% dc_shell-xg-t\ndc_shell&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db ../00-openram-memgen/SRAM_32x128_1rw.db\"\ndc_shell&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db ../00-openram-memgen/SRAM_32x128_1rw.db\"\ndc_shell&gt; analyze -format sverilog ../../../sim/build/SRAMMinion_noparam__pickled.v\ndc_shell&gt; elaborate SRAMMinion_noparam\ndc_shell&gt; create_clock clk -name ideal_clock1 -period 2.0\ndc_shell&gt; compile\ndc_shell&gt; write -format ddc     -hierarchy -output post-synth.ddc\ndc_shell&gt; write -format verilog -hierarchy -output post-synth.v\ndc_shell&gt; write_sdc post-synth.sdc\ndc_shell&gt; report_area   -hierarchy\ndc_shell&gt; report_timing -nets\ndc_shell&gt; exit\n</code></pre> <p>We are basically using the same steps we used in the Synopsys/Cadence ASIC tool tutorial. Notice how we must point Synopsys DC to the <code>.db</code> file generated by OpenRAM so Synopsys DC knows the abstract logical, timing, power view of the SRAM.</p> <p>If you look for the SRAM module in the synthesized gate-level netlist, you will see that it is referenced but not declared. This is what we expect since we are not synthesizing the memory but instead using an SRAM macro.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram/synopsys-dc\n% less -p SRAM post-synth.v\n</code></pre>"},{"location":"ece6745-tut10-sram/#44-fast-functional-gate-level-simulation","title":"4.4. Fast-Functional Gate-Level Simulation","text":"<p>We can use fast-functional gate-level simulation to simulate the gate-level netlist integrated with the Verilog RTL models for the SRAMs.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram/03-synopsys-vcs-ffglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +delay_mode_zero \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../00-openram-memgen/SRAM_32x128_1rw.v \\\n    ../02-synopsys-dc-synth/post-synth.v \\\n    ${TOPDIR}/sim/build/SRAMMinion_noparam_sram-rtl-random_tb.v\n% ./simv\n</code></pre> <p>Notice how we now need to provide the Verilog behavioral model for the SRAM which will be simulated along with the gate-level implementation.</p>"},{"location":"ece6745-tut10-sram/#5-asic-back-end-flow-with-sram-macros","title":"5. ASIC Back-End Flow with SRAM Macros","text":"<p>Now we will push our SRAM minion wrapper through the ASIC back-end flow. In this section, we will go through the steps manually. Later in the tutorial we will use the ASIC automated flow.</p>"},{"location":"ece6745-tut10-sram/#51-place-and-route","title":"5.1. Place and Route","text":"<p>We use Cadence Innovus for placing and routing both the standard cells and the SRAM macros. As in the ASIC back-end flow tutorial, we need to create a file to setup the timing analysis.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut10-sram/04-cadence-innovus-pnr\n% cd $TOPDIR/asic/build-tut10-sram/04-cadence-innovus-pnr\n% code setup-timing.tcl\n</code></pre> <p>The file should have the following content:</p> <pre><code>create_rc_corner -name typical \\\n   -cap_table \"$env(ECE6745_STDCELLS)/rtk-typical.captable\" \\\n   -T 25\n\ncreate_library_set -name libs_typical \\\n   -timing [list \"$env(ECE6745_STDCELLS)/stdcells.lib\" \\\n                 \"../00-openram-memgen/SRAM_32x128_1rw.lib\"]\n\ncreate_delay_corner -name delay_default \\\n   -library_set libs_typical \\\n   -rc_corner typical\n\ncreate_constraint_mode -name constraints_default \\\n   -sdc_files [list ../02-synopsys-dc-synth/post-synth.sdc]\n\ncreate_analysis_view -name analysis_default \\\n   -constraint_mode constraints_default \\\n   -delay_corner delay_default\n\nset_analysis_view -setup analysis_default -hold  analysis_default\n</code></pre> <p>This is very similar to the <code>setup-timing.tcl</code> file we used in the ASIC back-end flow tutorial, except that we have to include the <code>.lib</code> file generated by OpenRAM.</p> <p>Now let's start Cadence Innovus, load in the design, and complete the power routing just as in the ASIC back-end tutorial.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram/04-cadence-innovus-pnr\n% innovus\n</code></pre> <p>The initial setup is very similar to what we used in the ASIC back-end flow tutorial.</p> <pre><code>innovus&gt; set init_mmmc_file \"setup-timing.tcl\"\ninnovus&gt; set init_verilog   \"../02-synopsys-dc-synth/post-synth.v\"\ninnovus&gt; set init_top_cell  \"SRAMMinion_noparam\"\ninnovus&gt; set init_lef_file  \"$env(ECE6745_STDCELLS)/rtk-tech.lef \\\n                            $env(ECE6745_STDCELLS)/stdcells.lef \\\n                            ../00-openram-memgen/SRAM_32x128_1rw.lef\"\ninnovus&gt; set init_pwr_net   {VDD vdd}\ninnovus&gt; set init_gnd_net   {VSS gnd}\n</code></pre> <p>Two key differences from earlier tutorials are: (1) including the <code>.lef</code> file generated by OpenRAM; and (2) including <code>vdd</code> and <code>gnd</code> which are the names of the power nets used in OpenRAM.</p> <p>We are now ready to use the <code>init_design</code> command to read in the verilog, set the design name, setup the timing analysis views, read the technology <code>.lef</code> for layer information, and read the standard cell <code>.lef</code> for physical information about each cell and the SRAM used in the design.</p> <pre><code>innovus&gt; init_design\n</code></pre> <p>We also need to tell Cadence Innovus some additional setup information just like in the ASIC back-end flow tutorial.</p> <pre><code>innovus&gt; setDesignMode -process 45\ninnovus&gt; setDelayCalMode -SIAware false\ninnovus&gt; setOptMode -usefulSkew false\ninnovus&gt; setOptMode -holdTargetSlack 0.010\ninnovus&gt; setOptMode -holdFixingCells {\n           BUF_X1 BUF_X1 BUF_X2 BUF_X4 BUF_X8 BUF_X16 BUF_X32\n         }\n</code></pre> <p>In the earlier tutorials, we used automatic floorplanning which determines the overall dimensions given a target aspect ratio and placement density. We used a target aspect ratio of 1.0 and a placement density of 70%. Because the SRAM macro has an aspect ratio closer to 2:1 we will will need to use a different floorplan. So instead of using automatic floorplanning, we will use a fixed floorplan which uses a specific width and height.</p> <pre><code>innovus&gt; floorPlan -d 175 175 4.0 4.0 4.0 4.0\n</code></pre> <p>From looking at the <code>.gds</code> file for the SRAM earlier in the tutorial, we know that the SRAM is about 140um wide by 75um tall, so we set the height and width of the floorplan to be 175um.</p> <p></p> <p>The next step is to place the design. We first need to add a \"halo\" around all SRAM macros using the <code>addHaloToBlock</code> command. A halo is a way to tell Cadence Innovus not to place any standard cells too close to the SRAM macros. We specify a halo of 4.8um.</p> <pre><code>innovus&gt; addHaloToBlock 4.8 4.8 4.8 4.8 -allMacro\n</code></pre> <p>Now we need to use extra commands to concurrently place the standard cells and the SRAM macro at the same time. For best results, we would need to create a representative power grid so Cadence Innovus can take into account power distribution when automatically placing SRAM macros, but to simplify our flow we can just specify 20% metal 1 power routing density.</p> <pre><code>innovus&gt; set_macro_place_constraint -pg_resource_model {metal1 0.2}\ninnovus&gt; place_design -concurrent_macros\ninnovus&gt; refine_macro_place\n</code></pre> <p>After these steps the macros will be placed in their final positions, but the standard cells are likely not in legal positions. So we now do the final optimized placement.</p> <pre><code>innovus&gt; place_opt_design\n</code></pre> <p>After placing the design we want to automatically place tie hi/lo cells and the IO pins around the perimeter of the floorplan.</p> <pre><code>innovus&gt; addTieHiLo -cell \"LOGIC1_X1 LOGIC0_X1\"\ninnovus&gt; assignIoPins -pin *\n</code></pre> <p>You should be able to see the SRAM macro placed in the middle of the floorplan with the standard cells implementing the pipeline registers, queue, and control logic positioned above and below the SRAM macro.</p> <p></p> <p>In the following close, up the halo is shown in a salmon color. Some of the standard cells placed above the SRAM macro outside the halo.</p> <p></p> <p>The next step is power routing. We need to connect the power/ground pins of both the standard cells and the SRAM macro to the global power/ground nets. We also need to make sure the tie hi/lo cells are connected to the global power/ground nets.</p> <pre><code>innovus&gt; globalNetConnect VDD -type pgpin -pin VDD -all -verbose\ninnovus&gt; globalNetConnect VSS -type pgpin -pin VSS -all -verbose\ninnovus&gt; globalNetConnect VDD -type pgpin -pin vdd -all -verbose\ninnovus&gt; globalNetConnect VSS -type pgpin -pin gnd -all -verbose\ninnovus&gt; globalNetConnect VDD -type tiehi -pin VDD -all -verbose\ninnovus&gt; globalNetConnect VSS -type tielo -pin VSS -all -verbose\n</code></pre> <p>Just as in the previous tutorials, we then route the M1 power rails for the standard cells, create a power ring, and add horizontal/vertical power stripes to create a power grid.</p> <pre><code>innovus&gt; sroute -nets {VDD VSS}\ninnovus&gt; addRing \\\n           -nets {VDD VSS} -width 0.8 -spacing 0.8 \\\n           -layer [list top 9 bottom 9 left 8 right 8]\ninnovus&gt; addStripe \\\n           -nets {VSS VDD} -layer 9 -direction horizontal \\\n           -width 0.8 -spacing 4.8 \\\n           -set_to_set_distance 11.2 -start_offset 2.4\ninnovus&gt; addStripe \\\n           -nets {VSS VDD} -layer 8 -direction vertical \\\n           -width 0.8 -spacing 4.8 \\\n           -set_to_set_distance 11.2 -start_offset 2.4\n</code></pre> <p></p> <p>In the following close up, we have hidden the halo so we can clearly see how the power routing stops the M1 power rails from going through the SRAM macro. You can also see the horizontal VDD and VSS power stripes have vias that connect to the SRAM macro power/ground pins (i.e., connect to the power ring which is inside the SRAM macro).</p> <p></p> <p>The next step is to route the clock tree and do an initial round of fixing setup-time and hold-time violations.</p> <pre><code>innovus&gt; create_ccopt_clock_tree_spec\ninnovus&gt; set_ccopt_property update_io_latency false\ninnovus&gt; ccopt_design -cts\ninnovus&gt; optDesign -postCTS -setup\ninnovus&gt; optDesign -postCTS -hold\n</code></pre> <p></p> <p>The next step is to route the signals, do a final round of fixing setup-time and hold-time violations, and extract the interconnect RC parasitics.</p> <pre><code>innovus&gt; routeDesign\ninnovus&gt; optDesign -postRoute -setup\ninnovus&gt; optDesign -postRoute -hold\ninnovus&gt; extractRC\n</code></pre> <p>In the following close-up, we can see how Cadence Innovus has routed from the standard-cells to the pins on the SRAM macro, but we can also see how Cadence Innovus has routed some nets over top of the SRAM macro on M5. Cadence Innovus will not route any signals on M1, M2, M3, or M4 over the SRAM macro since the SRAM uses these metal layers for internal routing. Cadence Innovus knows to not use these metal layers by looking at the routing blockages in the SRAM macro's <code>.lef</code> file.</p> <p></p> <p>We can now finish up by adding filler cells and running some physical verification checks.</p> <pre><code>innovus&gt; setFillerMode -core {FILLCELL_X4 FILLCELL_X2 FILLCELL_X1}\ninnovus&gt; addFiller\ninnovus&gt; verifyConnectivity\ninnovus&gt; verify_drc\n</code></pre> <p>As in previous tutorials, we output the design, gate-level netlist, interconnect parasitics, timing delays, and the final layout. Notice how we have to include the <code>.gds</code> file for the SRAM macro so it can be merged into the final <code>.gds</code> file.</p> <pre><code>innovus&gt; saveDesign post-pnr.enc\ninnovus&gt; saveNetlist post-pnr.v\ninnovus&gt; rcOut -rc_corner typical -spef post-pnr.spef\ninnovus&gt; write_sdf post-pnr.sdf\ninnovus&gt; streamOut post-pnr.gds \\\n           -merge \"$env(ECE6745_STDCELLS)/stdcells.gds \\\n                   ../00-openram-memgen/SRAM_32x128_1rw.gds\" \\\n           -mapFile \"$env(ECE6745_STDCELLS)/rtk-stream-out.map\"\n</code></pre> <p>We can generate a timing report for the setup-time constraint.</p> <pre><code>innovus&gt; report_timing -late -path_type full_clock -net\n...\nOther End Arrival Time          0.000\n- External Delay                0.050\n+ Phase Shift                   2.000\n= Required Time                 1.950\n- Arrival Time                  1.582\n= Slack Time                    0.368\n     Clock Fall Edge                      1.000\n     = Beginpoint Arrival Time            1.000\n     +-----------------------------------------------------------------------------------------------------------------------------------+\n     |                        Pin             | Edge |               Net               |        Cell        | Delay | Arrival | Required |\n     |                                        |      |                                 |                    |       |  Time   |   Time   |\n     |----------------------------------------+------+---------------------------------+--------------------+-------+---------+----------|\n     | clk[0]                                 |  v   | clk[0]                          |                    |       |   1.000 |    1.368 |\n     | v/CTS_ccl_a_buf_00002/A                |  v   | clk[0]                          | CLKBUF_X3          | 0.001 |   1.001 |    1.369 |\n     | v/CTS_ccl_a_buf_00002/Z                |  v   | v/CTS_2                         | CLKBUF_X3          | 0.036 |   1.037 |    1.405 |\n     | v/sram/genblk1.sram/clk0               |  v   | v/CTS_2                         | SRAM_32x128_1rw    | 0.001 |   1.038 |    1.406 |\n     | v/sram/genblk1.sram/dout0[29]          |  v   | v/sram_read_data_M1[29]         | SRAM_32x128_1rw    | 0.294 |   1.333 |    1.700 |\n     | v/FE_PDC58_sram_read_data_M1_29/A      |  v   | v/sram_read_data_M1[29]         | BUF_X1             | 0.000 |   1.333 |    1.700 |\n     | v/FE_PDC58_sram_read_data_M1_29/Z      |  v   | v/FE_PDN58_sram_read_data_M1_29 | BUF_X1             | 0.022 |   1.354 |    1.722 |\n     | v/FE_OFC34_sram_read_data_M1_29/A      |  v   | v/FE_PDN58_sram_read_data_M1_29 | CLKBUF_X1          | 0.000 |   1.354 |    1.722 |\n     | v/FE_OFC34_sram_read_data_M1_29/Z      |  v   | v/FE_OFN34_sram_read_data_M1_29 | CLKBUF_X1          | 0.030 |   1.385 |    1.752 |\n     | v/FE_OFC3_sram_read_data_M1_29/A       |  v   | v/FE_OFN34_sram_read_data_M1_29 | CLKBUF_X1          | 0.000 |   1.385 |    1.753 |\n     | v/FE_OFC3_sram_read_data_M1_29/Z       |  v   | v/FE_OFN3_sram_read_data_M1_29  | CLKBUF_X1          | 0.049 |   1.434 |    1.801 |\n     | v/U66/A1                               |  v   | v/FE_OFN3_sram_read_data_M1_29  | AND2_X1            | 0.002 |   1.436 |    1.803 |\n     | v/U66/ZN                               |  v   | v/memresp_msg_M1[data][29]      | AND2_X1            | 0.045 |   1.481 |    1.849 |\n     | v/memresp_queue/dpath/bypass_mux/U30/A |  v   | v/memresp_msg_M1[data][29]      | MUX2_X1            | 0.001 |   1.482 |    1.849 |\n     | v/memresp_queue/dpath/bypass_mux/U30/Z |  v   | v/minion_resp_msg_raw[data][29] | MUX2_X1            | 0.057 |   1.539 |    1.906 |\n     | v/U34/A2                               |  v   | v/minion_resp_msg_raw[data][29] | AND2_X1            | 0.000 |   1.539 |    1.906 |\n     | v/U34/ZN                               |  v   | minion_respstream_msg[29]       | AND2_X1            | 0.043 |   1.582 |    1.950 |\n     | minion_respstream_msg[29]              |  v   | minion_respstream_msg[29]       | SRAMMinion_noparam | 0.000 |   1.582 |    1.950 |\n     +-----------------------------------------------------------------------------------------------------------------------------------+\n</code></pre> <p>Here we can see the SRAM macro is on the critical path. The clock constraint is 2ns. The negative edge of the clock is used to trigger the read data, so the path has an initial 1ns arrival time. This means the clock-to-data path must be less than 1ns. We can see it takes approximately 38ps for the top-level clock pin to reach the clock pin on the SRAM macro and then the actual SRAM read requires 294ps which matches what we saw in the <code>.lib</code> file earlier in the tutorial. It takes 249ps for the data to travel from the SRAM read data ports to the top-level response message pin. The critical path takes 582ps which is less than the required 1ns so we meet the setup time constraint.</p> <p>We can also generate a timing report for the hold-time constraint.</p> <pre><code>innovus&gt; report_timing -early -path_type full_clock -net\n...\nOther End Arrival Time          0.037\n+ Hold                          0.001\n+ Phase Shift                   0.000\n= Required Time                 0.038\n  Arrival Time                  0.048\n  Slack Time                    0.010\n     Clock Rise Edge                      0.000\n     + Input Delay                        0.000\n     = Beginpoint Arrival Time            0.000\n     Timing Path:\n     +---------------------------------------------------------------------------------------------------------------------------+\n     |                Pin                | Edge |               Net               |      Cell       | Delay | Arrival | Required |\n     |                                   |      |                                 |                 |       |  Time   |   Time   |\n     |-----------------------------------+------+---------------------------------+-----------------+-------+---------+----------|\n     | minion_reqstream_msg[3]           |  ^   | minion_reqstream_msg[3]         |                 |       |   0.000 |   -0.010 |\n     | FE_PHC87_minion_reqstream_msg_3/A |  ^   | minion_reqstream_msg[3]         | BUF_X1          | 0.000 |   0.000 |   -0.010 |\n     | FE_PHC87_minion_reqstream_msg_3/Z |  ^   | FE_PHN87_minion_reqstream_msg_3 | BUF_X1          | 0.018 |   0.018 |    0.007 |\n     | FE_PHC50_minion_reqstream_msg_3/A |  ^   | FE_PHN87_minion_reqstream_msg_3 | BUF_X1          | 0.000 |   0.018 |    0.007 |\n     | FE_PHC50_minion_reqstream_msg_3/Z |  ^   | FE_PHN50_minion_reqstream_msg_3 | BUF_X1          | 0.030 |   0.048 |    0.037 |\n     | v/sram/genblk1.sram/din0[3]       |  ^   | FE_PHN50_minion_reqstream_msg_3 | SRAM_32x128_1rw | 0.000 |   0.048 |    0.038 |\n     +---------------------------------------------------------------------------------------------------------------------------+\n     Clock Rise Edge                      0.000\n     = Beginpoint Arrival Time            0.000\n     Other End Path:\n     +------------------------------------------------------------------------------------------+\n     |           Pin            | Edge |   Net   |      Cell       | Delay | Arrival | Required |\n     |                          |      |         |                 |       |  Time   |   Time   |\n     |--------------------------+------+---------+-----------------+-------+---------+----------|\n     | clk[0]                   |  ^   | clk[0]  |                 |       |   0.000 |    0.010 |\n     | v/CTS_ccl_a_buf_00002/A  |  ^   | clk[0]  | CLKBUF_X3       | 0.001 |   0.001 |    0.011 |\n     | v/CTS_ccl_a_buf_00002/Z  |  ^   | v/CTS_2 | CLKBUF_X3       | 0.035 |   0.036 |    0.046 |\n     | v/sram/genblk1.sram/clk0 |  ^   | v/CTS_2 | SRAM_32x128_1rw | 0.001 |   0.037 |    0.047 |\n     +------------------------------------------------------------------------------------------+\n</code></pre> <p>Here we can see that Cadence Innovus has inserted buffers from the top-level input pins to the pipeline register to ensure this path meets the hold-time constraint of 1ps for the SRAM macro. The delay from the top-level clock pin to the clock pin on the pipeline register is 37ps and the delay from the top-level input pin to the data pin of the SRAM macro is 48ps. Since 48ps - 37ps = 11ps this path just meets the hold-time constraint of 1ps with 10ps of slack which was the target.</p> <p>We can report the area as well.</p> <pre><code>innovus&gt; report_area\nHinst Name                            Module Name      Inst Count     Area\n--------------------------------------------------------------------------\nSRAMMinion_noparam                                            539  11675.5\n v                                    tut10_sram_SRAMMinion   424  11584.8\n  v/memresp_queue                     vc_Queue_2_48_2         209    627.2\n   v/memresp_queue/ctrl               vc_QueueCtrl_2_2         22     33.7\n    v/memresp_queue/ctrl/deq_ptr_reg  vc_ResetReg_p_nbits1_1    3      6.3\n    v/memresp_queue/ctrl/enq_ptr_reg  vc_ResetReg_p_nbits1_2    3      5.8\n    v/memresp_queue/ctrl/full_reg     vc_ResetReg_p_nbits1_0    5      7.4\n   v/memresp_queue/dpath              vc_QueueDpath_2_48_2    187    593.4\n    v/memresp_queue/dpath/bypass_mux  vc_Mux2_p_nbits48        45     83.7\n    v/memresp_queue/dpath/qstore      vc_Regfile_1r1w         142    509.6\n  v/sram                              sram_SRAM                38  10740.8\n</code></pre> <p>As expected over 90% of the area is in the SRAM with less than 10% in the pipeline registers, queues, and control logic.</p> <pre><code>innovus&gt; exit\n</code></pre> <p>And now we can use Klayout to look at the final integrated layout.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram/04-cadence-innovus-pnr\n% klayout -l $ECE6745_STDCELLS/klayout.lyp post-pnr.gds\n</code></pre> <p></p> <p>In the following close-up we can see the SRAM bitcell array in the upper right-hand corner along with the SRAM address decoder and SRAM column muxing and sense amps. We can see a row of flip-flops which are part of the SRAM macro and at the bottom we can see a few of the standard cells used for the response queue where they connect to the data pins of the SRAM macro.</p> <p></p>"},{"location":"ece6745-tut10-sram/#52-back-annotated-gate-level-simulation-with-sram-macros","title":"5.2. Back-Annotated Gate-Level Simulation with SRAM Macros","text":"<p>Now that we have finished the place-and-route step, we need to use back-annotated gate-level simulation to verify that the final design still passes all of our tests.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut10-sram/05-synopsys-vcs-baglsim\n% cd $TOPDIR/asic/build-tut10-sram/05-synopsys-vcs-baglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +neg_tchk +sdfverbose \\\n    -sdf max:Top.DUT:../04-cadence-innovus-pnr/post-pnr.sdf \\\n    +define+CYCLE_TIME=2.000 \\\n    +define+VTB_INPUT_DELAY=0.025 \\\n    +define+VTB_OUTPUT_DELAY=0.025 \\\n    +define+VTB_DUMP_SAIF=waves.saif \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../00-openram-memgen/SRAM_32x128_1rw.v \\\n    ../04-cadence-innovus-pnr/post-pnr.v \\\n    ${TOPDIR}/sim/build/SRAMMinion_noparam_sram-rtl-random_tb.v\n% ./simv\n</code></pre> <p>Let's open-up the waveforms using Surfer and verify that the clock-to-data delay for the SRAM is about 300ps.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram/05-synopsys-vcs-baglsim\n% code waves.vcd\n</code></pre> <p>The following close-up shows the clock-to-data delay is indeed about 300ps.</p> <p></p>"},{"location":"ece6745-tut10-sram/#53-power-analysis-with-sram-macros","title":"5.3. Power Analysis with SRAM Macros","text":"<p>Now we can use Synopsys PrimeTime (PT) for power analysis.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut10-sram/06-synopsys-pt-pwr\n% cd $TOPDIR/asic/build-tut10-sram/06-synopsys-pt-pwr\n% pt_shell\n</code></pre> <p>The initial setup similar to the previous tutorials, except we need to provide Synopsys PT the <code>.db</code> files for the SRAM macro.</p> <pre><code>pt_shell&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db ../00-openram-memgen/SRAM_32x128_1rw.db\"\npt_shell&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db ../00-openram-memgen/SRAM_32x128_1rw.db\"\npt_shell&gt; set_app_var power_enable_analysis true\n</code></pre> <p>We then read in the post-pnr gate-level netlist, the <code>.saif</code> file with the activity factors from back-annotated gate-level simulation, and the <code>.spef</code> file with the interconnect parasitics.</p> <pre><code>pt_shell&gt; read_verilog ../04-cadence-innovus-pnr/post-pnr.v\npt_shell&gt; current_design SRAMMinion_noparam\npt_shell&gt; link_design\npt_shell&gt; read_saif ../05-synopsys-vcs-baglsim/waves.saif -strip_path Top/DUT\npt_shell&gt; read_parasitics -format spef ../04-cadence-innovus-pnr/post-pnr.spef\n</code></pre> <p>Finally, we create the clock and perform the power analysis.</p> <pre><code>pt_shell&gt; create_clock clk -name ideal_clock1 -period 2.000\npt_shell&gt; update_power\npt_shell&gt; report_power\npt_shell&gt; report_power -hierarchy\n</code></pre>"},{"location":"ece6745-tut10-sram/#6-asic-automated-flow-with-sram-macros","title":"6. ASIC Automated Flow with SRAM Macros","text":"<p>Manually entering commands is a great way to understand how the tools work but is also tedious and error prone. The ASIC automated flow includes support for using OpenRAM to generate SRAMs. We just need to specify a list of SRAM macros we want to use in the YAML design file. Take a look at the following YAML design file:</p> <pre><code>% cd $TOPDIR/asic/designs\n% code tut10-sram.yml\n</code></pre> <p>The key to using SRAM macros is (1) adding <code>00-openram-memgen</code> as the first step and (2) adding the the <code>sram_dir</code> and <code>srams</code> variables as shown below.</p> <pre><code>steps:\n - 00-openram-memgen\n - 01-synopsys-vcs-rtlsim\n - 02-synopsys-dc-synth\n - 03-synopsys-vcs-ffglsim\n - 04-cadence-innovus-pnr\n - 05-synopsys-vcs-baglsim\n - 06-synopsys-pt-pwr\n - 07-summarize-results\n\n...\n\nsram_dir : ../../../sim/sram\nsrams:\n - SRAM_32x128_1rw\n</code></pre> <p>The ASIC automated flow includes a new step template for using OpenRAM to generate SRAMs. Take a look at the corresponding run script</p> <pre><code>% cd $TOPDIR/asic/steps/00-openram-memgen\n% code run\n</code></pre> <p>The template at the bottom runs the <code>memgen</code> bash function for each SRAM macro.</p> <pre><code>{% for sram in srams | default([]) -%}\nmemgen {{sram}}\n{% endfor %}\n</code></pre> <p>You should recognize the steps in the <code>memgen</code> bash function which include running OpenRAM, copying the <code>.lib</code>, <code>.lef</code>, <code>.gds</code>, and <code>.v</code> files, and running library compiler to generate the <code>.db</code> file.</p> <p>Let's see some examples of how the remaining step templates include support for using SRAM macros. First, let's look at the run scripts for synthesis.</p> <pre><code>% cd $TOPDIR/asic/steps/02-synopsys-dc-synth\n% code run.tcl\n</code></pre> <p>The key difference for synthesis is we need to include the <code>.db</code> file for each SRAM macro.</p> <pre><code>set_app_var target_library [list \\\n  \"$env(ECE6745_STDCELLS)/stdcells.db\" \\\n  {% for sram in srams | default([]) -%}\n  \"../00-openram-memgen/{{sram}}.db\" \\\n  {% endfor %}\n]\n</code></pre> <p>For gate-level simulation we need to include the Verilog behavioral models. Let's look at the run scripts for place-and-route.</p> <pre><code>% cd $TOPDIR/asic/steps/04-cadence-innovus-pnr\n% code run.tcl\n</code></pre> <p>The key difference is we need to include the <code>.lef</code> and <code>.gds</code> files for each SRAM macro.</p> <pre><code>set lef_files [list \\\n  \"$env(ECE6745_STDCELLS)/rtk-tech.lef\" \\\n  \"$env(ECE6745_STDCELLS)/stdcells.lef\" \\\n  {% for sram in srams | default([]) -%}\n  \"../00-openram-memgen/{{sram}}.lef\" \\\n  {% endfor %}\n]\n\n...\n\nset gds_files [list \\\n  \"$env(ECE6745_STDCELLS)/stdcells.gds\" \\\n  {% for sram in srams | default([]) -%}\n  \"../00-openram-memgen/{{sram}}.gds\" \\\n  {% endfor %}\n]\n</code></pre> <p>We also need to make sure to include the <code>.lib</code> files in the <code>setup-timing.tcl</code> script.</p> <p>Now that we know understand how the step templates include support for using SRAM macros, let's go ahead and push the SRAM val/rdy wrapper through the ASIC automated flow. First let's delete the build directory we have been using so far so we can start over.</p> <pre><code>% cd $TOPDIR/asic\n% trash build-tut10-sram\n</code></pre> <p>Now let's use pyhflow to generate the run scripts and go through each step one at a time.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut10-sram\n% cd $TOPDIR/asic/build-tut10-sram\n% pyhflow ../designs/tut10-sram.yml\n% ./00-openram-memgen/run\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% ./03-synopsys-vcs-ffglsim/run\n% ./04-cadence-innovus-pnr/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n% ./07-summarize-results/run\n</code></pre> <p>The summary results should be similar to as shown below.</p> <pre><code> timestamp           = 2025-04-06 13:32:59\n design_name         = SRAMMinion_noparam\n clock_period        = 2.0\n rtlsim              = 7/7 passed\n synth_setup_slack   = 0.4255 ns\n synth_num_stdcells  = 354\n synth_area          = 11508.482 um^2\n ffglsim             = 7/7 passed\n pnr_setup_slack     = 0.3165 ns\n pnr_hold_slack      = 0.0102 ns\n pnr_clk_ins_src_lat = 0 ns\n pnr_num_stdcells    = 545\n pnr_area            = 11680.318 um^2\n baglsim             = 7/7 passed\n\n SRAMMinion_noparam_sram-rtl-random\n  - exec_time = 263 cycles\n  - exec_time = 526.0000 ns\n  - power     = 0.3296 mW\n  - energy    = 0.1734 nJ\n</code></pre>"},{"location":"ece6745-tut10-sram/#7-to-do-on-your-own","title":"7. To-Do On Your Own","text":"<p>Now that you understand how to use SRAM macros, try a simple experiment to see the difference in energy when we only read/write zeros to the SRAM macro. Our interactive simulator provides such a dataset.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut10_sram/sram-sim --impl rtl --input allzero --translate --dump-vtb\n</code></pre> <p>Now modify the YAML design file to add this new evaluation.</p> <pre><code>evals:\n - SRAMMinion_noparam_sram-rtl-random\n - SRAMMinion_noparam_sram-rtl-allzero\n</code></pre> <p>Then you can regenerate the flow using pyhflow. There is no need to regenerate the SRAM macros, rerun synthesis, or rerun place-and-route. We can just just rerun four-state RTL, fast-functional gate-level, back-annotated gate-level simulation, power analysis, and the final summary.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram\n% pyhflow ../designs/tut10-sram.yml\n% ./01-synopsys-vcs-rtlsim/run\n% ./03-synopsys-vcs-ffglsim/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n% ./07-summarize-results/run\n</code></pre> <p>Compare the energy of the experiments with random data vs all zeros. Look at the detailed energy reports.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram\n% code 06-synopsys-pt-pwr/SRAMMinion_noparam_sram-rtl-random-detailed.rpt\n% code 06-synopsys-pt-pwr/SRAMMinion_noparam_sram-rtl-allzero-detailed.rpt\n</code></pre> <p>The energy is not zero since even for the all zeros dataset the addresses are random and choosing between read/writes is also random.</p> <p>Now let's try another experiment to see the impact of column muxing. Change the column muxing for the 32x128 SRAM macro from 4 to 2 by updating the <code>words_per_row</code> variable in the <code>SRAM_32x128_1rw_cfg.py</code> configuration file. Then delete the build directory we have been using so far so we can start over.</p> <pre><code>% cd $TOPDIR/asic\n% trash build-tut10-sram\n</code></pre> <p>Use OpenRAM to regenerate the SRAM macros.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut10-sram\n% cd $TOPDIR/asic/build-tut10-sram\n% pyhflow ../designs/tut10-sram.yml\n% ./00-openram-memgen/run\n</code></pre> <p>Take a look at the resulting layout using Klayout. Notice how the SRAM array is much taller now, but also how the output flip-flops result in quite a bit of white space. Go ahead and run the rest of the ASIC automated flow.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% ./03-synopsys-vcs-ffglsim/run\n% ./04-cadence-innovus-pnr/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n% ./07-summarize-results/run\n</code></pre>"},{"location":"ece6745-tut12-spice-sim/","title":"ECE 6745 Tutorial 9: SPICE Simulation","text":"<p>ngspice is an open-source SPICE simulator for electrical circuits. We can use it to try out some circuit simulations as we go through the semester. In this tutorial, we will start by exploring two simple circuits: an NMOS transistor discharging a load capacitance and an NMOS transistor charging a load capacitance. We can use ngspice to simulate these two scenarios and plot the voltages on various nets. We will then simulate simple logic gates constructed explicitly using transistors, before simulating a few gates from a standard cell library.</p> <p>ngspice takes as input a SPICE deck. This is a text file which describes the circuit you want to simulate along with what kind of analysis you would like to perform on your circuit. You can learn more about SPICE decks in Chapter 8 of Weste &amp; Harris. You can also look at the ngspice documentation:</p> <ul> <li>http://ngspice.sourceforge.net/docs/ngspice-34-manual.pdf</li> </ul> <p>The first step is to source the setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% mkdir $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut12-spice-sim tut12\n% cd tut12\n% TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut12-spice-sim/#1-simulating-an-nmos-discharging-a-load-capacitance","title":"1. Simulating an NMOS Discharging a Load Capacitance","text":"<p>Here is a simple SPICE deck for the first scenario where we have an NMOS transistor discharging a load capacitance.</p> <pre><code>* MMOS Discharging Capacitor\n* ========================================================================\n\n* Parameters and Models\n* ------------------------------------------------------------------------\n\n.param VDD='1.1V'\n.temp  25\n.inc   \"/classes/ece6745/install/adk-pkgs/freepdk-45nm/stdview/pdk-models.sp\"\n\n* Supply Voltage Source\n* ------------------------------------------------------------------------\n\nVdd vdd gnd VDD\n\n* Transistors\n* ------------------------------------------------------------------------\n\n*  src  gate drain body type\nM1 gnd  in   out   gnd  NMOS_VTL W=0.450um L=0.045um\n\n* Output Load\n* ------------------------------------------------------------------------\n\nCload out gnd 7fF\n\n* Input Signals\n* ------------------------------------------------------------------------\n\nVin in gnd pwl( 0ns 0V 0.5ns 0V 0.7ns VDD )\n\n* Analysis\n* ------------------------------------------------------------------------\n\n.ic   V(out)=VDD\n.tran 0.01ns 2.5ns\n\n.control\nrun\nset color0=white\nset color1=black\nset xbrushwidth=2\nplot V(in) V(out)\n.endc\n\n.end\n</code></pre> <p>The first line in the SPICE deck must be a comment. Comments start with an asterisk. Let's discuss each part. The first part sets up parameters and models:</p> <pre><code>.param VDD='1.1V'\n.temp  25\n.inc   \"/classes/ece6745/install/adk-pkgs/freepdk-45nm/stdview/pdk-models.sp\"\n</code></pre> <p>We create a constant named VDD which is the supply voltage we want to use in our circuit. Note that VDD is -not- a voltage source or a node in our circuit. It is just a constant. We set the temperature we want to use for the simulation. Finally, we include the model files associated with the technology we want to use. We will be using the FreePDK 45nm technology in the labs/projects, so here we are including the transistor models from that technology.</p> <p>The next part instantiates a supply voltage source:</p> <pre><code>Vdd vdd gnd VDD\n</code></pre> <p>SPICE decks have this weird thing where the very first character of a line indicates the type of circuit element you want to instantiate. The book gives many more examples. If the first character is a <code>V</code> then it is a voltage source. So here we are creating a voltage source between two nodes named <code>vdd</code> and <code>gnd</code>. Other examples include <code>R</code> for resistor, <code>C</code> for capacitor, <code>M</code> for MOSFET transistor, <code>A</code> for models with special code, and <code>X</code> for subcircuits. Note that SPICE decks are case sensitive. The voltage source is a constant 1.1V. We just use the constant <code>VDD</code> so we can set the supply voltage in one place at the top of the deck.</p> <p>The next part instantiates a transistor:</p> <pre><code>*  src   gate drain body type\nM1 gnd   in   out   gnd  NMOS_VTL W=0.450um L=0.045um\n</code></pre> <p>The first letter is an <code>M</code> which means MOSFET. We specify nodes for the source, gate, drain, and body. We also indicate whether this is an NMOS or PMOS and the width and length in micron. This is a 45nm technology, so we use the minimum transistor length of 45nm (0.045um). If we look at our Nangate standard cell library for a INV_X1 we can see that the NMOS has a width of about 10x the length, so for we make the NMOS width to be 0.450um. So the above example creates a \"minimum\" sized NMOS transistor, where \"minimum\" means the NMOS we will be using in a minimum sized inverter.</p> <p>The next part instantiates an output load:</p> <pre><code>Cload out gnd 7fF\n</code></pre> <p>The first letter is a <code>C</code> which means capacitor. We specify the positive and negative terminals and the capacitance. An INV_X4 inverter has an input cap of 6.25fF so we round up to 7fF as a reasonable output load.</p> <p>The next part instantiates another voltage source, but this source will be used for the input signal:</p> <pre><code>Vin in gnd pwl( 0ns 0V 0.5ns 0V 0.7ns 1.1V )\n</code></pre> <p>Here we can use <code>pwl</code> to create a piece-wise-linear voltage signal.</p> <p>The final part specifies what analysis we want to do:</p> <pre><code>.ic   V(out)=VDD\n.tran 0.01ns 2.5ns\n\n.control\nrun\nset color0=white\nset color1=black\nset xbrushwidth=2\nplot V(in) V(out)\n.endc\n</code></pre> <p>So the <code>.ic</code> line sets an initial condition. Here we want to make sure the output node is initially charged up. The <code>.tran</code> line specifies that we want to do transient analysis for 2.5ns in 0.01ns timesteps. The <code>.control</code>/<code>.endc</code> block is a set of interactive commands which run the simulation and then plot the results.</p> <p>Now let's run the simulation using ngspice:</p> <pre><code>% cd $TOPDIR/sim\n% ngspice nmos-discharge-cap-sim.sp\n</code></pre> <p>Note that if we use ngspice to display plots, then it is a Linux GUI application so you will need to use Microsoft Remote Desktop. A little plot should pop up that looks like the following. This plot clearly shows Vin going from 0V to 1.1V and Vout going from 1.1V to 0V. Everything is \"full rail\".</p> <p></p> <p>To Do On Your Own: Increase the load capacitance by 10x and then 100x and observe the impact on the time to discharge the capacitor.</p>"},{"location":"ece6745-tut12-spice-sim/#2-simulating-an-nmos-charging-a-load-capacitance","title":"2. Simulating an NMOS Charging a Load Capacitance","text":"<p>Now let's try a similar experiment except this time we are going to use the NMOS transistor to charge up an output load. Here is the corresponding spice deck:</p> <pre><code>* MMOS Charging Capacitor\n* ========================================================================\n\n* Parameters and Models\n* ------------------------------------------------------------------------\n\n.param VDD='1.1V'\n.temp  25\n.inc   \"/classes/ece6745/install/adk-pkgs/freepdk-45nm/stdview/pdk-models.sp\"\n\n* Supply Voltage Source\n* ------------------------------------------------------------------------\n\nVdd vdd gnd VDD\n\n* Transistors\n* ------------------------------------------------------------------------\n\n*  src  gate drain body type\nM1 vdd  in   out   gnd  NMOS_VTL W=0.450um L=0.045um\n\n* Output Load\n* ------------------------------------------------------------------------\n\nCLoad out gnd 7fF\n\n* Input Signals\n* ------------------------------------------------------------------------\n\nVin in gnd pwl( 0ns 0V 0.5ns 0V 0.7ns VDD )\n\n* Analysis\n* ------------------------------------------------------------------------\n\n.ic   V(out)=0V\n.tran 0.01ns 2.5ns\n\n.control\nrun\nset color0=white\nset color1=black\nset xbrushwidth=2\nplot V(in) V(out) V(in)-V(out) V(vdd)-V(out)\n.endc\n\n.end\n</code></pre> <p>This is similar to what we had above except now the source of the NMOS transistor is connected to vdd, and we set the initial condition such that the output load is initially discharged. Now let's run the simulation using ngspice:</p> <pre><code>% cd $TOPDIR/sim\n% ngspice nmos-charge-cap-sim.sp\n</code></pre> <p>A little plot should pop up that looks like the following. This plot shows things are not working as well! Vin obviously goes from 0V to 1.1V, but Vout goes from 0V and then starts to level off around 0.8V. It never reaches 1.1V. Why? Well, we are also plotting Vgs (this is the organize line, it is V(in)-V(out)). You can see that Vgs goes up but then starts to go down because Vout is increasing! The transistor starts to turn off an this prevents us from fully charging up Vout. Notice that Vout is still slowly increasing ... this is probably due to some second order effect like leakage or more likely that the NMOS is not 100% off since Vgs is right around the threshold voltage.</p> <p></p> <p>To Do On Your Own: Increase the load capacitance by 10x and then 100x and observe the impact on the time to discharge the capacitor.</p>"},{"location":"ece6745-tut12-spice-sim/#3-simulating-simple-logic-gates","title":"3. Simulating Simple Logic Gates","text":"<p>Let's experiment with some simple logic gates. Take a look at the SPICE deck in <code>inv-sim.sp</code> which contains the canonical minimum sized inverter:</p> <pre><code>*  src  gate drain body type\nM1 vdd  in   out   vdd  PMOS_VTL W=0.900um L=0.045um\nM2 gnd  in   out   gnd  NMOS_VTL W=0.450um L=0.045um\n</code></pre> <p>Notice how the PMOS transistor is sized to be twice the size of the minimum-sized NMOS transistor. We can use a more complicated piece-wise linear voltage source to toggle the input to the inverter:</p> <pre><code>Vin in gnd pwl\n+ (\n+   0.0ns  0V\n+   0.4ns  0V\n+   0.6ns VDD\n+   0.9ns VDD\n+   1.1ns VDD\n+   1.4ns VDD\n+   1.6ns  0V\n+   1.9ns  0V\n+ )\n</code></pre> <p>We can use <code>+</code> to continue a long line SPICE command across multiple lines in the SPICE deck. Here we have formatted the piece-wise linear voltage source to look a little like a table. The input is low for 0.5ns, then goes high for 1ns, and then goes low again for 0.5ns. Our SPICE deck also includes some measurement commands:</p> <pre><code>.measure tran tpdr trig v(in) val='VDD/2' fall=1 targ v(out) val='VDD/2' rise=1\n.measure tran tpdf trig v(in) val='VDD/2' rise=1 targ v(out) val='VDD/2' fall=1\n.measure tran tpd param='(tpdr+tpdf)/2'\n</code></pre> <p>The ngspice manual explains measurement commands in more detail. Briefly, the first command measures the propagation delay for a low-to-high output transition, and the second command measures the propagation delay for a high-to-low output transition. These delays are measured from when the input is VDD/2 to when the output is VDD/2. The third measurement command uses the average of these two propagation delays to estimate the overall propagation delay of the inverter. Chapter 8 of Weste &amp; Harris discusses in more detail how to effectively characterize various CMOS circuits. Now let's run the simulation using ngspice:</p> <pre><code>% cd $TOPDIR/sim\n% ngspice inv-sim.sp\n...\ntpdr = 1.037703e-11 targ = 1.510377e-09 trig = 1.500000e-09\ntpdf = 2.409571e-11 targ = 5.240957e-10 trig = 5.000000e-10\ntpd  = 1.72364e-11\n</code></pre> <p>A little plot should pop up that shows the input and output voltages, and the measurement results will be displayed in the terminal. The propagation delay is approximately 17.2ps.</p> <p>To Do On Your Own: Increase the load capacitance by 10x and then 100x and observe the impact on the propagation delay. Make sure you look at the actual waveforms to see if the output has time to go full rail. If not, you need to increase the time between input transitions to make an accurate estimate of the propagation delay.</p> <p>Let's dig a little deeper. Notice that the rise time is not equal to the fall time for our inverter. The rise time is 10.4ps but the fall time is 24.1ps. We have made the PMOS twice the width of the NMOS (i.e., the PMOS is 900nm wide while the NMOS is 450nm wide), so why aren't the rise and fall times equal? Part of the reason is the PMOS mobility is not exactly half the NMOS mobility in this technology as well as many other second order effects. Change the size of PMOS so it is only 1.5x as large as the NMOS like this:</p> <pre><code>*  src  gate drain body type\nM1 vdd  in   out   vdd  PMOS_VTL W=0.675um L=0.045um\nM2 gnd  in   out   gnd  NMOS_VTL W=0.450um L=0.045um\n</code></pre> <p>Rerun the simulation:</p> <pre><code>% cd $TOPDIR/sim\n% ngspice inv-sim.sp\n...\ntpdr = 1.940778e-11 targ = 2.019408e-09 trig = 2.000000e-09\ntpdf = 1.812324e-11 targ = 1.018123e-09 trig = 1.000000e-09\ntpd  = 1.87655e-11\n</code></pre> <p>You can now see the rise and fall times are much closer to being equal. Of course this begs the question, \"Why is it important to have equal rise and fall times?\". To some degree this is a design decision. It is certainly possible to have unequal rise and fall times, and indeed this can also often lead to better area/power or enabling making a critical transition faster (at the expense of the other transition). However, the largest motivation for equal rise and fall times is that it maximizes the noise margins. To understand this, let's use ngspice to analyze the DC transfer curve of an inverter. Take a look at the SPICE deck in <code>inv-sim-xfer.sp</code> which contains the same canonical minimum sized inverter but with DC instead of transient analysis:</p> <pre><code>.dc Vin 0 'VDD' 0.01\n</code></pre> <p>Here is the resulting DC transfer curve showing Vin vs Vout (after I manually annotated the noise margins):</p> <p></p> <p>Recall that the noise margins are with respect to where the slope of the transfer curve is -1 (i.e., maximum gain). V_IL is the maximum low input voltage and V_IH is the minimum high input voltage. V_OL is the maximum low output voltage and V_OH is the minimum high output voltage. The noise margins are NM_H = V_OH - V_IH and NM_L = V_IL - V_OL and we want these noise margins to be as large as possible. With large noise margins we can tolerate noise on the input without it propagating through the inverter and causing it to switch the output. For this example the noise margins are roughly equal at 0.3V:</p> <pre><code>V_IL = 0.45V\nV_IH = 0.65V\nV_OL = 0.15V\nV_OH = 0.95V\nNM_H = V_OH - V_IH = 0.95V - 0.65V = 0.31V\nNM_L = V_IL - V_OL = 0.45V - 0.15V = 0.30V\n</code></pre> <p>Now the problem with unequal rise and fall times is it means we essentially skew the noise margins. We make one noise larger but the other noise margin smaller. Try rerunning the simulation, but this time make the PMOS the same size as the NMOS like this:</p> <pre><code>*  src  gate drain body type\nM1 vdd  in   out   vdd  PMOS_VTL W=0.450um L=0.045um\nM2 gnd  in   out   gnd  NMOS_VTL W=0.450um L=0.045um\n</code></pre> <p>Rerun the simulation and you should see something like the following (after I manually annotated the noise margins):</p> <p></p> <p>And here are roughly the corresponding noise margins:</p> <pre><code>V_IL = 0.35V\nV_IH = 0.48V\nV_OL = 0.15V\nV_OH = 0.98V\nNM_H = V_OH - V_IH = 0.98V - 0.48V = 0.5V\nNM_L = V_IL - V_OL = 0.35V - 0.15V = 0.2V\n</code></pre> <p>Notice how the low noise margin has gone from 0.3V to 0.2V. This means the gate is now much more sensitive to noise. So in general we perfer equal rise and fall times becuase it improves our noise margins (and also simplifies our analysis).</p> <p>To Do On Your Own: Make the NMOS twice as big as the PMOS and observe how this impacts the noise margins.</p> <p>Creating voltage sources to change the inputs can be very tedious, especially when we want to drive multiple inputs. We can take advantage of ngspice's support for mixed-signal analog/digital simulation to simplify the task of creating many digital input values. Take a look at the SPICE deck in <code>inv-dsource-sim.sp</code> to see a different way of generating input sources:</p> <pre><code>A1 [in_] inv_source\n.model inv_source d_source (input_file=\"inv-source.txt\")\n</code></pre> <p>Here we are instantiating a <code>d_source</code> and giving this new component the name <code>a1</code>. The <code>d_source</code> reads an input text file to see the values of the given input nodes (i.e., <code>in_</code>). The <code>inv-source.txt</code> file looks like this:</p> <pre><code>* inv-source.txt\n* ====================================================================\n\n* time in\n0.0ns  0s\n1.0ns  1s\n2.0ns  0s\n</code></pre> <p>Lines that start with <code>*</code> are comments. The first column corresponds to time and each remaining column corresponds to an input node. The input node can be either <code>0s</code> (for a strong logic zero) or <code>1s</code> (for a strong logic one). So the above example toggles the input node just as with the previous piece-wise linear voltage source. Note that there is a positional mapping from the columns in the text file to the nodes in the SPICE deck when instantiating the <code>d_source</code>. So the second column maps to the <code>in_</code> input node.</p> <p>We also need to instantiate a digital-to-analog converter (DAC) to translate the digital values into analog values suitable for driving a CMOS circuit:</p> <pre><code>Ain [in_] [in] dac_in\n.model dac_in dac_bridge (out_low=0V out_high='VDD' t_rise=0.2ns t_fall=0.2ns)\n</code></pre> <p>The <code>dac_bridge</code> component takes parameters specifying the logic low and logic high voltage levels and the rise/fall times. We also need to specify the mapping from digital input nodes (<code>in_</code>) to analog input nodes (<code>in</code>). Now let's run the simulation using ngspice and confirm that the result is the same as when using piece-wise linear voltage sources:</p> <pre><code>% cd $TOPDIR/sim\n% ngspice inv-dsource-sim.sp\n</code></pre> <p>Now let's experiment with a NAND2 gate. Take a look at the SPICE deck in <code>nand2-sim.sp</code> which contains the canonical NAND2 gate:</p> <pre><code>*  src  gate drain body type\nM1 vdd  a    y     vdd  PMOS_VTL W=0.900um L=0.045um\nM2 vdd  b    y     vdd  PMOS_VTL W=0.900um L=0.045um\nM3 n0   a    y     gnd  NMOS_VTL W=0.900um L=0.045um\nM4 gnd  b    n0    gnd  NMOS_VTL W=0.900um L=0.045um\n</code></pre> <p>Notice how we have sized this NAND2 gate to have equal worst-case rise and fall times assuming a PMOS/NMOS mobility ratio of two, and we have also sized this NAND2 gate to have similar effective resistance as the canonical minimum-sized inverter</p> <p>To Do On Your Own: Copy the <code>nand2-sim.sp</code> SPICE deck to create a new file named <code>nor2-sim.sp</code> and copy the <code>nand2-source.txt</code> input file to create a new file named <code>nor2-source.txt</code>. Replace the NAND2 gate with an explicit transistor implementation of a NOR2 gate. Size the NOR2 gate to have equal worst-case rise and fall times assuming a PMOS/NMOS mobility ratio of two and similar effective resistance as the canonical minimum-sized inverter. Run the simulation and verify the functionality using the waveforms.</p>"},{"location":"ece6745-tut12-spice-sim/#4-simulating-standard-cells","title":"4. Simulating Standard Cells","text":"<p>A standard cell library will include many views including SPICE decks for each standard cell. Actually, the standard cell library will usually include two kinds of SPICE decks. The schematic SPICE deck includes just the transistors, while the extracted SPICE deck will include all of the extracted parasitic resistances and capacitances. Take a look at the schematic SPICE deck for a minimum sized inverter (INV_X1):</p> <pre><code>% less -p INV_X1 ${ECE6745_STDCELLS}/stdcells.spi\n.SUBCKT INV_X1 A ZN VDD VSS\n*.PININFO A:I ZN:O VDD:P VSS:G\n*.EQN ZN=!A\nM_i_0 ZN A VSS VSS NMOS_VTL W=0.415000U L=0.050000U\nM_i_1 ZN A VDD VDD PMOS_VTL W=0.630000U L=0.050000U\n.ENDS\n</code></pre> <p>The SPICE deck for an inverter is encapsulated in a SPICE subcircuit (<code>SUBCKT</code>). A subcircuit is like a PyMTL3 or Verilog module with an interface (i.e., list of ports) and an implementation (i.e., instantiating transistors or other subcircuits). In this case, the INV_X1 gate includes four ports: the input (<code>A</code>), the output (<code>ZN</code>), the power supply (<code>VDD</code>) and ground (<code>VSS</code>). As expected, the implementation includes a PMOS and NMOS transistor. Notice that even though the minimum length transistor in this technology is 0.045um, both transistors are 0.050um. This is actually quite common. Standard cells often use slightly longer transistors to offer a better performance vs. power trade-off (i.e., lower leakage). Some standard cell libraries will actually include different implementations of every gate each with a different channel length. Also notice how the PMOS is only 1.5x larger than the NMOS. Again, this is actually quite common. A PMOS/NMOS mobility ratio of two is just an assumption; a specific technology will likely have a different mobility ratio which is often less than two. Standard cells will also often have slightly skewed rise/fall times to offer a better area vs. noise margin trade-off.</p> <p>While we could certainly simulate the schematic SPICE deck, it is more useful to simulate the extracted SPICE deck since this will provide accurate performance analysis. Take a loo at the extracted SPICE deck for a minimum sized inverter (INV_X1):</p> <pre><code>% less -p INV_X1 $ECE6745_STDCELLS/stdcells-lpe.spi\n.SUBCKT INV_X1 VDD VSS A ZN\n*.PININFO VDD:P VSS:G A:I ZN:O\n*.EQN ZN=!A\nM_M1 N_ZN_M0_d N_A_M0_g N_VDD_M0_s VDD PMOS_VTL W=0.630000U L=0.050000U\nM_M0 N_ZN_M1_d N_A_M1_g N_VSS_M1_s VSS NMOS_VTL W=0.415000U L=0.050000U\nC_x_PM_INV_X1%VDD_c0 x_PM_INV_X1%VDD_31 VSS 4.13109e-17\nC_x_PM_INV_X1%VDD_c1 x_PM_INV_X1%VDD_19 VSS 2.61599e-16\nC_x_PM_INV_X1%VDD_c2 x_PM_INV_X1%VDD_18 VSS 1.89932e-17\nC_x_PM_INV_X1%VDD_c3 N_VDD_M0_s VSS 3.88255e-17\nC_x_PM_INV_X1%VDD_c4 x_PM_INV_X1%VDD_12 VSS 1.92462e-17\nC_x_PM_INV_X1%VDD_c5 x_PM_INV_X1%VDD_11 VSS 2.334e-16\nC_x_PM_INV_X1%VDD_c6 x_PM_INV_X1%VDD_8 VSS 5.52247e-16\nR_x_PM_INV_X1%VDD_r7 VDD x_PM_INV_X1%VDD_31 0.13879\nR_x_PM_INV_X1%VDD_r8 VDD x_PM_INV_X1%VDD_28 0.392137\n...\n.ENDS\n</code></pre> <p>The INV_X1 gate still includes four ports (although they are in a different order which is annoying), but notice that the implementation is radically different. There are ~50 parasitic resistances and capacitances extracted from the actual layout for this standard cell. These parasitics are what enable more accurate performance analysis.</p> <p>Take a look at the SPICE deck in <code>inv-stdcell-sim.sp</code> which is meant for simulating the INV_X1 standard cell. First, notice that we need to include the standard cell SPICE deck:</p> <pre><code>.param VDD='1.1V'\n.temp  25\n.inc   \"/classes/ece6745/install/adk-pkgs/freepdk-45nm/stdview/pdk-models.sp\"\n.inc   \"/classes/ece6745/install/adk-pkgs/freepdk-45nm/stdview/stdcells-lpe.spi\"\n</code></pre> <p>Instead of directly instantiating transistors, we simply instantiate the <code>INV_X1</code> subcircuit:</p> <pre><code>X1 vdd gnd in out INV_X1\n</code></pre> <p>The instance name of subcircuits (<code>X1</code>) must start with <code>X</code>. The instance name is followed by the list of nodes that should be connected to the ports of the subcircuit. The nodes are connected by position. So since the port list in the subcircuit definition is <code>VDD VSS A ZN</code>, we must list the nodes in the subcircuit instance in the exact same order. The subcircuit instance ends with the type of subcircuit we wish to instantiate. The rest of the SPICE deck is the same as earlier in the tutorial. Let's run the simulation using ngspice:</p> <pre><code>% cd $TOPDIR/sim\n% ngspice inv-stdcell-sim.sp\n...\ntpdr = 2.577757e-11 targ = 2.125778e-09 trig = 2.100000e-09\ntpdf = 2.275623e-11 targ = 1.122756e-09 trig = 1.100000e-09\ntpd  = 2.42669e-11\n</code></pre> <p>Recall that the propagation delay when we instantiated transistors directly was 17.2ps while now it is 24.3ps. The extracted SPICE decks are almost always slower than schematic SPICE decks, since we are actually modeling the parasitic resistances and capacitances.</p> <p>To Do On Your Own: Increase the load capacitance by 10x and then 100x and observe the impact on the propagation delay. Make sure you look at the actual waveforms to see if the output has time to go full rail. If not, you need to increase the time between input transitions to make an accurate estimate of the propagation delay.</p> <p>Now let's experiment with the NAND2_X1 gate from the standard cell library. Take a look at the SPICE deck in <code>nand2-stdcell-sim.sp</code> which instantiates the appropriate subcircuit, then run the simulation using ngspice:</p> <pre><code>% cd $TOPDIR/sim\n% ngspice nand2-stdcell-sim.sp\n</code></pre> <p>To Do On Your Own: Copy the <code>nand2-stdcell-sim.sp</code> SPICE deck to create a new file named <code>nor2-stdcell-sim.sp</code> and copy the <code>nand2-source.txt</code> input file to create a new file named <code>nor2-source.txt</code>. Replace the NAND2_X1 subcircuit instance with an instance of the NOR2_X1 gate from the standard cell library. Run the simulation and verify the functionality using the waveforms.</p>"},{"location":"ece6745-tut12-spice-sim/#5-to-do-on-your-own","title":"5. To Do On Your Own","text":"<p>The Nangate standard cell library includes a full-adder gate:</p> <pre><code>% less -p FA_X1 ${ECE6745_STDCELLS}/stdcells-lpe.spi\n.SUBCKT FA_X1 VDD VSS CO CI A B S\n*.PININFO VDD:P VSS:G CO:O CI:I A:I B:I S:O\n*.EQN CO=((A * B) + (CI * (A + B)));S=(CI ^ (A ^ B))\nM_M14 N_VDD_M0_d N_4_M0_g N_CO_M0_s VDD PMOS_VTL W=0.630000U L=0.050000U\nM_M15 net_007 N_B_M1_g N_VDD_M0_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M16 N_4_M2_d N_A_M2_g net_007 VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M17 N_6_M3_d N_CI_M3_g N_4_M2_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M18 N_VDD_M4_d N_A_M4_g N_6_M3_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M19 N_6_M5_d N_B_M5_g N_VDD_M4_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M20 N_11_M6_d N_B_M6_g N_VDD_M6_s VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M21 N_VDD_M7_d N_CI_M7_g N_11_M6_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M22 N_11_M8_d N_A_M8_g N_VDD_M7_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M23 N_12_M9_d N_4_M9_g N_11_M8_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M24 net_010 N_CI_M10_g N_12_M9_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M25 net_009 N_B_M11_g net_010 VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M26 N_VDD_M12_d N_A_M12_g net_009 VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M27 N_S_M13_d N_12_M13_g N_VDD_M12_d VDD PMOS_VTL W=0.630000U L=0.050000U\nM_M0 N_VSS_M14_d N_4_M14_g N_CO_M14_s VSS NMOS_VTL W=0.415000U L=0.050000U\nM_M1 net_000 N_B_M15_g N_VSS_M14_d VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M2 N_4_M16_d N_A_M16_g net_000 VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M3 N_7_M17_d N_CI_M17_g N_4_M16_d VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M4 N_VSS_M18_d N_A_M18_g N_7_M17_d VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M5 net_002 N_B_M19_g N_VSS_M18_d VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M6 net_006 N_B_M20_g N_VSS_M20_s VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M7 N_VSS_M21_d N_CI_M21_g net_006 VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M8 N_10_M22_d N_A_M22_g N_VSS_M21_d VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M9 N_12_M23_d N_4_M23_g N_10_M22_d VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M10 net_004 N_CI_M24_g N_12_M23_d VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M11 net_003 N_B_M25_g net_004 VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M12 N_VSS_M26_d N_A_M26_g net_003 VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M13 N_S_M27_d N_12_M27_g N_VSS_M26_d VSS NMOS_VTL W=0.415000U L=0.050000U\n...\n.ENDS\n</code></pre> <p>Try instantiating and chaining four of these gates together to create a four-bit ripple-carry adder. Create an appropriate SPICE deck to drive the simulation including a <code>d_source</code> that reads in a text file with the two four-bit input values. Here is what the results look like if you start with adding 0b1111 to 0b0000 and then change the b input to 0b0001 at 200ps. Notice the sum outputs transitioning from 0 to 1 as the carry is propagated through the full-adder gates. As discussed in Chapter 8 of Weste &amp; Harris, for more accurate performance analysis you would need to add inverters to the inputs for realistic waveform shaping and to the outputs for realistic load capacitance.</p> <p></p>"},{"location":"ece6745-tut13-dw/","title":"6745 Tutorial 13: DesignWare and Retiming","text":"<p>Synopsys Design Compiler (DC) includes the DesignWare (DW) library which is a collection of hardware components implementing arbiters, integer arithmetic units, floating-point arithmetic units, and memories. The Synopsys DW components also have optimized gate-level implementations that Synopsys DC can use when synthesizing your design. This tutorial will describe how these components can be used either through automatic inference or explicit instantiation. You can see a list of all of the available Synopsys DW components in the user guide here:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/asicdocs/dwbb_userguide.pdf</li> </ul> <p>The user guide shows which units can be automatically inferred from an operator or function and which can only be used through explicit instantiation. Since most of the arithmetic units are combinational, the tutorial will also discuss how you can use register retiming to automatically pipeline these units so they can operate at higher clock frequencies. This tutorial assumes you have already completed the tutorials on Linux, Git, PyMTL, Verilog, ASIC front-end flow, ASIC back-end flow, and ASIC automated ASIC flow.</p> <p>The first step is to access <code>ecelinux</code>. Use VS Code to log into a specific <code>ecelinux</code> server. Once you are at the <code>ecelinux</code> prompt, source the setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut13-dw tut13\n% cd tut13\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut13-dw/#1-synopsys-designware-automatic-inference","title":"1. Synopsys DesignWare Automatic Inference","text":"<p>Let's start by exploring how Synopsys DC can automatically infer the use of Synopsys DW components by reviewing the sort unit from earlier tutorials. Recall the sort unit is implemented using a three-stage pipelined, bitonic sorting network and the datapath is shown below.</p> <p></p> <p>Let's look at the min/max unit:</p> <pre><code>module tut3_verilog_sort_MinMaxUnit\n#(\n  parameter p_nbits = 1\n)(\n  input  logic [p_nbits-1:0] in0,\n  input  logic [p_nbits-1:0] in1,\n  output logic [p_nbits-1:0] out_min,\n  output logic [p_nbits-1:0] out_max\n);\n\n  always_comb begin\n\n    // Find min/max\n\n    if ( in0 &gt;= in1 ) begin\n      out_max = in0;\n      out_min = in1;\n    end\n    else if ( in0 &lt; in1 ) begin\n      out_max = in1;\n      out_min = in0;\n    end\n\n    // Handle case where there is an X in the input\n\n    else begin\n      out_min = 'x;\n      out_max = 'x;\n    end\n\n  end\n\nendmodule\n</code></pre> <p>Notice how this unit uses two comparison operators, one for greater-than-equal and one for less than. We will see how Synopsys DC is able to automatically infer the use of two Synopsys DW components for these operators.</p> <p>First, we need to run the tests and interactive simulator to create the Verilog test benches which we can use for four-state RTL, fast-functional gate-level, and back-annotated gate-level simulation.</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/sort/test --test-verilog --dump-vtb\n% ../tut3_verilog/sort/sort-sim --impl rtl-struct --input random --stats --translate --dump-vtb\n% ../tut3_verilog/sort/sort-sim --impl rtl-struct --input zeros  --stats --translate --dump-vtb\n</code></pre> <p>Now let's use the ASIC automated flow to push the sort unit through synthesis and place-and-route.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut08-sort\n% cd $TOPDIR/asic/build-tut08-sort\n% pyhflow ../designs/tut08-sort.yml\n% ./run-flow\n</code></pre> <p>Then you can look at the resources report generated by Synopsys DC to see what Synopsys DW components were inferred.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% cat 02-synopsys-dc-synth/resources.rpt\n</code></pre> <p>You should see something like this.</p> <pre><code>================================================================\n| Cell     | Module  | Parameters | Contained Operations       |\n================================================================\n| gte_x_1  | DW_cmp  | width=8    | gte_30 (MinMaxUnit.v:30)   |\n| lt_x_2   | DW_cmp  | width=8    | lt_34 (MinMaxUnit.v:34)    |\n================================================================\n\nImplementation Report\n========================================\n|          |         | Current         |\n| Cell     | Module  | Implementation  |\n========================================\n| gte_x_1  | DW_cmp  | apparch (area)  |\n| lt_x_2   | DW_cmp  | apparch (area)  |\n========================================\n</code></pre> <p>The report shows how Synopsys DC was able to infer the use of a Synopsys DW comparator (<code>DW_cmp</code>). You can learn more about this component from its datasheet here:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/asicdocs/dwbb_datasheets/DW01_cmp2.pdf</li> </ul> <p>You will see that the component includes three different microarchitectures:</p> <ul> <li><code>rpl</code>: Ripple carry</li> <li><code>pparch</code>: Delay-optimized flexible parallel-prefix</li> <li><code>apparch</code>: Area-optimized flexible architecture</li> </ul> <p>Since the clock constraint is relatively generous (140ps of positive slack), Synopsys DC has decided to use a more area-optimized implementation.</p>"},{"location":"ece6745-tut13-dw/#2-synopsys-designware-explicit-instantiation","title":"2. Synopsys DesignWare Explicit Instantiation","text":"<p>Synopsys DC will to its best to infer Synopsys DW components whenever possible, but many components can only be used by explicitly instantiating the component in your Verilog. In this section, we will look at two examples: (1) instantiating a six-function comparator in the sort unit; and (2) instantiating a floating-point adder.</p>"},{"location":"ece6745-tut13-dw/#21-explicitly-instantiating-six-function-comparator","title":"2.1. Explicitly Instantiating Six-Function Comparator","text":"<p>To illustrate how explicit instantiation works, let's use a six-function comparator to implement the min/max unit. Review the corresponding data-sheet here:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/asicdocs/dwbb_datasheets/DW01_cmp6.pdf</li> </ul> <p>Now go ahead and modify the min/max unit to explicitly instantiate and use this six-function comparator as shown below.</p> <pre><code>module tut3_verilog_sort_MinMaxUnit\n#(\n  parameter p_nbits = 1\n)(\n  input  logic [p_nbits-1:0] in0,\n  input  logic [p_nbits-1:0] in1,\n  output logic [p_nbits-1:0] out_min,\n  output logic [p_nbits-1:0] out_max\n);\n\n  logic lt;\n  logic gt;\n  logic eq;\n  logic le;\n  logic ge;\n  logic ne;\n\n  DW01_cmp6#(p_nbits) cmp_gt\n  (\n    .A  (in0),\n    .B  (in1),\n    .TC (1'b0),\n    .LT (lt),\n    .GT (gt),\n    .EQ (eq),\n    .LE (le),\n    .GE (ge),\n    .NE (ne)\n  );\n\n  assign out_max = gt ? in0 : in1;\n  assign out_min = lt ? in0 : in1;\n\nendmodule\n</code></pre> <p>Now try to rerun the tests.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/sort/test -x --tb=long\n</code></pre> <p>The tests will fail because Verilator cannot find the implementation of the Synopsys DW component. Add the following include directive at the top of the implementation of the min/max unit:</p> <pre><code>`include \"/opt/synopsys/syn/V-2023.12-SP5/dw/sim_ver/DW01_cmp6.v\"\n</code></pre> <p>Now Verilator will be able to find the implementation of the Synopsys DW component, but it produces a warning about an implicit static function. We will need to disable this warning when processing the Synopsys DW component using Verilator's special linting comments.</p> <pre><code>/* verilator lint_off IMPLICITSTATIC */\n`include \"/opt/synopsys/syn/V-2023.12-SP5/dw/sim_ver/DW01_cmp6.v\"\n/* verilator lint_on IMPLICITSTATIC */\n</code></pre> <p>Now the tests should all pass so we can now regenerate the Verilog test benches for four-state RTL, fast-functional gate-level, and back-annotated gate-level simulation.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/sort/test --test-verilog --dump-vtb\n% ../tut3_verilog/sort/sort-sim --impl rtl-struct --input random --stats --translate --dump-vtb\n% ../tut3_verilog/sort/sort-sim --impl rtl-struct --input zeros  --stats --translate --dump-vtb\n</code></pre> <p>Now let's push the sort unit through the ASIC automated flow again. We will start by just running the first two steps and looking at the resources report.</p> <pre><code>% cd ${TOPDIR}/asic/build-tut08-sort\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% cat 02-synopsys-dc-synth/resources.rpt\n</code></pre> <p>You should see something like this:</p> <pre><code>==================================================================\n| Cell     | Module    | Parameters | Contained Operations       |\n==================================================================\n| cmp_gt   | DW01_cmp6 | width=8    | cmp_gt (MinMaxUnit.v:38)   |\n==================================================================\n\nImplementation Report\n==========================================\n|          |           | Current         |\n| Cell     | Module    | Implementation  |\n==========================================\n| cmp_gt   | DW01_cmp6 | apparch (area)  |\n==========================================\n</code></pre> <p>This clearly indicates that Synopsys DC is now using the explicitly instantiated six-function comparator instead of automatically inferring a two-function comparator.</p> <p>Let's go ahead and push the sort unit through the reset of the ASIC automated flow.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% ./03-synopsys-vcs-ffglsim/run\n% ./04-cadence-innovus-pnr/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n% ./07-summarize-results/run\n</code></pre> <p>Since the implementation now depends on Verilog code outside the source tree, your tests will no longer work on GitHub Actions. You can solve this by copying the Verilog corresponding to the explicitly instantiated components into your source tree. For example, we can copy the Verilog for the six-function comparator into a <code>dw</code> subdirectory.</p> <pre><code>% mkdir -p $TOPDIR/sim/dw\n% cd $TOPDIR/sim/dw\n% cp /opt/synopsys/syn/V-2023.12-SP5/dw/sim_ver/DW01_cmp6.v .\n</code></pre> <p>Then modify the include directive at the top of the implementation of the min/max unit appropriately.</p> <pre><code>`include \"dw/DW01_cmp6.v\"\n</code></pre> <p>Note that since the verilog provided by Synopsys DW is copyrighted you should not make it public.</p>"},{"location":"ece6745-tut13-dw/#22-explicitly-instantiating-floating-point-adder","title":"2.2. Explicitly Instantiating Floating-Point Adder","text":"<p>This section will further illustrate how to use Synopsys DW components by explicitly instantiating a floating-point adder. You can learn more about the Synopsys DW component for a floating-point adder from its datasheet here:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/asicdocs/dwbb_datasheets/dw_fp_add.pdf</li> </ul> <p>We have already shown how to explicitly instantiate this Synopsys DW component along with input registers to create a single-stage floating-point adder. Look at the implementation provided in <code>FPAdd1stage.v</code>.</p> <pre><code>% cd $TOPDIR/sim/tut13_dw\n% code FPAdd1stage.v\n</code></pre> <p>The implementation is shown below.</p> <pre><code>module tut13_dw_FPAdd1stage\n(\n  input  logic        clk,\n  input  logic        reset,\n\n  input  logic        in_val,\n  input  logic [31:0] in0,\n  input  logic [31:0] in1,\n\n  output logic        out_val,\n  output logic [31:0] out\n);\n\n  // pipeline registers\n\n  logic        val_X0;\n  logic [31:0] in0_X0;\n  logic [31:0] in1_X0;\n\n  always_ff @(posedge clk) begin\n    if ( reset )\n      val_X0 &lt;= 1'b0;\n    else\n      val_X0 &lt;= in_val;\n\n    in0_X0 &lt;= in0;\n    in1_X0 &lt;= in1;\n  end\n\n  // floating-point adder\n\n  logic [7:0]  status_X0;\n  logic [31:0] out_X0;\n\n  DW_fp_add\n  #(\n    .sig_width       (23),\n    .exp_width       (8),\n    .ieee_compliance (1)\n  )\n  fp_add\n  (\n    .a      (in0_X0),\n    .b      (in1_X0),\n    .rnd    (3'b000),\n    .z      (out_X0),\n    .status (status_X0)\n  );\n\n  // output logic\n\n  assign out_val = val_X0;\n  assign out = out_X0 &amp; {32{val_X0}};\n\nendmodule\n</code></pre> <p>We configure the floating-point adder to support 32-bit floating point in standard single-precision IEEE format. The Synopsys DW component supports disabling IEEE compliance, different rounding modes, and status flags. We need to also explicitly include the Synopsys DW behavioral Verilog files. Let's go ahead and copy them into a <code>dw</code> directory in the source tree.</p> <pre><code>% mkdir -p $TOPDIR/sim/dw\n% cd $TOPDIR/sim/dw\n% cp /opt/synopsys/syn/V-2023.12-SP5/dw/sim_ver/DW_fp_addsub.v .\n% cp /opt/synopsys/syn/V-2023.12-SP5/dw/sim_ver/DW_fp_add.v .\n</code></pre> <p>Notice how we have to copy two files since <code>DW_fp_add.v</code> uses the module defined in <code>DW_fp_addsub.v</code>. You may need to experiment to ensure you have copied all of the files required for the desired Synopsys DW component.</p> <p>Now add the following include directives at the top of the <code>FPAdd1stage.v</code> file.</p> <pre><code>/* verilator lint_off LATCH */\n`include \"dw/DW_fp_addsub.v\"\n`include \"dw/DW_fp_add.v\"\n/* verilator lint_on LATCH */\n</code></pre> <p>Here we are using Verilator's special linting comments to turn off linting checks for inferred latches. You may need to experiment to ensure you have turned off the right linting checks so that Verilator can use the Synopsys DW behavioral Verilog component.</p> <p>Examine the simple basic test we have provided for the floating-point adder.</p> <pre><code>% cd $TOPDIR/sim/tut13_dw/test\n% code FPAdd1stage_test.py\n</code></pre> <p>The basic test case along with some helper functions is shown below.</p> <pre><code>def fp2bits( fp ):\n  if fp == '?':\n    return '?'\n  else:\n    return Bits32(int.from_bytes( pack( '&gt;f', fp ), byteorder='big' ))\n\ndef row( in_val, in0, in1, out_val, out ):\n  return [ in_val, fp2bits(in0), fp2bits(in1), out_val, fp2bits(out) ]\n\ndef test_basic( cmdline_opts ):\n  run_test_vector_sim( FPAdd1stage(), [\n       ( 'in_val in0   in1   out_val* out*'   ),\n    row( 0,      0.00, 0.00, 0,       '?'     ),\n    row( 1,      1.00, 1.00, 0,       '?'     ),\n    row( 1,      1.50, 1.50, 1,       2.00    ),\n    row( 1,      1.25, 2.50, 1,       3.00    ),\n    row( 0,      0.00, 0.00, 1,       3.75    ),\n    row( 0,      0.00, 0.00, 0,       '?'     ),\n  ], cmdline_opts )\n</code></pre> <p>We can use the Python <code>struct</code> package to convert a Python floating-point variable into 32-bit IEEE single-precision format. Here is an example:</p> <pre><code>% python\n&gt;&gt;&gt; from struct import pack\n&gt;&gt;&gt; pack( '&gt;f', 1.5 ).hex()\n'3fc00000'\n</code></pre> <p>The encoding of 0x3fc00000 matches what we expect when using an IEEE-754 floating-point converter such as this:</p> <ul> <li>https://www.h-schmidt.net/FloatConverter/IEEE754.html</li> </ul> <p>We need to use <code>int.from_bytes</code> to convert a byte array into an integer which is required when creating a <code>Bits32</code> object.</p> <p>Let's go ahead and run this basic test.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut13_dw/test/FPAdd1stage_test.py -sv\n</code></pre> <p>Now we are ready to generate a Verilog test bench which we can use for four-state RTL, fast-functional gate-level, and back-annotated gate-level simulation.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut13_dw/test/FPAdd1stage_test.py --test-verilog --dump-vtb\n</code></pre> <p>Now let's push the 1-stage floating-point adder through the ASIC automated flow again. We will start by just running the first two steps and looking at the synthesis reports.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut13-fpadd-1stage\n% cd $TOPDIR/asic/build-tut13-fpadd-1stage\n% pyhflow ../designs/tut13-fpadd-1stage.yml\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n</code></pre> <p>Let's first check the resources report to confirm that Synopsys DC is indeed using the Synopsys DW component for the floating-point adder as expected.</p> <pre><code>% cd $TOPDIR/asic/build-tut13-fpadd-1stage\n% cat 02-synopsys-dc-synth/resources.rpt\n</code></pre> <p>The resources report shows how Synopsys DC ultimately ended using not just one Synopsys DW component, but many components which together implement the floating-point addition. For example, consider this part of the resources report.</p> <pre><code>===============================================================================\n| Cell      | Module     | Parameters            | Contained Operations       |\n===============================================================================\n| lt_x_1    | DW_cmp     | width=31              | lt_189                     |\n| sub_x_6   | DW01_sub   | width=8               | sub_230                    |\n| ashr_7    | DW_rightsh | A_width=26,SH_width=8 | srl_235_lsb_trim           |\n| ash_8     | DW_leftsh  | A_width=26,SH_width=8 | sll_237                    |\n| gt_x_10   | DW_cmp     | width=8               | gt_253                     |\n| ash_12    | DW_leftsh  | A_width=27,SH_width=5 | sll_264                    |\n| add_x_16  | DW01_inc   | width=23              | add_301                    |\n| U1        | DW_lzd     | a_width=27            | U1                         |\n| DP_OP_54J1| DP_OP_54J1 |                       |                            |\n| DP_OP_55J1| DP_OP_55J1 |                       |                            |\n===============================================================================\n</code></pre> <p>Here we can see that Synopsys DC is using Synopsys DW components for comparators, subtractors, shifters, incrementers, and zero detectors. The bottom two rows tell us that Synospys DC has also created some custom components by unmerging and merging Synopsys DW components. You can learn more about these custom operators later in the report.</p> <pre><code>Datapath Report for DP_OP_54J1_124_7007\n==============================================================================\n| Cell                 | Contained Operations                                |\n==============================================================================\n| DP_OP_54J1_124_7007  | add_247 add_247_2                                   |\n==============================================================================\n\n==============================================================================\n|       |      | Data     |       |                                          |\n| Var   | Type | Class    | Width | Expression                               |\n==============================================================================\n| I1    | PI   | Unsigned | 27    |                                          |\n| I2    | PI   | Unsigned | 28    |                                          |\n| I3    | PI   | Unsigned | 1     |                                          |\n| O1    | PO   | Unsigned | 28    | I1 + I2 + I3                             |\n==============================================================================\n\nDatapath Report for DP_OP_55J1_125_9206\n==============================================================================\n| Cell                 | Contained Operations                                |\n==============================================================================\n| DP_OP_55J1_125_9206  | add_304 sub_305                                     |\n==============================================================================\n\n==============================================================================\n|       |      | Data     |       |                                          |\n| Var   | Type | Class    | Width | Expression                               |\n==============================================================================\n| I1    | PI   | Unsigned | 8     |                                          |\n| I2    | PI   | Unsigned | 5     |                                          |\n| O1    | PO   | Unsigned | 9     | I1 + $unsigned(1'b1)                     |\n| O2    | PO   | Signed   | 10    | O1 - I2                                  |\n==============================================================================\n</code></pre> <p>The <code>DP_OP_54J1</code> custom component implements a three input adder which adds a 27-bit, 28-bit, and 1-bit input to produce a 28-bit output. The <code>DP_OP_55J1</code> custom component implements a kind of addition/subtraction operation.</p> <p>Now let's check the timing report.</p> <pre><code>% cd $TOPDIR/asic/build-tut13-fpadd-1stage\n% cat 02-synopsys-dc-synth/timing.rpt\n</code></pre> <p>The timing report should look similar to what is shown below.</p> <pre><code>  Startpoint: v/in1_reg_reg[7]\n              (rising edge-triggered flip-flop clocked by ideal_clock1)\n  Endpoint: out[20] (output port clocked by ideal_clock1)\n  Path Group: ideal_clock1\n  Path Type: max\n\n  Des/Clust/Port     Wire Load Model       Library\n  ------------------------------------------------\n  FPAdd1stage_noparam\n                     5K_hvratio_1_1        NangateOpenCellLibrary\n\n  Point                        Fanout      Incr       Path\n  -----------------------------------------------------------\n  clock ideal_clock1 (rise edge)         0.0000     0.0000\n  clock network delay (ideal)            0.0000     0.0000\n  v/in1_X0_reg[7]/CK (DFF_X1)            0.0000     0.0000 r\n  v/in1_X0_reg[7]/Q (DFF_X1)             0.0790     0.0790 f\n  v/in1_reg[7] (net)             1       0.0000     0.0790 f\n  v/U44/ZN (OR2_X2)                      0.0525     0.1315 f\n  v/n246 (net)                   2       0.0000     0.1315 f\n  v/U493/ZN (OAI211_X1)                  0.0368     0.1683 r\n  ...\n  v/U442/ZN (XNOR2_X1)                   0.0528     2.8226 f\n  v/n213 (net)                   1       0.0000     2.8226 f\n  v/U474/ZN (NOR2_X1)                    0.0359     2.8584 r\n  v/n1483 (net)                  1       0.0000     2.8584 r\n  v/U39/ZN (OR2_X2)                      0.0452     2.9036 r\n  v/out[20] (net)                1       0.0000     2.9036 r\n  v/out[20] (tut13_dw_FPAdd1stage)       0.0000     2.9036 r\n  out[20] (net)                          0.0000     2.9036 r\n  out[20] (out)                          0.0456     2.9492 r\n  data arrival time                                 2.9492\n\n  clock ideal_clock1 (rise edge)         3.0000     3.0000\n  clock network delay (ideal)            0.0000     3.0000\n  output external delay                 -0.0500     2.9500\n  data required time                                2.9500\n  -----------------------------------------------------------\n  data required time                                2.9500\n  data arrival time                                -2.9492\n  -----------------------------------------------------------\n  slack (MET)                                       0.0008\n</code></pre> <p>The clock period constraint was set to be 3ns. The design is able to meet this constraint with a critical path that through almost 60 logic gates.</p> <p>Let's go ahead and push the 1-stage floating-point adder through the reset of the ASIC automated flow.</p> <pre><code>% cd $TOPDIR/asic/build-tut13-fpadd-1stage\n% ./03-synopsys-vcs-ffglsim/run\n% ./04-cadence-innovus-pnr/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n% ./07-summarize-results/run\n</code></pre> <p>The final summary is shown below.</p> <pre><code> timestamp           = 2025-04-06 11:17:28\n design_name         = FPAdd1stage_noparam\n clock_period        = 3.0\n rtlsim              = 1/1 passed\n synth_setup_slack   = 0.0008 ns\n synth_num_stdcells  = 1713\n synth_area          = 1985.956 um^2\n ffglsim             = 1/1 passed\n pnr_setup_slack     = 0.2676 ns\n pnr_hold_slack      = 0.0100 ns\n pnr_clk_ins_src_lat = 0 ns\n pnr_num_stdcells    = 1760\n pnr_area            = 2005.108 um^2\n baglsim             = 1/1 passed\n</code></pre>"},{"location":"ece6745-tut13-dw/#3-synopsys-design-compiler-for-register-retiming","title":"3. Synopsys Design Compiler for Register Retiming","text":"<p>While it can be very useful to leverage Synopsys DW components, what do we do if the provided component does not meet timing? In the previous section, our floating-point adder met the 3ns clock period constraint, but what if our target constraint is 1.5ns? Normally, we would consider pipelining the floating-point adder but this is not possible since we did not implement the floating-point adder ourselves. Even if we did implement the floating-point adder pipelining complex arithmetic units can be quite tedious. To address this issue, we can use a powerful technique called register retiming where the synthesis tool will automatically move pipeline registers to try and balance the pipeline stages. If we add an extra stage of pipeline registers at the end of the floating-point adder, then the synthesis tool can push these registers into the combinational logic to reduce the critical path.</p> <p>To illustrate register retiming, we have provided a 2-stage floating-point adder in <code>FPAdd2stage.v</code>.</p> <pre><code>% cd $TOPDIR/sim/tut13_dw\n% code FPAdd2stage.v\n</code></pre> <p>This implementation is similar to the 1-stage floating-point adder except for the extra set of retiming registers shown below.</p> <pre><code>  // retiming registers\n\n  logic        val_X1;\n  logic [31:0] out_X1;\n\n  always_ff @(posedge clk) begin\n    if ( reset )\n      val_X1 &lt;= 1'b0;\n    else\n      val_X1 &lt;= val_X0;\n\n    out_X1 &lt;= out_X0;\n  end\n\n  // output logic\n\n  assign out_val = val_X1;\n  assign out = out_X1 &amp; {32{val_X1}};\n</code></pre> <p>This looks strange since we are adding a set of pipeline registers after the floating-point adder. Without register retiming this would make no sense since these extra retiming registers will not actually reduce the critical path. The key idea though, is that register retiming will enable the synthesis tool to move these retiming registers into the middle of the combinational logic for the floating-point adder.</p> <p>Let's run the tests for our 2-stage floating point adder.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut13_dw/test/FPAdd2stage_test.py -sv\n</code></pre> <p>The trace output is shown in part below.</p> <pre><code>../tut13_dw/test/FPAdd1stage_test.py::test_basic\n  1r in_val=0, in0=00000000, in1=00000000, out=00000000, out_val=0\n  2r in_val=0, in0=00000000, in1=00000000, out=00000000, out_val=0\n  3: in_val=0, in0=00000000, in1=00000000, out=00000000, out_val=0\n  4: in_val=1, in0=3f800000, in1=3f800000, out=00000000, out_val=0\n  5: in_val=1, in0=3fc00000, in1=3fc00000, out=00000000, out_val=0\n  6: in_val=1, in0=3fa00000, in1=40200000, out=40000000, out_val=1\n  7: in_val=0, in0=00000000, in1=00000000, out=40400000, out_val=1\n  8: in_val=0, in0=00000000, in1=00000000, out=40700000, out_val=1\n</code></pre> <p>We can now see that a transaction takes two instead of one cycle. The first transaction goes into the floating-point adder on cycle 4 and the result is valid on cycle 6. Let's run the tests to create the Verilog test benches which we can use for four-state RTL, fast-functional gate-level, and back-annotated gate-level simulation.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut13_dw/test/FPAdd2stage_test.py --test-verilog --dump-vtb\n</code></pre> <p>Now let's push the 2-stage floating-point adder through the first two steps of the ASIC automated flow and look at the synthesis timing reports.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut13-fpadd-2stage\n% cd $TOPDIR/asic/build-tut13-fpadd-2stage\n% pyhflow ../designs/tut13-fpadd-2stage.yml\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% cat ./02-synopsys-dc-synth/timing.rpt\n</code></pre> <p>The timing report should look similar to what is shown below.</p> <pre><code>  Startpoint: v/in1_X0_reg[0]\n              (rising edge-triggered flip-flop clocked by ideal_clock1)\n  Endpoint: v/out_X1_reg[22]\n            (rising edge-triggered flip-flop clocked by ideal_clock1)\n  Path Group: ideal_clock1\n  Path Type: max\n\n  Des/Clust/Port     Wire Load Model       Library\n  ------------------------------------------------\n  FPAdd2stage_noparam\n                     5K_hvratio_1_1        NangateOpenCellLibrary\n\n  Point                                       Fanout      Incr       Path\n  --------------------------------------------------------------------------\n  clock ideal_clock1 (rise edge)                        0.0000     0.0000\n  clock network delay (ideal)                           0.0000     0.0000\n  v/in1_X0_reg[0]/CK (DFF_X1)                           0.0000     0.0000 r\n  v/in1_X0_reg[0]/Q (DFF_X1)                            0.0929     0.0929 r\n  v/in1_X0[0] (net)                             4       0.0000     0.0929 r\n  v/U318/ZN (AND2_X1)                                   0.0445     0.1373 r\n  v/n217 (net)                                  1       0.0000     0.1373 r\n  v/U580/ZN (NAND2_X1)                                  0.0246     0.1619 f\n  ...\n  v/U368/ZN (AND3_X2)                                   0.0677     2.3291 f\n  v/n2090 (net)                                11       0.0000     2.3291 f\n  v/U2004/ZN (NAND2_X1)                                 0.0377     2.3667 r\n  v/n1854 (net)                                 1       0.0000     2.3667 r\n  v/U2005/ZN (NAND2_X1)                                 0.0254     2.3922 f\n  v/n2221 (net)                                 1       0.0000     2.3922 f\n  v/out_X1_reg[22]/D (DFF_X1)                           0.0086     2.4007 f\n  data arrival time                                                2.4007\n\n  clock ideal_clock1 (rise edge)                        1.5000     1.5000\n  clock network delay (ideal)                           0.0000     1.5000\n  v/out_X1_reg[22]/CK (DFF_X1)                          0.0000     1.5000 r\n  library setup time                                   -0.0395     1.4605\n  data required time                                               1.4605\n  --------------------------------------------------------------------------\n  data required time                                               1.4605\n  data arrival time                                               -2.4007\n  --------------------------------------------------------------------------\n  slack (VIOLATED)                                                -0.9402\n</code></pre> <p>Since we are using a 2-stage floating-point adder we reduced the clock period constraint to 1.5ns but we are not able to meet timing. This is because even though we added a set of retiming registers, we have not actually enabled retiming so the critical path will still be through the entire floating-point adder. The tools try hard but missing timing with a negative slack of 940ps.</p> <p>We need to use the <code>set_optimize_registers</code> command in the TCL script for Synospys DC to enable register retiming for specific modules in our design. The command would look like this:</p> <pre><code>set_optimize_registers true \\\n  -check_design -verbose -print_critical_loop \\\n  -design FPAdd2stage_noparam \\\n  -clock ideal_clock1 \\\n  -delay_threshold 1.5\n</code></pre> <p>We have support for register retiming in the ASIC automated flow. You can see it in the synthesis step template.</p> <pre><code>% cd $TOPDIR/asic/steps/02-synopsys-dc-synth\n% code run.tcl\n</code></pre> <p>Search through the TCL file to find the part related to register retiming which should be similar to what is shown below.</p> <pre><code>{% for module in retiming | default([]) -%}\nset_optimize_registers true \\\n  -design {{module}}  \\\n  -check_design -verbose -print_critical_loop \\\n  -clock ideal_clock1 -delay_threshold {{clock_period}}\n{% endfor %}\n</code></pre> <p>The <code>retime</code> variable in the YAML design file is used to specify a list of module names that should be retimed. Modify the <code>tut13-fpadd-2stage.yml</code> using VS Code.</p> <pre><code>% cd $TOPDIR/asic/designs/tut13-fpadd-2stage.yml\n% code run.tcl\n</code></pre> <p>Add the following to indicate that the <code>FPAdd2stage_noparam</code> module should be retimed.</p> <pre><code>retiming:\n  - FPAdd2stage_noparam\n</code></pre> <p>Now rerun pyhflow and verify the run scripts for synthesis now include the <code>set_optimize_registers</code> command.</p> <pre><code>% cd $TOPDIR/asic/build-tut13-fpadd-2stage\n% pyhflow ../designs/tut13-fpadd-2stage.yml\n% less ./02-synopsys-dc-synth/run.tcl\n</code></pre> <p>Assuming everything looks good, let's rerun synthesis and look at the timing report again.</p> <pre><code>% cd $TOPDIR/asic/build-tut13-fpadd-2stage\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% cat ./02-synopsys-dc-synth/timing.rpt\n</code></pre> <p>The timing report should look similar to what is shown below.</p> <pre><code>  Startpoint: v/ideal_clock1_r_REG58_S1\n              (rising edge-triggered flip-flop clocked by ideal_clock1)\n  Endpoint: v/ideal_clock1_r_REG13_S2\n            (rising edge-triggered flip-flop clocked by ideal_clock1)\n  Path Group: ideal_clock1\n  Path Type: max\n\n  Des/Clust/Port     Wire Load Model       Library\n  ------------------------------------------------\n  FPAdd2stage_noparam\n                     5K_hvratio_1_1        NangateOpenCellLibrary\n\n  Point                                       Fanout      Incr       Path\n  --------------------------------------------------------------------------\n  clock ideal_clock1 (rise edge)                        0.0000     0.0000\n  clock network delay (ideal)                           0.0000     0.0000\n  v/ideal_clock1_r_REG58_S1/CK (DFF_X1)                 0.0000     0.0000 r\n  v/ideal_clock1_r_REG58_S1/Q (DFF_X1)                  0.0803     0.0803 f\n  v/n1594 (net)                                 2       0.0000     0.0803 f\n  v/U14/ZN (OR2_X1)                                     0.0691     0.1494 f\n  v/n34 (net)                                   4       0.0000     0.1494 f\n  v/U57/ZN (NOR2_X1)                                    0.0900     0.2395 r\n  ...\n  v/U943/ZN (AND3_X1)                                   0.0366     1.3132 f\n  v/n774 (net)                                  1       0.0000     1.3132 f\n  v/U944/ZN (AND2_X1)                                   0.0373     1.3505 f\n  v/n776 (net)                                  1       0.0000     1.3505 f\n  v/U945/ZN (NOR4_X1)                                   0.0863     1.4368 r\n  v/n1692 (net)                                 1       0.0000     1.4368 r\n  v/ideal_clock1_r_REG13_S2/D (DFF_X1)                  0.0090     1.4458 r\n  data arrival time                                                1.4458\n\n  clock ideal_clock1 (rise edge)                        1.5000     1.5000\n  clock network delay (ideal)                           0.0000     1.5000\n  v/ideal_clock1_r_REG13_S2/CK (DFF_X1)                 0.0000     1.5000 r\n  library setup time                                   -0.0400     1.4600\n  data required time                                               1.4600\n  --------------------------------------------------------------------------\n  data required time                                               1.4600\n  data arrival time                                               -1.4458\n  --------------------------------------------------------------------------\n  slack (MET)                                                      0.0142\n</code></pre> <p>We are now able to meet timing. The synthesis tool has retimed both the input and output registers which is why the critical path starts and ends at registers with new names.</p> <p>Let's go ahead and push the 2-stage floating-point adder through the reset of the ASIC automated flow.</p> <pre><code>% cd $TOPDIR/asic/build-tut13-fpadd-2stage\n% ./03-synopsys-vcs-ffglsim/run\n% ./04-cadence-innovus-pnr/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n% ./07-summarize-results/run\n</code></pre> <p>The final summary is shown below.</p> <pre><code> timestamp           = 2025-04-06 11:57:03\n design_name         = FPAdd2stage_noparam\n clock_period        = 1.5\n rtlsim              = 1/1 passed\n synth_setup_slack   = 0.0142 ns\n synth_num_stdcells  = 1759\n synth_area          = 2272.970 um^2\n ffglsim             = 1/1 passed\n pnr_setup_slack     = 0.2948 ns\n pnr_hold_slack      = 0.0108 ns\n pnr_clk_ins_src_lat = 0 ns\n pnr_num_stdcells    = 1851\n pnr_area            = 2372.454 um^2\n baglsim             = 1/1 passed\n</code></pre> <p>Compare these results to the results for the 1-stage floating-point adder. The 1-stage design met timing at 3ns, while the 2-stage design is able to meet timing at 1.5ns. The trade-off is area. The 2-stage design requires 2372um^2 while the 1-stage design only required 2005um^2 (18% increase). The energy for the 2-stage design would also likely be higher.</p>"}]}